{
  "indexBuiltAt": "2015-10-05T14:09:56.319Z",
  "packages": {
    "python": {
      "2": {
        "name": "2",
        "command": "pip install '2'"
      },
      "5": {
        "name": "5",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/5",
        "summary": "a test mod",
        "command": "pip install '5'"
      },
      "11": {
        "name": "11",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/11",
        "summary": "A simple printer of nested lists",
        "command": "pip install '11'"
      },
      "42": {
        "name": "42",
        "description": "",
        "url": "http://pypi.python.org/pypi/42",
        "summary": "",
        "command": "pip install '42'"
      },
      "1337": {
        "name": "1337",
        "description": "Run\n\n::\n\n    $ 1337\n\n...to be 1337.",
        "url": "http://pypi.python.org/pypi/1337",
        "summary": "This is so 1337!",
        "command": "pip install '1337'"
      },
      "2112": {
        "name": "2112",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/2112",
        "summary": "Shows 2112' starman on terminal.",
        "command": "pip install '2112'"
      },
      "_license": {
        "name": "_license",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y _license"
      },
      "abstract-rendering": {
        "name": "abstract-rendering",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y abstract-rendering"
      },
      "accelerate": {
        "name": "accelerate",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y accelerate"
      },
      "anaconda": {
        "name": "anaconda",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y anaconda"
      },
      "anaconda-build": {
        "name": "anaconda-build",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y anaconda-build"
      },
      "anaconda-client": {
        "name": "anaconda-client",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y anaconda-client"
      },
      "ansi2html": {
        "name": "ansi2html",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ansi2html"
      },
      "apptools": {
        "name": "apptools",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y apptools"
      },
      "argcomplete": {
        "name": "argcomplete",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y argcomplete"
      },
      "argparse": {
        "name": "argparse",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y argparse"
      },
      "arraymanagement": {
        "name": "arraymanagement",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y arraymanagement"
      },
      "astroid": {
        "name": "astroid",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y astroid"
      },
      "astropy": {
        "name": "astropy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y astropy"
      },
      "aterm": {
        "name": "aterm",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y aterm"
      },
      "atlas": {
        "name": "atlas",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y atlas"
      },
      "atom": {
        "name": "atom",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y atom"
      },
      "azure": {
        "name": "azure",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y azure"
      },
      "babel": {
        "name": "babel",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y babel"
      },
      "bandersnatch": {
        "name": "bandersnatch",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y bandersnatch"
      },
      "basemap": {
        "name": "basemap",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y basemap"
      },
      "bcolz": {
        "name": "bcolz",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y bcolz"
      },
      "beautiful-soup": {
        "name": "beautiful-soup",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y beautiful-soup"
      },
      "beautifulsoup4": {
        "name": "beautifulsoup4",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y beautifulsoup4"
      },
      "binstar": {
        "name": "binstar",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y binstar"
      },
      "binstar-build": {
        "name": "binstar-build",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y binstar-build"
      },
      "biopython": {
        "name": "biopython",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y biopython"
      },
      "bitarray": {
        "name": "bitarray",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y bitarray"
      },
      "bitey": {
        "name": "bitey",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y bitey"
      },
      "blaze": {
        "name": "blaze",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y blaze"
      },
      "blaze-core": {
        "name": "blaze-core",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y blaze-core"
      },
      "blist": {
        "name": "blist",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y blist"
      },
      "blockspring": {
        "name": "blockspring",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y blockspring"
      },
      "blosc": {
        "name": "blosc",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y blosc"
      },
      "blz": {
        "name": "blz",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y blz"
      },
      "bokeh": {
        "name": "bokeh",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y bokeh"
      },
      "boost": {
        "name": "boost",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y boost"
      },
      "boto": {
        "name": "boto",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y boto"
      },
      "bottleneck": {
        "name": "bottleneck",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y bottleneck"
      },
      "bsddb": {
        "name": "bsddb",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y bsddb"
      },
      "bsdiff4": {
        "name": "bsdiff4",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y bsdiff4"
      },
      "btrees": {
        "name": "btrees",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y btrees"
      },
      "bz2file": {
        "name": "bz2file",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y bz2file"
      },
      "bzip2": {
        "name": "bzip2",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y bzip2"
      },
      "cachecontrol": {
        "name": "cachecontrol",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cachecontrol"
      },
      "cairo": {
        "name": "cairo",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cairo"
      },
      "casuarius": {
        "name": "casuarius",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y casuarius"
      },
      "cdecimal": {
        "name": "cdecimal",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cdecimal"
      },
      "certifi": {
        "name": "certifi",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y certifi"
      },
      "cffi": {
        "name": "cffi",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cffi"
      },
      "chaco": {
        "name": "chaco",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y chaco"
      },
      "chalmers": {
        "name": "chalmers",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y chalmers"
      },
      "chameleon": {
        "name": "chameleon",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y chameleon"
      },
      "cheetah": {
        "name": "cheetah",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cheetah"
      },
      "cherrypy": {
        "name": "cherrypy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cherrypy"
      },
      "chest": {
        "name": "chest",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y chest"
      },
      "chrpath": {
        "name": "chrpath",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y chrpath"
      },
      "clawpack": {
        "name": "clawpack",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y clawpack"
      },
      "click": {
        "name": "click",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y click"
      },
      "cligj": {
        "name": "cligj",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cligj"
      },
      "cloog": {
        "name": "cloog",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cloog"
      },
      "cloudpickle": {
        "name": "cloudpickle",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cloudpickle"
      },
      "clyent": {
        "name": "clyent",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y clyent"
      },
      "cmake": {
        "name": "cmake",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cmake"
      },
      "coffee-grunt": {
        "name": "coffee-grunt",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y coffee-grunt"
      },
      "colorama": {
        "name": "colorama",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y colorama"
      },
      "conda": {
        "name": "conda",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y conda"
      },
      "conda-api": {
        "name": "conda-api",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y conda-api"
      },
      "conda-build": {
        "name": "conda-build",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y conda-build"
      },
      "conda-env": {
        "name": "conda-env",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y conda-env"
      },
      "conda-server": {
        "name": "conda-server",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y conda-server"
      },
      "configobj": {
        "name": "configobj",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y configobj"
      },
      "contextlib2": {
        "name": "contextlib2",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y contextlib2"
      },
      "coverage": {
        "name": "coverage",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y coverage"
      },
      "cryptacular": {
        "name": "cryptacular",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cryptacular"
      },
      "cryptography": {
        "name": "cryptography",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cryptography"
      },
      "cssselect": {
        "name": "cssselect",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cssselect"
      },
      "csvkit": {
        "name": "csvkit",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y csvkit"
      },
      "cubes": {
        "name": "cubes",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cubes"
      },
      "cudatoolkit": {
        "name": "cudatoolkit",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cudatoolkit"
      },
      "curl": {
        "name": "curl",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y curl"
      },
      "cvxopt": {
        "name": "cvxopt",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cvxopt"
      },
      "cx_oracle": {
        "name": "cx_oracle",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cx_oracle"
      },
      "cymem": {
        "name": "cymem",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cymem"
      },
      "cython": {
        "name": "cython",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cython"
      },
      "cytoolz": {
        "name": "cytoolz",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y cytoolz"
      },
      "dask": {
        "name": "dask",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y dask"
      },
      "datashape": {
        "name": "datashape",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y datashape"
      },
      "dateutil": {
        "name": "dateutil",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y dateutil"
      },
      "datrie": {
        "name": "datrie",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y datrie"
      },
      "db": {
        "name": "db",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y db"
      },
      "dbf": {
        "name": "dbf",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y dbf"
      },
      "debug": {
        "name": "debug",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y debug"
      },
      "decorator": {
        "name": "decorator",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y decorator"
      },
      "dill": {
        "name": "dill",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y dill"
      },
      "disco": {
        "name": "disco",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y disco"
      },
      "distribute": {
        "name": "distribute",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y distribute"
      },
      "django": {
        "name": "django",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y django"
      },
      "dnspython": {
        "name": "dnspython",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y dnspython"
      },
      "docopt": {
        "name": "docopt",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y docopt"
      },
      "docutils": {
        "name": "docutils",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y docutils"
      },
      "drmaa": {
        "name": "drmaa",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y drmaa"
      },
      "dropbox": {
        "name": "dropbox",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y dropbox"
      },
      "dynd-python": {
        "name": "dynd-python",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y dynd-python"
      },
      "ecdsa": {
        "name": "ecdsa",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ecdsa"
      },
      "enable": {
        "name": "enable",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y enable"
      },
      "enaml": {
        "name": "enaml",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y enaml"
      },
      "enum34": {
        "name": "enum34",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y enum34"
      },
      "envisage": {
        "name": "envisage",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y envisage"
      },
      "ephem": {
        "name": "ephem",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ephem"
      },
      "erlang": {
        "name": "erlang",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y erlang"
      },
      "essbasepy": {
        "name": "essbasepy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y essbasepy"
      },
      "execnet": {
        "name": "execnet",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y execnet"
      },
      "fabric": {
        "name": "fabric",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y fabric"
      },
      "fastcache": {
        "name": "fastcache",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y fastcache"
      },
      "faulthandler": {
        "name": "faulthandler",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y faulthandler"
      },
      "feedparser": {
        "name": "feedparser",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y feedparser"
      },
      "fiona": {
        "name": "fiona",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y fiona"
      },
      "flake8": {
        "name": "flake8",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y flake8"
      },
      "flask": {
        "name": "flask",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y flask"
      },
      "flask-ldap-login": {
        "name": "flask-ldap-login",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y flask-ldap-login"
      },
      "flask-login": {
        "name": "flask-login",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y flask-login"
      },
      "flask-wtf": {
        "name": "flask-wtf",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y flask-wtf"
      },
      "fontconfig": {
        "name": "fontconfig",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y fontconfig"
      },
      "freeglut": {
        "name": "freeglut",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y freeglut"
      },
      "freetype": {
        "name": "freetype",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y freetype"
      },
      "funcsigs": {
        "name": "funcsigs",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y funcsigs"
      },
      "future": {
        "name": "future",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y future"
      },
      "futures": {
        "name": "futures",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y futures"
      },
      "gcc": {
        "name": "gcc",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y gcc"
      },
      "gdal": {
        "name": "gdal",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y gdal"
      },
      "gdata": {
        "name": "gdata",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y gdata"
      },
      "gdbm": {
        "name": "gdbm",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y gdbm"
      },
      "gensim": {
        "name": "gensim",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y gensim"
      },
      "geos": {
        "name": "geos",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y geos"
      },
      "gevent": {
        "name": "gevent",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y gevent"
      },
      "gevent-websocket": {
        "name": "gevent-websocket",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y gevent-websocket"
      },
      "gevent_zeromq": {
        "name": "gevent_zeromq",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y gevent_zeromq"
      },
      "glueviz": {
        "name": "glueviz",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y glueviz"
      },
      "gmp": {
        "name": "gmp",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y gmp"
      },
      "google-apputils": {
        "name": "google-apputils",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y google-apputils"
      },
      "googlecl": {
        "name": "googlecl",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y googlecl"
      },
      "graphite-web": {
        "name": "graphite-web",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y graphite-web"
      },
      "graphviz": {
        "name": "graphviz",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y graphviz"
      },
      "greenlet": {
        "name": "greenlet",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y greenlet"
      },
      "gridmap": {
        "name": "gridmap",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y gridmap"
      },
      "grin": {
        "name": "grin",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y grin"
      },
      "gunicorn": {
        "name": "gunicorn",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y gunicorn"
      },
      "h5py": {
        "name": "h5py",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y h5py"
      },
      "hdf5": {
        "name": "hdf5",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y hdf5"
      },
      "headers_workaround": {
        "name": "headers_workaround",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y headers_workaround"
      },
      "heapdict": {
        "name": "heapdict",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y heapdict"
      },
      "holoviews": {
        "name": "holoviews",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y holoviews"
      },
      "html5lib": {
        "name": "html5lib",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y html5lib"
      },
      "hyde": {
        "name": "hyde",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y hyde"
      },
      "icu": {
        "name": "icu",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y icu"
      },
      "idna": {
        "name": "idna",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y idna"
      },
      "imaging": {
        "name": "imaging",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y imaging"
      },
      "into": {
        "name": "into",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y into"
      },
      "iopro": {
        "name": "iopro",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y iopro"
      },
      "ipaddress": {
        "name": "ipaddress",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ipaddress"
      },
      "ipykernel": {
        "name": "ipykernel",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ipykernel"
      },
      "ipyparallel": {
        "name": "ipyparallel",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ipyparallel"
      },
      "ipython": {
        "name": "ipython",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ipython"
      },
      "ipython-notebook": {
        "name": "ipython-notebook",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ipython-notebook"
      },
      "ipython-qtconsole": {
        "name": "ipython-qtconsole",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ipython-qtconsole"
      },
      "ipython_genutils": {
        "name": "ipython_genutils",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ipython_genutils"
      },
      "ipywidgets": {
        "name": "ipywidgets",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ipywidgets"
      },
      "isl": {
        "name": "isl",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y isl"
      },
      "itsdangerous": {
        "name": "itsdangerous",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y itsdangerous"
      },
      "jdcal": {
        "name": "jdcal",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y jdcal"
      },
      "jedi": {
        "name": "jedi",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y jedi"
      },
      "jinja2": {
        "name": "jinja2",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y jinja2"
      },
      "joblib": {
        "name": "joblib",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y joblib"
      },
      "jpeg": {
        "name": "jpeg",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y jpeg"
      },
      "jsonschema": {
        "name": "jsonschema",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y jsonschema"
      },
      "jupyter": {
        "name": "jupyter",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y jupyter"
      },
      "jupyter_client": {
        "name": "jupyter_client",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y jupyter_client"
      },
      "jupyter_console": {
        "name": "jupyter_console",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y jupyter_console"
      },
      "jupyter_core": {
        "name": "jupyter_core",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y jupyter_core"
      },
      "keyring": {
        "name": "keyring",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y keyring"
      },
      "kiwisolver": {
        "name": "kiwisolver",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y kiwisolver"
      },
      "krb5": {
        "name": "krb5",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y krb5"
      },
      "lancet": {
        "name": "lancet",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y lancet"
      },
      "lancet-ioam": {
        "name": "lancet-ioam",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y lancet-ioam"
      },
      "launcher": {
        "name": "launcher",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y launcher"
      },
      "lcms": {
        "name": "lcms",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y lcms"
      },
      "ldap3": {
        "name": "ldap3",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ldap3"
      },
      "libconda": {
        "name": "libconda",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libconda"
      },
      "libdynd": {
        "name": "libdynd",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libdynd"
      },
      "libevent": {
        "name": "libevent",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libevent"
      },
      "libffi": {
        "name": "libffi",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libffi"
      },
      "libgcc": {
        "name": "libgcc",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libgcc"
      },
      "libgdal": {
        "name": "libgdal",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libgdal"
      },
      "libgfortran": {
        "name": "libgfortran",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libgfortran"
      },
      "libnetcdf": {
        "name": "libnetcdf",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libnetcdf"
      },
      "libnvvm": {
        "name": "libnvvm",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libnvvm"
      },
      "libpng": {
        "name": "libpng",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libpng"
      },
      "libsodium": {
        "name": "libsodium",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libsodium"
      },
      "libtiff": {
        "name": "libtiff",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libtiff"
      },
      "libxml2": {
        "name": "libxml2",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libxml2"
      },
      "libxslt": {
        "name": "libxslt",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y libxslt"
      },
      "lighttpd": {
        "name": "lighttpd",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y lighttpd"
      },
      "line_profiler": {
        "name": "line_profiler",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y line_profiler"
      },
      "llvm": {
        "name": "llvm",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y llvm"
      },
      "llvmlite": {
        "name": "llvmlite",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y llvmlite"
      },
      "llvmmath": {
        "name": "llvmmath",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y llvmmath"
      },
      "llvmpy": {
        "name": "llvmpy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y llvmpy"
      },
      "locket": {
        "name": "locket",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y locket"
      },
      "lockfile": {
        "name": "lockfile",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y lockfile"
      },
      "logilab-common": {
        "name": "logilab-common",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y logilab-common"
      },
      "lxml": {
        "name": "lxml",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y lxml"
      },
      "lzo": {
        "name": "lzo",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y lzo"
      },
      "mako": {
        "name": "mako",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mako"
      },
      "markdown": {
        "name": "markdown",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y markdown"
      },
      "markdown2": {
        "name": "markdown2",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y markdown2"
      },
      "markupsafe": {
        "name": "markupsafe",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y markupsafe"
      },
      "mathjax": {
        "name": "mathjax",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mathjax"
      },
      "matplotlib": {
        "name": "matplotlib",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y matplotlib"
      },
      "mayavi": {
        "name": "mayavi",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mayavi"
      },
      "mccabe": {
        "name": "mccabe",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mccabe"
      },
      "mdp": {
        "name": "mdp",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mdp"
      },
      "meld3": {
        "name": "meld3",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y meld3"
      },
      "mercurial": {
        "name": "mercurial",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mercurial"
      },
      "mesa": {
        "name": "mesa",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mesa"
      },
      "meta": {
        "name": "meta",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y meta"
      },
      "mistune": {
        "name": "mistune",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mistune"
      },
      "mkl": {
        "name": "mkl",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mkl"
      },
      "mkl-rt": {
        "name": "mkl-rt",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mkl-rt"
      },
      "mkl-service": {
        "name": "mkl-service",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mkl-service"
      },
      "mklfft": {
        "name": "mklfft",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mklfft"
      },
      "mock": {
        "name": "mock",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mock"
      },
      "mongo-driver": {
        "name": "mongo-driver",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mongo-driver"
      },
      "mongodb": {
        "name": "mongodb",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mongodb"
      },
      "mpc": {
        "name": "mpc",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mpc"
      },
      "mpfr": {
        "name": "mpfr",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mpfr"
      },
      "mpi4py": {
        "name": "mpi4py",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mpi4py"
      },
      "mpich2": {
        "name": "mpich2",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mpich2"
      },
      "mpmath": {
        "name": "mpmath",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mpmath"
      },
      "msgpack": {
        "name": "msgpack",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y msgpack"
      },
      "msgpack-python": {
        "name": "msgpack-python",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y msgpack-python"
      },
      "mtq": {
        "name": "mtq",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mtq"
      },
      "multimethods": {
        "name": "multimethods",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y multimethods"
      },
      "multipledispatch": {
        "name": "multipledispatch",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y multipledispatch"
      },
      "murmurhash": {
        "name": "murmurhash",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y murmurhash"
      },
      "mysql": {
        "name": "mysql",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mysql"
      },
      "mysql-connector-python": {
        "name": "mysql-connector-python",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mysql-connector-python"
      },
      "mysql-python": {
        "name": "mysql-python",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y mysql-python"
      },
      "nano": {
        "name": "nano",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y nano"
      },
      "natsort": {
        "name": "natsort",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y natsort"
      },
      "nbconvert": {
        "name": "nbconvert",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y nbconvert"
      },
      "nbformat": {
        "name": "nbformat",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y nbformat"
      },
      "ncurses": {
        "name": "ncurses",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ncurses"
      },
      "ndg-httpsclient": {
        "name": "ndg-httpsclient",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ndg-httpsclient"
      },
      "ndg_httpsclient": {
        "name": "ndg_httpsclient",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ndg_httpsclient"
      },
      "netcdf4": {
        "name": "netcdf4",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y netcdf4"
      },
      "networkx": {
        "name": "networkx",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y networkx"
      },
      "nltk": {
        "name": "nltk",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y nltk"
      },
      "node": {
        "name": "node",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y node"
      },
      "node-webkit": {
        "name": "node-webkit",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y node-webkit"
      },
      "nose": {
        "name": "nose",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y nose"
      },
      "notebook": {
        "name": "notebook",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y notebook"
      },
      "numba": {
        "name": "numba",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y numba"
      },
      "numbapro": {
        "name": "numbapro",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y numbapro"
      },
      "numbapro_cudalib": {
        "name": "numbapro_cudalib",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y numbapro_cudalib"
      },
      "numexpr": {
        "name": "numexpr",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y numexpr"
      },
      "numpy": {
        "name": "numpy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y numpy"
      },
      "numpydoc": {
        "name": "numpydoc",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y numpydoc"
      },
      "odo": {
        "name": "odo",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y odo"
      },
      "openblas": {
        "name": "openblas",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y openblas"
      },
      "opencv": {
        "name": "opencv",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y opencv"
      },
      "openldap": {
        "name": "openldap",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y openldap"
      },
      "openpyxl": {
        "name": "openpyxl",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y openpyxl"
      },
      "openssl": {
        "name": "openssl",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y openssl"
      },
      "oracle-instantclient": {
        "name": "oracle-instantclient",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y oracle-instantclient"
      },
      "orange": {
        "name": "orange",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y orange"
      },
      "ordereddict": {
        "name": "ordereddict",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ordereddict"
      },
      "pandas": {
        "name": "pandas",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pandas"
      },
      "pandasql": {
        "name": "pandasql",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pandasql"
      },
      "param": {
        "name": "param",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y param"
      },
      "paramiko": {
        "name": "paramiko",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y paramiko"
      },
      "partd": {
        "name": "partd",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y partd"
      },
      "passlib": {
        "name": "passlib",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y passlib"
      },
      "paste": {
        "name": "paste",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y paste"
      },
      "pastedeploy": {
        "name": "pastedeploy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pastedeploy"
      },
      "patchelf": {
        "name": "patchelf",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y patchelf"
      },
      "path.py": {
        "name": "path.py",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y path.py"
      },
      "patsy": {
        "name": "patsy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y patsy"
      },
      "pbkdf2": {
        "name": "pbkdf2",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pbkdf2"
      },
      "pbr": {
        "name": "pbr",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pbr"
      },
      "pcre": {
        "name": "pcre",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pcre"
      },
      "pep381client": {
        "name": "pep381client",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pep381client"
      },
      "pep8": {
        "name": "pep8",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pep8"
      },
      "persistent": {
        "name": "persistent",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y persistent"
      },
      "pexpect": {
        "name": "pexpect",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pexpect"
      },
      "pickleshare": {
        "name": "pickleshare",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pickleshare"
      },
      "pigz": {
        "name": "pigz",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pigz"
      },
      "pil": {
        "name": "pil",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pil"
      },
      "pillow": {
        "name": "pillow",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pillow"
      },
      "pip": {
        "name": "pip",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pip"
      },
      "pixman": {
        "name": "pixman",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pixman"
      },
      "pkgconfig": {
        "name": "pkgconfig",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pkgconfig"
      },
      "plac": {
        "name": "plac",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y plac"
      },
      "ply": {
        "name": "ply",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ply"
      },
      "portaudio": {
        "name": "portaudio",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y portaudio"
      },
      "postgresql": {
        "name": "postgresql",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y postgresql"
      },
      "preshed": {
        "name": "preshed",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y preshed"
      },
      "progressbar": {
        "name": "progressbar",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y progressbar"
      },
      "proj.4": {
        "name": "proj.4",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y proj.4"
      },
      "protobuf": {
        "name": "protobuf",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y protobuf"
      },
      "psqlodbc": {
        "name": "psqlodbc",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y psqlodbc"
      },
      "psutil": {
        "name": "psutil",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y psutil"
      },
      "psycopg2": {
        "name": "psycopg2",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y psycopg2"
      },
      "ptyprocess": {
        "name": "ptyprocess",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ptyprocess"
      },
      "py": {
        "name": "py",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y py"
      },
      "py2cairo": {
        "name": "py2cairo",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y py2cairo"
      },
      "pyamg": {
        "name": "pyamg",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyamg"
      },
      "pyasn1": {
        "name": "pyasn1",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyasn1"
      },
      "pyclaw": {
        "name": "pyclaw",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyclaw"
      },
      "pycosat": {
        "name": "pycosat",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pycosat"
      },
      "pycparser": {
        "name": "pycparser",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pycparser"
      },
      "pycrypto": {
        "name": "pycrypto",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pycrypto"
      },
      "pycurl": {
        "name": "pycurl",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pycurl"
      },
      "pydot": {
        "name": "pydot",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pydot"
      },
      "pydot-ng": {
        "name": "pydot-ng",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pydot-ng"
      },
      "pyface": {
        "name": "pyface",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyface"
      },
      "pyflakes": {
        "name": "pyflakes",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyflakes"
      },
      "pygments": {
        "name": "pygments",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pygments"
      },
      "pykit": {
        "name": "pykit",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pykit"
      },
      "pylint": {
        "name": "pylint",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pylint"
      },
      "pymc": {
        "name": "pymc",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pymc"
      },
      "pymongo": {
        "name": "pymongo",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pymongo"
      },
      "pymysql": {
        "name": "pymysql",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pymysql"
      },
      "pyodbc": {
        "name": "pyodbc",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyodbc"
      },
      "pyopengl": {
        "name": "pyopengl",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyopengl"
      },
      "pyopengl-accelerate": {
        "name": "pyopengl-accelerate",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyopengl-accelerate"
      },
      "pyopenssl": {
        "name": "pyopenssl",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyopenssl"
      },
      "pyparsing": {
        "name": "pyparsing",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyparsing"
      },
      "pyproj": {
        "name": "pyproj",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyproj"
      },
      "pyqt": {
        "name": "pyqt",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyqt"
      },
      "pyramid": {
        "name": "pyramid",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyramid"
      },
      "pyramid_chameleon": {
        "name": "pyramid_chameleon",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyramid_chameleon"
      },
      "pyramid_debugtoolbar": {
        "name": "pyramid_debugtoolbar",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyramid_debugtoolbar"
      },
      "pyramid_jinja2": {
        "name": "pyramid_jinja2",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyramid_jinja2"
      },
      "pyramid_mako": {
        "name": "pyramid_mako",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyramid_mako"
      },
      "pyramid_tm": {
        "name": "pyramid_tm",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyramid_tm"
      },
      "pysal": {
        "name": "pysal",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pysal"
      },
      "pysam": {
        "name": "pysam",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pysam"
      },
      "pyserial": {
        "name": "pyserial",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyserial"
      },
      "pyside": {
        "name": "pyside",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyside"
      },
      "pysnmp": {
        "name": "pysnmp",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pysnmp"
      },
      "pystan": {
        "name": "pystan",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pystan"
      },
      "pytables": {
        "name": "pytables",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pytables"
      },
      "pytest": {
        "name": "pytest",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pytest"
      },
      "pytest-cache": {
        "name": "pytest-cache",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pytest-cache"
      },
      "pytest-pep8": {
        "name": "pytest-pep8",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pytest-pep8"
      },
      "python": {
        "name": "python",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y python"
      },
      "python-dateutil": {
        "name": "python-dateutil",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y python-dateutil"
      },
      "python-gdbm": {
        "name": "python-gdbm",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y python-gdbm"
      },
      "python-gflags": {
        "name": "python-gflags",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y python-gflags"
      },
      "python-ldap": {
        "name": "python-ldap",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y python-ldap"
      },
      "python-memcached": {
        "name": "python-memcached",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y python-memcached"
      },
      "python-ntlm": {
        "name": "python-ntlm",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y python-ntlm"
      },
      "pytz": {
        "name": "pytz",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pytz"
      },
      "pywget": {
        "name": "pywget",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pywget"
      },
      "pyyaml": {
        "name": "pyyaml",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyyaml"
      },
      "pyzmq": {
        "name": "pyzmq",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y pyzmq"
      },
      "qt": {
        "name": "qt",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y qt"
      },
      "qtconsole": {
        "name": "qtconsole",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y qtconsole"
      },
      "quandl": {
        "name": "quandl",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y quandl"
      },
      "queuelib": {
        "name": "queuelib",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y queuelib"
      },
      "rasterio": {
        "name": "rasterio",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y rasterio"
      },
      "readline": {
        "name": "readline",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y readline"
      },
      "redis": {
        "name": "redis",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y redis"
      },
      "redis-py": {
        "name": "redis-py",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y redis-py"
      },
      "reportlab": {
        "name": "reportlab",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y reportlab"
      },
      "repoze.lru": {
        "name": "repoze.lru",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y repoze.lru"
      },
      "requests": {
        "name": "requests",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y requests"
      },
      "rope": {
        "name": "rope",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y rope"
      },
      "routes": {
        "name": "routes",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y routes"
      },
      "runipy": {
        "name": "runipy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y runipy"
      },
      "sas7bdat": {
        "name": "sas7bdat",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y sas7bdat"
      },
      "scikit-bio": {
        "name": "scikit-bio",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y scikit-bio"
      },
      "scikit-image": {
        "name": "scikit-image",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y scikit-image"
      },
      "scikit-learn": {
        "name": "scikit-learn",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y scikit-learn"
      },
      "scikit-rf": {
        "name": "scikit-rf",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y scikit-rf"
      },
      "scikits-image": {
        "name": "scikits-image",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y scikits-image"
      },
      "scipy": {
        "name": "scipy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y scipy"
      },
      "scons": {
        "name": "scons",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y scons"
      },
      "scrapy": {
        "name": "scrapy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y scrapy"
      },
      "seaborn": {
        "name": "seaborn",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y seaborn"
      },
      "semantic_version": {
        "name": "semantic_version",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y semantic_version"
      },
      "setuptools": {
        "name": "setuptools",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y setuptools"
      },
      "sh": {
        "name": "sh",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y sh"
      },
      "shapely": {
        "name": "shapely",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y shapely"
      },
      "shiboken": {
        "name": "shiboken",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y shiboken"
      },
      "simplegeneric": {
        "name": "simplegeneric",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y simplegeneric"
      },
      "simplejson": {
        "name": "simplejson",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y simplejson"
      },
      "singledispatch": {
        "name": "singledispatch",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y singledispatch"
      },
      "sip": {
        "name": "sip",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y sip"
      },
      "six": {
        "name": "six",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y six"
      },
      "snowballstemmer": {
        "name": "snowballstemmer",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y snowballstemmer"
      },
      "snuggs": {
        "name": "snuggs",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y snuggs"
      },
      "sockjs-tornado": {
        "name": "sockjs-tornado",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y sockjs-tornado"
      },
      "spacy": {
        "name": "spacy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y spacy"
      },
      "sphinx": {
        "name": "sphinx",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y sphinx"
      },
      "sphinx_rtd_theme": {
        "name": "sphinx_rtd_theme",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y sphinx_rtd_theme"
      },
      "spyder": {
        "name": "spyder",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y spyder"
      },
      "spyder-app": {
        "name": "spyder-app",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y spyder-app"
      },
      "sqlalchemy": {
        "name": "sqlalchemy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y sqlalchemy"
      },
      "sqlite": {
        "name": "sqlite",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y sqlite"
      },
      "sqlparse": {
        "name": "sqlparse",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y sqlparse"
      },
      "ssh": {
        "name": "ssh",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ssh"
      },
      "ssl_match_hostname": {
        "name": "ssl_match_hostname",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ssl_match_hostname"
      },
      "starcluster": {
        "name": "starcluster",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y starcluster"
      },
      "statsmodels": {
        "name": "statsmodels",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y statsmodels"
      },
      "stripe": {
        "name": "stripe",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y stripe"
      },
      "supervisor": {
        "name": "supervisor",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y supervisor"
      },
      "swig": {
        "name": "swig",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y swig"
      },
      "sympy": {
        "name": "sympy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y sympy"
      },
      "system": {
        "name": "system",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y system"
      },
      "terminado": {
        "name": "terminado",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y terminado"
      },
      "theano": {
        "name": "theano",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y theano"
      },
      "thinc": {
        "name": "thinc",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y thinc"
      },
      "tk": {
        "name": "tk",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y tk"
      },
      "toolz": {
        "name": "toolz",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y toolz"
      },
      "tornado": {
        "name": "tornado",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y tornado"
      },
      "traitlets": {
        "name": "traitlets",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y traitlets"
      },
      "traits": {
        "name": "traits",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y traits"
      },
      "traitsui": {
        "name": "traitsui",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y traitsui"
      },
      "transaction": {
        "name": "transaction",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y transaction"
      },
      "translationstring": {
        "name": "translationstring",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y translationstring"
      },
      "twisted": {
        "name": "twisted",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y twisted"
      },
      "ujson": {
        "name": "ujson",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y ujson"
      },
      "unicodecsv": {
        "name": "unicodecsv",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y unicodecsv"
      },
      "unidecode": {
        "name": "unidecode",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y unidecode"
      },
      "unittest2": {
        "name": "unittest2",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y unittest2"
      },
      "unixodbc": {
        "name": "unixodbc",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y unixodbc"
      },
      "util-linux": {
        "name": "util-linux",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y util-linux"
      },
      "uuid": {
        "name": "uuid",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y uuid"
      },
      "venusian": {
        "name": "venusian",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y venusian"
      },
      "virtualenv": {
        "name": "virtualenv",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y virtualenv"
      },
      "vispy": {
        "name": "vispy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y vispy"
      },
      "vtk": {
        "name": "vtk",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y vtk"
      },
      "w3lib": {
        "name": "w3lib",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y w3lib"
      },
      "waitress": {
        "name": "waitress",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y waitress"
      },
      "wakaridata": {
        "name": "wakaridata",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y wakaridata"
      },
      "webob": {
        "name": "webob",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y webob"
      },
      "websocket": {
        "name": "websocket",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y websocket"
      },
      "webtest": {
        "name": "webtest",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y webtest"
      },
      "werkzeug": {
        "name": "werkzeug",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y werkzeug"
      },
      "wheel": {
        "name": "wheel",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y wheel"
      },
      "whisper": {
        "name": "whisper",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y whisper"
      },
      "whoosh": {
        "name": "whoosh",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y whoosh"
      },
      "wiserf": {
        "name": "wiserf",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y wiserf"
      },
      "workerpool": {
        "name": "workerpool",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y workerpool"
      },
      "wtforms": {
        "name": "wtforms",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y wtforms"
      },
      "wxpython": {
        "name": "wxpython",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y wxpython"
      },
      "xlrd": {
        "name": "xlrd",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y xlrd"
      },
      "xlsxwriter": {
        "name": "xlsxwriter",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y xlsxwriter"
      },
      "xlutils": {
        "name": "xlutils",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y xlutils"
      },
      "xlwt": {
        "name": "xlwt",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y xlwt"
      },
      "xmlrpc2": {
        "name": "xmlrpc2",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y xmlrpc2"
      },
      "xray": {
        "name": "xray",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y xray"
      },
      "xz": {
        "name": "xz",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y xz"
      },
      "yaml": {
        "name": "yaml",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y yaml"
      },
      "yt": {
        "name": "yt",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y yt"
      },
      "zeromq": {
        "name": "zeromq",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y zeromq"
      },
      "zlib": {
        "name": "zlib",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y zlib"
      },
      "zope.deprecation": {
        "name": "zope.deprecation",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y zope.deprecation"
      },
      "zope.interface": {
        "name": "zope.interface",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y zope.interface"
      },
      "zope.sqlalchemy": {
        "name": "zope.sqlalchemy",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y zope.sqlalchemy"
      },
      "": {
        "name": "",
        "description": null,
        "url": null,
        "summary": null,
        "command": "conda install -y "
      },
      "0-._.-._.-._.-._.-._.-._.-0": {
        "name": "0-._.-._.-._.-._.-._.-._.-0",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/0-._.-._.-._.-._.-._.-._.-0",
        "summary": "UNKNOWN",
        "command": "pip install '0-._.-._.-._.-._.-._.-._.-0'"
      },
      "02exercicio": {
        "name": "02exercicio",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/02exercicio",
        "summary": "Um simples programa dee teste da função def e loop for",
        "command": "pip install '02exercicio'"
      },
      "0x10c-asm": {
        "name": "0x10c-asm",
        "description": "``0x10c-asm`` assembly compiler for Notch's DCPU-16\n---------------------------------------------------\n\nInstall from PyPI:\n==================\n\n  pip install 0x10c-asm\n\nUsage:\n======\n\n  $ 0x10c-asm.py -h\n\n  usage: ``0x10-asm.py [-h] IN [OUT]``\n\n  A simple Python-based DCPU assembly compiler\n\n  positional arguments:\n    ``IN``          file path of the file containing the assembly code\n\n    ``OUT``         file path where to store the binary code\n\n  optional arguments:\n    -h, --help  show this help message and exit",
        "url": "http://pypi.python.org/pypi/0x10c-asm",
        "summary": "A simple Python-based DCPU assembly compiler",
        "command": "pip install '0x10c-asm'"
      },
      "115wangpan": {
        "name": "115wangpan",
        "description": "115 Wangpan\n===========\n\n|Build| |PyPI version|\n\n115 Wangpan (115网盘 or 115云) is an unofficial Python API and SDK for 115.com. Supported Python verisons are 2.6, 2.7, 3.3, 3.4.\n\n* Documentation: http://115wangpan.readthedocs.org\n* GitHub: https://github.com/shichao-an/115wangpan\n* PyPI: https://pypi.python.org/pypi/115wangpan/\n\nFeatures\n--------\n\n* Authentication\n* Persistent session\n* Tasks management: BitTorrent and links\n* Files management: uploading, downloading, searching, and editing\n\nInstallation\n------------\n\n`libcurl <http://curl.haxx.se/libcurl/>`_ is required. Install dependencies before installing the python package:\n\nUbuntu:\n\n.. code-block:: bash\n\n    $ sudo apt-get install build-essential libcurl4-openssl-dev python-dev\n\nFedora:\n\n.. code-block:: bash\n\n    $ sudo yum groupinstall \"Development Tools\"\n    $ sudo yum install libcurl libcurl-devel python-devel\n\n\nThen, you can install with pip:\n\n.. code-block:: bash\n\n    $ pip install 115wangpan\n\nOr, if you want to install the latest from GitHub:\n\n.. code-block:: bash\n\n    $ pip install git+https://github.com/shichao-an/115wangpan\n\nUsage\n-----\n\n.. code-block:: python\n\n    >>> import u115\n    >>> api = u115.API()\n    >>> api.login('username@example.com', 'password')\n    True\n    >>> tasks = api.get_tasks()\n    >>> task = tasks[0]\n    >>> print task.name\n    咲-Saki- 阿知賀編 episode of side-A\n    >>> print task.status_human\n    TRANSFERRED\n    >>> print task.size_human\n    1.6 GiB\n    >>> files = task.list()\n    >>> files\n    [<File: 第8局 修行.mkv>]\n    >>> f = files[0]\n    >>> f.url\n    u'http://cdnuni.115.com/some-very-long-url.mkv'\n    >>> f.directory\n    <Directory: 咲-Saki- 阿知賀編 episode of side-A>\n    >>> f.directory.parent\n    <Directory: 离线下载>\n\n\nCLI commands \n------------\n\n* 115 down: for downloading files\n* 115 up: for creating tasks from torrents and links\n\n.. |Build| image:: https://api.travis-ci.org/shichao-an/115wangpan.png?branch=master\n   :target: http://travis-ci.org/shichao-an/115wangpan\n.. |PyPI version| image:: https://img.shields.io/pypi/v/115wangpan.png\n   :target: https://pypi.python.org/pypi/115wangpan/",
        "url": "http://pypi.python.org/pypi/115wangpan",
        "summary": "Unofficial Python API wrapper for 115.com",
        "command": "pip install '115wangpan'"
      },
      "131228_pytest_1": {
        "name": "131228_pytest_1",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/131228_pytest_1",
        "summary": "A easy printer of nested list",
        "command": "pip install '131228_pytest_1'"
      },
      "17MonIP": {
        "name": "17monip",
        "description": "17MonIP Python Lib\n==================\n\n.. image:: http://img.shields.io/pypi/v/17MonIP.svg?style=flat\n   :target: https://pypi.python.org/pypi/17MonIP\n\n.. image:: http://img.shields.io/travis/lxyu/17monip/master.svg?style=flat\n   :target: https://travis-ci.org/lxyu/17monip\n\n.. image:: http://img.shields.io/pypi/dm/17MonIP.svg?style=flat\n   :target: https://pypi.python.org/pypi/17MonIP\n\nIP search based on 17mon.cn, the best IP database for china.\n\nSource: http://tool.17mon.cn\n\n\nInstall\n-------\n\nSupports python2.6 to python3.4 and pypy.\n\n.. code:: bash\n\n    $ pip install 17monip\n\nUsage\n-----\n\n.. code:: python\n\n    >>> import IP\n    >>> IP.find(\"www.baidu.com\")\n    '中国\\t浙江\\t杭州'\n    >>> IP.find(\"127.0.0.1\")\n    '本机地址\\t本机地址'\n\n\nCMD Util\n--------\n\n.. code:: bash\n\n    $ iploc ele.me\n    中国    北京    北京\n    $ iploc aliyun.com\n    中国    浙江    杭州\n\n\nChangelog\n---------\n\nhttps://github.com/lxyu/17monip/blob/master/CHANGES.rst",
        "url": "http://pypi.python.org/pypi/17MonIP",
        "summary": "IP search based on 17mon.cn, the best IP database for China.",
        "command": "pip install '17MonIP'"
      },
      "18-e": {
        "name": "18-e",
        "description": "",
        "url": "http://pypi.python.org/pypi/18-e",
        "summary": "",
        "command": "pip install '18-e'"
      },
      "199Fix": {
        "name": "199fix",
        "description": "===============\n199Fix\n===============\n\n199Fix provides a logging handler to push exceptions and other errors to https://199fix.com/. \n\nInstallation\n============\n\nInstallation with ``pip``:\n::\n\n    $ pip install 199fix\n\n\nGet an API Key here https://199fix.com/signup/\n\nAdd ``'199fix.handlers.I99FixHandler'`` as a logging handler:\n::\n\n    LOGGING = {\n        'version': 1,\n        'disable_existing_loggers': False,\n        'filters': {\n            'require_debug_false': {\n                '()': 'django.utils.log.RequireDebugFalse'\n            }\n        },\n        'handlers': {\n            '199fix': {\n                'level': 'INFO',\n                'class': '199fix.handlers.I99FixHandler',\n                'filters': ['require_debug_false'],\n                'api_key': '[your-api-key]',\n                'env_name': 'production',\n            }\n        },\n        'loggers': {\n            'django': {\n                'handlers': ['199fix'],\n                'level': 'INFO',\n                'propagate': True,\n            },\n        }\n    }\n\nSettings\n========\n\n``level`` (built-in setting)\n    Change the ``level`` to ``'ERROR'`` to disable logging of 404 error messages.\n\n``api_key`` (required)\n    API key , Get one here https://199fix.com/.\n\n``env_name`` (required)\n    Name of the environment (e.g. production, develop, testing)\n\nContributing\n============\n* Fork the repository on GitHub and start hacking.\n* Run the tests.\n* Send a pull request with your changes.",
        "url": "http://pypi.python.org/pypi/199Fix",
        "summary": "199fix exception logger for Django",
        "command": "pip install '199Fix'"
      },
      "1ee": {
        "name": "1ee",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/1ee",
        "summary": "a simple printer of test list",
        "command": "pip install '1ee'"
      },
      "1pass": {
        "name": "1pass",
        "description": "=====\n1pass\n=====\n\nA command line interface (and Python library) for reading passwords from\n`1Password <https://agilebits.com/onepassword>`_.\n\nCommand line usage\n==================\n\nTo get a password::\n\n    1pass mail.google.com\n\nBy default this will look in ``~/Dropbox/1Password.agilekeychain``. If that's\nnot where you keep your keychain::\n\n    1pass --path ~/whatever/1Password.agilekeychain mail.google.com\n\nOr, you can set your keychain path as an enviornment variable::\n\n    export ONEPASSWORD_KEYCHAIN=/path/to/keychain\n\n    1pass mail.google.com\n\nBy default, the name you pass on the command line must match the name of an\nitem in your 1Password keychain exactly. To avoid this, fuzzy matching is\nmade possible with the ``--fuzzy`` flag::\n\n    1pass --fuzzy mail.goog\n\nIf you don't want to be prompted for your password, you can use the\n``--no-prompt`` flag and provide the password via standard input instead::\n\n    emit_master_password | 1pass --no-prompt mail.google.com\n\nPython usage\n============\n\nThe interface is very simple::\n\n    from onepassword import Keychain\n\n    my_keychain = Keychain(path=\"~/Dropbox/1Password.agilekeychain\")\n    my_keychain.unlock(\"my-master-password\")\n    my_keychain.item(\"An item's name\").password\n\nAn example of real-world use\n============================\n\nI wrote this so I could add the following line to my ``.muttrc`` file::\n\n    set imap_pass = \"`1pass 'Google: personal'`\"\n\nNow, whenever I start ``mutt``, I am prompted for my 1Password Master Password\nand not my Gmail password.\n\nThe ``--no-prompt`` flag is very useful when configuring ``mutt`` and PGP.\n``mutt`` passes the PGP passphrase via standard in, so by inserting ``1pass``\ninto this pipline I can use my 1Password master password when prompted for my\nPGP keyphrase::\n\n    set pgp_decrypt_command=\"1pass --no-prompt pgp-passphrase | gpg --passphrase-fd 0 ...\"\n\nContributors\n============\n\n* Pip Taylor <https://github.com/pipt>\n* Adam Coddington <https://github.com/latestrevision>\n* Ash Berlin <https://github.com/ashb>\n* Zach Allaun <https://github.com/zachallaun>\n* Eric Mika <https://github.com/kitschpatrol>\n\nLicense\n=======\n\n*1pass* is licensed under the MIT license. See the license file for details.\n\nWhile it is designed to read ``.agilekeychain`` bundles created by 1Password,\n*1pass* isn't officially sanctioned or supported by\n`AgileBits <https://agilebits.com/>`_. I do hope they like it though.",
        "url": "http://pypi.python.org/pypi/1pass",
        "summary": "A Python library and command line interface for 1Password",
        "command": "pip install '1pass'"
      },
      "1to001": {
        "name": "1to001",
        "description": "======\n1to001\n======\n\n*1to001* is made for padding numbers in filenames automatically. It's written in Python 3.\n\n\nInstallation\n============\n\nSystem-wide installation:\n\n.. code:: sh\n\n  $ pip install 1to001\n\nUser installation:\n\n.. code:: sh\n\n  $ pip install --user 1to001\n\nFor development code:\n\n.. code:: sh\n\n  $ pip install git+https://github.com/livibetter/1to100.git\n\n\nExample\n=======\n\n.. code:: sh\n\n  $ touch 1.txt 100.txt\n  $ 1to001 *.txt\n  + 001.txt\n  ? ++\n  perform padding (y/n)? y\n  1.txt -> 001.txt\n\n\nOptions\n=======\n\n``-i`` (``--ignore-case``)\n  When cases are mixed, this option would ignore the cases, for example for files like::\n\n    read100me1.TXT\n    read5Me02.txt\n\n  They can be renamed to::\n\n    1to001 -i *.{txt,TXT}\n    + read005Me02.txt\n    ?     ++\n    + read100me01.TXT\n    ?          +\n    perform padding (y/n)?\n\n``-y`` (``--yes``)\n  Automatic yes to prompts\n\n\nMore information\n================\n\n* 1to001_ on GitHub\n* PyPI_\n* Some usage examples in this `blog post`_\n\n.. _1to001: https://github.com/livibetter/1to001\n.. _PyPI: https://pypi.python.org/pypi/1to001\n.. _blog post: http://blog.yjl.im/2013/07/padding-numbers-in-filenames.html\n\n\nLicense\n=======\n\nThis project is licensed under the MIT License, see ``COPYING``.",
        "url": "http://pypi.python.org/pypi/1to001",
        "summary": "Padding numbers in filenames automatically",
        "command": "pip install '1to001'"
      },
      "2013007_pyh": {
        "name": "2013007_pyh",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/2013007_pyh",
        "summary": "some print functions",
        "command": "pip install '2013007_pyh'"
      },
      "2C.py": {
        "name": "2c.py",
        "description": "",
        "url": "http://pypi.python.org/pypi/2C.py",
        "summary": "Python-to-C compiler for CPython 2.6",
        "command": "pip install '2C.py'"
      },
      "2factorcli": {
        "name": "2factorcli",
        "description": "# 2 Factor CLI\n\nThis is a simple python program to allow you to store and generate time-based\none-time passwords in a GPG encrypted vault.\n\nThis allows you to use 2factor to log in without getting out your phone\n\n# Extracting secrets from qrcodes\n\nYou can:\n\n * Use a QR code reader on your phone\n * [zbar](http://zbar.sourceforge.net/) provides zbarimg\n \nOnce you decode the qr code, it'll be a quasi-url that contains something like\n\n    secret=ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890\n    \nUse ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890 as the secret passed to the app\n\n\n# Install\n\nInstall via pip:\n\n    pip install 2factorcli\n    \n# Example\n\n    2factorcli add facebook FFFFFF email@example.org\n    2factorcli get facebook\n\n# Bash completion\n\nYou can find a sniplet to enable bash completion here:\n[https://gist.github.com/kormoc/e4fa7d9d523e9559984a](https://gist.github.com/kormoc/e4fa7d9d523e9559984a)",
        "url": "http://pypi.python.org/pypi/2factorcli",
        "summary": "This is a simple python program to allow you to store and  generate time-based one-time passwords in a GPG encrypted vault.",
        "command": "pip install '2factorcli'"
      },
      "2gis": {
        "name": "2gis",
        "description": "python-2gis\n============\n\nA Python library for accessing the 2gis API",
        "url": "http://pypi.python.org/pypi/2gis",
        "summary": "2gis library for Python",
        "command": "pip install '2gis'"
      },
      "2lazy2rest": {
        "name": "2lazy2rest",
        "description": "##########\n2lazy2rest\n##########\n\nA simple way to produce short-to-medium document using *reStructuredText*\n\nMulti-format themes\n    Render the same document in HTML, ODT, PDF keeping the main visual identity\nUnified interface\n    - Tired of switching between rst2* tools having different arguments or behavior ?\n    - Would like to not lose *code-blocks* or some rendering options switching the output format ?\n\n    This tool try to address this\nMake your own theme\n    TODO: templates will be customizable easily (say, probably colors only)\n\nHow to use it\n#############\n\nDependencies\n============\n\nYou'll need **rst2pdf** to use all the features, other rst2* tools are coming from docutils.\n\nUsing\n=====\n\n.. code-block:: console\n\n    mkrst [-h] [--html] [--pdf] [--odt] [--theme THEME]\n                 [--themes-dir THEMES_DIR]\n                 FILE\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --html                Generate HTML output\n  --pdf                 Generate PDF output\n  --odt                 Generate ODT output\n  --theme THEME         Use a different theme\n  --themes-dir THEMES_DIR\n                        Change the folder searched for theme\n\n\n.. code-block:: console\n\n    popo:~/2lazy2rest% ./mkrst test_page.rst --html --pdf\n    Using ./themes/default\n      html:  test_page.html\n       pdf:  test_page.pdf\n\n\nCustomizing\n===========\n\nMake a copy of ``themes/default``, edit to your needs the copy and use the **--theme** option with the name of your copy, that's All !\n\nExample\n-------\n\n.. code-block:: console\n\n   popo:~/2lazy2rest% cp -r themes/default themes/red\n   popo:~/2lazy2rest% sed -si 's/#FEFEFE/red/g' themes/red/html/stylesheet.css\n   popo:~/2lazy2rest% ./mkrst test_page.rst --html --theme red\n\nIssues\n######\n\n- ODT style is unfinished\n- PDF & HTML still needs more ReST coverage\n- No skin generation from template yet",
        "url": "http://pypi.python.org/pypi/2lazy2rest",
        "summary": "Effortless generation of PDF, HTML & ODT documents from RST (ReStructuredText)",
        "command": "pip install '2lazy2rest'"
      },
      "2mp3": {
        "name": "2mp3",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/2mp3",
        "summary": "convert your media files to mp3",
        "command": "pip install '2mp3'"
      },
      "2mp4": {
        "name": "2mp4",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/2mp4",
        "summary": "Simple utility to convert your video files into mp4s.",
        "command": "pip install '2mp4'"
      },
      "2or3": {
        "name": "2or3",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/2or3",
        "summary": "Writes a single byte to stdout (either \"2\" or \"3\") classifying a Python file using heuristics, giving priority to 3 if unclear",
        "command": "pip install '2or3'"
      },
      "3-1": {
        "name": "3-1",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/3-1",
        "summary": "test",
        "command": "pip install '3-1'"
      },
      "36ban_commons": {
        "name": "36ban_commons",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/36ban_commons",
        "summary": "eking commons",
        "command": "pip install '36ban_commons'"
      },
      "3color-Press": {
        "name": "3color-press",
        "description": "About\n======\n\n3color Press is a flask based application intended to streamline making your own comic based website.\nIt is a static website generator that takes markdown formatted text files and turns them into new pages.\n\nI am new to programming and I'm kind of brute learning python and flask with this project.\nThe project is under heavy development and features are being added as we work on them,\nhowever a very functional core set of features is included\n\nFor more in depth information on how to use check the doc pages You can see a demo\nsite generated with version 0.1 of this tool at http://3color.noties.org\n\nFeatures\n\n * automatic handling of book pages, news pages and single pages\n * easily add a page to the main menu\n * easily add custom single pages\n * News page to collect news feed page\n * Support for showing a thumbnail of most recent comic in desired story line on every page\n * command line tools for easy management\n\nIn Progress Features\n\n * custom themeing support\n * toggle-able theme elements\n * improvement on handling in site menus\n * admin interface\n * better error checking\n * much more?!\n\n\nInstallation\n-------------\n\nThe package is available in pypi::\n\n  $ pip install 3color-Press\n\nsee :doc:`install`\n\n\nContribute\n----------\n\nIf you're interested in contributing or checking out the source code you can take a look at:\n\n * Issue Tracker: https:github.com/chipperdoodles/3color/issues\n * Source Code: https:github.com/chipperdoodles/3color\n\n\nSupport\n-------\n\nIf you're having problems or have some questions,\nfeel free to check out the github page: https://github.com/chipperdoodles/3color\n\n\nLicense\n--------\n\n3color-Press is (c) Martin Knobel and contributors and is licensed under a BSD license\n\nsee :doc:`license`",
        "url": "http://pypi.python.org/pypi/3color-Press",
        "summary": "A Flask based static site generator for comics",
        "command": "pip install '3color-Press'"
      },
      "3d-wallet-generator": {
        "name": "3d-wallet-generator",
        "description": "3D Wallet Generator\n===================\n\nThis project helps you design and export 3D-printable wallets, similar to paper wallets (but they won't die in a flood)\n-----------------------------------------------------------------------------------------------------------------------\n\nEveryone who's seriously serious about bitcoin has tried paper wallet\ngenerators. While the idea is great, paper isn't a great medium out of\nwhich to make something that stores significant value. This this in\nmind, we set out to make a simple, easy-to-use software that can design\nand export 3D-printable wallets, with a variety of configuration\noptions.\n\nDependencies\n------------\n\n-  Python3: this project is designed for Python3, not Python2\n-  PyBitcoin, ``sudo pip3 install bitcoin`` **(no manual installation required)**\n-  PyQRCode, ``sudo pip3 install pyqrcode`` **(no manual installation required)**\n-  OpenSCAD 2015 (or higher), just install from their website, and the\n   program should find it automatically (submit an issue if it doesn't) - **(manual installation required)**\n\nFeatures\n--------\n\n-  Supports a variety of configuration and size options\n-  Exports wallets as STL\n-  Export keys as CSV-file for import into other software (for big\n   batches)\n-  Set the configuration and let it generate millions of **random**\n   wallets for you\n-  Support for other cryptocurrencies, including:\n\t- Bitcoin\n\t- Litecoin\n\t- Dogecoin\n\t- Any other currency (as long as you know the version bit for address generation)\n\nInstructions\n------------\n\n1. Install pip\n\t- Windows: download from their website\n\t- Mac: install from MacPorts or Brew\n\t- Linux (Ubuntu/Debian): ``sudo apt-get install python3-pip``\n2. Install OpenSCAD\n\t- `Download from their website <http://openscad.org/downloads.html>`_\n\t- Make sure you are running their newest version (or at least OpenSCAD 2015)\n\t- Contact us if you need help.\n3. Install our package\n\t- Try: ``sudo pip3 install 3d-wallet-generator``\n\t- If it continues to fail, shoot us an email and we'll try to help.\n4. Use our package\n\t- Run ``3dwallet -h`` to see your options\n\t- Try the default settings by running `3dwallet` - it will output five wallets, with the default settings, into a folder in your current directory.\n\t- Play with the other settings and decide how your printer, CNC, etc. likes the different styles.\n\t- Film it or take a picture, and give it to us! We'll add it to our collection!\n\nWe recommend you run the Linux version off of a LiveUSB for maximum\nsecurity (just as you would with a normal paper wallet).\n\nMiscellaneous\n-------------\n\n-  If you have any comments, questions, or feature requests, either\n   submit an issue or contact us at btcspry@bitforwarder.com\n-  We always accept donations at\n   **1MF7hKShzq2iSV9ZZ9hEx6ATnHQpFtM7cF!!** Please donate, this project\n   took a bunch of effort and we want to make sure it was worth it.\n\nTo Do / Features Coming Soon\n----------------------------\n\n-  Add pictures\n-  Add option to import your own addresses/private keys\n-  Offset the white in the QR code (instead of just offsetting the\n   black)\n-  If you want any of these developed faster, send us a gift to our donation address above.",
        "url": "http://pypi.python.org/pypi/3d-wallet-generator",
        "summary": "A tool to help you design and export 3D-printable bitcoin/cryptocurrency wallets",
        "command": "pip install '3d-wallet-generator'"
      },
      "3lwg": {
        "name": "3lwg",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/3lwg",
        "summary": "Three Letter Word Game",
        "command": "pip install '3lwg'"
      },
      "3to2": {
        "name": "3to2",
        "description": "Download\r\n========\r\nRelease for 2.7 and 3.x (last version I tested was 3.4.3): https://pypi.python.org/pypi/3to2\r\n\r\nAbstract\r\n========\r\n\r\nlib3to2 is a set of fixers that are intended to backport code written for\r\nPython version 3.x into Python version 2.x.  The final target 2.x version is\r\nthe latest version of the 2.7 branch, as that is the last release in the Python\r\n2.x branch.  Some attempts have been made, however, to make code compatible as\r\nmuch as possible with versions of Python back to 2.5, and bug reports are still\r\nwelcome for Python features only present in 2.6+ that are not addressed by\r\nlib3to2.\r\n\r\nThis project came about as a Google Summer of Code (TM) project in 2009.\r\n\r\nStatus\r\n======\r\n\r\nBecause of the nature of the subject matter, 3to2 is not perfect, so check all\r\noutput manually.  3to2 does the bulk of the work, but there is code that simply\r\ncannot be converted into a Python 2 equivalent for one reason or another.\r\n\r\n3to2 will either produce working Python 2 code or warn about why it did not.\r\nAny other behavior is a bug and should be reported.\r\n\r\nlib3to2's fixers are somewhat well-tested individually, but there is no testing\r\nthat is done on interactions between multiple fixers, so most of the bugs in\r\nthe future will likely be found there.\r\n\r\nIntention\r\n=========\r\n\r\nlib3to2 is intended to be a tool in the process of developing code that is\r\nbackwards-compatible between Python 3 and Python 2.  It is not intended to be a\r\ncomplete solution for directly backporting Python 3 code, though it can often\r\nbe used for this purpose without issue.  Sufficiently large packages should be\r\ndeveloped with lib3to2 used throughout the process to avoid backwards-\r\nincompatible code from becoming too embedded.\r\n\r\nThere are some features of Python 3 that have no equivalent in Python 2, and\r\nthough lib3to2 tries to fix as many of these as it can, some features are\r\nbeyond its grasp.  This is especially true of features not readily detectable\r\nby their syntax alone and extremely subtle features, so make sure that code\r\nusing lib3to2 is thoroughly tested.\r\n\r\nRepository\r\n==========\r\n\r\nlib3to2 resides at http://bitbucket.org/amentajo/lib3to2, where the bug tracker\r\ncan be found at http://bitbucket.org/amentajo/lib3to2/issues\r\n\r\nUsage\r\n=====\r\n\r\nRun \"./3to2\" to convert stdin (\"-\"), files or directories given as\r\narguments.  By default, the tool outputs a unified diff-formatted patch on\r\nstandard output and a \"what was changed\" summary on standard error, but the\r\n\"-w\" option can be given to write back converted files, creating\r\n\".bak\"-named backup files.\r\n\r\nIf you are root, you can also install with \"./setup.py build\" and\r\n\"./setup.py install\" (\"make install\" does this for you).\r\n\r\nThis branch of 3to2 must be run with Python 3.\r\n\r\nTo install locally (used for running tests as a non-privileged user), the\r\nscripts assume you are using python3.1.  Modify accordingly if you are not.\r\n\r\nRelationship with lib2to3\r\n=========================\r\n\r\nSome of the fixers for lib3to2 are directly copy-pasted from their 2to3\r\nequivalent, with the element of PATTERN and the corresponding transformation\r\nswitched places.  Most fixers written for this program with a corresponding\r\n2to3 fixer started from a clone of the 2to3 fixer, then modifying that fixer to\r\nwork in reverse.  I do not claim original authorship of these fixers, but I do\r\nclaim that they will work for 3to2, independent of how they work for 2to3.\r\nIn addition, this program depends on lib2to3 to implement fixers, test cases,\r\nrefactoring, and grammar.  Some portions of lib2to3 were modified to be more\r\ngeneric to support lib3to2's calls.\r\n\r\nYou should use the latest version of lib2to3 from the Python sandbox rather\r\nthan the version (if any) that comes with Python.  As a convenience,\r\n\"two2three\" from the Python Package Index is a recent enough version of lib2to3\r\nrenamed to avoid conflicts.  To use this package, replace all usage of\r\n\"lib2to3\" with \"two2three\" within the 3to2 source files after installing\r\n\"two2three\" from the PyPI.  Depending on the developer's mood, a version of\r\n3to2 may be provided with this change already made.",
        "url": "http://pypi.python.org/pypi/3to2",
        "summary": "Refactors valid 3.x syntax into valid 2.x syntax, if a syntactical conversion is possible",
        "command": "pip install '3to2'"
      },
      "3to2_py3k": {
        "name": "3to2_py3k",
        "description": "Thanks to Steven Silvester, this no longer needs to be a package that is separate from 3to2.\r\n\r\nSee: https://pypi.python.org/pypi/3to2",
        "url": "http://pypi.python.org/pypi/3to2_py3k",
        "summary": "See 3to2",
        "command": "pip install '3to2_py3k'"
      },
      "42cc-pystyle": {
        "name": "42cc-pystyle",
        "description": "# 42cc-pystyle\nflake8 plugins for 42 Coffee Cups style checks\n\n- 0.0.6\nfixed flake8 warnings :)\n\n- 0.0.5\nfixed package layout declaration\n\n- 0.0.4\nfixed nosetests\n\n- 0.0.3\nmoved code to a subfolder\n\n- 0.0.2\nAdded MANIFEST.in\n\n- 0.0.1\nTests should have docstrings\nTests for the module could be run via `nosetests` or `python setup.py nosetests`",
        "url": "http://pypi.python.org/pypi/42cc-pystyle",
        "summary": "flake8 checks for 42 Coffee Cups style guide",
        "command": "pip install '42cc-pystyle'"
      },
      "42qucc": {
        "name": "42qucc",
        "description": "the following is the usage:\n      1.Paste file to 42qu.cc\n        hi@Mars ~$ 42qucc < foo.txt            \n        http://42qu.cc/xa47qt471        \n      2.Custom url           \n        hi@Mars ~$ 42qucc hi < foo.txt          \n        http://42qu.cc/hi        \n      3.Save web page to local file          \n        hi@Mars ~$ 42qucc  http://42qu.cc/xa47qt471  >  foo.txt",
        "url": "http://pypi.python.org/pypi/42qucc",
        "summary": "A paste tool in CLI",
        "command": "pip install '42qucc'"
      },
      "4ch": {
        "name": "4ch",
        "description": "fourch\n======\n\n.. _docs: https://4ch.readthedocs.org\n.. _repo: https://github.com/plausibility/4ch\n\nfourch (stylized as 4ch) is a wrapper to the 4chan JSON API, provided by moot. It allows you to interact with 4chan (in a READONLY way) easily through your scripts.\n\nOriginally <strike>stolen</strike> forked from `e000/py-4chan <https://github.com/e000/py-4chan>`_, but then I moved repos and renamed stuff since I'm pretty bad about that.\n\nRequirements\n------------\n\n- Python 2.7 (what I test with, 2.x might work)\n- requests\n\nNotes\n-----\n\n- This isn't guaranteed to work all the time; after all, the API may change, and 4ch will have to be updated accordingly.\n- If a feature is missing, open an issue on the `repo`_, and it may well be implemented.\n\nRunning / Usage\n---------------\n\n- Install & import: ``$ pip install 4ch``, ``import fourch``\n- See the `docs`_\n\nContributing\n------------\nIf you're interested in contributing to the usability of 4ch, or just want to give away stars, you can visit the 4ch github `repo`_.",
        "url": "http://pypi.python.org/pypi/4ch",
        "summary": "Python wrapper for the 4chan JSON API.",
        "command": "pip install '4ch'"
      },
      "4chan": {
        "name": "4chan",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/4chan",
        "summary": "4chan",
        "command": "pip install '4chan'"
      },
      "4chandownloader": {
        "name": "4chandownloader",
        "description": "4chandownloader\n===============\n\n4chan thread downloader.\n\n::\n\n    pip install 4chandownloader\n    4chandownloader http://boards.4chan.org/b/res/423861837 4chanarchives --delay 5 --thumbs",
        "url": "http://pypi.python.org/pypi/4chandownloader",
        "summary": "4chan thread downloader",
        "command": "pip install '4chandownloader'"
      },
      "4Suite": {
        "name": "4suite",
        "description": "4Suite is a Python-based toolkit for XML and RDF application development. It features a library of integrated tools for XML processing, implementing open technologies such as DOM, RDF, XSLT, XInclude, XPointer, XLink, XPath, XUpdate, RELAX NG, and XML/SGML Catalogs. Layered upon this is an XML and RDF data repository and server, which supports multiple methods of data access, query, indexing, transformation, rich linking, and rule processing, and provides the data infrastructure of a full database system, including transactions, concurrency, access control, and management tools.It also supports HTTP, RPC, and FTP, plus APIs in Python and XSLT.\n\n4Suite's license_ is based on the ASL_.\n\n.. _license: http://4suite.org/COPYRIGHT\n.. _ASL: http://www.apache.org/licenses/LICENSE-1.1",
        "url": "http://pypi.python.org/pypi/4Suite",
        "summary": "an open-source platform for XML and RDF processing",
        "command": "pip install '4Suite'"
      },
      "4Suite-XML": {
        "name": "4suite-xml",
        "description": "XML tools and libraries for Python: Domlette, XPath, XSLT, XPointer, XLink, XUpdate",
        "url": "http://pypi.python.org/pypi/4Suite-XML",
        "summary": "An open-source platform for XML processing",
        "command": "pip install '4Suite-XML'"
      },
      "51degrees-mobile-detector": {
        "name": "51degrees-mobile-detector",
        "description": "51Degrees Mobile Detector\n        =========================\n        \n        51Degrees Mobile Detector is a server side mobile detection solution\n        by 51Degrees. Check out http://51degrees.com for a detailed\n        description, extra documentation and other useful information.\n        \n        :copyright: (c) 2013 by 51Degrees, see README.rst for more details.\n        :license: MPL2, see LICENSE.txt for more details.",
        "url": "http://pypi.python.org/pypi/51degrees-mobile-detector",
        "summary": "51Degrees Mobile Detector.",
        "command": "pip install '51degrees-mobile-detector'"
      },
      "51degrees-mobile-detector-lite-pattern-wrapper": {
        "name": "51degrees-mobile-detector-lite-pattern-wrapper",
        "description": "51Degrees Mobile Detector (Lite C Pattern Wrapper)\r\n==================================================\r\n\r\n51Degrees Mobile Detector is a Python wrapper of the lite C pattern-based\r\nmobile detection solution by 51Degrees.mobi. Check out http://51degrees.mobi\r\nfor a detailed description, extra documentation and other useful information.\r\n\r\n:copyright: (c) 2013 by 51Degrees.mobi, see README.rst for more details.\r\n:license: MPL2, see LICENSE.txt for more details.",
        "url": "http://pypi.python.org/pypi/51degrees-mobile-detector-lite-pattern-wrapper",
        "summary": "51Degrees Mobile Detector (Lite C Pattern Wrapper).",
        "command": "pip install '51degrees-mobile-detector-lite-pattern-wrapper'"
      },
      "51degrees-mobile-detector-trie-wrapper": {
        "name": "51degrees-mobile-detector-trie-wrapper",
        "description": "51Degrees Mobile Detector (C Trie Wrapper)\r\n==========================================\r\n\r\n51Degrees Mobile Detector is a Python wrapper of the C trie-based mobile\r\ndetection solution by 51Degrees.mobi. Check out http://51degrees.mobi for\r\na detailed description, extra documentation and other useful information.\r\n\r\n:copyright: (c) 2013 by 51Degrees.mobi, see README.rst for more details.\r\n:license: MPL2, see LICENSE.txt for more details.",
        "url": "http://pypi.python.org/pypi/51degrees-mobile-detector-trie-wrapper",
        "summary": "51Degrees Mobile Detector (C Trie Wrapper).",
        "command": "pip install '51degrees-mobile-detector-trie-wrapper'"
      },
      "51degrees-mobile-detector-v3-trie-wrapper": {
        "name": "51degrees-mobile-detector-v3-trie-wrapper",
        "description": "51Degrees Mobile Detector (C Trie Wrapper)\n        ==========================================\n        \n        51Degrees Mobile Detector is a Python wrapper of the C trie-based mobile\n        detection solution by 51Degrees.mobi. Check out http://51degrees.mobi for\n        a detailed description, extra documentation and other useful information.\n        \n        :copyright: (c) 2013 by 51Degrees.mobi, see README.rst for more details.\n        :license: MPL2, see LICENSE.txt for more details.",
        "url": "http://pypi.python.org/pypi/51degrees-mobile-detector-v3-trie-wrapper",
        "summary": "51Degrees Mobile Detector (C Trie Wrapper).",
        "command": "pip install '51degrees-mobile-detector-v3-trie-wrapper'"
      },
      "51degrees-mobile-detector-v3-wrapper": {
        "name": "51degrees-mobile-detector-v3-wrapper",
        "description": "51Degrees Mobile Detector (V3 Wrapper)\n        ==================================================\n        \n        51Degrees Mobile Detector is a Python wrapper of the lite C pattern-based\n        mobile detection solution by 51Degrees.mobi. Check out http://51degrees.mobi\n        for a detailed description, extra documentation and other useful information.\n        \n        :copyright: (c) 2013 by 51Degrees.mobi, see README.rst for more details.\n        :license: MPL2, see LICENSE.txt for more details.",
        "url": "http://pypi.python.org/pypi/51degrees-mobile-detector-v3-wrapper",
        "summary": "51Degrees Mobile Detector (C Pattern Wrapper).",
        "command": "pip install '51degrees-mobile-detector-v3-wrapper'"
      },
      "73.portlet.links": {
        "name": "73.portlet.links",
        "description": "This product is based on collective.portlet.links but it's possible to set the title of the port let.",
        "url": "http://pypi.python.org/pypi/73.portlet.links",
        "summary": "This product is based on collective.portlet.links with configurable title",
        "command": "pip install '73.portlet.links'"
      },
      "73.unlockItems": {
        "name": "73.unlockitems",
        "description": "Introduction\n============\n\nThis product is special for unlocking web_dav locked item in a plone portal.\nNeed simplejson if python version is less than 2.6\n\n\nrelease 0.3\n===========\nno need simplejson any more :-)\nCode is more clear and speed\nChangelog\n=========\n\n0.1dev (unreleased)\n-------------------\n\n- Initial release\n\n0.2 (unreleased)\n-----------------\n\n- add browserview in plone_control_panel\n\n0.3 (released)\n---------------\n\n- remove jquery used (javascript and python)\n- code is more clear and speed\n- make only one search in catalog",
        "url": "http://pypi.python.org/pypi/73.unlockItems",
        "summary": "A small tool for unlocking web_dav locked item in a plone portal.",
        "command": "pip install '73.unlockItems'"
      },
      "7th": {
        "name": "7th",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/7th",
        "summary": "UNKNOWN",
        "command": "pip install '7th'"
      },
      "9eek-nester": {
        "name": "9eek-nester",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/9eek-nester",
        "summary": "A simple printer of nested lists",
        "command": "pip install '9eek-nester'"
      },
      "9ML": {
        "name": "9ml",
        "description": "======\r\nNineML\r\n======\r\n\r\nNineML (http://nineml.incf.org) is a simulator independent language which aims to provide unambiguous descriptions of neuronal network models for efficient model sharing and reusability. This package provides a Python library for reading, writing, validating and manipulating NineML models.\r\n\r\nInstallation\r\n------------\r\n\r\n:: \r\n  \r\n  python setup.py install\r\n\r\n\r\nDependencies\r\n------------\r\n\r\n* lxml - see http://codespeak.net/lxml/\r\n* ply\r\n\r\nDocumentation\r\n-------------\r\n\r\nhttp://phobos.incf.ki.se/",
        "url": "http://pypi.python.org/pypi/9ML",
        "summary": "A tool for reading, writing and generally working with 9ML files.",
        "command": "pip install '9ML'"
      },
      "a": {
        "name": "a",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/a",
        "summary": "Python Distribution Utilities",
        "command": "pip install 'a'"
      },
      "a10-neutron-lbaas": {
        "name": "a10-neutron-lbaas",
        "description": "a10-neutron-lbaas\n=================\n\nA10 Networks, Openstack Neutron LBaaS Driver for Juno\n\nA10 github repos:\n\n- [a10-openstack-lbaas](https://github.com/a10networks/a10-openstack-lbaas) - OpenStack LBaaS driver, \nidentical to the files that are currently merged into Juno.  Also supports Icehouse.  Pypi package \n'a10-openstack-lbaas'.\n- [a10-openstack-lbaas, havana branch](https://github.com/a10networks/a10-openstack-lbaas/tree/havana) - OpenStack \nLBaaS driver, for the Havana release.  Pypi package 'a10-openstack-lbaas-havana'.\n- [a10-neutron-lbaas](https://github.com/a10networks/a10-neutron-lbaas) - Middleware sitting between the \nopenstack driver and our API client, mapping openstack constructs to A10's AxAPI.\n- [acos-client](https://github.com/a10networks/acos-client) - AxAPI client used by A10's OpenStack driver.\n- [neutron-thirdparty-ci](https://github.com/a10networks/neutron-thirdparty-ci) - Scripts used by \nour Jenkins/Zuul/Devstack-Gate setup, used to test every openstack code review submission against \nA10 appliances and our drivers.\n- [a10_lbaas_driver](https://github.com/a10networks/a10_lbaas_driver) - An older revision of A10's \nLBaaS driver; no longer supported.",
        "url": "http://pypi.python.org/pypi/a10-neutron-lbaas",
        "summary": "A10 Networks Openstack LBaaS Driver Middleware",
        "command": "pip install 'a10-neutron-lbaas'"
      },
      "a10-openstack-lbaas": {
        "name": "a10-openstack-lbaas",
        "description": "# A10 Networks LBaaS Driver\n\nA10 github repos:\n\n- [a10-openstack-lbaas](https://github.com/a10networks/a10-openstack-lbaas) - OpenStack LBaaS driver, \nidentical to the files that are currently merged into Juno.  Also supports Icehouse.  Pypi package \n'a10-openstack-lbaas'.\n- [a10-openstack-lbaas, havana branch](https://github.com/a10networks/a10-openstack-lbaas/tree/havana) - OpenStack \nLBaaS driver, for the Havana release.  Pypi package 'a10-openstack-lbaas-havana'.\n- [a10-neutron-lbaas](https://github.com/a10networks/a10-neutron-lbaas) - Middleware sitting between the \nopenstack driver and our API client, mapping openstack constructs to A10's AxAPI.\n- [acos-client](https://github.com/a10networks/acos-client) - AxAPI client used by A10's OpenStack driver.\n- [neutron-thirdparty-ci](https://github.com/a10networks/neutron-thirdparty-ci) - Scripts used by \nour Jenkins/Zuul/Devstack-Gate setup, used to test every openstack code review submission against \nA10 appliances and our drivers.\n- [a10_lbaas_driver](https://github.com/a10networks/a10_lbaas_driver) - An older revision of A10's \nLBaaS driver; no longer supported.\n\n## Installation\n\nTo use this driver, you must:\n\n1. Install the [a10-neutron-lbaas](https://github.com/a10networks/a10-neutron-lbaas) module. \n(E.g.: 'pip install a10-neutron-lbaas')\n- Create a driver config file, a [sample](#example-config-file) of which is given below.\n- Enable it in `neutron.conf`\n- Restart neutron-server\n\n### Configuration file:\n\nCreate a configuration file with a list of A10 appliances, similar to the\nfile below, located at: `/etc/neutron/services/loadbalancer/a10networks/config.py`.\n\nOr you can override that directory by setting the environment\nvariable `A10_CONFIG_DIR`.\n\n#### Example config file:\n\n```python\ndevices = {\n    \"ax1\": {\n        \"name\": \"ax1\",\n        \"host\": \"10.10.100.20\",\n        \"port\": 443,\n        \"protocol\": \"https\",\n        \"username\": \"admin\",\n        \"password\": \"a10\",\n        \"status\": True,\n        \"autosnat\": False,\n        \"api_version\": \"2.1\",\n        \"v_method\": \"LSI\",\n        \"max_instance\": 5000,\n        \"use_float\": False,\n        \"method\": \"hash\"\n    },\n    \"ax4\": {\n        \"host\": \"10.10.100.23\",\n        \"username\": \"admin\",\n        \"password\": \"a10\",\n    },\n}\n```\n\n## Third-party CI Information\n\nIf you encounter any problems, contact A10 at:\n\n* [a10-openstack-ci@a10networks.com](mailto: a10-openstack-ci@a10networks.com)\n* Doug Wiegley directly via IRC (dougwig)\n\n## Contributing\n\n1. Fork it ( http://github.com/a10networks/a10-openstack-lbaas/fork )\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create new Pull Request",
        "url": "http://pypi.python.org/pypi/a10-openstack-lbaas",
        "summary": "A10 Networks Openstack LBaaS Driver",
        "command": "pip install 'a10-openstack-lbaas'"
      },
      "a10sdk": {
        "name": "a10sdk",
        "description": "# A10 Networks Python Client SDK\n\n## Contributing\n\n1. Fork it ( http://github.com/a10networks/a10sdk-python/fork )\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create new Pull Request",
        "url": "http://pypi.python.org/pypi/a10sdk",
        "summary": "A10 Networks ACOS Python SDK",
        "command": "pip install 'a10sdk'"
      },
      "a2svm": {
        "name": "a2svm",
        "description": "**********************************************\nA2SVM  - Apache 2 Simple Virtualhost Manager  \n**********************************************\n\n**a2svm** is a Simple CLI tool to create and delete easily virtualhosts in Apache.\n\nusage: a2svm [-h] [-v] {mk,ls,rm,en,ds} ...\n\na2svm commands are:\n\n* **mk**         Create a virtualhosts\n* **ls**         Show managed virtualhosts on Apache server\n* **rm**         Delete a virtualhosts\n* **en**         Enable a virtualhosts\n* **ds**         Disable a virtualhosts\n\nSee 'a2svm <command> -h' for more information on a specific command.\n\nPyPI package `<http://pypi.python.org/pypi/a2svm>`__ \n\nSources `<https://github.com/cypx/a2svm>`__ \n \nRequirements\n##############\n\na2svm need apache mod_macro which could be installed on debian 6 by the following command\n\n.. code-block:: bash\n\n\t$ aptitude install libapache2-mod-macro\n\nOnce mod_macro is avalaible some template could be created for use by a2svm like this one\n\n.. code-block:: xml\n\n\t<Macro vhost_standard $name $servername $directory>\n\t  <VirtualHost *:80>\n\n\t    ServerName $servername\n\n\t    DocumentRoot /var/www/$directory/public\n\n\t    <Directory /var/www/$directory>\n\t        Options  FollowSymLinks MultiViews\n\t        AllowOverride All\n\t        Order allow,deny\n\t        allow from all\n\t    </Directory>\n\n\t    ErrorLog ${APACHE_LOG_DIR}/error-$name.log\n\n\t    # Possible values include: debug, info, notice, warn, error, crit,\n\t    # alert, emerg.\n\t    LogLevel warn\n\n\t    CustomLog ${APACHE_LOG_DIR}/access-$name.log combined\n\t  </VirtualHost>\n\t</Macro>\n\n\t#Comments beginning by \"a2svm_make_command\" are used to run external commands\n\t#when vhost is created \n\t#a2svm_make_command: /bin/mkdir -p /var/www/$directory/public /var/www/$directory/log\n\t#a2svm_make_command: /bin/chown -R cyp:www-data /var/www/$directory\n\t#Comments beginning by \"a2svm_remove_command\" are used to run external commands\n\t#when vhost is removed \n\t#a2svm_remove_command: /bin/tar czf /var/www/archive/$servername.tgz /var/www/$directory\n\t#a2svm_remove_command: /bin/rm -rf /var/www/$directory\n\n\t\n\nInstallation\n##############\n\nInstall it easily:\n\nUsing pip\n**************\n\n.. code-block:: bash\n\n\t$ pip install a2svm\n\nUsing easy_install\n*********************\n\nOn most Linux distribution \n\n.. code-block:: bash\n\n\t$ easy_install a2svm\n\nBut on some, prerequisites are required, for example, on Debian 6\n\n.. code-block:: bash\n\n\t$ aptitude install python-pip\n\n\nUpgrade\n##########\n\nUsing pip\n**************\n\n.. code-block:: bash\n\n\t$ pip --upgrade a2svm\n\nUsing easy_install\n*********************\n\n.. code-block:: bash\n\n\t$ easy_install --upgrade a2svm",
        "url": "http://pypi.python.org/pypi/a2svm",
        "summary": "Simple CLI tool to create and delete easily virtual hosts in Apache.",
        "command": "pip install 'a2svm'"
      },
      "A3MIO": {
        "name": "a3mio",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/A3MIO",
        "summary": "A3M/A2M I/O for BioPython",
        "command": "pip install 'A3MIO'"
      },
      "a4t-party_contact": {
        "name": "a4t-party_contact",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/a4t-party_contact",
        "summary": "Tryton module to manage party address and contact mechanisms",
        "command": "pip install 'a4t-party_contact'"
      },
      "a4t-sale_tax_included": {
        "name": "a4t-sale_tax_included",
        "description": "Sale Tax Included\n=================\n\nAdiczion's Tryton Module: sale_tax_included\n-------------------------------------------\n\nAdds the ability to Tryton to make sales and invoices with product with \nprice with tax included.\n\n.. warning::\n   Replace the deprecated module : sale_b2bc.\n\nInstalling\n----------\n\nSee INSTALL\n\nSupport\n-------\n\nFor more information or if you encounter any problems with this module,\nplease contact the programmers at\n\n  Adiczion\n  --------\n  website: http://www.adiczion.com/\n  email: atm@adiczion.net\n\nIf you encounter any problems with Tryton, please don't hesitate to ask\nquestions on the Tryton bug tracker, mailing list, wiki or IRC channel:\n\n  http://bugs.tryton.org/\n  http://groups.tryton.org/\n  http://wiki.tryton.org/\n  irc://irc.freenode.net/tryton\n\nLicense\n-------\n\nSee LICENSE\n\nCopyright\n---------\n\nSee COPYRIGHT\n\nAdditional information\n----------------------\n\nFor more information please visit the Tryton web site:\n\n  http://www.tryton.org/",
        "url": "http://pypi.python.org/pypi/a4t-sale_tax_included",
        "summary": "Tryton module for sale with price with tax included",
        "command": "pip install 'a4t-sale_tax_included'"
      },
      "a8": {
        "name": "a8",
        "description": "\n# a8, the Abominade IDE #\n\n(c) 2011, PIDA Authors\nLicense GPL v3 (http://www.gnu.org/copyleft/gpl.html)\n\nThe One True IDE™, successor to the PIDA IDE. An ultra-lightweight IDE, that\nembeds Vim, a terminal emulator, and a file browser and makes them work\ntogether.\n\n* [Installation](#installation)\n* [Configuration](#configuration)\n* [Keyboard Shortcuts](#keyboard-shortcuts)\n* [Extensions](#extensions)\n* [FAQ](#faq)\n* [Intentional Breakages](#intentional-breakages)\n* [SSH Tips and Tricks](#ssh-tips-and-tricks)\n\n![a8 screenshot](https://lh4.googleusercontent.com/-PtipCpFvTcc/TvpPhtdtTeI/AAAAAAAADI0/tUVBvU3uLAA/s0-d/a8.png)\n\n----\n\n## Installation ##\n\n⠠⠊⠝⠎⠞⠁⠇⠇⠁⠞⠊⠕⠝\n\n```\n$ pip install a8\n```\nRemember the system dependencies:\n```\n# apt-get install vim-gtk python-gtk2 python-vte python-dbus\n```\n(non debian distros, please drop me a line to add you.)\n\n----\n\n## Configuration\n\n\na8 is a bit configurable. Not so much because I never planned on using it in more than one way.\n\n### Configuration file\n\nCreate a config file at `~/.a8/config.yaml`\n\nAs the name suggests it will be in Yaml, as a map of key values:\n```\nfoo1: blah\nfoo2:\n    foo3: blah\n```\n\n### Terminal Configuration ###\n\nIs the biggest bit, terminal options live under the `temrinal` key, and these\nare them, with default values if they exist (or Unset otherwise):\n```\n  terminal:\n    'color_foreground': Unset,\n    'color_background': Unset,\n    'backspace_binding': Unset,\n    'cursor_blink_mode': Unset,\n    'cursor_shape': Unset,\n    'font': Unset,\n    'allow_bold': Unset,\n    'audible_bell': Unset,\n    'emulation': Unset,\n    'pointer_autohide': Unset,\n    'scroll_on_keystroke': Unset,\n    'scroll_on_output': Unset,\n    'scrollback_lines': 1000,\n    'visible_bell': Unset,\n    'word_chars': '-A-Za-z0-9,./?%&#:_',\n```\n\n### Window Configuration ###\n\nTo turn on the toolbar:\n```\ntoolbar: true\n```\n\n### Session Configuration ###\n\nAbominade 0.11 supports 3 session types:\n```\nsession_type: 'none'   # don't remember sessions (alias for \"session: false\")\nsession_type: 'local'  # stores session in the ./.a8 wherever abominade runs\nsession_type: 'user'   # default, stores session in ~/.a8\n```\nTo turn off sessions in 0.10 and earlier:\n```\nsession: false\n```\n\n### Terminals in a separate window ###\n\nUseful for multiple screens:\n```\nterminal_window: true\n```\n----\n\n## Keyboard Shortcuts ##\n\n⠠⠅⠑⠽⠃⠕⠁⠗⠙ ⠠⠎⠓⠕⠗⠞⠉⠥⠞⠎\n\nKeyboard shortucts are of two types:\n\n1. Internal a8 actions\n2. Custom shell commands\n\nDefine keyboard shortcuts by creating the file:\n\n`~/.a8/shortcuts.yaml`\n\nThis file should contain keys and values of the form:\n\n`<action>: <shortcut>`\n\nor of the form\n\n`key: <shortcut>`\n\n`[cmd: <command>]`\n\n`[cwd: <working directory>]`\n\n`[env: <environment>]`\n\n\nWhere action is a string defining the action to be performed, and shortcut is a shortcut string.\n\n### Available actions ###\n\nAvailable actions are (with defaults):\n\n* `shell (<Alt>t)`\n* `focus_vim (<Alt>e)`\n* `focus_terminal (<Alt>r)`\n* `focus_buffers (<Alt>b)`\n* `focus_files (<Alt>m)`\n* `focus_terminals (<Alt>i)`\n* `focus_bookmarks (<Alt>k)`\n* `prev_buffer (<Alt>Up)`\n* `next_buffer (<Alt>Down)`\n* `prev_terminal (<Alt>Left)`\n* `next_terminal (<Alt>Right)`\n* `refresh_files (<Alt>g)`\n* `toggle_expanded_files (<Alt>x)` (0.11 and later)\n* `close_all_buffers (<Alt>c)`\n* `browse_home (<Alt>h)`\n\n### Other hotkeys ###\n\n* pressing `<Shift>Up` and `<Shift>Down` in terminals will jump to prev/next\nprompt (or at least the scrollbar position where you last hit Enter)\n\n### Shortcut format ###\n\nThe format looks like `<Control>a` or `<Shift><Alt>F1` or `<Release>z` (the last\none is for key release). The parser is fairly liberal and allows lower or upper\ncase, and also abbreviations such as `<Ctl>` and `<Ctrl>`. Keys such as `Up`,\n`Down`, `Left`, `Right` etc are available, but be careful, the keypress will not\npass through to the underlying app, terminal or Vim.\n\n### Custom shortcuts ###\n\nThese are custom shell commands bound to a keyboard shortcut. Their format is different from internal a8 shortcuts. They should be part of a list in the value of the `custom` key. Each item in the list should define at least the key `key` as a shortcut string in the format above. Additionally they may define `cmd`, `cwd` and `env` keys. These are used to execute a new terminal with the command.\n\n### Example file ###\n\nAn example shortcut file might look like:\n\n```\nshell:     <Control>o\nfocus_vim: <Alt>Space\n\ncustom:\n  - key: <Alt>j\n    cmd: ifconfig\n```\n----\n\n## Extensions ##\n⠠⠑⠭⠞⠑⠝⠎⠊⠕⠝⠎\n\nA8 is slightly extensible, to the absolute minimal degree to add functionality without having the burden of a massive framework. This is achieved by the concepts of:\n\n1. Extensions\n2. Signals\n\nSince we are just using Python, all the a8 API is public to any Python code in the same process, and that is intentional. If you want to break it by abusing this, go for it, break it.\n\nExtensions are any Python module or instance with a callable `setup` attribute. The signature of `setup` should be:\n\n```\ndef setup(app):\n   \"\"\"My setup function.\"\"\"\n```\n\nOf course this can be in an object where the signature would be:\n\n```\nclass MyExtension(object):\n\n  def setup(self, app):\n    \"My setup function.\"\"\"\n```\n\nExtensions are listed in the configuration file under the `extensions` key, and should be importable names, such as `a8.a8_example_ext`, an example to get you started. If importing an attribute from a module, the `:` notation can be used, such as `path.mymodule:myattr`, which would be suitable for an instance as an extension.\n\nThe app that is passed to the `setup` function is an instance of `a8.app.Abominade` which is the main monolith for a8, i.e., it has access to everything. Terrible, but intentional.\n\nThe `setup` function can be used to create user interface features and to connect to signals, and as mentioned above, since all the API is public, anything can be achieved using this.\n\n### Signals ###\n\nA8 exports a number of signals for use by extensions. They are not used internally, so mostly behave as a no op. These are connected using `app.connect` and can be emitted by using `app.emit`. \n\n`app.connect` takes a signal name, and a callback to be called. Callbacks are only passed keyword arguments, so it is important to get the names of the arguments correct. here is an example of connecting to the `file-saved` signal in a plugin. All available signals and arguments are listed below.\n\n```\ndef on_file_saved(filename):\n  print filename, 'was saved.'\n\ndef setup(app):\n  app.connect('file-saved', on_file_saved)\n```\n\n### Available Signals ###\n\n| *Name*                | *Arguments*        | *Description*                                 |\n|-----------------------|--------------------|-----------------------------------------------|\n| `file-item-added`     | `filename`         | File item is shown in the file manager        |\n| `file-opened`         | `filename`         | File opened in the editor                     |\n| `file-closed`         | `filename`         | File closed in the editor                     |\n| `bookmark-item-added` | `filename`         | Bookmark to `filename` is added               |\n| `terminal-executed`   | `argv` `env` `cwd` | New terminal has been executed                |\n\nIf you need more signals, just let us know. Since they are not used internally, there is basically no cost.\n\n----\n\n## FAQ ##\n⠠⠋⠠⠁⠠⠟\n\n### What happened to my favourite PIDA feature? ###\n\nAbominade doesn't hope to replace [http://pida.co.uk PIDA], how could it? So if\nyou require some special PIDA features, please go ahead and use PIDA.\n[Intentional Breakages](#intentional-breakages)\n\n### Does it work on a Mac? ###\n\nProbably, with difficulty. You'll need X, Gtk, DBus, all with Python support. (and possibly psychiatric help)\n\n----\n\n## Intentional Breakages ##\n⠠⠊⠝⠞⠑⠝⠞⠊⠕⠝⠁⠇ ⠠⠃⠗⠑⠁⠅⠁⠛⠑⠎\n\nFeatures intentionally left out of Abominade that make it simpler, but\nessentially a tool written for me. If you want a real application, try\n[https://bitbucket.org/aafshar/pida-main/wiki/Home PIDA]. The motivation for\nAbominade is to make an IDE that is tailor-made to me.\n\n* Internationalization (I only ever use English)\n* Non-Vim editors (I only ever use Vim)\n* Language support (I don't find those outliners useful)\n* Version control support (Command line is enough)\n* Project support (Replaced with bookmarks)\n* Gui configuration (Plain text is enough)\n* Gui shortcut config (As Gui config)\n* Window management (Detaching, moving, hovering, floating)\n* Saving layout\n* Documentation (ok, so PIDA doesn't have any, either!)\n* Lots of options (No need to make stuff optional that I use.)\n* GTK's Actions are a pain\n* Glade/GTKBuilder is a pain\n* GTK's stock icons are totally useless\n* Statusbar/Toolbar/menubar\n\n----\n\n## SSH Tips and Tricks ##\n⠠⠎⠠⠎⠠⠓⠀⠠⠞⠊⠏⠎⠀⠁⠝⠙⠀⠠⠞⠗⠊⠉⠅⠎\n\nAbominade's features work surprisingly well for working remotely over SSH.\n\n### SSHFS ###\n\nIf you edit a lot of code on remote hosts, you can mount your project directory\nlocally via SSHFS.\n\nIf you then SSH directly from a mounted local dir to the corresponding remote\ndir, Abominade's terminal filename recognition will still catch relative\nfilenames. This will break if you cd in your SSH session so that relative paths\ndon't match your local current dir anymore, but if you configure SSH's\n!EscapeChar setting, you can suspend SSH, cd locally, and resume SSH.\n\nAnother interesting trick is you start Abominade in an SSHFS dir while using\na local session, the session will be shared with remote instances at the same\npath, and can be resumed on a different host.\n\n### Screen/tmux ###\n\nIt's a good idea to use GNU screen or tmux for some terminals in Abominade's\nterminals pane, since it's easy to accidentally close Abominade\nand lose your terminal history.\n\n### Vim's Built-in SSH Support ###\n\nHaven't used this much in Abominade...\n",
        "url": "http://pypi.python.org/pypi/a8",
        "summary": "The Abominade IDE",
        "command": "pip install 'a8'"
      },
      "aa": {
        "name": "aa",
        "description": "aa",
        "url": "http://pypi.python.org/pypi/aa",
        "summary": "aaa",
        "command": "pip install 'aa'"
      },
      "aaa": {
        "name": "aaa",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aaa",
        "summary": "quick sort",
        "command": "pip install 'aaa'"
      },
      "aaa103439": {
        "name": "aaa103439",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aaa103439",
        "summary": "print list",
        "command": "pip install 'aaa103439'"
      },
      "Aaaaaaaaaaaaaaaaaaa-aaaaaaaaa-aaaaaaasa-aaaaaaasa-aaaaasaa-aaaaaaasa-bbbbbbbbbbb": {
        "name": "aaaaaaaaaaaaaaaaaaa-aaaaaaaaa-aaaaaaasa-aaaaaaasa-aaaaasaa-aaaaaaasa-bbbbbbbbbbb",
        "description": "",
        "url": "http://pypi.python.org/pypi/Aaaaaaaaaaaaaaaaaaa-aaaaaaaaa-aaaaaaasa-aaaaaaasa-aaaaasaa-aaaaaaasa-bbbbbbbbbbb",
        "summary": "",
        "command": "pip install 'Aaaaaaaaaaaaaaaaaaa-aaaaaaaaa-aaaaaaasa-aaaaaaasa-aaaaasaa-aaaaaaasa-bbbbbbbbbbb'"
      },
      "aaargh": {
        "name": "aaargh",
        "description": "******\nAaargh\n******\n\n*Aaargh*: an astonishingly awesome application argument helper.\n\n*Aaargh* is a Python module that makes building friendly command line\napplications really easy. Applications built with *Aaargh* provide a single\nexecutable with a subcommand for each exposed Python function. Each subcommand\nmay have its own command line arguments. This is similar to the way version\ncontrol systems provide multiple commands using a single entry point. (Examples\ninclude ``bzr commit`` and ``git checkout``).\n\n*Aaargh* is named after one of the castles in the movie *Monty Python and the\nHoly Grail*. The acronym *Aaargh* stands for *an astonishingly awesome\napplication argument helper*, but omits a few letters to make it triple A.\n\n*Aaargh* is compatible with both Python 2.6+ and Python 3.\n\n\nRationale\n=========\n\nThe Python standard library contains the *optparse*, *getopt*, and *argparse*\nmodules, and out in the wild you will find many alternative command line\ninterface libraries stacked on top of these, such as *cliff*, *cement*,\n*opster*, *plac*, and many others. Some of these libraries separate the command\nline interface setup of your application from the actual code, some force yet\nanother argument parsing API upon you, some force you to hide your code in\nnon-obvious framework constructs, and some even add dependencies on other\nmodules.\n\nThis makes you scream *aaargh*. And, lo and behold, here it is!\n\n\nUsage\n=====\n\n*Aaargh* delegates almost all of its work to the `argparse` module, which does\na great job handling arguments and printing usage information. However,\n`argparse` is a bit verbose and cumbersome for many simple applications, so\n*Aaargh* lets application authors minimize boilerplate code by wrapping\ncommonly used `argparse` features in a few non-intrusive decorators. *Aaargh*\ndoes not hide the `argparse` API, since the decorators have *exactly the same\nAPI* as their `argparse` counterparts. This is a deliberate design decision,\nand this is what makes *Aaargh* different from its many alternatives.\n\nThe docstrings in the `aaargh.py` file contain all information you need to use\n*Aaargh*. Refer to the `argparse` documentation for information on specifying\narguments, providing defaults, adding help texts, and so on.\n\n\nExample\n=======\n\nA simple command line application that exposes a few functions looks like\nthis::\n\n   #!/usr/bin/env python\n\n   import aaargh\n\n   app = aaargh.App(description=\"A simple greeting application.\")\n\n   # Application level arguments:\n   app.arg('--name', help=\"Name of the person to greet\", default=\"stranger\")\n\n   # Application level defaults:\n   app.defaults(name=\"visitor\")  # overrides \"stranger\"\n\n\n   @app.cmd\n   def hello(name):  # application level \"name\" argument is always passed\n       print(\"Hello, world!\")\n\n\n   @app.cmd(name=\"hi\", help=\"Say hi\")  # override subcommand name\n   @app.cmd_arg('-r', '--repeat', type=int, default=1, help=\"How many times?\")\n   def say_hi(name, repeat):  # both application and subcommand args\n       for i in range(repeat):\n           print(\"Hi, %s!\" % name)\n\n\n   @app.cmd\n   @app.cmd_defaults(name=\"my friend\")  # overrides \"visitor\" for this command only\n   def greetings(name):\n       print(\"Greetings, %s.\" % name)\n\n\n   @app.cmd(alias='bye')  # Allow \"bye\" aswell as goodbye\n   def goodbye(name):\n       print(\"Goodbye, cruel world!\")\n\n\n   if __name__ == '__main__':\n       app.run()\n\nThe command line interface for this application behaves like this::\n\n   $ ./example.py hello\n   Hello, world!\n\n   $ ./example.py hi --repeat=3\n   Hi, visitor!\n   Hi, visitor!\n   Hi, visitor!\n\n   $ ./example.py --help\n   usage: example.py [-h] [--name NAME] {hello,hi,greetings} ...\n\n   A simple greeting application.\n\n   optional arguments:\n     -h, --help            show this help message and exit\n     --name NAME           Name of the person to greet\n\n   Subcommands:\n     {hello,hi,greetings}\n       hello\n       hi                  Say hi\n       greetings\n\n   $ ./example.py hi --help\n   usage: example.py hi [-h] [-r REPEAT]\n\n   optional arguments:\n     -h, --help            show this help message and exit\n     -r REPEAT, --repeat REPEAT\n                           How many times?\n\n\nInstallation\n============\n\nInstallation using `pip` is trivial, especially when using `virtualenv`::\n\n   (yourenv) $ pip install aaargh\n\nAfter succesful installation, this should work::\n\n   (yourenv) $ python\n   >>> import aaargh\n   >>> help(aaargh)\n\n.. note:\n\n   For Python 2.6 you also need to install the `argparse` module.\n\n\nHistory\n=======\n\nVersion 0.7.1 (2014-03-13)\n--------------------------\n\n* Include licensing file in source distribution (issue #9, issue #13)\n\nVersion 0.7 (2014-02-18)\n------------------------\n\n* Add basic support for command aliases packaging (issue #4, issue #10)\n\nVersion 0.6 (2014-02-16)\n------------------------\n\n* No longer use `pbr` for packaging (issue #12)\n* Add proper licensing file (issue #9)\n* Fix error message when calling the program without a subcommand under Python 3\n\nVersion 0.5 (2013-09-23)\n------------------------\n\n* No longer add global args to subcommands  (issues #3 and #5)\n* Switch to `pbr` for packaging\n\nVersion 0.4 (2012-10-17)\n------------------------\n\n* Fix automatic `argparse` dependency installation when using `pip install` with\n  Python 2.6.\n\nVersion 0.3 (2012-06-10)\n------------------------\n\n* Also accept global args after the subcommand\n\nVersion 0.2 (2012-05-17)\n------------------------\n\n* Add support for Python 3\n\nVersion 0.1 (2012-05-17)\n------------------------\n\n* Initial release\n\n\n.. image:: https://d2weczhvl823v0.cloudfront.net/wbolster/aaargh/trend.png\n   :alt: Bitdeli badge\n   :target: https://bitdeli.com/free",
        "url": "http://pypi.python.org/pypi/aaargh",
        "summary": "An astonishingly awesome application argument helper",
        "command": "pip install 'aaargh'"
      },
      "aadict": {
        "name": "aadict",
        "description": "=================================\n(Yet Another) Auto-Attribute Dict\n=================================\n\nAn ``aadict`` is a python dict sub-class that allows attribute-style\naccess to dict items, e.g. ``d.foo`` is equivalent to ``d['foo']``.\n``aadict`` also provides a few other helpful methods, such as ``pick``\nand ``omit`` methods. Also, an ``aadict`` is more call chaining\nfriendly (e.g. methods such as `update` return ``self``) and is\npickle'able.\n\n\nProject\n=======\n\n* Homepage: https://github.com/metagriffin/aadict\n* Bugs: https://github.com/metagriffin/aadict/issues\n\n\nTL;DR\n=====\n\nInstall:\n\n.. code-block:: bash\n\n  $ pip install aadict\n\nUse:\n\n.. code-block:: python\n\n  from aadict import aadict\n\n  # attribute access\n  d = aadict(foo='bar', zig=87)\n  assert d.foo == d['foo'] == 'bar'\n\n  # helper methods\n  assert d.pick('foo') == {'foo': 'bar'}\n  assert d.omit('foo') == {'zig': 87}\n\n  # method chaining\n  d2 = aadict(x='y').update(d).omit('zig')\n  assert d2.x == 'y' and d2.foo == 'bar' and d2.zig is None\n\n  # converting a dict to an aadict recursively\n  d3 = aadict.d2ar(dict(foo=dict(bar='zig')))\n  assert d3.foo.bar == 'zig'\n\n\nDetails\n=======\n\nThe aadict module provides the following functionality:\n\n\naadict\n------\n\nAn `aadict` object is basically identical to a `dict` object, with the\nexception that attributes, if not reserved for other purposes, map to\nthe dict's items. For example, if a dict ``d`` has an item ``'foo'``,\nthen a request for ``d.foo`` will return that item lookup. aadicts\nalso have several helper methods, for example ``aadict.pick``. To\nfetch the value of an item that has the same name as one of the helper\nmethods you need to reference it by item lookup,\ni.e. ``d['pick']``. The helper methods are:\n\n* **aadict.pick** instance method:\n\n  Returns a new aadict, reduced to only include the specified\n  keys. Example:\n\n  .. code-block:: python\n\n    d = aadict(foo='bar', zig=87, zag=['a', 'b'])\n    assert d.pick('foo', 'zag') == {'foo': 'bar', 'zag': ['a', 'b']}\n\n* **aadict.omit** instance method:\n\n  Identical to the ``aadict.pick`` method, but returns the complement,\n  i.e. all of those keys that are *not* specified. Example:\n\n  .. code-block:: python\n\n    d = aadict(foo='bar', zig=87, zag=['a', 'b'])\n    assert d.omit('foo', 'zag') == {'zig': 87}\n\n* **aadict.d2ar** class method:\n\n  Recursively converts the supplied `dict` to an `aadict`, including\n  all sub-list and sub-dict types. Due to being recursive, but only\n  copying dict-types, this is effectively a hybrid of a shallow and\n  a deep clone. Example:\n\n  .. code-block:: python\n\n    d = aadict.d2ar(dict(foo=dict(bar='zig')))\n    assert d.foo.bar == 'zig'\n\n  Without the recursive walking, the ``.bar`` attribute syntax\n  would yield an AttributeError exception because d.foo would\n  reference a `dict` type, not an `aadict`.\n\n* **aadict.d2a** class method:\n\n  Converts the supplied `dict` to an `aadict`. Example:\n\n  .. code-block:: python\n\n    d = aadict.d2a(dict(foo='bar'))\n    assert d.foo == d['foo'] == 'bar'\n\n  Note that this is identical to just using the constructor,\n  but is provided as a symmetry to the ``aadict.d2ar`` class\n  method, e.g.:\n\n  .. code-block:: python\n\n    d = aadict(dict(foo='bar'))\n    assert d.foo == d['foo'] == 'bar'",
        "url": "http://pypi.python.org/pypi/aadict",
        "summary": "An auto-attribute dict (and a couple of other useful dict functions)",
        "command": "pip install 'aadict'"
      },
      "aadishgarg": {
        "name": "aadishgarg",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aadishgarg",
        "summary": "prints nested lists",
        "command": "pip install 'aadishgarg'"
      },
      "aafigure": {
        "name": "aafigure",
        "description": "This package provides a module ``aafigure``, that can be used from other\nprograms, and a command line tool ``aafigure``.\n\nExample, test.txt::\n\n            +-----+   ^\n            |     |   |\n        --->+     +---o--->\n            |     |   |\n            +-----+   V\n\nCommand::\n\n    aafigure test.txt -t svg -o test.svg\n\nPlease see README.txt for examples.",
        "url": "http://pypi.python.org/pypi/aafigure",
        "summary": "ASCII art to image converter",
        "command": "pip install 'aafigure'"
      },
      "aaltopoiju": {
        "name": "aaltopoiju",
        "description": "Unofficial parser for aaltopoiju.fi\n===================================\n\nThis is screen scraper for aaltopoiju.fi website. Please check terms and conditions before using.\n\nInstallation\n------------\n\n::\n\n  pip install aaltopoiju",
        "url": "http://pypi.python.org/pypi/aaltopoiju",
        "summary": "Screen scraper for aaltopoiju.fi",
        "command": "pip install 'aaltopoiju'"
      },
      "aam": {
        "name": "aam",
        "description": "All About \"All about me\"\n----------------\n\nAam means \"All about me\". It is a lightweight about me site generator. To compare with blog, Aam is for pages not posts. So you can use it to build your own pages to introduce everything about you.\n\nInstallation\n===============\n\nRequirements:\n\n* Jinja2\n* Mistune\n* Pygments\n* Parguments\n\nInstall Aam with pip ::\n\n    $ (sudo) pip install aam\n\nOr you can install with Git ::\n\n    $ git clone git://github.com/JmPotato/Aam\n    $ cd Aam\n    $ (sudo) python setup.py install\n\n\nUsage\n===============\n\nFirst, you need to creat a new site ::\n\n    $ mkdir site\n    $ cd site\n    $ aam init\n\nThen, edit the config file ::\n\n    $ vim config.ini\n\nYou need to build a home page befor writing a page. A home page is like this ::\n\n    title: Welcome\n    date: 2014.7.1\n    type: home\n    ----\n\n    Weclome to Aam!\n\nWrite a page like this and save it to `Hello.md` ::\n\n    title: Hello World\n    date: 2014.7.1\n    description: The first page\n    type: page\n    ----\n\n    Hello, World!\n\nBuild your about me site ::\n\n    $ aam build\n\nNotice\n===============\n\nEvery page file needs to have all the metas, it includes\n\n* title\n* date\n* description\n* type\n\nIf you miss any one of them, your site will be incomplete.",
        "url": "http://pypi.python.org/pypi/aam",
        "summary": "a lightweight about me site generator",
        "command": "pip install 'aam'"
      },
      "aamnotifs": {
        "name": "aamnotifs",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aamnotifs",
        "summary": "Simple notifications implementation with RabbitMQ using pika.",
        "command": "pip install 'aamnotifs'"
      },
      "aamoer": {
        "name": "aamoer",
        "description": "Moer dada\n=============\nSpecify some function and an iterable of iterables\n(like a list of lists), where the inner iterable is\na row in a data table.\n\nReceive histograms of the results of those functions.\nYou receive one histogram per function per column.\nThat is, if each row is eight long and you pass two\nfunctions, you'll get 16 histograms.\n",
        "url": "http://pypi.python.org/pypi/aamoer",
        "summary": "Run statistics on data tables.",
        "command": "pip install 'aamoer'"
      },
      "aangifte": {
        "name": "aangifte",
        "description": "op datum ... doet bij de politie te ... aangifte:\n\n Naam                        : \n\n Voornamen                   : \n\n Geboortedatum               : \n\n Adres                       : \n\n Woonplaats                  : \n\n Postcode                    : \n\n Telefoon                    : \n\n\ntegen de verdachte:\n\n\n Naam                        : \n\n Voornaam/initialen en titel : \n\n Geboortedatum               : \n\n Adres                       : \n\n Woonplaats                  : \n\n Postcode                    : \n\n Functie                     : \n\n Werkgever                   : \n\n\n\n Datum/tijdstip plegen feit: van ... tot ...\n\n Plaats van het feit : \n\n Omschrijving incident feit:  \n\n  1) Antipsychotica blokkeren de receptoren en benadelen daarmee de gezondheid.\n  2) Men dient de antipsychotica ook toe voor het blokkeren van de receptoren, opzettelijke benadeling van de gezondheid.\n  3) Behandeling met antipsychotica is langdurige opzettelijke benadeling van de gezondheid.\n\n Aankruisen welk artikel en wet van toepassing is.\n\n  [x] Mishandeling  - Wetboek van Strafrecht 300 lid 4 \n\n Ik verzoek om een bewijs van aangifte.\n\n Naam aangever:  ...\n\n\n Handtekening: \n\n    ...",
        "url": "http://pypi.python.org/pypi/aangifte",
        "summary": "AANGIFTE - Men dient de antipsychotica ook toe voor het blokkeren van de receptoren, opzettelijke benadeling van de gezondheid.",
        "command": "pip install 'aangifte'"
      },
      "Aap": {
        "name": "aap",
        "description": "The Aap program executes recipes. It is a kind of super-make program. In a\r\nrecipe you describe how to perform a certain task. Like a Makefile it contains\r\ndependencies and build commands. Additionally, many powerful features are\r\nincluded, such as automatic dependency checking, using signatures in addition to\r\ntime stamps, automatic downloading of files, publishing files on the internet\r\nand much more.  Implemented in Python and Python can be used in build commands.",
        "url": "http://pypi.python.org/pypi/Aap",
        "summary": "A portable build tool (make replacement) with internet support",
        "command": "pip install 'Aap'"
      },
      "aarddict": {
        "name": "aarddict",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aarddict",
        "summary": "Aard Dictionary is a multiplatform dictionary and offline Wikipedia reader.",
        "command": "pip install 'aarddict'"
      },
      "aardtools": {
        "name": "aardtools",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aardtools",
        "summary": "Tools to create dictionaries in aarddict format.",
        "command": "pip install 'aardtools'"
      },
      "Aaron": {
        "name": "aaron",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Aaron",
        "summary": "Nice function composition",
        "command": "pip install 'Aaron'"
      },
      "AarontestAaron": {
        "name": "aarontestaaron",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AarontestAaron",
        "summary": "a",
        "command": "pip install 'AarontestAaron'"
      },
      "aarpy": {
        "name": "aarpy",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aarpy",
        "summary": "Python Connector for AutomaticApiRest",
        "command": "pip install 'aarpy'"
      },
      "aasms": {
        "name": "aasms",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aasms",
        "summary": "aaisp.net SMS interface",
        "command": "pip install 'aasms'"
      },
      "aatree": {
        "name": "aatree",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aatree",
        "summary": "simplified variant of the red-black balanced binary search tree",
        "command": "pip install 'aatree'"
      },
      "ab": {
        "name": "ab",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ab",
        "summary": "Manage your address book.",
        "command": "pip install 'ab'"
      },
      "ab2cb": {
        "name": "ab2cb",
        "description": "",
        "url": "http://pypi.python.org/pypi/ab2cb",
        "summary": "",
        "command": "pip install 'ab2cb'"
      },
      "aba": {
        "name": "aba",
        "description": "python-aba\n==========\n\nThis is a tiny Python library for generating ABA/Cemtext/Direct Entry files\nused by Australian banks for bulk payments.\n\nUsage\n-----\nSee example below.\n\n.. code:: python\n\n    import datetime\n    from aba.generator import AbaFile\n    from aba import records\n\n    header = records.DescriptiveRecord(\n        user_bank='NAB',\n        user_name='AJAX CRACKERS',\n        user_number=12345,\n        description='SALARIES',\n        date=datetime.date(day=05, month=02, year=2000)\n    )\n\n    entry = records.DetailRecord(\n        bsb='123-456',\n        account_number='123456',\n        txn_code=53,\n        amount=4242,\n        payee_name='HACKER, J. RANDOM',\n        lodgment_ref='RANDOM PAYMENT',\n        sender_bsb='987-654',\n        sender_account='445566777',\n        remitter_name='AJAX CRACKERS',\n    )\n\n    aba_file = AbaFile(header)\n    aba_file.add_record(entry)\n    print aba_file.render_to_string()",
        "url": "http://pypi.python.org/pypi/aba",
        "summary": "Python library to generate ABA (Cemtext) files.",
        "command": "pip install 'aba'"
      },
      "abacus": {
        "name": "abacus",
        "description": "======\nabacus\n======\n\nHelper library for Tornado web framework",
        "url": "http://pypi.python.org/pypi/abacus",
        "summary": "Helper Library for Tornado Web Framework",
        "command": "pip install 'abacus'"
      },
      "abakaffe-cli": {
        "name": "abakaffe-cli",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abakaffe-cli",
        "summary": "A CLI for the Abakus Coffee API",
        "command": "pip install 'abakaffe-cli'"
      },
      "AbakaffeNotifier": {
        "name": "abakaffenotifier",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AbakaffeNotifier",
        "summary": "Notifies phone when Abakaffe is ready.",
        "command": "pip install 'AbakaffeNotifier'"
      },
      "abalone": {
        "name": "abalone",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abalone",
        "summary": "Abalone strategy game",
        "command": "pip install 'abalone'"
      },
      "abaparser": {
        "name": "abaparser",
        "description": "# ABA Parser/Reporter in Python #\n\nABA (Australian Bankers Association or Cemtext file format) is the standard format all Australian online banks accept. This is an archaic fixed file format, and it's hard to eye-ball for correctness.\n\nThis script serves currently serves 2 purposes\n\n 1. A python library to parse ABA files.\n 2. A basic command line report of all the debit transactions in the ABA file (I use this to sanity check payments out of Xero)\n\n## Usage ##\n`\n$ python abaparser.py < path/to/FILE.ABA\n`\n\nThe output will be something like this\n\n```\nContractors\n012-327\t293353749\tJohn Doe\tContractor Payment\t1220.00\n082-406\t598209320\tJane Doe\tContractor Payment\t6600.00\n```",
        "url": "http://pypi.python.org/pypi/abaparser",
        "summary": "UNKNOWN",
        "command": "pip install 'abaparser'"
      },
      "abb": {
        "name": "abb",
        "description": null,
        "url": "http://pypi.python.org/pypi/abb",
        "summary": "A non-blocking Application Backend Boilerplate (Tornado, SPARQLTools and PyLD)",
        "command": "pip install 'abb'"
      },
      "ABBA": {
        "name": "abba",
        "description": "Tools for statistical analysis of A/B test results.\n\nABBA provides several statistical tools for analysis of binomial data, typically resulting from A/B\ntests:\n\n* Wald and Agresti-Coull confidence intervals on binomial proportions\n* Confidence intervals on the difference and ratio of two binomial proportions\n* Hypothesis tests for inequality of two binomial proportions\n* Multiple test correction for control of familywise error rate\n\nSome simple example usage::\n\n    >>> import abba.stats\n    >>> abba.stats.confidence_interval_on_proportion(\n    ...     num_successes=50, num_trials=200, confidence_level=0.99)\n    ValueWithInterval(value=0.25, lower_bound=0.17962262748069852, upper_bound=0.33643200973247306)\n\n    >>> experiment = abba.stats.Experiment(\n    ...     num_trials=5, baseline_num_successes=50, baseline_num_trials=200)\n    >>> results = experiment.get_results(num_successes=70, num_trials=190)\n    >>> results.relative_improvement\n    ValueWithInterval(value=0.4736842105263157, lower_bound=-0.014130868125315277, upper_bound=0.90421878236700903)\n    >>> results.two_tailed_p_value\n    0.047886616311815511\n\n\nABBA requires SciPy for underlying statistical functions.\n\nFor more info, see the docstrings, unit tests, and the ABBA website (including an interactive\nJavascript version) at http://www.thumbtack.com/labs/abba/.",
        "url": "http://pypi.python.org/pypi/ABBA",
        "summary": "Tools for statistical analysis of A/B test results",
        "command": "pip install 'ABBA'"
      },
      "Abbas": {
        "name": "abbas",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Abbas",
        "summary": "A simple printer of lists",
        "command": "pip install 'Abbas'"
      },
      "abbreviate": {
        "name": "abbreviate",
        "description": "Abbreviate\n==========\n\nThis filter attempts to automatically and intelligently abbreviate strings.\n\nThis library contains a dictionary of known abbreviations. Some words have\nmultiple abbreviations, e.g. Thursday could be abbreviated as any of Thurs,\nThur, Thr, Th, or T depending on context. With no other information, each word\nhas a \"preferred abbreviation\" (Thr), however options can push things one way\nor another. For words without known abbreviations, a series of heuristics are\napplied to shorten them as needed.\n\nThe basic `abbreviate` method will only apply preferred abbreviations and\nno heuristics. For more advanced applications, the library can be given a\ntarget length and effort, and will attempt to generate the best string\npossible. Length can be supplied either as a simple character count, or with a\ncustom length function. The latter is useful in many graphics applications\nwithout monospaced fonts or constant kerning. By default, abbreviate will not\nshorten any exisiting abbreviations (e.g. Thur -> Th), assuming that any\nexplicit abbreviation was passed as such for a reason.\n\nIssues, updates, pull requests, etc should be directed\n`to github <https://github.com/ppannuto/python-abbreviate`__.\n\n\nState\n-----\n\nThis tool was written to scratch an immediate itch and is thus quite\nincomplete, but with extensibility and somewhat grander ideas in mind.\nArchitectural thoughts, radical changes to methodology, or just greater\nabbreviations are all welcome.\n\nInstallation\n------------\n\nThe easiest method is to simply use pip:\n\n::\n\n    (sudo) pip install abbreviate\n\nUsage\n-----\n\nTODO",
        "url": "http://pypi.python.org/pypi/abbreviate",
        "summary": "Automatically abbreviate text",
        "command": "pip install 'abbreviate'"
      },
      "ABBYY": {
        "name": "abbyy",
        "description": "=====\nABBYY\n=====\n\nThis package contain a wrapper to the ABBYY Cloud OCR API <http://ocrsdk.com/documentation/apireference/> and some helper functions.\n\nEXAMPLE\n=======\n\n    >>> from ABBYY import CloudOCR\n    >>> ocr_engine = CloudOCR(application_id='YOUR_ABBYY_APPLICATION_ID', password='YOUR_ABBY_APPLICATION_PASSWORD')\n    >>> pdf = open('budget1988.pdf', 'rb')\n    >>> file = {pdf.name: pdf}\n    >>> result = ocr_engine.process_and_download(file, exportFormat='xml,pdfTextAndImages', language='French')\n    >>> result\n    {'xml': <_io.BytesIO object at 0x2e2e290>, 'pdfSearchable': <_io.BytesIO object at 0x2e2e2f0>}\n\nINSTALLATION\n============\n\n    $ pip install ABBYY",
        "url": "http://pypi.python.org/pypi/ABBYY",
        "summary": "ABBYY Cloud OCR API Wrapper.",
        "command": "pip install 'ABBYY'"
      },
      "ABC": {
        "name": "abc",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ABC",
        "summary": "UNKNOWN",
        "command": "pip install 'ABC'"
      },
      "abc1": {
        "name": "abc1",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abc1",
        "summary": "a list about my think",
        "command": "pip install 'abc1'"
      },
      "abclinuxuapi": {
        "name": "abclinuxuapi",
        "description": "Introduction\n============\n\n.. image:: https://badge.fury.io/py/abclinuxuapi.png\n    :target: https://pypi.python.org/pypi/abclinuxuapi\n\n.. image:: https://img.shields.io/pypi/dm/abclinuxuapi.svg\n    :target: https://pypi.python.org/pypi/abclinuxuapi\n\n.. image:: https://readthedocs.org/projects/abclinuxuapi/badge/?version=latest\n    :target: http://abclinuxuapi.readthedocs.org/\n\n.. image:: https://img.shields.io/pypi/l/abclinuxuapi.svg\n\n.. image:: https://img.shields.io/github/issues/Bystroushaak/abclinuxuapi.svg\n    :target: https://github.com/Bystroushaak/abclinuxuapi/issues\n\nThis module contains basic API for crawling the http://abclinuxu.cz website.\n\nInstallation\n------------\nModule is hosted at `PYPI <https://pypi.python.org/pypi/abclinuxuapi/>`_, and\ncan be installed using `PIP <http://en.wikipedia.org/wiki/Pip_%28package_manager%29>`_:\n\n::\n\n    pip install abclinuxuapi\n\nDocumentation\n-------------\nFull module documentation is hosted at ReadTheDocs:\nhttp://abclinuxuapi.readthedocs.org\n\nDisclaimer\n----------\nThe API was made by me (Bystroushaak) and it is not officially related to the\nhttp://abclinuxu.cz project.\n\nChangelog\n=========\n\n0.4.1\n-----\n    - Fixed bugs in uploader.\n\n0.4.0\n-----\n    - Added badges to README.\n    - ``Blogpost.comments`` are now by default blank list instead of None.\n\n0.3.11\n------\n    - Added a lot of documentation, fixed docstrings and so on.\n    - ``User.has_blog()`` changed to `bool` property ``User.has_blog``.\n    - ``Concept`` class refactored.\n    - Added new parameter ``data`` for ``shared.download()``.\n    - ``User.ts_to_concept_date`` moved to ``shared.ts_to_concept_date()``.\n\n0.3.7 - 0.3.10\n--------------\n    - Fixed #7 - blogs with opening HTML comments in perex.\n    - Fixed bug in ``Blogpost._parse_content_tag()``.\n    - Another attempt to solve shit in old blogs. There are missing tags, crossed tags and a lot of other shitfucks.\n    - Fixed bug caused by http://abclinuxu.cz/blog/Mostly_IMDB/2008/6/radeon-hd-4850-a-tak-vubec#17\n\n0.3.0 - 0.3.6\n-------------\n    - Added parsing of comments under blogposts.\n    - Fixed bugs.\n    - Fixed bugs in user.py.\n    - Added ``iter_blogposts()``, ``first_blog_page()`` functions for browsing the bloglist.\n    - Implemented ``Blogpost.get_image_urls()``.\n    - Added date_izolator(). Fixed bugs in comments parsing with relative dates.\n    - Fixed bug in parsing of Blogpost's content.\n    - Added blog iterator tor User object.\n    - Fixed #4 - bug in username parsing.\n    - Fixed parsing of censored comments.\n    - Added ``Comment.censored``.\n    - ``Comment.registered_user`` renamed to ``Comment.registered``.\n    - Fixed bug which skipped censored comments.\n    - Fixed problems with old blogs (different HTML).\n    - Implemented #6: ``.__repr__()`` for all important classes.\n\n0.2.0\n-----\n    - Added a lot of features.\n    - Fixed broken setup.py.\n\n0.1.0\n-----\n    - Created.\n    - It can be now used to read data from the abclinuxu, but it is incomplete and it will need a lot of work to do.",
        "url": "http://pypi.python.org/pypi/abclinuxuapi",
        "summary": "API for http://abclinuxu.cz.",
        "command": "pip install 'abclinuxuapi'"
      },
      "abcpmc": {
        "name": "abcpmc",
        "description": "=============================\nabcpmc\n=============================\n\n.. image:: https://badge.fury.io/py/abcpmc.png\n    :target: http://badge.fury.io/py/abcpmc\n\n.. image:: https://travis-ci.org/jakeret/abcpmc.png?branch=master\n        :target: https://travis-ci.org/jakeret/abcpmc\n        \n.. image:: https://coveralls.io/repos/jakeret/abcpmc/badge.png?branch=master\n        :target: https://coveralls.io/r/jakeret/abcpmc?branch=master\n\n.. image:: http://img.shields.io/badge/arXiv-1504.07245-orange.svg?style=flat\n        :target: http://arxiv.org/abs/1504.07245\n\n\n\nA Python Approximate Bayesian Computing (ABC) Population Monte Carlo (PMC) implementation based on Sequential Monte Carlo (SMC) with Particle Filtering techniques.\n\n.. image:: https://raw.githubusercontent.com/jakeret/abcpmc/master/docs/abcpmc.png\n   :alt: approximated 2d posterior (created with triangle.py).\n   :align: center\n\nThe **abcpmc** package has been developed at ETH Zurich in the `Software Lab of the Cosmology Research Group <http://www.cosmology.ethz.ch/research/software-lab.html>`_ of the `ETH Institute of Astronomy <http://www.astro.ethz.ch>`_. \n\nThe development is coordinated on `GitHub <http://github.com/jakeret/abcpmc>`_ and contributions are welcome. The documentation of **abcpmc** is available at `readthedocs.org <http://abcpmc.readthedocs.org/>`_ and the package is distributed over `PyPI <https://pypi.python.org/pypi/abcpmc>`_.\n\nFeatures\n--------\n\n* Entirely implemented in Python and easy to extend\n\n* Follows Beaumont et al. 2009 PMC algorithm\n\n* Parallelized with muliprocessing or message passing interface (MPI)\n\n* Extendable with k-nearest neighbour (KNN) or optimal local covariance matrix (OLCM) pertubation kernels (Fillipi et al. 2012)\n\n* Detailed examples in IPython notebooks \n\n\t* A `2D gauss <http://nbviewer.ipython.org/github/jakeret/abcpmc/blob/master/notebooks/2d_gauss.ipynb>`_ case study \n\t\n\t* A `toy model <http://nbviewer.ipython.org/github/jakeret/abcpmc/blob/master/notebooks/toy_model.ipynb>`_ including a comparison to theoretical predictions\n\t\n\t\n\n\n\nDocumentation\n-------------\n\nThe full documentation can be generated with Sphinx\n\n\n\nHistory\n-------\n0.1.1 (2015-05-03)\n++++++++++++++++++\n\n* Python 3 support\n* Minor fixes\n* Improved documentation\n\n0.1.0 (2015-04-28)\n++++++++++++++++++\n\n* First release",
        "url": "http://pypi.python.org/pypi/abcpmc",
        "summary": "approximate bayesian computing with population monte carlo",
        "command": "pip install 'abcpmc'"
      },
      "abcyui": {
        "name": "abcyui",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abcyui",
        "summary": "Sorry ,This is practice!",
        "command": "pip install 'abcyui'"
      },
      "abduct": {
        "name": "abduct",
        "description": "Abduct |Version| |Build| |Coverage| |Health|\n============================================\n\n|Compatibility| |Implementations| |Format| |Downloads|\n\nCapture stdout/stderr and optionally release when an exception occurs.\n\n.. code:: python\n\n    from abduct import captured, out, err\n\n    with captured(out()) as stdout:\n        ...\n\n    with captured(out(), err()) as (stdout, stderr):\n        ...\n\n    @captured(out(), err())\n    ...\n\n\nInstallation:\n\n.. code:: console\n\n    $ pip install abduct\n\n\nWhen stdout or stderr is captured, the related ``sys.stdout`` or\n``sys.stderr`` object is replaced with a ``StringIO`` object for the\nlife of the context.\n\n\nExamples\n--------\n\nIt's often useful to capture the output of a block of code. Abduct\nmakes this easy:\n\n.. code:: python\n\n    with captured(out()) as stdout:\n        print('hello!')\n\n    assert stdout.getvalue() == 'hello!'\n\n\nSometimes you may want to hide the output of some code *unless*\nsomething goes wrong. In this case, simply specify\n``release_on_exception=True``:\n\n.. code:: python\n\n    with captured(out(release_on_exception=True)):\n        print('Really important message!')\n        if blow_up:\n            raise RuntimeError()\n\n\nIn this case, ``Really important message!`` will be printed on\n``stdout`` if the exception is raised.\n\nIf you'd like to capture the output, but still write through to\n``stdout`` or ``stderr``, use the ``tee=True`` parameter:\n\n.. code:: python\n\n    with captured(err(tee=True)) as stderr:\n        sys.stderr.write('Error!')\n\n    assert stderr.getvalue() == 'Error!'\n\n\nIn this case, ``Error!`` is captured *and* written to ``stderr``\nat the same time.\n\n\nChangelog\n---------\n\n**2.0.1**\n\n- Added tests for the decorator usage.\n\n\n**2.0.0**\n\n- Feature: \"Create a write-through option for output.\"\n- Backwards-incompatible change: ``stdout`` and ``stderr`` methods are now ``out`` and ``err`` respectively.\n\n\n**1.0.4**\n\n- Fixed Travis release criteria.\n\n\n**1.0.3**\n\n- Refactored test runner.\n\n\n**1.0.2**\n\n- Fixed README and description.\n\n\n**1.0.1**\n\n- Travis config now defers to tox.\n- Added examples to README.\n\n\n**1.0.0**\n\n- Actual working code. Yay!\n\n\n**0.0.1**\n\n- Initial release.\n\n\n.. |Build| image:: https://travis-ci.org/themattrix/python-abduct.svg?branch=master\n   :target: https://travis-ci.org/themattrix/python-abduct\n.. |Coverage| image:: https://img.shields.io/coveralls/themattrix/python-abduct.svg\n   :target: https://coveralls.io/r/themattrix/python-abduct\n.. |Health| image:: https://landscape.io/github/themattrix/python-abduct/master/landscape.svg\n   :target: https://landscape.io/github/themattrix/python-abduct/master\n.. |Version| image:: https://pypip.in/version/abduct/badge.svg?text=version\n   :target: https://pypi.python.org/pypi/abduct\n.. |Downloads| image:: https://pypip.in/download/abduct/badge.svg\n   :target: https://pypi.python.org/pypi/abduct\n.. |Compatibility| image:: https://pypip.in/py_versions/abduct/badge.svg\n   :target: https://pypi.python.org/pypi/abduct\n.. |Implementations| image:: https://pypip.in/implementation/abduct/badge.svg\n   :target: https://pypi.python.org/pypi/abduct\n.. |Format| image:: https://pypip.in/format/abduct/badge.svg\n   :target: https://pypi.python.org/pypi/abduct\n",
        "url": "http://pypi.python.org/pypi/abduct",
        "summary": "Capture stdout/stderr and optionally release when an exception occurs.",
        "command": "pip install 'abduct'"
      },
      "Abe": {
        "name": "abe",
        "description": "Abe reads the Bitcoin block chain from disk, loads\nit into a database, indexes it, and provides a web interface to search\nand navigate it.  Abe works with several Bitcoin-derived currencies,\nincluding Namecoin and LiteCoin.\n\nAbe draws inspiration from Bitcoin Block Explorer (BBE,\nhttp://blockexplorer.com/) and seeks some level of compatibility with\nit but uses a completely new implementation.",
        "url": "http://pypi.python.org/pypi/Abe",
        "summary": "Abe: a free block chain browser for Bitcoin-based currencies.",
        "command": "pip install 'Abe'"
      },
      "abe-mocks": {
        "name": "abe-mocks",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abe-mocks",
        "summary": "Parse ABE files for usage within python tests",
        "command": "pip install 'abe-mocks'"
      },
      "abe-python": {
        "name": "abe-python",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abe-python",
        "summary": "Parse ABE files for usage within python tests",
        "command": "pip install 'abe-python'"
      },
      "aberdeen": {
        "name": "aberdeen",
        "description": "\nAberdeen\n========\n\nSimple python script for taking a directory of markdown files and\ngenerating/storing the backend of a blog.\n\nThe goal is to enable quick editing of simple text-files and posting them to a\ndatabase via a push to a git branch (default 'publish').\n\nUpon running, a python JSON object is created from each file found. There is a\nmarkdown header extracted from the file indicating post title, date posted,\nauthors, tags, etc. The content of the post is converted automatically to html\nand added to the final object in the path.\n\nThe resulting objects (currently) are sent to a MongoDB session and saved to the\nspecified collection.\n\nThis process is strictly a 'model' management system, any view and controller\nmust be built/managed by you.\n\n(The name comes from the \"Aberdeen\" fish hook 🎣)\n\nRequirements\n------------\n\n- `Python 3.4 <https://www.python.org/>`__\n- `Markdown <https://pythonhosted.org/Markdown>`__\n- **Supported Databases**\n    -  mongodb - `asyncio\\_mongo <https://pypi.python.org/pypi/asyncio_mongo>`__\n\nInstallation\n------------\n\nCopy the ``post-update``, ``aberdeen.py`` and config files to the directory\n``hooks`` in the git repository on the server. Edit the config file to your\nspecifications. This will be updated when uploaded to pypi.\n\nServer Setup\n------------\n\nOn your server, create a bare git repository, something like 'blog\\_data'. This\nwill simply hold all your markdown (or maybe *other* type) files. Create a\n'publish' branch in addition to another 'working' one (presumably 'master'). Add\nthe post-update webhook and configuration as explained in Installation. Clone\nthe repo to your working computer.\n\nUsage\n-----\n\nThis program requires a key-value pair header in each of the markdown files that\nhave typical elements required for blogging\n\n::\n\n    ---\n    title : Post Title\n    date  : Mar 15, 2015\n    tags  : Example\n            Feeling Happy\n            XYZ\n    author: Me\n    ---\n\n    # My New Post\n    This is a great post! *All* my markdown works\n\nThe 'tags' attribute in this example will generate a list of strings; for more\ninformation on how the metadata header works, `read this\n<https://pythonhosted.org/Markdown/extensions/meta_data.html>`__.\n\nAberdeen creates a python 'time' object from the 'date' attribute. It will try\nto be smart about the style of the date, and there are a few ways to interpret\nthe datetime from the string, but it has to be accepted in some form or another\nby the `strptime\n<https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior>`__\nfunction of python ‘time’ library. The first way to work will be saved, so it\nrewards consistency. It is recommended you put in a time field if you care about\nthat, else it will default to midnight of the determined date.\n\n*Maybe this can be specified in the config file? (that's not implemented yet.)*\n\nThis kind of information is great for storing in NoSQL databases, so MongoDB is\nthe only database currently supported. The content of the markdown is converted\nto HTML and added to the result as 'html\\_content' field. The objects are sorted\nin terms of date and written to the database. The previous table or collection\nwill dropped and the new items added. (***NO GUARANTEE*** that the items will be\nin the same order).\n\nOther Things\n------------\n\nRemeber this does not have any HTML structure or view-support for a blog. This\nstrictly converts one form of a model (markdown files) to another (database\nentries). The view/controllers are totally up to you for retreiving and\ndisplaying the posts.\n\nAlways assume that the database collection/table will be **erased** upon every\npush. The idea is the database reflects the files, so changing a file will\nreplace that entry in the database. It is recommended to NOT use fixed links to\nposts. It is suggested to used date+title as a unique identifier. Alternatively,\nyou could store a unique post id in the metadata field, if you want some\nassurance that things will be fixed (but it's up to you to keep track of the and\ntheir uniqueness).\n\nLICENSE\n-------\n\nApache 2.0\n",
        "url": "http://pypi.python.org/pypi/aberdeen",
        "summary": "Conversion from markdown files to database entries to use as the backend of a blog",
        "command": "pip install 'aberdeen'"
      },
      "aberquota": {
        "name": "aberquota",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aberquota",
        "summary": "Python3 tool for getting internet usage off the Aberystwyth University network",
        "command": "pip install 'aberquota'"
      },
      "abf": {
        "name": "abf",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abf",
        "summary": "Abstract Binary Format manipulation : elf pe mach-o",
        "command": "pip install 'abf'"
      },
      "abhi": {
        "name": "abhi",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abhi",
        "summary": "UNKNOWN",
        "command": "pip install 'abhi'"
      },
      "abifpy": {
        "name": "abifpy",
        "description": "======\nABIFPY\n======\n\n-----------------------------------------------------------\nPython module for reading ABI Sanger sequencing trace files\n-----------------------------------------------------------\n\nabifpy is a python module that extracts sequence and various other data from\nApplied Biosystem's, Inc. format (ABI) file. The module is python3-compatible\nand was written based on the `official spec`_ released by Applied Biosystems.\n\nA modified version of this module has been merged into the `Biopython \nproject`_, available from version 1.58 onwards. If you already have Biopython\nversion >=1.58, there is no need to use abifpy. Despite that, I am keeping \nthe module available as a stand-alone for personal reasons :).\n\nabifpy provides the following items:\n\n*class* Trace(in_file)\n    Class representing the trace file ``in_file``.\n\nTrace object attributes and methods\n===================================\n\nseq\n    String of base-called nucleotide sequence stored in the file.\n\nqual\n    String of phred quality characters of the base-called sequence.\n\nqual_val\n    List of phred quality values of the base-called sequence.\n\nid\n    String of the sequence file name.\n\nname\n    String of the sample name entered prior to sequencing.\n\ntrim(sequence[, cutoff=0.05])        \n    Returns a trimmed sequence using Richard Mott's algorithm (used in phred)\n    with the probability cutoff of 0.05. Can be used on ``seq``, ``qual``, and\n    ``qual_val``.\n    \nget_data(key)\n    Returns metadata stored in the file, accepts keys from ``tags`` (see below).\n\nexport([out_file=\"\", fmt='fasta'])       \n    Writes a fasta (``fmt='fasta'``), qual (``fmt='qual'``), or \n    fastq (``fmt='fastq'``) file from the trace file. Default format is ``fasta``.\n\nclose()\n    Closes the Trace file object.\n\nseq_remove_ambig(seq)\n    Replaces extra ambigous base characters (K, Y, W, M, R, S) with 'N'. Accepts ``seq``\n    for input.\n\nEXTRACT\n    Dictionary for determining which metadata are extracted.\n\ndata\n    Dictionary that contains the file metadata. The keys are values of ``EXTRACT``.\n\ntags\n    Dictionary of tags with values of data directory class instance. Keys are tag name and \n    tag number, concatenated. Use ``get_data()`` to access values in each ``tags`` entry.\n\nUsage\n=====\n\n::\n\n    $ python\n    >>> from abifpy import Trace\n    >>> yummy = Trace('tests/3730.ab1')\n\nOr if you want to perform base trimming directly::\n    \n    >>> yummy = Trace('tests/3730.ab1', trimming=True)\n\nSequence can be accessed with the ``seq`` attribute. Other attributes of note\nare ``qual`` for phred quality characters, ``qual_val`` for phred quality values,\n``id`` for sequencing trace file name, and ``name`` for the sample name::\n\n    >>> yummy.seq\n    'GGGCGAGCKYYAYATTTTGGCAAGAATTGAGCTCT...\n    >>> yummy.qual\n    '5$%%%\\'%%!!!\\'!+5;726@>A=3824DESHSS...\n    >>> yummy.qual_val\n    [20, 3, 4, 4, 4, 6, 4, 4, 0, 0, 0, 6, 0, 10, 20, 26, 22, 17, 21...\n    >>> yummy.id\n    '3730'\n    >>> yummy.name\n    '226032_C-ME-18_pCAGseqF'\n\nIf trimming was not performed when instantiating, you can still do it afterwards::\n    \n    >>> yummy.trim(yummy.seq)\n\nThe quality values itself can be trimmed as well::\n\n    >>> yummy.trim(yummy.qual)\n\nViewing the trace file metadata is easy. Use the values from ``EXTRACT``\nas the keys in ``data``::\n\n    >>> yummy.data['well']\n    'B9'\n    >>> yummy.data['model']\n    '3730'\n    >>> yummy.data['run start date']\n    datetime.date(2009, 12, 12)\n\nmetadata not contained in ``data`` can be viewed using ``get_data()``\nwith one of the keys in ``tags`` as the argument, e.g.::\n\n    >>> yummy.get_data('PTYP1')\n    '96-well'\n\nFor more info on the meaning of these tags and the file metadata, consult the `official spec`_. \n\nInstallation\n============\n\n* ``pip install abifpy``, or\n\n* Add the abifpy directory to your ``$PYTHONPATH`` (in ``.bashrc`` to make it persistent)\n\nLicense\n=======\n\nabifpy is licensed under the MIT License.\n\nCopyright (c) 2011 by Wibowo Arindrarto <bow@bow.web.id>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n.. _official spec: http://www.appliedbiosystems.com/support/software_community/ABIF_File_Format.pdf\n.. _Biopython project: http://biopython.org/wiki/Biopython",
        "url": "http://pypi.python.org/pypi/abifpy",
        "summary": "abifpy is a module for reading ABI Sanger sequencing trace files.",
        "command": "pip install 'abifpy'"
      },
      "abilian-core": {
        "name": "abilian-core",
        "description": "About\n=====\n\n.. image:: http://jenkins.abilian.com/job/Abilian-Core/badge/icon\n   :target: http://jenkins.abilian.com/job/Abilian-Core/\n\n.. image:: https://api.travis-ci.org/abilian/abilian-core.png\n   :target: https://travis-ci.org/abilian/abilian-core\n\n.. image:: https://coveralls.io/repos/abilian/abilian-core/badge.png?branch=master\n   :target: https://coveralls.io/r/abilian/abilian-core?branch=master\n\n.. image:: https://pypip.in/download/abilian-core/badge.svg?period=month\n    :target: https://pypi.python.org/pypi/abilian-core/\n    :alt: Downloads\n\n\nAbilian Core is an enterprise application development platform based on the `Flask micro-framework <http://flask.pocoo.org/>`_, the `SQLAlchemy ORM <http://www.sqlalchemy.org/>`_, good intentions and best practices (for some value of \"best\").\n\nThe full documentation is available on http://docs.abilian.com/.\n\n\nGoals & principles\n------------------\n\n- Development must be easy and fun (some some definition of \"easy\" and \"fun\", of course)\n\n- The less code (and configuration) we write, the better\n\n- Leverage existing reputable open source libraries and frameworks, such as SQLAlchemy and Flask\n\n- It must lower errors, bugs, project's time to deliver. It's intended to be a rapid application development tool\n\n- It must promote best practices in software development, specially Test-Driven Development (as advocated by the `GOOS book <http://www.amazon.com/gp/product/0321503627/>`_)\n\n\nFeatures\n--------\n\nHere's a short list of features that you may find appealing in Abilian:\n\nInfrastructure\n^^^^^^^^^^^^^^\n\n-  Plugin framework\n\n-  Asynchronous tasks (using `Celery <http://www.celeryproject.org/>`_)\n\n-  Security model and service\n\nDomain model and services\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\n-  Persistent domain object model, based on SQLAlchemy\n\n-  Audit\n\nContent management and services\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n-  Simple file-based content repository\n\n-  Indexing service\n\n-  Document preview and transformation\n\nSocial\n^^^^^^\n\n-  Users, groups and social graph (followers)\n\n-  Activity streams\n\nUser Interface and API\n^^^^^^^^^^^^^^^^^^^^^^\n\n-  Forms (based on `WTForms <http://wtforms.simplecodes.com/>`_)\n\n-  CRUD (Create, Retrieve, Edit/Update, Remove) interface from domain\n   models\n\n-  Labels and descriptions for each field\n\n-  Various web utilities: view decorators, class-based views, Jinja2\n   filters, etc.\n\n-  A default UI based on `Bootstrap 3 <http://getbootstrap.com/>`_ and\n   several carefully selected jQuery plugins such as\n   `Select2 <http://ivaynberg.github.io/select2/>`_\n\n-  REST and AJAX API helpers\n\n-  i8n: support for multi-language via Babel, with multiple translation\n   dictionaries\n\nManagement and admin\n^^^^^^^^^^^^^^^^^^^^\n\n-  Initial settings wizard\n\n-  Admin and user settings framework\n\n-  System monitoring (using `Sentry <https://getsentry.com/welcome/>`_)\n\nCurrent status\n--------------\n\nAbilian Core is currently alpha (or even pre-alpha) software, in terms\nof API stability.\n\nIt is currently used in several applications that have been developped\nby `Abilian <http://www.abilian.com/>`_ over the last two years:\n\n-  [Abilian SBE (Social Business\n   Engine)](https://github.com/abilian/abilian-sbe) - an enterprise 2.0 (social\n   collaboration) platform\n\n-  Abilian EMS (Event Management System)\n\n-  Abilian CRM (Customer / Contact / Community Relationship Management\n   System)\n\n-  Abilian Le MOOC - a MOOC prototype\n\n-  Abilian CMS - a Web CMS\n\nIn other words, Abilian Core is the foundation for a small, but growing,\nfamily of business-critical applications that our customers intend us to\nsupport in the coming years.\n\nSo while Abilian Core APIs, object model and even architecture, may (and\nmost probably will) change due to various refactorings that are expected\nas we can't be expected to ship perfect software on the firt release, we\nalso intend to treat it as a valuable business asset and keep\nmaintaining and improving it in the foreseeable future.\n\nRoadmap & getting involved\n--------------------------\n\nIf you need help or for general discussions about the Abilian Platform, we\nrecommend joing the `Abilian Users\n<https://groups.google.com/forum/#!forum/abilian-users>`_ forum on Google\nGroups.\n\nWe have a `roadmap on Pivotal\nTracker <https://www.pivotaltracker.com/s/projects/878951>`_ that we use\ninternally to manage our iterative delivery process.\n\nFor features and bug requests (or is it the other way around?), we\nrecommend that you use the `GitHub issue\ntracker <https://github.com/abilian/abilian-core/issues>`_.\n\n\nInstall\n=======\n\nIf you are a Python web developer (which is the primary target for this\nproject), you probably already know about:\n\n-  Python 2.7\n-  Virtualenv\n-  Pip\n\nSo, after you have created and activated a virtualenv for the project,\njust run::\n\n    pip install -r requirements.txt\n\nIf you need to work on the project, first install the requirements as above,\nthen type:\n\n    pip install -e '.[dev]'\n\n\nTo use some features of the library, namely document and images\ntransformation, you will need to install the additional native packages,\nusing our operating system's package management tools (``dpkg``,\n``yum``, ``brew``...):\n\n-  A few image manipulation libraries (``libpng``, ``libjpeg``)\n-  The ``poppler-utils``, ``unoconv``, ``LibreOffice``, ``ImageMagick``\n   utilities\n\nLook at the ``fabfile.py`` for the exact list.\n\n\nTesting\n=======\n\nAbilian Core come with a full unit and integration testing suite. You\ncan run it with ``make test`` (once your virtualenv has been activated and\nall required dependencies have been installed, see above).\n\nAlternatively, you can use ``tox`` to run the full test suite in an\nisolated environment.\n\n\nLicence\n=======\n\nAbilian Core is licensed under the LGPL.\n\n\nCredits\n=======\n\nAbilian Core has been created by the development team at Abilian\n(currently: Stefane and Bertrand), with financial support from our\nwonderful customers, and R&D fundings from the French Government, the\nParis Region and the European Union.\n\nWe are also specially grateful to:\n\n-  `Armin Ronacher <http://lucumr.pocoo.org/>`_ for his work on Flask.\n-  `Michael Bayer <http://techspot.zzzeek.org/>`_ for his work on\n   SQLAlchemy.\n-  Everyone who has been involved with and produced open source software\n   for the Flask ecosystem (Kiran Jonnalagadda and the\n   `HasGeek <https://hasgeek.com/>`_ team, Max Countryman, Matt Wright,\n   Matt Good, Thomas Johansson, James Crasta, and probably many others).\n-  The creators of Django, Pylons, TurboGears, Pyramid and Zope, for\n   even more inspiration.\n-  The whole Python community.\n\nLinks\n=====\n\n- `Discussion list (Google Groups) <https://groups.google.com/forum/#!forum/abilian-users>`_\n- `Documentation <http://docs.abilian.com/>`_\n- `GitHub repository <https://github.com/abilian/abilian-core>`_\n- `Corporate support <http://www.abilian.com>`_",
        "url": "http://pypi.python.org/pypi/abilian-core",
        "summary": "A framework for social business (aka Enterprise 2.0) applications, based on Flask and SQLAlchemy",
        "command": "pip install 'abilian-core'"
      },
      "abilian-sbe": {
        "name": "abilian-sbe",
        "description": "About\n=====\n\nAbilian SBE (Social Business Engine) is a platform for developing social business applications, and more specifically collaborative / enterprise 2.0 business applications, such as enterprise social networks (ESN).\n\nIt is based on the `Abilian Core <http://abilian-core.readthedocs.org/en/latest/>`_ project which provide the basic services, on top of Flask and SQLAlchemy.\n\nAbilian SBE adds the concept of *communities*, which are collaborative spaces with services such as lightweight document management, discussions, wikis, user timelines.\n\nAbilian SBE is currently alpha software and evolving quickly. OTOH, it's already used by several major customers in production, since mid 2013.\n\n\nInstall\n=======\n\nPrerequisites (native dependencies)\n-----------------------------------\n\n- Python 2.7, ``virtualenv``, ``pip``\n- `Redis <http://redis.io/>`_\n- Sqlite, or a postgresql database.\n- A few image manipulation libraries (``libpng``, ``libjpeg``...)\n- ``poppler-utils``, ``unoconv``, ``LibreOffice``, ``ImageMagick``.\n- `{Less} <http://lesscss.org/>`__ css pre-processor\n- A Java environment (JRE 1.7 for example). The `closure compiler\n  <https://developers.google.com/closure/compiler/>`_ is used for minifying\n  javascript files. You don't have to install the compiler yourself, but a Java\n  environment is required.\n\nGet a working application\n-------------------------\n\nThe following commands will create a virtualenv for the application,\ninstall a script named ``abilian_sbe``, launch development server and\nopen a setupwizard in your browser:\n\n.. code:: bash\n\n    $ virtualenv sbe\n    $ cd sbe; source bin/activate\n    $ pip install -U setuptools pip\n    $ pip install abilian-sbe\n    $ python -m abilian.sbe.app setup_sbe_app\n\nMAC OS + Homebrew\n-----------------\n\nYou will need to install the following packages using homebrew\n(**before** running ``pip install ...``):\n\n::\n\n    brew install python2.7 jpeg git libmagic poppler imagemagick\n\n\nTesting\n=======\n\nShort test\n----------\n\nMake sure all the dependencies are installed (cf. above), then run ``make\ntest``.\n\nWith coverage\n-------------\n\nRun ``make test-with-coverage``.\n\nFull test suite\n---------------\n\nInstall `tox <http://pypi.python.org/pypi/tox>`_. Run ``tox -e ALL``.\n\n2 environments are available:\n\n- ``py27``: uses in-memory sqlite\n- ``py27_postgres``: uses local postgresql server (you need to first create a\n   database, and user/password; tox uses environment variables\n   ``POSTGRES_HOST``, ``POSTGRES_PORT``, ``POSTGRES_DB``, ``POSTGRES_USER``,\n   ``POSTGRES_PASSWORD``)\n\nRunning with gunicorn\n---------------------\n\n.. code:: bash\n\n    gunicorn 'abilian.sbe.app.create_app()'\n\nBuild Status\n============\n\nThe project is under continuous integration with Travis:\n\n.. image:: https://travis-ci.org/abilian/abilian-sbe.svg?branch=master\n   :target: https://travis-ci.org/abilian/abilian-sbe\n\n.. image:: https://coveralls.io/repos/abilian/abilian-sbe/badge.svg?branch=master\n   :target: https://coveralls.io/r/abilian/abilian-sbe?branch=master\n\nLinks\n=====\n\n- `Discussion list (Google Groups) <https://groups.google.com/forum/#!foru      m/abilian-users>`_\n- `Documentation <http://docs.abilian.com/>`_\n- `GitHub repository <https://github.com/abilian/abilian-sbe>`_\n- `Corporate support <http://www.abilian.com>`_",
        "url": "http://pypi.python.org/pypi/abilian-sbe",
        "summary": "Social Business / Enterprise Social Networking platform",
        "command": "pip install 'abilian-sbe'"
      },
      "abipy": {
        "name": "abipy",
        "description": "The goal of abipy is to create a comprehensive environment for\ninteractive and exploratory computing.  To support this goal,\nabipy provides:\n\n* A set of pythons objects to store the results of the calculations.\n\n* A set of scripts for performing common tasks such as plotting the results\n  of the calculation.\n\nThe latest development version is always available from ...\nsite <http://??>.",
        "url": "http://pypi.python.org/pypi/abipy",
        "summary": "('Set of python modules and scripts to analyze the results of ABINIT computations.',)",
        "command": "pip install 'abipy'"
      },
      "abiquo-api": {
        "name": "abiquo-api",
        "description": "Abiquo API Python Client\n========================\n\nThis is a Python client for the Abiquo API. It allows to consume the API\nin a dynamic way and to navigate its resources using its built-in\nlinking features.\n\nThe project depends on\n`requests <http://docs.python-requests.org/en/latest/>`__ and optionally\non\n`requests\\_oauthlib <https://requests-oauthlib.readthedocs.org/en/latest/>`__,\nif you prefer to use OAuth instead of Basic Authentication.\n\nInstallation\n------------\n\nYou can easily install the module with:\n\n.. code:: bash\n\n    pip install abiquo-api\n\nUsage\n-----\n\nUsing the client is pretty straightforward. Here are some examples:\n\nUsing HTTP Basic Authentication\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThis example shows how to get the list of existing datacenters and how\nto navigate its links to create a rack in each of them:\n\n.. code:: python\n\n    import json\n    from abiquo.client import Abiquo\n\n    api = Abiquo(API_URL, auth=(username, password))\n    code, datacenters = api.admin.datacenters.get(\n        headers={'Accept':'application/vnd.abiquo.datacenters+json'})\n\n    print \"Response code is: %s\" % code\n    for dc in datacenters:\n        print \"Creating rack in datacenter %s [%s]\" % (dc.name, dc.location)\n        code, rack = datacenter.follow('racks').post(\n                data=json.dumps({'name': 'New rack'}),\n                headers={'Accept':'application/vnd.abiquo.rack+json',\n                         'Content-type':'application/vnd.abiquo.rack+json'})\n        print \"Response code is: %s\" % code\n        print \"Created Rack: %s\" % rack.name\n\nNote that you don't need to care about pagination, the client handles it\ninternally for you.\n\nUsing OAuth\n~~~~~~~~~~~\n\nTo use OAuth first you have to register your client application in the\nAbiquo API. To do that, you can use the ``register.py`` script as\nfollows, and it will register the application and generate the access\ntokens:\n\n.. code:: bash\n\n    $ python register.py \n    Abiquo API endpoint: http://localhost/api\n    Username: your-username\n    Password: your-password\n    Application name: My Cool App\n\n    App key: 54e00f27-6995-40e8-aefe-75f76f514d89\n    App secret: eayP6ll3G02ypBhQBmg0398HYBldkf3B5Jqti73Z\n    Access token: c9c9bd44-6812-4ddf-b39d-a27f86bf03da\n    Access token secret: MifYOffkoPkhk33ZTiGOYnIg8irRjw7BlUCR2GUh7IQKv4omfENlMi/tr+gUdt5L8eRCSYKFQVhI4Npga6mXIVl1tCMHqTldYfqUJZdHr0c=\n\nOnce you have the tokens, you just have to create the authentication\nobject and pass it to the Abiquo client as follows:\n\n.. code:: python\n\n    from requests_oauthlib import OAuth1\n    from abiquo.client import Abiquo\n\n    APP_KEY = '54e00f27-6995-40e8-aefe-75f76f514d89'\n    APP_SECRET = 'eayP6ll3G02ypBhQBmg0398HYBldkf3B5Jqti73Z'\n    ACCESS_TOKEN = 'c9c9bd44-6812-4ddf-b39d-a27f86bf03da'\n    ACCESS_TOKEN_SECRET = 'MifYOffkoPkhk33ZTiGOYnIg8irRjw7BlUCR2GUh7IQKv4omfENlMi/tr+gUdt5L8eRCSYKFQVhI4Npga6mXIVl1tCMHqTldYfqUJZdHr0c='\n\n    oauth=OAuth1(APP_KEY,\n            client_secret=APP_SECRET,\n            resource_owner_key=ACCESS_TOKEN,\n            resource_owner_secret=ACCESS_TOKEN_SECRET)\n\n    api = Abiquo(API_URL, auth=oauth)\n\nAnd that's it! Now you can use the Abiquo client as shown in the Basic\nAuthentication examples.\n\nContributing\n------------\n\nThis project is still in an early development stage and is still\nincomplete. All contributions are welcome, so feel free to `raise a pull\nrequest <https://help.github.com/articles/using-pull-requests/>`__.\n\nLicense\n-------\n\nThe Abiquo API Java Client is licensed under the Apache License version\n2. For further details, see the `LICENSE <LICENSE>`__ file.",
        "url": "http://pypi.python.org/pypi/abiquo-api",
        "summary": "Abiquo API Python Client",
        "command": "pip install 'abiquo-api'"
      },
      "Abjad": {
        "name": "abjad",
        "description": "##########\nAbjad 2.16\n##########\n\nAbjad helps composers build up complex pieces of music notation in an iterative\nand incremental way. Use Abjad to create symbolic representations of all the\nnotes, rests, staves, tuplets, beams and slurs in any score. Because Abjad\nextends the `Python`_ programming language, you can use Abjad to make\nsystematic changes to your music as you work. And because Abjad wraps the\npowerful `LilyPond`_ music notation package, you can use Abjad to control the\ntypographic details of the symbols on the page.\n\n..  _LilyPond: http://lilypond.org/\n..  _Python: https://www.python.org/\n\n`GitHub`_ |\n`PyPI`_ |\n`Documentation <http://projectabjad.org/>`_ |\n`Mailing list <http://groups.google.com/group/abjad-user>`_ |\n`Issue Tracker <https://github.com/Abjad/abjad/issues>`_ |\n`Travis-CI <https://travis-ci.org/Abjad/abjad>`_\n\n..  _GitHub: https://github.com/Abjad/abjad\n..  _PyPI: https://pypi.python.org/pypi/Abjad\n\n..  image:: https://img.shields.io/travis/Abjad/abjad/master.svg?style=flat-square\n    :target: https://travis-ci.org/Abjad/abjad\n\n..  image:: https://img.shields.io/coveralls/Abjad/abjad/master.svg?style=flat-square\n    :target: https://coveralls.io/r/Abjad/abjad\n\n..  image:: https://img.shields.io/pypi/v/abjad.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/abjad\n\n..  image:: https://img.shields.io/pypi/dm/abjad.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/abjad\n\nInstallation\n============\n\nAbjad works on Unix/Linux, OSX, and Windows.\n\nAbjad also works with `CPython`_ versions 2.7 and 3.3+, as well as `PyPy`_.\n\nInstall Abjad\n-------------\n\nTo install Abjad from `PyPI`_, the Python Package Index, via `pip`_::\n\n    ~$ sudo pip install abjad\n\nTo install the cutting-edge version Abjad from its `GitHub`_ repository, via\n`git <https://git-scm.com/>`_ and `pip`_::\n\n    ~$ git clone https://github.com/Abjad/abjad.git \n    ~$ cd abjad\n    abjad$ sudo pip install .\n\nInstall LilyPond\n````````````````\n\nAbjad uses `LilyPond`_, an open-source automated engraving engine, to produce\nnotational output.\n\nAbjad targets whichever is the most recent version of `LilyPond`_. At the time\nof this writing, that means 2.18-stable or 2.19-development. We recommend\ninstalling directly from `LilyPond`_'s website, rather than using whichever\nversion of `LilyPond`_ your package manager provides, as these packages are\noften out-of-date.\n\nOnce you have installed LilyPond, test if LilyPond is callable from your\ncommand-line by running the following command:\n\n..  code-block:: bash\n\n    ~$ lilypond --version\n    GNU LilyPond 2.19.20\n\n    Copyright (c) 1996--2015 by\n      Han-Wen Nienhuys <hanwen@xs4all.nl>\n      Jan Nieuwenhuizen <janneke@gnu.org>\n      and others.\n\n    This program is free software.  It is covered by the GNU General Public\n    License and you are welcome to change it and/or distribute copies of it\n    under certain conditions.  Invoke as `lilypond --warranty` for more\n    information.\n\nIf LilyPond is not callable from your command-line, you should add the\nlocation of the LilyPond executable to your ``PATH`` environment variable.\nThe `LilyPond`_ documentation provides instructions for making the\n``lilypond`` command available on the command-line under OSX at\nhttp://www.lilypond.org/macos-x.html.\n\nIf you are new to working with the command-line you should use Google to\nget a basic introduction to navigating in the shell, editing your profile and\nsetting environment variables. There are more tutorials than we can count!\n\nInstall Graphviz (optional)\n```````````````````````````\n\nAbjad uses `Graphviz`_, an open-source graph visualization library, to create\ngraphs of rhythm-trees and other tree structures, and to create visualizations\nof class hierarchies for its documentation. Graphviz is not necessary for\ncreating notation with Abjad.\n\nTo install `Graphviz`_ on Debian and Ubuntu::\n\n    ~$ sudo apt-get install graphviz\n\nTo install `Graphviz`_ on OSX via `Homebrew`_ or `MacPorts`_::\n\n    ~$ brew install graphviz\n    ~$ sudo port install graphviz\n\nOnce you have install `Graphviz`_, test if `Graphviz`_ is callable from your\ncommand-line by running the following command:\n\n..  code-block:: bash\n\n    ~$ dot -V\n    dot - graphviz version 2.38.0 (20140413.2041)\n\nDevelopment installation\n------------------------\n\nTo perform development on Abjad, run the test suite, or build Abjad's\ndocumentation locally, clone Abjad from the Github repository and install it in\n**edit mode** with its **development extras**::\n\n    ~$ git clone https://github.com/Abjad/abjad.git\n    ~$ cd abjad\n    abjad$ sudo pip install -e \".[development]\"\n\nInstalling Abjad in development mode will install the following `Python`_\npackage dependencies.\n\n-   `pytest`_, for running Abjad's test suite\n\n-   `Sphinx`_, for building Abjad's documentation\n\n-   `sphinx_rtd_theme <https://pypi.python.org/pypi/sphinx_rtd_theme>`_, for\n    theming Abjad's HTML documentation\n\n-   `PyPDF2`_, for performing preprocessing on `LaTeX`_ source with Abjad's\n    ``ajv book`` tool\n\nSome of `Sphinx`_'s dependencies provide optional optimized `Python`_\nextensions, which must be compiled before they can be used. If your machine\ndoes not have a C compiler available, you may see error message while the ``pip\ninstall -e \".[development]\"`` command runs. These warnings are harmless and will\nnot prevent the dependencies from being installed.\n\nTo install C compilation tools on Debian and Ubuntu::\n\n    ~$ sudo apt-get install build-essential\n\nTo install C compilation tools on OSX, we recommend simply installing XCode\nfrom the Apple App Store. Alternatively, you can install via `Homebrew`_ or\n`MacPorts`_, although this may take a significant amount of time.\n\nAdditionally, a few non-`Python`_ tools need to be installed in order to\ndevelop Abjad or build its documentation: `TeXLive`_, `ImageMagick`_, and\n`Graphviz`_ (which was explained above).\n\nInstall TeXLive\n````````````````\n\nBuilding the `LaTeX`_ documentation, running the test suite, and using Abjad's\n``ajv book`` document preprocessing tools require `TeXLive`_.\nAbjad makes use of both ``pdftex`` for producing PDFs, and the ``pdfcrop`` tool\ndistributed with `TeXLive`_.\n\nTo install `TeXLive`_ on Debian and Ubuntu::\n\n    ~$ sudo apt-get install texlive-full\n\nOn OSX, we recommend installing via the `MacTeX`_ distribution.\n\nInstall ImageMagick\n```````````````````\n\nBuilding Abjad's documentation requires `ImageMagick`_, a collection of raster\nimage processing tools.\n\nTo install `ImageMagick`_ on Debian and Ubuntu:: \n\n    ~$ sudo apt-get install imagemagick\n\nTo install `ImageMagick`_ on OSX, we recommend installing via `Homebrew`_ or\n`MacPorts`_::\n\n    ~$ brew install imagemagick\n    ~$ sudo port install imagemagick\n\nAbjad and IPython\n-----------------\n\nAbjad can be used with `IPython`_ to embed notation, graphs and audio into an\n`IPython notebook`_. To work with Abjad in `IPython`_, install Abjad with both\nits **development** and **ipython** extra dependencies::\n\n    ~$ sudo pip install abjad [development, ipython]\n\nCapturing MIDI files into an `IPython notebook`_ requires the `fluidsynth`_\npackage.\n\nTo install `fluidsynth`_ on Debian or Ubuntu::\n\n    ~$ apt-get install fluidsynth\n\nTo install `fluidsynth`_ on OSX via `Homebrew`_ or `MacPorts`_::\n\n    ~$ brew install fluidsynth --with-libsndfile\n    ~$ sudo port install fluidsynth\n\nOnce all dependencies have been installed, create a new `IPython notebook`_ and\nrun the following magic command in a cell to load Abjad's `IPython`_\nextension::\n\n    %load_ext abjad.ext.ipython\n\nVirtual environments\n--------------------\n\nWe strongly recommend installing Abjad into a virtual environment, especially\nif you intend to hack on Abjad's own source code. Virtual environments allow\nyou to isolate `Python`_ packages from your systems global collection of\npackages. They also allow you to install Python packages without ``sudo``. The\n`virtualenv`_ package provides tools for creating Python virtual environments,\nand the `virtualenvwrapper`_ package provides additional tools which make\nworking with virtual environments incredibly easy::\n\n    ~$ pip install virtualenv virtualenvwrapper\n    ...\n    ~$ export WORKON_HOME=~/Envs\n    ~$ mkdir -p $WORKON_HOME\n    ~$ source /usr/local/bin/virtualenvwrapper.sh\n    ~$ mkvirtualenv abjad\n    ...\n    ~(abjad)$ pip install abjad\n\nIf you have `virtualenvwrapper`_ installed, create a virtual environment and\ninstall Abjad into that instead::\n\n    ~$ mkvirtualenv abjad\n    ...\n    ~(abjad)$ git clone https://github.com/Abjad/abjad.git\n    ~(abjad)$ cd abjad\n    abjad(abjad)$ pip install -e \".[development]\"\n\nConfiguring Abjad\n-----------------\n\nAbjad creates a ``~/.abjad`` directory the first time it runs. In the\n``~/.abjad`` directory you will find an ``abjad.cfg`` file. This is the Abjad\nconfiguration file. You can use the Abjad configuration file to tell Abjad\nabout your preferred PDF file viewer, MIDI player, LilyPond language and so on.\n\nYour configuration file will look something like this the first time you open\nit::\n\n    # Abjad configuration file created by Abjad on 31 January 2014 00:08:17.\n    # File is interpreted by ConfigObj and should follow ini syntax.\n\n    # Set to the directory where all Abjad-generated files\n    # (such as PDFs and LilyPond files) should be saved.\n    # Defaults to $HOME.abjad/output/\n    abjad_output_directory = /Users/username/.abjad/output\n\n    # Default accidental spelling (mixed|sharps|flats).\n    accidental_spelling = mixed\n\n    # Comma-separated list of LilyPond files that \n    # Abjad will \"\\include\" in all generated *.ly files\n    lilypond_includes = ,\n\n    # Language to use in all generated LilyPond files.\n    lilypond_language = english\n\n    # Lilypond executable path. Set to override dynamic lookup.\n    lilypond_path = lilypond\n\n    # MIDI player to open MIDI files.\n    # When unset your OS should know how to open MIDI files.\n    midi_player = \n\n    # PDF viewer to open PDF files.\n    # When unset your OS should know how to open PDFs.\n    pdf_viewer = \n\n    # Text editor to edit text files.\n    # When unset your OS should know how to open text files.\n    text_editor = \n\nFollow the basics of ``ini`` syntax when editing the Abjad configuration file.\nBackground information is available at http://en.wikipedia.org/wiki/INI_file.\nUnder MacOS you might want to set you ``midi_player`` to iTunes. Under Linux\nyou might want to set your ``pdf_viewer`` to ``evince`` and your\n``midi_player`` to ``tiMIDIty``, and so on.\n\n..  _CPython: http://www.python.org\n..  _GitHub: https://github.com/Abjad/abjad\n..  _Graphviz: http://graphviz.org/\n..  _Homebrew: http://brew.sh/\n..  _IPython notebook: http://ipython.org/notebook.html\n..  _IPython: http://ipython.org/\n..  _ImageMagick: http://www.imagemagick.org/script/index.php\n..  _LaTeX: https://tug.org/\n..  _LilyPond: http://lilypond.org/\n..  _MacPorts: https://www.macports.org/\n..  _MacTeX: https://tug.org/mactex/\n..  _PyPDF2: http://pythonhosted.org/PyPDF2/\n..  _PyPI: https://pypi.python.org/pypi/Abjad\n..  _PyPy: http://pypy.org/\n..  _Python: https://www.python.org/\n..  _Sphinx: http://sphinx-doc.org/\n..  _TeXLive: https://www.tug.org/texlive/\n..  _fluidsynth: http://www.fluidsynth.org/\n..  _pip: https://pip.pypa.io/en/stable/\n..  _pytest: http://pytest.org/latest/\n..  _virtualenv: https://readthedocs.org/projects/virtualenv/\n..  _virtualenvwrapper: https://virtualenvwrapper.readthedocs.org/en/latest/",
        "url": "http://pypi.python.org/pypi/Abjad",
        "summary": "Abjad is a Python API for Formalized Score Control.",
        "command": "pip install 'Abjad'"
      },
      "abl.cssprocessor": {
        "name": "abl.cssprocessor",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abl.cssprocessor",
        "summary": "A processor to aggregate CSS-files and their referenced media",
        "command": "pip install 'abl.cssprocessor'"
      },
      "abl.errorreporter": {
        "name": "abl.errorreporter",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abl.errorreporter",
        "summary": "Lightweight exception recorder, cli part of WebError",
        "command": "pip install 'abl.errorreporter'"
      },
      "abl.jquery": {
        "name": "abl.jquery",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abl.jquery",
        "summary": "ToscaWidgets wrapping for jquery",
        "command": "pip install 'abl.jquery'"
      },
      "abl.jquery.plugins.form": {
        "name": "abl.jquery.plugins.form",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abl.jquery.plugins.form",
        "summary": "ToscaWidgets wrapper for jquery.form.js",
        "command": "pip install 'abl.jquery.plugins.form'"
      },
      "abl.jquery.ui": {
        "name": "abl.jquery.ui",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abl.jquery.ui",
        "summary": "UI-Extensions for jQuery",
        "command": "pip install 'abl.jquery.ui'"
      },
      "ablog": {
        "name": "ablog",
        "description": "ABlog for Sphinx\n================\n\nA Sphinx extension that converts any documentation or personal website project\ninto a full-fledged blog. See http://ablog.readthedocs.org for details.\n\n.. image:: https://secure.travis-ci.org/abakan/ablog.png?branch=devel\n   :target: http://travis-ci.org/#!/abakan/ablog\n\n.. image:: https://pypip.in/v/ABlog/badge.png\n   :target: https://pypi.python.org/pypi/ABlog\n\n.. image:: https://pypip.in/d/ABlog/badge.png\n   :target: https://crate.io/packages/ablog\n\n.. image:: https://readthedocs.org/projects/ablog/badge/?version=latest\n   :target: http://ablog.readthedocs.org/",
        "url": "http://pypi.python.org/pypi/ablog",
        "summary": "ABlog for blogging with Sphinx",
        "command": "pip install 'ablog'"
      },
      "abl.robot": {
        "name": "abl.robot",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abl.robot",
        "summary": "The Ableton Robot Framework, for writing daemons or commandline tools, with powerful features for error handling and logging.",
        "command": "pip install 'abl.robot'"
      },
      "abl.util": {
        "name": "abl.util",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abl.util",
        "summary": "A package that contains various helpful classes and functions used widely in the Ableton Python code base.",
        "command": "pip install 'abl.util'"
      },
      "abl.vpath": {
        "name": "abl.vpath",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abl.vpath",
        "summary": "A OO-abstraction of file-systems",
        "command": "pip install 'abl.vpath'"
      },
      "ABN": {
        "name": "abn",
        "description": "===\r\nABN\r\n===\r\n\r\nThis package validates Australian Business Numbers (ABNs) and converts Australian Company Numbers (ACNs) or Australian Registered Body Numbers (ARBNs) to ABNs.\r\n\r\nThe following example show checking of a valid and an invalid ABN:\\\r\n\r\n.. code-block:: python\r\n\r\n    >>> import abn\r\n    >>> abn.validate('53004085616')\r\n    '53 004 085 616'\r\n\r\n    >>> abn.validate('99999999999')\r\n    False\r\n\r\n\r\nTo calculate the ABN based on an existing ACN or ARBN:\r\n\r\n.. code-block:: python\r\n\r\n    >>> abn.acn_to_abn('004085616')\r\n    '53 004 085 616'\r\n\r\n\r\nTo run the tests:\r\n\r\n.. code-block:: bash\r\n\r\n    $ tox\r\n\r\n\r\nRelease History\r\n---------------\r\n\r\n0.3.6 (2015-08-03)\r\n++++++++++++++++++\r\n\r\n**Bug fixes**\r\n\r\n - Enable tests for Python 2.7, 3.3 and 3.4.",
        "url": "http://pypi.python.org/pypi/ABN",
        "summary": "Validate Australian Business Numbers.",
        "command": "pip install 'ABN'"
      },
      "aboardly": {
        "name": "aboardly",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aboardly",
        "summary": "Official Aboardly API library client for python",
        "command": "pip install 'aboardly'"
      },
      "abo-generator": {
        "name": "abo-generator",
        "description": "python-abo-generator\r\n====================\r\n\r\n.. image:: https://badge.fury.io/py/abo-generator.png\r\n    :target: http://badge.fury.io/py/abo-generator\r\n\r\nABO banking format generator.\r\nhttps://github.com/hareevs/python-abo-generator\r\n\r\nCurrently supports only \"CSOB\" compatible format.\r\n\r\nSpecification sources: http://www.fio.cz/docs/cz/struktura-abo.pdf and http://www.equabank.cz/files/doc/13-format-abo.pdf (available only in czech).\r\n\r\nThanks to Lukas Hurych for providing generator code.\r\n\r\n.. code-block:: python\r\n\r\n    from datetime import datetime, timedelta\r\n    from abo import ABO\r\n\r\n    tomorrow = datetime.now() + timedelta(days=1)\r\n    abo_export = ABO(client_account_number='123456789/0300', client_name='Super company a.s.', due_date=tomorrow)\r\n\r\n    abo_export.add_transaction('123456789/0100', 500.34, variable_symbol='123456', message='Hello world!')\r\n    abo_export.add_transaction('155-987523423/2010', 1234.55, variable_symbol='789654321', message='Test transaction')\r\n\r\n    with file('example.pkc', 'w') as f:\r\n        abo_export.save(f)\r\n\r\nInstallation\r\n------------\r\n\r\nTo install ABO generator, simply:\r\n\r\n.. code-block:: bash\r\n\r\n    $ pip install abo-generator\r\n\r\nLicense\r\n-------\r\n\r\nThis software is licensed under MPL 2.0.\r\n\r\n- http://mozilla.org/MPL/2.0/\r\n- http://www.mozilla.org/MPL/2.0/FAQ.html#use",
        "url": "http://pypi.python.org/pypi/abo-generator",
        "summary": "ABO banking format generator",
        "command": "pip install 'abo-generator'"
      },
      "abook": {
        "name": "abook",
        "description": "Python library to convert between Abook and vCard\n=================================================\n\n* http://abook.sourceforge.net/\n* Saves photo to ~/.abook/photo/NAME.jpeg (if directory is present).\n\nConfiguration\n-------------\n\n::\n\n  field other = Other\n  view CONTACT = name, email\n  view ADDRESS = address, address2, city, state, zip, country\n  view PHONE = phone, workphone, mobile, other\n  view OTHER = nick, url, notes\n",
        "url": "http://pypi.python.org/pypi/abook",
        "summary": "Abook Python lib",
        "command": "pip install 'abook'"
      },
      "abo-s-pysync": {
        "name": "abo-s-pysync",
        "description": "Pysync has both a demonstration implementation of the rsync and related\r\nalgorithms in pure Python, and a high speed librsync Python extension. The pure\r\nPython is not fast and is not optimized, however it does work and provides a\r\nsimple implementation of the algorithm for reference and experimentation. It\r\nincludes a combination of ideas taken from librsync, xdelta, and rsync. The\r\nlibrsync Python extension is less flexible and harder to understand, but is very\r\nfast.",
        "url": "http://pypi.python.org/pypi/abo-s-pysync",
        "summary": "A Python implementation of the rsync algorithm",
        "command": "pip install 'abo-s-pysync'"
      },
      "about": {
        "name": "about",
        "description": "About\n=====\n\n**Summary:** define the metadata of your project in a single place, then\nmake it available at setup-time and at runtime.\n\nLet's consider the ``about`` package as an example ; we add to our\nproject files, in the source tree, a file named ``about.py`` that\ncontains the metadata of the project:\n\n::\n\n    about\n    |--- setup.py\n    |--- README.md\n    |...\n    |--- about\n    |    |--- __init__.py\n    |    |...\n    |    |--- about.py\n\nThis file contains the metadata (and a little boilerplate):\n\n::\n\n    # coding: utf-8\n\n    metadata = dict(\n      __name__        = \"about\",\n      __version__     = \"4.0.0\",\n      __license__     = \"MIT License\",  \n      __author__      = u\"Sébastien Boisgérault <Sebastien.Boisgerault@gmail.com>\",\n      __url__         = \"https://warehouse.python.org/project/about\",\n      __summary__     = \"Software Metadata for Humans\",\n      __readme__      = \"README.md\",\n      __classifiers__ = [\"Programming Language :: Python :: 2.7\" ,\n                         \"Topic :: Software Development\"         ,\n                         \"Operating System :: OS Independent\"    ,\n                         \"Intended Audience :: Developers\"       ,\n                         \"License :: OSI Approved :: MIT License\",\n                         \"Development Status :: 3 - Alpha\"       ]\n    )\n\n    globals().update(metadata)\n    __all__ = metadata.keys()\n\n**Setup.** To use this metadata, the ``setup.py`` file includes the\ncode:\n\n::\n\n    import about\n    import about.about\n\n    info = about.get_metadata(about.about)\n\n    # add extra information (contents, requirements, etc.).\n    info.update(...)\n\n    if __name__ == \"__main__\":\n        setuptools.setup(**info)\n\n**Runtime.** The metadata is stored as a collection of attributes of the\n``about.about`` module. If we include in the ``about/__init__.py`` file\nthe one-liner\n\n::\n\n    from .about import *\n\nthey become available in the top-level module:\n\n::\n\n    >>> import about\n    >>> print about.__name__\n    about\n    >>> print about.__version__\n    4.0.0\n    >>> print about.__license__\n    MIT License",
        "url": "http://pypi.python.org/pypi/about",
        "summary": "Software Metadata for Humans",
        "command": "pip install 'about'"
      },
      "about_numtest": {
        "name": "about_numtest",
        "command": "pip install 'about_numtest'"
      },
      "about_pandoc": {
        "name": "about_pandoc",
        "command": "pip install 'about_pandoc'"
      },
      "abouttag": {
        "name": "abouttag",
        "description": "This package provides functions for generating about tags for\nFluidinfo following various conventions.\n\nFluidinfo is a hosted, online database based on the notion of tagging.\nFor more information on FluidDB, visit http://fluidinfo.com.\n\nFor more information on the ideas that motivated this module,\nsee posts at http://abouttag.blogspot.com.   A good place to\nstart is\n\nhttp://abouttag.blogspot.com/2010/03/about-tag-conventions-in-fluiddb.html\n\nEXAMPLE\n\nExamples of usage are provided in the examples directory.\nSome simple examples are:\n\n    from abouttag.books import book\n    from abouttag.music import album, artist, track\n    from abouttag.film import film, movie\n\n    print book(u\"One Hundred Years of Solitude\", u'Gabriel García Márquez')\n    print book(u'The Feynman Lectures on Physics',\n               u'Richard P. Feynman', u'Robert B. Leighton',\n               u'Matthew Sands')\n    print track(u'Bamboulé', u'Bensusan and Malherbe')\n    print album(u\"Solilaï\", u'Pierre Bensusan')\n    print artist(u\"Crosby, Stills, Nash & Young\")\n    print film(u\"Citizen Kane\", u'1941')\n    print movie(u\"L'Âge d'Or\", u'1930')\n\n\nINSTALLATION\n\n    pip install -U abouttag\n\nDEPENDENCIES\n\n    urlnorm",
        "url": "http://pypi.python.org/pypi/abouttag",
        "summary": "Normalizes about tags for Fluidinfo",
        "command": "pip install 'abouttag'"
      },
      "aboutyou": {
        "name": "aboutyou",
        "description": "AboutYou-Shop-SDK\n=================\n\n**Author:** Arne Simon [arne.simon@silce-dice.de]\n\n\nA Python implementation for the AboutYou shop API.\n\n\nInstallation\n------------\n\nInstall the package via PIP::\n\n    $ pip install aboutyou\n\nOr checkout the most recent version::\n\n    $ git clone https://bitbucket.org/slicedice/aboutyou-shop-sdk-python.git\n    $ cd aboutyou-shop-sdk-python\n    $ python setup.py install\n\n\nQuick Start\n-----------\n\n1. Register for an account at the [AboutYou Devcenter](https://developer.aboutyou.de/) and create a new app.\n   You will be given credentials to utilize the About You API.\n2. Modefiy one of the example credential files.\n3. Use the following lines::\n\n    from aboutyou.config import YAMLCredentials\n    from aboutyou.shop import ShopApi\n\n    shop = ShopApi(YAMLCredentials('mycredentials.yml'))\n    cagtegory_forest = shop.categories()\n\n\nDocumentation\n-------------\n\nDocumentation is found at http://aboutyou-shop-sdk.readthedocs.org/en/latest/.\n\nIf you want to build the documentation yourself.\n\n1. Checkout the git repo.\n2. Go to the *doc/* folder.\n3. make html\n\n\nChange Log\n----------\n\n- 1.0.1:\n    - Fixed bug in login url generation\n\n- 1.0:\n    * Added Django backend and middleware\n    * Fixed configuration bug\n    * Cleand up project structure\n    * setup.py is not dependent on setuptools\n\n- 0.9\n    * Is now Python 3 compatible.\n    * Test cases with mocking.\n    * Added Auth module.\n    * Moved thin api wrapper in own api module.\n    * The app credentials are now seperated from the other configurations.\n\n- 0.3:\n    * Additional docmentation.\n    * Auto fetch flag.\n    * PyPI integration.\n    * YAML configuration files.\n\n- 0.2:\n    * Caching with Memcached and pylibmc.\n    * EasyAboutYou has function, *getSimpleColors*.\n    * Error handling fix.\n\n- 0.1:\n    * Products return now there url to the mary+paul shop.\n    * Dirty caching without memcached.\n    * EasyCollins products are no bulk requests.\n    * Extended documentation for EasyAboutYou.",
        "url": "http://pypi.python.org/pypi/aboutyou",
        "summary": "A connection to the aboutyou.de shop.",
        "command": "pip install 'aboutyou'"
      },
      "abris": {
        "name": "abris",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abris",
        "summary": "Small data preprocessing engine built on top of sklearn for easy prototyping.",
        "command": "pip install 'abris'"
      },
      "abroute": {
        "name": "abroute",
        "description": "abroute|Autobahn experiments in router to router delivery\r\n\r\nMore information:\r\n\r\n* `abroute Site <http://github.com/lgfausak/abroute>`__",
        "url": "http://pypi.python.org/pypi/abroute",
        "summary": "Autobahn based router networking.  Connect Autobahn routed networks together.",
        "command": "pip install 'abroute'"
      },
      "abrupt": {
        "name": "abrupt",
        "description": "",
        "url": "http://pypi.python.org/pypi/abrupt",
        "summary": "Abrupt: interactive HTTP(S) tool",
        "command": "pip install 'abrupt'"
      },
      "absdga": {
        "name": "absdga",
        "description": "absdga\r\n======\r\n\r\nBrief Description\r\n-----------------\r\n\r\nThis is a introductory level project that teaches RubyLearning's \r\n\"An Introduction to Python\" course students on how to uplaod their modules to Python Package Index.\r\n\r\nUsage\r\n-----\r\n\r\nimport absdga\r\n\r\nprint(absdga.absdga(-20))\r\n\r\nor\r\n\r\nfrom absdga import *\r\n\r\nprint(absdga(-20))\r\n\r\n\r\n",
        "url": "http://pypi.python.org/pypi/absdga",
        "summary": "Gives the absolute value of a number",
        "command": "pip install 'absdga'"
      },
      "Absinthe": {
        "name": "absinthe",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Absinthe",
        "summary": "A tiny server(-client) app to open sshfs connected files over ssh in any local editor",
        "command": "pip install 'Absinthe'"
      },
      "absolute": {
        "name": "absolute",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/absolute",
        "summary": "A simple function which computes the absolute value of a number",
        "command": "pip install 'absolute'"
      },
      "absolute32": {
        "name": "absolute32",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/absolute32",
        "summary": "UNKNOWN",
        "command": "pip install 'absolute32'"
      },
      "absorbing_centrality": {
        "name": "absorbing_centrality",
        "description": "================================\nAbsorbing Random-Walk Centrality\n================================\n\n|docs| |travis| |coveralls|\n    \nThis is an implementation of the *absorbing random-walk centrality* measure for \nnodes in graphs. For the definition of the measure, as well as a study of the\nrelated optimization problem and algorithmic techniques, please see the pre-print\npublication on arXiv_. A short version of this paper will appear in the\n`ICDM 2015`__.\n\n.. _arXiv: http://arxiv.org/abs/1509.02533\n__ http://icdm2015.stonybrook.edu/\n\nTo cite this work, please use\n\n::\n\n   Mavroforakis, Charalampos, Michael Mathioudakis, and Aristides Gionis.\n   \"Absorbing random-walk centrality: Theory and algorithms\"\n   Data Mining (ICDM), 2015 IEEE International Conference on. IEEE, 2015.\n\n\nInstallation\n------------\n\nYou can install the *absorbing_centrality* package by executing the following command in a terminal.\n\n::\n\n   pip install git+https://github.com/harrymvr/absorbing-centrality#Egg=absorbing_centrality\n\nDocumentation\n-------------\n\nFor instructions on how to use the package, consult `its documentation`__.\n\n__ https://absorbing-centrality.readthedocs.org/\n\nDevelopment\n-----------\n\nTo run all the tests for the code, you will need tox_ -- check its webpage for instructions on how to install it.\n\n.. _tox: https://testrun.org/tox/latest/\n\nOnce tox_ is installed, use your terminal to enter the directory with the local copy of the code (here it's named '*absorbing-centrality*') and simply type the following command.\n\n::\n\n    absorbing-centrality $ tox\n\nIf everything goes well, you'll receive a congratulatory message. \n\n\nNote that the code is distributed under the Open Source Initiative (ISC) license.\nFor the exact terms of distribution, see the LICENSE_.\n\n.. _LICENSE: ./LICENSE\n\n::\n\n   Copyright (c) 2015, absorbing-centrality contributors,\n   Charalampos Mavroforakis <cmav@bu.edu>,\n   Michael Mathioudakis <michael.mathioudakis@aalto.fi>,\n   Aristides Gionis <aristides.gionis@aalto.fi>\n\n    \n.. |docs| image:: https://readthedocs.org/projects/absorbing-centrality/badge/?version=latest\n    :target: https://absorbing-centrality.readthedocs.org/en/latest/\n    :alt: Documentation Statu\n\n.. |travis| image:: https://travis-ci.org/harrymvr/absorbing-centrality.svg?branch=master\n    :alt: Travis-CI Build Status\n    :target: https://travis-ci.org/harrymvr/absorbing-centrality\n\n.. |requires| image:: https://requires.io/github/harrymvr/absorbing-centrality/requirements.svg?branch=master\n    :alt: Requirements Status\n    :target: https://requires.io/github/harrymvr/absorbing-centrality/requirements/?branch=master\n\n\n.. |coveralls| image:: https://coveralls.io/repos/harrymvr/absorbing-centrality/badge.svg?branch=master&service=github\n    :alt: Coverage Status\n    :target: https://coveralls.io/github/harrymvr/absorbing-centrality?branch=master\n\n\n.. |version| image:: https://img.shields.io/pypi/v/absorbing_centrality.svg?style=flat\n    :alt: PyPI Package latest release\n    :target: https://pypi.python.org/pypi/absorbing_centrality\n\n.. |downloads| image:: https://img.shields.io/pypi/dm/absorbing_centrality.svg?style=flat\n    :alt: PyPI Package monthly downloads\n    :target: https://pypi.python.org/pypi/absorbing_centrality\n\n.. |wheel| image:: https://img.shields.io/pypi/wheel/absorbing_centrality.svg?style=flat\n    :alt: PyPI Wheel\n    :target: https://pypi.python.org/pypi/absorbing_centrality\n\n.. |supported-versions| image:: https://img.shields.io/pypi/pyversions/absorbing_centrality.svg?style=flat\n    :alt: Supported versions\n    :target: https://pypi.python.org/pypi/absorbing_centrality\n\n.. |supported-implementations| image:: https://img.shields.io/pypi/implementation/absorbing_centrality.svg?style=flat\n    :alt: Supported imlementations\n    :target: https://pypi.python.org/pypi/absorbing_centrality\n\n\n\nChangelog\n=========\n\n0.1.0 (2015-08-31)\n-----------------------------------------\n\n* Working version of the package.",
        "url": "http://pypi.python.org/pypi/absorbing_centrality",
        "summary": "An implementation of the absorbing random-walk centrality measure for graphs.",
        "command": "pip install 'absorbing_centrality'"
      },
      "abspath": {
        "name": "abspath",
        "description": "abspath\n=======\n\n``abspath`` is a command line tool that prints the absolute paths of all given\nfiles. File names can be piped via ``STDIN`` or given as arguments.\n\nUsage\n-----\n\n::\n\n    abspath file1.txt path/to/file2.pdf\n    abspath Desktop/*\n    find . -name *.pdf | abspath\n\nInstallation\n------------\n\nInstallation from PyPI\n~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    sudo pip install abspath\n\nInstallation from the repository\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    git clone https://github.com/arne-cl/abspath.git\n    cd abspath\n    sudo python setup.py install\n\nLicense\n-------\n\n3-clause BSD.",
        "url": "http://pypi.python.org/pypi/abspath",
        "summary": "get the absolute paths of files on the command line",
        "command": "pip install 'abspath'"
      },
      "abssmt": {
        "name": "abssmt",
        "description": "abssmt\r\n======\r\n\r\nBrief Description\r\n-----------------\r\n\r\nThis is a introductory level project that teaches RubyLearning's \"An Introduction to Python\" course students on how to uplaod their modules to Python Package Index.\r\n\r\nUsage\r\n-----\r\n\r\nimport abssmt\r\n\r\nprint(abssmt.abssmt(-20))\r\n\r\n",
        "url": "http://pypi.python.org/pypi/abssmt",
        "summary": "Gives the absolute value of a number",
        "command": "pip install 'abssmt'"
      },
      "abstrackr": {
        "name": "abstrackr",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abstrackr",
        "summary": "Web-based Citation Screening Tool",
        "command": "pip install 'abstrackr'"
      },
      "abstract.jwrotator": {
        "name": "abstract.jwrotator",
        "description": "abstract.jwrotator Package Readme\r\n=========================\r\n\r\nOverview\r\n--------\r\nabstract.jwrotator is a simple wrapper to JW Image Rotator\r\n(http://www.jeroenwijering.com/?item=jw_image_rotator).\r\nIt simply provides the a jwrotator_view for Folder and Topics.\r\n\r\n\r\n\r\n#TODO:         \r\n- make portlet configurable\r\n\r\nChangelog for abstract.jwrotator\r\n\r\nabstract.jwrotator - 0.3                   \r\n    - added JWRotator Portlet [Steven Shade]\r\n    - added some other configurable features\r\n\r\nabstract.jwrotator - 0.2\r\n    - Changed namespace to abstract.*\r\n    - Fix an issue on automatic \"Plone Default\" skin switch after install [Davi\r\nLima]\r\n\r\nplone.jwrotator - 0.1 Unreleased\r\n\r\n    - Initial package structure.\r\n      [zopeskel]",
        "url": "http://pypi.python.org/pypi/abstract.jwrotator",
        "summary": "Abstract JWRotator",
        "command": "pip install 'abstract.jwrotator'"
      },
      "abstract_rendering": {
        "name": "abstract_rendering",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abstract_rendering",
        "summary": "Rendering as a binning process",
        "command": "pip install 'abstract_rendering'"
      },
      "abstrys-toolkit": {
        "name": "abstrys-toolkit",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abstrys-toolkit",
        "summary": "Useful command-line tools and scripts, designed for\n      technical writing and publication.",
        "command": "pip install 'abstrys-toolkit'"
      },
      "abu.admin": {
        "name": "abu.admin",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/abu.admin",
        "summary": "UNKNOWN",
        "command": "pip install 'abu.admin'"
      },
      "abu.rpc": {
        "name": "abu.rpc",
        "command": "pip install 'abu.rpc'"
      },
      "abydos": {
        "name": "abydos",
        "description": "Abydos\n======\n\n.. image:: https://travis-ci.org/chrislit/abydos.svg\n    :target: https://travis-ci.org/chrislit/abydos\n    :alt: Build Status\n\n.. image:: https://coveralls.io/repos/chrislit/abydos/badge.svg\n    :target: https://coveralls.io/r/chrislit/abydos\n    :alt: Coverage Status\n\n.. image:: https://codeclimate.com/github/chrislit/abydos/badges/gpa.svg\n   :target: https://codeclimate.com/github/chrislit/abydos\n   :alt: Code Climate\n\n.. image:: https://img.shields.io/badge/Pylint-9.99/10-green.svg\n    :alt: Pylint Score\n\n.. image:: https://img.shields.io/badge/PEP8-0-brightgreen.svg\n    :alt: PEP8 Errors\n\n.. image:: https://img.shields.io/pypi/v/abydos.svg\n    :target: https://pypi.python.org/pypi/abydos\n    :alt: PyPI\n\n.. image:: https://readthedocs.org/projects/abydos/badge/?version=latest\n    :target: https://abydos.readthedocs.org/en/latest/\n    :alt: Documentation Status\n\n.. image:: https://www.openhub.net/p/abydosnlp/widgets/project_thin_badge.gif\n    :target: https://www.openhub.net/p/abydosnlp\n    :alt: OpenHUB\n\n|\n\n.. image:: https://raw.githubusercontent.com/chrislit/abydos/master/abydos-small.png\n    :alt: abydos\n    :align: right\n\n|\n| Abydos NLP/IR library\n| Copyright 2014-2015 by Chris Little\n\nThis library contains code I'm using for research, in particular dissertation research & experimentation.\n\nRequired:\n\n- Numpy\n\n\nRecommended:\n\n- PylibLZMA   (Python 2 only--for LZMA compression string distance metric)\n\nSuggested for testing & QA:\n\n- Nose        (for unit testing)\n- coverage.py (for code coverage checking)\n- Pylint      (for code quality checking)\n- PEP8        (for code quality checking)\n\n-----\n\nTo build/install/unittest in Python 2:\n\n::\n\n    sudo python setup.py install\n    nosetests -v --with-coverage --cover-erase --cover-html --cover-branches --cover-package=abydos .\n\nTo build/install/unittest in Python 3:\n\n::\n\n    sudo python3 setup.py install\n    nosetests3 -v --with-coverage --cover-erase --cover-html --cover-branches --cover-package=abydos .\n\nFor pylint testing, run:\n\n::\n\n    pylint --rcfile=pylint.rc abydos > pylint.log\n\n\nRelease History\n---------------\n\n0.2 (2015-05-27)\n++++++++++++++++++\n\n- Added Caumanns' German stemmer\n- Added Lovins' English stemmer\n- Added basic docs via Sphinx\n- Updated Beider-Morse Phonetic Matching to 3.04\n- added Sphinx documentation\n\n\n0.1.1 (2015-05-12)\n++++++++++++++++++\n\n- First Beta release to PyPI\n\n\n\nAuthors\n```````\n\n- Chris Little (`@chrislit <https://github.com/chrislit>`_) <chrisclittle+abydos@gmail.com>",
        "url": "http://pypi.python.org/pypi/abydos",
        "summary": "Abydos NLP/IR library",
        "command": "pip install 'abydos'"
      },
      "abyss": {
        "name": "abyss",
        "description": "abyss\n=====\n\nMMO/RPG/RTS/RESTAPI game in your terminal!",
        "url": "http://pypi.python.org/pypi/abyss",
        "summary": "MMO/RPG/RTS/RESTAPI game in your terminal!",
        "command": "pip install 'abyss'"
      },
      "ac": {
        "name": "ac",
        "description": "# AC.py - Python Autoconf #\n\n## Introduction #\n\nAC.py is a Python implementation of the popular autoconf tool used in \nascertaining a sane, stable environment before attempting to build large\nprojects. The purpose of AC.py is to provide a simpler way of performing\nthese tests, along with added functionality to resolve environmental issues\nat the same time. \n\n### License #\n\nAC.py is licensed with [GPLv3](http://www.gnu.org). This is free software that\nmay be used by anyone for any purposes and distributed freely, and comes with\nno warranty. \n\n### Author Info. #\nOriginally authored by \n[Tom A. Thorogood](mailto:tom@tomthorogood.com). \n\nAC.py's central repository is located at\n[github.com/tomthorogood/ac.py](http://www.github.com/tomthorogood/ac.py).\n\n## Installation #\n\nAC.py can be installed using\n\n    pip install ac\n\nor\n\n    easy_install ac\n\nAdditionally, you can clone and install yourself using:\n\n    git clone git://github.com/tomthorogood/AC.py\n    cd AC.py\n    python setup.py install\n\nYou do not need to install ac.py in order to use it. It can be cloned and used\nas any standard Python module.\n\n## Usage #\n\nAC.py aims to be simpler than than traditional autoconf, and is highly \ncustomizable. The following tutorial will allow you to:\n\n+ Test for libraries and executables\n+ Set up distribution-specific alternatives for failed tests\n+ Use test results to populate fields in a manifest Makefile.\n\n## The Shell Environment#\n\nAC.py will always attempt to test the shell environment first. The default\nshell can be changed using the `--shell` flag. When running any shell scripts\ngenerated by AC.py or written by you, the hashbang interpreter directive will\nalways be at the head of each script (#!/bin/sh), using the results from the\nshell environment test.\n\nIf you do not want your users to have to use the shell flag, but do want to\nrequire a specific shell environment, you can set the default using\n\n    # ac.set_shell\n    ac.set_shell(\"sh\")\n    ac.set_shell(\"bash\")\n    ac.set_shell(\"tcsh\")\n\nHowever, it is highgly recommended that you use bash commands and scripts that\nwill work across all platforms and shells. \n\n## Required Successes #\n\nTests marked as required (or called with a 'require' function) will halt\nthe configuration script if the test is not a success and there is no \nfail alternative provided.\n\n## A Generic Test #\n\nYou can use any Python scripting to come up with a true/false result and\npass the result into the test framework using\n\n    # ac.test(\"test_name\", result, [required=True|False])",
        "url": "http://pypi.python.org/pypi/ac",
        "summary": "A python library for writing C/C++ configure files.",
        "command": "pip install 'ac'"
      },
      "acapi": {
        "name": "acapi",
        "description": "Python Library for Acquia's Cloud API\n=====================================\n\nThis is a python client for using the `Acquia Cloud\nAPI <https://cloudapi.acquia.com/>`__.\n\n|Requirements Status|\n\nInstallation\n------------\n\nInstalling With pip (recommended)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n``pip install acapi``\n\nManual Installation\n-------------------\n\n::\n\n    $ git clone git@github.com:skwashd/python-acquia-cloud.git acapi\n    $ cd acapi\n    $ ./setup.py build && ./setup.py install\n\nExamples\n--------\n\n.. code:: python\n\n\n    import acapi\n\n    from pprint import pprint\n\n    # Acquia subscription name.\n    subname = 'example'\n    # Website domain.\n    domain = 'example.com'\n\n    # Instantiate client using environment variables.\n    c = acapi.Client()\n\n    # Get the site object.\n    site = c.site(subname)\n\n    # Get the environments object.\n    envs = site.environments()\n\n    # Print all environments on a subscription.\n    pprint(envs)\n\n    # List the SSH host for each environment.\n    for env in envs:\n        print \"Env: {env} SSH Host: {host}\".format(env=env, host=envs[env]['ssh_host'])\n\n    # Move a domain from stage to production.\n    envs['prod'].domain(domain).move('test')\n\n    # Backup the development environment database and download the dump file.\n    site.environment('dev').db(subname).backups().create().download('/tmp/backup.sql.gz')\n\nThis library was created and maintained by `Dave\nHall <http://davehall.com.au>`__.\n\nSee `LICENSE <LICENSE>`__.\n\n.. |Requirements Status| image:: https://requires.io/github/skwashd/python-acquia-cloud/requirements.svg?style=flat\n   :target: https://requires.io/github/skwashd/python-acquia-cloud/requirements/\n",
        "url": "http://pypi.python.org/pypi/acapi",
        "summary": "Update depedencies",
        "command": "pip install 'acapi'"
      },
      "ACAutomation": {
        "name": "acautomation",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ACAutomation",
        "summary": "ACAutomation python wrapper,support unicode",
        "command": "pip install 'ACAutomation'"
      },
      "ACCC": {
        "name": "accc",
        "description": "# Always Correct Correctness Compiler\nPython implementation of a very basic langage compiler that never throw errors while compiling. (almost)  \nIts not a big and complex compiler, and its implementation is something like awful.  \nSome links are given below.\n\n\n## Errors\nThe only errors releved by the compiler is :\n- source code contains characters not present in provided alphabet;\n- provided vocabulary don't follow conventions of writing;\n\nIf these conditions are respected, whatever you give to the __ACCC__, it will always return something valid.\n(but it can be an empty code)\n\n\n## Bias\nIf compiled source code is too short, or made of lots of repetitions, \nsome bias can appear:  \n- always same values in object code  \n- lots of neutral values  \n\nThe bigger is the vocabulary and bigger is the list of lexems,   \nthe less bias will appear.\n\n\n## Interests\nA compilable source code is a string of characters.  \nValid characters are provided at Compiler instanciation.  \n\nFor example, if you have the alphabet *'01'*, \nany string exclusively composed of *'0'* and *'1'* is compilable and will produce something.  \n\nAny little modification of the string can lead to heavy or no modification of object code.  \nIn fact, with ACCC you can generate mutation of a source code without problem of compilation error.  \n\nWrite a code with lots of parameters is another way to do almost the same thing.\n\n\n## Object code\nCurrently, current object langage is __very simple__: you can compare things, and do things.\nThat's all. No loops, variables, functions, objects,… Just conditions and actions.\n\nThis is an example of code, not totally illogic, created one time with a source code size of 60 and the alphabet '01':  \n(indentation can miss)   \n\n        if parameter1 == parameter2 and haveThat:\n            do_that\n            if have_that:\n                say_this\n                do_that\n                if know_that and have_many_things:\n                    do_that\n                    say_this\n                do_that\n            if have_many_things:\n                say_this\n\nPlease have a look to docstring of *Compiler* class for more details about that. (notabily used vocabulary)  \n\n\n## I/O speaking\nInputs:\n- iterable of characters (doublons are unexpected) that compose the source code  \n- vocabulary used for compiling  \n\nOutputs:  \n- a python compilable code, according to vocabulary  \n\n\n## Next improvements\nIn random-priority order:  \n- [ ] allow lexems to have arguments;  \n- [ ] create before convert in any langage;  \n- [ ] allow configuration of output langage;    \n- [ ] unit tests;  \n- [ ] usage example;  \n- [ ] base tables on source code instead of only vocabulary;  \n- [X] upload on pypi and github (see links below);  \n\n\n\n## Why don't you use…\nSomeone do the same thing ? Or better ?  \nGive me the link, i want to see that !\n\n\n## Why do that ?\n1. It's fun\n2. I need it for test something in another project (an Evolution simulation named [EvolAcc](http://www.github.com/Aluriak/EvolAcc) ; no surprise)\n\n\n## Links\n- ACCC on [github](http://www.github.com/Aluriak/ACCC);  \n- ACCC on [pypi](https://pypi.python.org/pypi/ACCC);",
        "url": "http://pypi.python.org/pypi/ACCC",
        "summary": "Always Correct Correctness Compilator",
        "command": "pip install 'ACCC'"
      },
      "accept": {
        "name": "accept",
        "description": "accept\n======\n\n\n.. image:: https://travis-ci.org/rhyselsmore/accept.png?branch=master\n        :target: https://travis-ci.org/rhyselsmore/accept\n\n.. image:: https://pypip.in/d/accept/badge.png\n        :target: https://pypi.python.org/pypi/accept\n\n\nA simple library for parsing and ordering a HTTP Accept header.\n\nIncludes parameter extraction.\n\n\nInstallation\n------------\n\n.. code-block:: bash\n\n    pip install accept\n\nOr if you *must* use easy_install:\n\n.. code-block:: bash\n\n    alias easy_install=\"pip install $1\"\n    easy_install accept\n\n\nUsage\n-----\n\n.. code-block:: python\n\n    >>> import accept\n    >>> accept.parse(\"text/*, text/html, text/html;level=1, */*\")\n    [<Media Type: text/html; q=1.0; level=1>, <Media Type: text/html; q=1.0>, <Media Type: text/*; q=1.0>, <Media Type: */*; q=1.0>]\n    >>> d = accept.parse(\"application/json; version=1; q=1.0; response=raw\")[0]\n    >>> d.media_type\n    'application/json'\n    >>> d.quality\n    1.0\n    >>> d.q\n    1.0\n    >>> d.params\n    {'version': '1', 'response': 'raw'}\n    >>> d['version']\n    '1'\n    >>> d['potato']\n    None\n\n\nContribute\n----------\n\n#. Check for open issues or open a fresh issue to start a discussion around a feature idea or a bug. There is a Contributor Friendly tag for issues that should be ideal for people who are not very familiar with the codebase yet.\n#. Fork `the repository`_ on Github to start making your changes to the **master** branch (or branch off of it).\n#. Write a test which shows that the bug was fixed or that the feature works as expected.\n#. Send a pull request and bug the maintainer until it gets merged and published.\n\n.. _`the repository`: http://github.com/rhyselsmore/accept\n\n\nHistory\n-------\n\n0.1.0 (2015-01-05)\n++++++++++++++++++\n\n* Initial Release!",
        "url": "http://pypi.python.org/pypi/accept",
        "summary": "Parse and order a HTTP Accept header.",
        "command": "pip install 'accept'"
      },
      "accepton": {
        "name": "accepton",
        "description": "AcceptOn\n========\n\n|circleci|\n\n.. |circleci| image:: https://circleci.com/gh/accepton/accepton-python.svg?style=shield&circle-token=9a4878f9e5d7eb8ff1cbcfb863641772aa7e9005\n   :target: https://circleci.com/gh/accepton/accepton-python\n   :alt: Build Status\n\nDocumentation\n-------------\n\nPlease see the `Python developer documentation`_ for more information.\n\n.. _Python developer documentation: http://developers.accepton.com/?python\n\nInstallation\n------------\n\nInstall from PyPI using `pip`_, a package manager for Python.\n\n.. code-block:: bash\n\n    $ pip install accepton\n\nDon't have pip installed? Try installing it by running this from the\ncommand line:\n\n.. code-block:: bash\n\n    $ curl https://raw.github.com/pypa/pip/master/contrib/get-pip.py | python\n\nYou may need to run the above commands with ``sudo``.\n\n.. _pip: http://www.pip-installer.org/en/latest/\n\nContributing\n------------\n\n1. Fork it\n2. Create your feature branch (``git checkout -b my-new-feature``)\n3. Run the test suite on all supported Pythons (``tox``)\n4. Run the code linter to find style violations (``tox -e pep8``)\n5. Commit your changes (``git commit -am 'Add some feature'``)\n6. Push the branch (``git push origin my-new-feature``)\n7. Create a new Pull Request",
        "url": "http://pypi.python.org/pypi/accepton",
        "summary": "AcceptOn Python library",
        "command": "pip install 'accepton'"
      },
      "accept-types": {
        "name": "accept-types",
        "description": "========================================================\naccept-types - Use the correct accept type for a request\n========================================================\n\n``accept-types`` helps your application respond to a HTTP request in a way that a client prefers.\nThe ``Accept`` header of an HTTP request informs the server which MIME types the client is expecting\nback from this request, with weighting to indicate the most prefered. If your server can respond in\nmultiple formats (e.g.: JSON, XML, HTML), the client can easily tell your server which is the\nprefered format without resorting to hacks like '&amp;format=json' on the end of query strings.\n\n\nUsage\n=====\n\n``get_best_match``\n------------------\n\nWhen provided with an ``Accept`` header and a list of types your server can respond with, this function\nreturns the clients most prefered type. This function will only return one of the acceptable types you\npassed in, or ``None`` if no suitable type was found:\n\n.. code:: python\n\n\tfrom accept_type import get_best_match\n\n\tdef get_the_info(request):\n\t\tinfo = gather_info()\n\n\t\treturn_type = get_best_match(request.META.get('HTTP_ACCEPT'), ['text/html', 'application/xml', 'text/json'])\n\n\t\tif return_type == 'application/xml':\n\t\t\treturn render_xml(info)\n\n\t\telif return_type == 'text/json':\n\t\t\treturn render_json(info)\n\n\t\telif return_type == 'text/html':\n\t\t\treturn render_html(info)\n\n\t\telif return_type == None:\n\t\t\treturn HttpResponse406()\n\n``parse_header``\n----------------\n\nWhen provided with an ``Accept`` header, this will parse it and return a sorted list of the clients\naccepted mime types. These will be instances of the ``AcceptableType`` class.\n\n.. code:: python\n\n\t>>> from accept_type import parse_header\n\t>>> parse_header('text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8')\n\t['text/html, weight 1', 'application/xhtml+xml, weight 1', 'application/xml, weight 0.9', '*/*, weight 0.8']\n\n``AcceptableType``\n------------------\n\n``AcceptableType`` instances represent one of the types that a client is willing to accept. This\ntype could include wildcards, to match more than one MIME type.\n\n.. code:: python\n\n\t>>> from accept_type import AcceptableType\n\t>>> type = AcceptableType('image/*;q=0.9')\n\tAcceptableType\n\t>>> type.mime_type\n\t'image/*'\n\t>>> type.weight\n\t0.9\n\t>>> type.matches('image/png')\n\tTrue\n\t>>> type.matches('text/html')\n\tFalse",
        "url": "http://pypi.python.org/pypi/accept-types",
        "summary": "Determine the best content to send in an HTTP response",
        "command": "pip install 'accept-types'"
      },
      "access2theMatrix": {
        "name": "access2thematrix",
        "description": "access2theMatrix is a Python library for accessing Omicron NanoTechnology's\nMATRIX Control System result files. Only topography image data will be accessed\nby this library.\n\nThe library access2theMatrix has the package access2thematrix which in turn\ncontains the module access2thematrix. The class MtrxData in the access2thematrix\nmodule has the methods to open result files and to select one out of the four\ntraces (forward/up, backward/up, forward/down and backward/down).\n\nDependencies\n------------\naccess2theMatrix requires the NumPy library (http://www.numpy.org). You must\ninstall it manually.\n\nInstallation\n------------\nUsing pip::\n\n    > pip install access2theMatrix\n\nExample usage\n-------------\nIn this example the MATRIX Control System has stored the acquired data in the\nfolder ``c:\\data``. In addition to the result data files the folder must also\ncontain the result file chain, see the MATRIX Application Manual for SPM.\nThe file ``20140325-092702_AFM_NonContact_QPlus--51_1.Z_mtrx`` will be opened\nand the ``backward/up`` trace will be selected.\n\n.. code-block:: pycon\n\n    >>> import access2thematrix\n    >>> mtrx_data = access2thematrix.MtrxData()\n    >>> data_file = r'c:\\data\\20140325-092702_AFM_NonContact_QPlus--51_1.Z_mtrx'\n    >>> traces, message = mtrx_data.open(data_file)\n    >>> print message\n    Successfully opened and processed data file 20140325-092702_AFM_NonContact_QPlus--51_1.Z_mtrx.\n    >>> traces\n    {0: 'forward/up', 1: 'backward/up', 2: 'forward/down', 3: 'backward/down'}\n    >>> im, message = mtrx_data.select_image(traces[1])\n    >>> print message\n    Trace backward/up selected.\n    >>> im.data\n    array([[ -1.80605572e-08,  -1.80625201e-08,  -1.80663057e-08, ...,\n             -1.82079808e-08,  -1.82142887e-08,  -1.82174186e-08],\n           [ -1.80587456e-08,  -1.80613477e-08,  -1.80623131e-08, ...,\n             -1.82091517e-08,  -1.82156607e-08,  -1.82195526e-08],\n           [ -1.80513618e-08,  -1.80510353e-08,  -1.80531660e-08, ...,\n             -1.82131799e-08,  -1.82177880e-08,  -1.82229330e-08],\n           ..., \n           [ -1.79789472e-08,  -1.79819920e-08,  -1.79856806e-08, ...,\n             -1.81261956e-08,  -1.81293811e-08,  -1.81332706e-08],\n           [ -1.79804649e-08,  -1.79810591e-08,  -1.79850527e-08, ...,\n             -1.81223942e-08,  -1.81250894e-08,  -1.81293146e-08],\n           [ -1.79775549e-08,  -1.79791702e-08,  -1.79830948e-08, ...,\n             -1.81149155e-08,  -1.81181441e-08,  -1.81199908e-08]])\n    >>> im.data.shape\n    (240, 320)\n    >>> im.angle\n    122\n    >>> im.height\n    3.0000000000000004e-09\n    >>> im.width\n    4e-09\n    >>> im.x_offset\n    -8.7804110391206612e-08\n    >>> im.y_offset\n    1.86005503318584e-07\n    >>> \n\nAuthors & affiliations\n----------------------\nStephan J. M. Zevenhuizen [#]_\n\n..  [#] Condensed Matter and Interfaces, Debye Institute for Nanomaterials\n    Science, Utrecht University, Utrecht, The Netherlands.",
        "url": "http://pypi.python.org/pypi/access2theMatrix",
        "summary": "Omicron NanoTechnology's MATRIX Control System result file accessing tool",
        "command": "pip install 'access2theMatrix'"
      },
      "accessall": {
        "name": "accessall",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/accessall",
        "summary": "Google Music command line tool.",
        "command": "pip install 'accessall'"
      },
      "AccessControl": {
        "name": "accesscontrol",
        "description": "Overview\n========\n\nAccessControl provides a general security framework for use in Zope2.\n\nChangelog\n=========\n\nFor changes before verison 3.0, see ``HISTORY.txt``.\n\n3.0.11 (2014-11-02)\n-------------------\n\n- Harden test fix for machines that do not define `localhost`.\n\n\n3.0.10 (2014-11-02)\n-------------------\n\n- Test fix for machines that do not define `localhost`.\n\n3.0.9 (2014-08-08)\n------------------\n\n- GitHub #6: Do not pass SecurityInfo instance itself to declarePublic/declarePrivate\n  when using the public/private decorator. This fixes ``Conflicting security declarations``\n  warnings on Zope startup.\n\n- LP #1248529: Leave existing security manager in place inside\n  ``RoleManager.manage_getUserRolesAndPermissions``.\n\n3.0.8 (2013-07-16)\n------------------\n\n- LP #1169923:  ensure initialization of shared ``ImplPython`` state\n  (used by ``ImplC``) when using the \"C\" security policy.  Thanks to\n  Arnaud Fontaine for the patch.\n\n3.0.7 (2013-05-14)\n------------------\n\n- Remove long-deprecated 'Shared' roles support (pre-dates Zope, never\n  used by Zope itself)\n\n- Prevent infinite loop when looking up local roles in an acquisition chain\n  with cycles.\n\n3.0.6 (2012-10-31)\n------------------\n\n- LP #1071067: Use a stronger random number generator and a constant time\n  comparison function.\n\n3.0.5 (2012-10-21)\n------------------\n\n- LP #966101: Recognize special `zope2.Private` permission in ZCML\n  role directive.\n\n3.0.4 (2012-09-09)\n------------------\n\n- LP #1047318: Tighten import restrictions for restricted code.\n\n3.0.3 (2012-08-23)\n------------------\n\n- Fix a bug in ZopeSecurityPolicy.py. Global variable `rolesForPermissionOn`\n  could be overridden if `__role__` had custom rolesForPermissionOn.\n\n3.0.2 (2012-06-22)\n------------------\n\n- Add Anonymous as a default role for Public permission.\n\n3.0.1 (2012-05-24)\n------------------\n\n- Fix tests under Python 2.6.\n\n3.0 (2012-05-12)\n----------------\n\n- Added decorators for public, private and protected security declarations.\n\n- Update tests to take advantage of automatic test suite discovery.",
        "url": "http://pypi.python.org/pypi/AccessControl",
        "summary": "Security framework for Zope2.",
        "command": "pip install 'AccessControl'"
      },
      "accessibility": {
        "name": "accessibility",
        "description": "Accessibility: Wrapper for the Accessibility API\n================================================\n``accessibility`` is a Python module that wraps the Accessibility API for Mac OS X. It can be used to query and modify attributes of running applications, as well as watch for a variety of notifications. The source code and several examples (in the ``examples`` directory) are hosted on `GitHub <https://github.com/atheriel/accessibility>`_.\n\nThe module should compile under recent versions of both Python 2 and 3, and work with Mac OS X 10.8.x and 10.9.x. In addition, to compile the module on version 10.9.0 or later of OS X, you will need to have the Xcode IDE installed.\n\nBuilding\n--------\nThe module can be compiled using the traditional ``python setup.py clean build install`` provided by setuptools.\n\nDocumentation\n-------------\nThe module includes extensive docstrings, complete with examples in many cases. These can be can be browsed using Python's ``help`` command, or one can compile the Sphinx documentation. For the latter: \n\n1. ``cd docs``\n2. Initialize the git submodule with ``git submodule update --init --recursive`` to retrieve the custom Sphinx theme.\n3. ``make html`` and then browse the documentation in ``docs/_build/html``.\n\nLicense\n-------\nThis project is under the ISC License. See the ``LICENSE.txt`` file for details.",
        "url": "http://pypi.python.org/pypi/accessibility",
        "summary": "Extension module that wraps the Accessibility API for Mac OS X.",
        "command": "pip install 'accessibility'"
      },
      "accessible_output": {
        "name": "accessible_output",
        "description": "=====================================================\n The accessible_output library\n=====================================================\n\n:Author: Christopher Toth <Q@Qwitter-Client.net>\n:Date: $Date: 06-27-2011 02:00:00 -0400 (Mon, Jun 27, 2011)\n:Web site: http://www.qwitter-client.net/\n:Copyright: 2011\n\n\n.. contents::\n\n============\nIntroduction\n============\n\nAccessible Output provides a standard way for developers to output text in either speech or braille using a preinstalled screen reader.  Using accessible_output makes creating self-voicing applications extremely easy.  \n\n===========\nBasic Usage\n===========\nUsing accessible output is extremely simple::\n\n    #!/usr/bin/env python\n    from accessible_output import speech\n    s = speech.Speaker() #Will load the default speaker.\n    s.output(\"The message to speak\")\n\n==============\nSpeech Outputs\n==============\n\n* JAWS for Windows\n* Window Eyes\n* Dolphin Screen Readers newer than v11.\n* NVDA 2010.1 or newer\n* System Access and System Access To Go\n* Microsoft sapi 5 speech\n* Speech Dispatcher\n* Apple VoiceOver\n\n===============\nBraille Outputs\n===============\n\n\n* JAWS for Windows\n* Window Eyes\n* NVDA\n* System Access and System Access To Go",
        "url": "http://pypi.python.org/pypi/accessible_output",
        "summary": "Library to provide speech and braille output to a variety of different screen readers and other accessibility solutions.",
        "command": "pip install 'accessible_output'"
      },
      "accfifo": {
        "name": "accfifo",
        "description": "accfifo: A FIFO accounting calculator\n=====================================\n\n.. image:: https://travis-ci.org/vst/accfifo.svg?branch=develop\n\n``TODO: Provide a complete README file``\n\nUsage\n-----\n\nCheck tests to see examples.\n\nLicense\n-------\n\nThis library is licensed under `BSD 2-Clause <http://opensource.org/licenses/BSD-2-Clause>`_.\n",
        "url": "http://pypi.python.org/pypi/accfifo",
        "summary": "A FIFO accounting calculator",
        "command": "pip install 'accfifo'"
      },
      "accio": {
        "name": "accio",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/accio",
        "summary": "Sends information from code editors to server",
        "command": "pip install 'accio'"
      },
      "Accord": {
        "name": "accord",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Accord",
        "summary": "A high-level Python Web framework that encourages rapid development and clean, pragmatic design.",
        "command": "pip install 'Accord'"
      },
      "accordian": {
        "name": "accordian",
        "description": ".. image:: https://img.shields.io/travis/numberoverzero/accordian/master.svg?style=flat-square\n    :target: https://travis-ci.org/numberoverzero/accordian\n.. image:: https://img.shields.io/coveralls/numberoverzero/accordian/master.svg?style=flat-square\n    :target: https://coveralls.io/github/numberoverzero/accordian\n.. image:: https://img.shields.io/pypi/v/accordian.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/accordian\n.. image:: https://img.shields.io/github/issues-raw/numberoverzero/accordian.svg?style=flat-square\n    :target: https://github.com/numberoverzero/accordian/issues\n\n\nEvent dispatch in Python 3.5 using asyncio\n\nInstallation\n------------\n\n``pip install accordian``\n\nGetting Started\n---------------\n::\n\n    import asyncio\n    import accordian\n    import random\n\n    loop = asyncio.new_event_loop()\n\n    dispatch = accordian.Dispatch(loop=loop)\n    dispatch.register(\"my_event\", [\"id\", \"value\"])\n\n\n    @dispatch.on(\"my_event\")\n    async def handle(id, value):\n        sleep = 5.0 * random.random()\n        print(\"Handling `my_event(id={})` in {} seconds.\".format(id, sleep))\n        await asyncio.sleep(sleep, loop=loop)\n        print(\"`Completed my_event(id={})`!\".format(id))\n\n\n    ids = range(4)\n    values = [random.random() for _ in ids]\n    for id, value in zip(ids, values):\n        params = {\"id\": id, \"value\": value}\n        dispatch.trigger(\"my_event\", params)\n\n    loop.create_task(dispatch.start())\n    loop.run_until_complete(asyncio.sleep(0.01, loop=loop))\n    loop.run_until_complete(dispatch.stop())\n\n\nContributing\n------------\n\nContributions welcome!  Please make sure `tox` passes (including flake8) before submitting a PR.\n\nDevelopment\n-----------\n\naccordian uses `tox`, `pytest` and `flake8`.  To get everything set up::\n\n    # RECOMMENDED: create a virtualenv with:\n    #     mkvirtualenv accordian\n    git clone https://github.com/numberoverzero/accordian.git\n    pip install tox\n    tox",
        "url": "http://pypi.python.org/pypi/accordian",
        "summary": "Event dispatch in Python 3.5 using asyncio",
        "command": "pip install 'accordian'"
      },
      "accordion_presentation": {
        "name": "accordion_presentation",
        "description": "Accordion presentation\n======================\n\nIt is a simple horizontal (cycle2) accordion for django cms 3.0.6 and django 1.7.\n\nInstallation\n-----------------------\n\nInstall from pypi \n\n.. code:: bash\n\n\t$ pip install accordion_presentation\n\nor clone from with git \n\n.. code:: bash\n\n\t$ git clone https://github.com/luisza/accordion_presentation.git\n\t$ cd accordion_presentation\n\t$ python setup.py install\n\nSetup\n-------\n\nAnd put in your apps\n\n.. code:: python\n\t\n    INSTALLED_APPS = (\n        ...\n        'accordion_presentation',\n        'paintstore'\n    )\n\nRun migrate\n\n.. code:: bash\n\n    $ python manager.py migrate",
        "url": "http://pypi.python.org/pypi/accordion_presentation",
        "summary": "It is a simple horizontal accordion for django cms",
        "command": "pip install 'accordion_presentation'"
      },
      "AccordionWidget": {
        "name": "accordionwidget",
        "description": "Turbogears porting of Minikit makeAccordion javascript function.\r\n(Requires updating to MochiKit 1.4)",
        "url": "http://pypi.python.org/pypi/AccordionWidget",
        "summary": "An accordion widget for TG framework",
        "command": "pip install 'AccordionWidget'"
      },
      "Accost": {
        "name": "accost",
        "description": "Accost\r\n========\r\nAccost website <https://bitbucket.org/guyingbo/accost>",
        "url": "http://pypi.python.org/pypi/Accost",
        "summary": "Fast and easy python web framework",
        "command": "pip install 'Accost'"
      },
      "accountingModules": {
        "name": "accountingmodules",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/accountingModules",
        "summary": "UNKNOWN",
        "command": "pip install 'accountingModules'"
      },
      "accounts": {
        "name": "accounts",
        "description": "# accounts - Save your accounts of web services\n\nThe **accounts** saves your account of any web services.\nA goal of **accounts** is management services you always checking.\n\n## positional commands\n\n+ **add** \\<service\\> \\<account\\>\n    + **acounts** add account to registory.\n    + service: any web service name, url, domain.\n    + account: your account name\n    + *If you set the url to \\<service\\>, accounts set the sevice name to domain name of url.*\n    + From **v0.1.2**, accounts has any services information to `/accounts/services` directory,\n      If you set the **not-known** service name, accounts get that service's information by **fetching Google Search**.\n\n```sh\n$ accounts add github alice1017\naccounts saves the github account: alice1017\n$ accounts add http://qiita.com Alice1017\naccounts saves the qiita account: Alice1017\n```\n\n+ **upd** \\<service\\> \\<account\\>\n    + **accounts** updates account name.\n```sh\n$ accounts upd github Alice1017\naccounts updates the github account: alie1017 -> Alice1017\n```\n\n+ **del** \\<service\\>\n    + **accounts** deletes the account.\n\n```sh\n$ accounts del github\naccounts deletes the github account.\n```\n\n+ **login** \\<service\\>\n    + **accounts** opens browser to login service.\n    + service: you addesd service name or part of url\n    + If you put **\"all\"** to \\<service\\>, **accounts** opens all service.\n\n```sh\n$ accounts login github\naccounts Opening http://github.com to browser.\n```\n\n+ **list** [--service]\n    + **accounts** shows the list of accounts.\n    + *--service*: shows list of the known services\n\n```sh\n$ accounts list\n - github: alice1017\n - qiita: Alice1017\n```\n\n## install\n\n```sh\n$ pip install accounts\n```\n\nor\n\n```sh\n$ git clone git@github.com:alice1017/accounts.git\n$ cd accounts\n$ python setup.py build install\n```",
        "url": "http://pypi.python.org/pypi/accounts",
        "summary": "The accounts saves your account of web services.",
        "command": "pip install 'accounts'"
      },
      "accountsSSO": {
        "name": "accountssso",
        "description": "Account-SSO bindings How to\n===========================\n\nrequiriments:\n-------------\n    * shiboken              1.0.4\n    * pyside                qt4.7+1.0.4\n    * accounts.qt\n    * signon-qt\n    * AccountSetup\n",
        "url": "http://pypi.python.org/pypi/accountsSSO",
        "summary": "AccountSSO bindings for Harmattan platform",
        "command": "pip install 'accountsSSO'"
      },
      "accuri2fcs": {
        "name": "accuri2fcs",
        "description": "Accuri2fcs is a command line program for the conversion of accura .c6         formatted flow cytometry files to standard .fcs. In practise this is relatively         straightforward as Accuri files are simply zip structures containing multiple .fcs.         in a structured format. However, extracting and naming these individual files is a         little more tricky. This program allows rapid batch processing of multiple Accura         files into multiple .fcs files, with regular expression sample name matching, splitting         and copying to build the output filenames. It can get quite complicated, see the examples.",
        "url": "http://pypi.python.org/pypi/accuri2fcs",
        "summary": "Convert Accuri format flow cytometry files to standard .fcs",
        "command": "pip install 'accuri2fcs'"
      },
      "acdcli": {
        "name": "acdcli",
        "description": "|Donate| |Gitter| |PyVersion| |Status| |License| |Build| |PyPiVersion| |PyPiDownloadsMonth|\n\nacd\\_cli\n========\n\n**acd\\_cli** provides a command line interface to Amazon Cloud Drive and allows mounting your\ncloud drive using FUSE for read and write access. It is currently in beta stage.\n\nNode Cache Features\n-------------------\n\n- caching of local node metadata in an SQLite database\n- addressing of remote nodes via a pathname (e.g. ``/Photos/kitten.jpg``)\n- file search\n\nCLI Features\n------------\n\n- tree or flat listing of files and folders\n- simultaneous uploads/downloads, retry on error\n- basic plugin support\n\nFile Operations\n~~~~~~~~~~~~~~~\n\n- upload/download of single files and directories\n- streamed upload/download\n- folder creation\n- trashing/restoring\n- moving/renaming nodes\n\nQuick Start\n-----------\n\nInstallation\n~~~~~~~~~~~~\n\nPlease check which pip command is appropriate for Python 3 packages in your environment.\nI will be using 'pip3' as superuser in the examples.\n\nThe easiest way is to directly install from PyPI.\n::\n\n   pip3 install --upgrade --pre acdcli\n\n\nThe most up-to-date way is to directly install from github.\n::\n\n   pip3 install --upgrade git+https://github.com/yadayada/acd_cli.git\n\n\nFurther setup options and dependencies are described in the `setup guide <docs/setup.rst>`_.\n\nFirst Run\n~~~~~~~~~\n\nOn the first start of the program (try ``acd_cli sync``), you will have to complete the OAuth procedure.\nA browser tab will open and you will be asked to log in or grant access for 'acd\\_cli\\_oa'.\nSigning in or clicking on 'Continue' will download a JSON file named ``oauth_data``,\nwhich must be placed in the cache directory displayed on screen (e.g. ``/home/<USER>/.cache/acd_cli``).\n\nYou may view the source code of the Appspot app that is used to handle the server part\nof the OAuth procedure at https://tensile-runway-92512.appspot.com/src.\n\nAdvanced Users\n++++++++++++++\n\nAlternatively, you may put your own security profile data in a file called ``client_data`` in the cache directory.\nIt needs to be created prior to starting the program and adhere to the following form.\n\n.. code :: json\n\n {\n     \"CLIENT_ID\": \"\",\n     \"CLIENT_SECRET\": \"\"\n }\n\nYour security profile must be able to redirect to ``http://localhost``.\nThe procedure is similar to the above, the difference is that you will\nbe asked to paste the redirect URL into your shell.\n\nUsage\n-----\n\nacd_cli can be run as ``acd_cli`` or ``acdcli``.\n\nMost actions need the node cache to be initialized and up-to-date, so please run a sync.\nA sync will fetch the changes since the last sync or the full node list if the cache is empty.\n\nThe following actions are built in\n::\n\n        sync (s)            refresh node list cache; necessary for many actions\n        clear-cache (cc)    clear node cache [offline operation]\n\n        tree (t)            print directory tree [offline operation]\n        children (ls)       list a folder's children [offline operation]\n\n        find (f)            find nodes by name [offline operation] [case insensitive]\n        find-md5 (fm)       find files by MD5 hash [offline operation]\n        find-regex (fr)     find nodes by regular expression [offline operation] [case insensitive]\n\n        upload (ul)         file and directory upload to a remote destination\n        overwrite (ov)      overwrite file A [remote] with content of file B [local]\n        stream (st)         upload the standard input stream to a file\n        download (dl)       download a remote folder or file; will skip existing local files\n        cat                 output a file to the standard output stream\n\n        create (c, mkdir)   create folder using an absolute path\n\n        list-trash (lt)     list trashed nodes [offline operation]\n        trash (rm)          move node to trash\n        restore (re)        restore node from trash\n\n        move (mv)           move node A into folder B\n        rename (rn)         rename a node\n\n        resolve (rs)        resolve a path to a node ID [offline operation]\n\n        usage (u)           show drive usage data\n        quota (q)           show drive quota [raw JSON]\n        metadata (m)        print a node's metadata [raw JSON]\n\n        mount               mount the cloud drive at a local directory\n        umount              unmount cloud drive(s)\n\nPlease run ``acd_cli --help`` to get a current list of the available actions. A list of further\narguments of an action and their order can be printed by calling ``acd_cli [action] --help``.\n\nMost node arguments may be specified as a 22 character ID or a UNIX-style path.\nTrashed nodes' paths might not be able to be resolved correctly; use their ID instead.\n\nThere are more detailed instructions for `file transfer actions <docs/transfer.rst>`_ and\n`find actions <docs/find.rst>`_.\n\nMounting\n~~~~~~~~\n\nFirst, create an empty mount directory, then run ``acd_cli mount path/to/mountpoint``.\nTo unmount later, run ``acd_cli umount``.\n\nFurther information can be found in the `FUSE documentation <docs/FUSE.rst>`_.\n\nExit Status\n~~~~~~~~~~~\n\nWhen the script is done running, its exit status can be checked for flags. If no error occurs,\nthe exit status will be 0. Possible flag values are:\n\n===========================  =======\n        flag                  value\n===========================  =======\ngeneral error                    1\nargument error                   2\nfailed file transfer             8\nupload timeout                  16\nhash mismatch                   32\nerror creating folder           64\nfile size mismatch             128\ncache outdated                 256\nremote duplicate               512\nduplicate inode               1024\nfile/folder name collision    2048\n===========================  =======\n\nIf multiple errors occur, their values will be compounded by a binary OR operation.\n\nProxy support\n~~~~~~~~~~~~~\n\n`Requests <https://github.com/kennethreitz/requests>`_ supports HTTP(S) proxies via environment\nvariables. Since all connections to Amazon Cloud Drive are using HTTPS, you need to\nset the variable ``HTTPS_PROXY``. The following example shows how to do that in a bash-compatible\nenvironment.\n::\n\n    $ export HTTPS_PROXY=\"https://user:pass@1.2.3.4:8080/\"\n\nCLI Usage Example\n-----------------\n\nIn this example, a two-level folder hierarchy is created in an empty cloud drive.\nThen, a relative local path ``local/spam`` is uploaded recursively using two connections.\n::\n\n    $ acd_cli sync\n      Syncing...\n      Done.\n\n    $ acd_cli ls /\n      [PHwiEv53QOKoGFGqYNl8pw] [A] /\n\n    $ acd_cli mkdir /egg/\n    $ acd_cli mkdir /egg/bacon/\n\n    $ acd_cli upload -x 2 local/spam/ /egg/bacon/\n      [################################]   100.0% of  100MiB  12/12  654.4KB/s\n\n    $ acd_cli tree\n      /\n          egg/\n              bacon/\n                  spam/\n                      sausage\n                      spam\n      [...]\n\n\nThe standard node listing format includes the node ID, the first letter of its status and its full path.\nPossible statuses are \"AVAILABLE\" and \"TRASH\".\n\nKnown Issues\n------------\n\nIt is not possible to upload files using Python 3.2.3, 3.3.0 and 3.3.1.\n\nIf you encounter Unicode problems, check that your locale is set correctly or use the ``--utf``\nargument to force the script to use UTF-8 output encoding.\nWindows users may try to execute the provided `reg file <assets/win_codepage.reg>`_\n(tested with Windows 8.1) to set the command line interface encoding to cp65001.\n\nAPI Restrictions\n~~~~~~~~~~~~~~~~\n\n- the current upload file size limit is 50GiB\n- uploads of large files >10 GiB may be successful, yet a timeout error is displayed (please check manually)\n- storage of node names is case-preserving, but not case-sensitive (this concerns Linux users mainly)\n- it is not possible to share or delete files\n\nContribute\n----------\n\nHave a look at the `contributing guidelines <CONTRIBUTING.rst>`_.\n\nRecent Changes\n--------------\n\n..\n    0.3.1\n    ~~~~~\n\n    * general improvements for FUSE\n    * FUSE write support added\n\n0.3.0\n~~~~~\n\n* FUSE read support added\n\n0.2.2\n~~~~~\n\n* sync speed-up\n* node listing format changed\n* optional node listing coloring added (for Linux or via LS_COLORS)\n* re-added possibility for local OAuth\n\n0.2.1\n~~~~~\n\n* curl dependency removed\n* added job queue, simultaneous transfers\n* retry on error\n\n0.2.0\n~~~~~\n* setuptools support\n* workaround for download of files larger than 10 GiB\n* automatic resuming of downloads\n\n\n.. |Donate| image:: https://img.shields.io/badge/paypal-donate-blue.svg\n   :alt: Donate via PayPal\n   :target: https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=V4V4HVSAH4VW8\n\n.. |Gitter| image:: https://img.shields.io/badge/GITTER-join%20chat-brightgreen.svg\n   :alt: Join the Gitter chat\n   :target: https://gitter.im/cloud-drive/acd_cli\n\n.. |PyPiVersion| image:: https://img.shields.io/pypi/v/acdcli.svg\n   :alt: PyPi\n   :target: https://pypi.python.org/pypi/acdcli\n\n.. |PyVersion| image:: https://img.shields.io/badge/python-3.2+-blue.svg\n   :alt:\n\n.. |Status| image:: https://img.shields.io/badge/status-beta-yellow.svg\n   :alt:\n\n.. |License| image:: https://img.shields.io/badge/license-GPLv2+-blue.svg\n   :alt:\n\n.. |PyPiDownloadsMonth| image:: https://img.shields.io/pypi/dm/acdcli.svg\n   :alt:\n   :target: https://pypi.python.org/pypi/acdcli\n\n.. |Build| image:: https://img.shields.io/travis/yadayada/acd_cli.svg\n   :alt:\n   :target: https://travis-ci.org/yadayada/acd_cli",
        "url": "http://pypi.python.org/pypi/acdcli",
        "summary": "a command line interface and FUSE filesystem for Amazon Cloud Drive",
        "command": "pip install 'acdcli'"
      },
      "ace": {
        "name": "ace",
        "description": "ace is an implementation of the Alternating Conditional Expectation (ACE) algorithm [Breiman85]_,\nwhich can be used to find otherwise difficult-to-find relationships between predictors\nand responses and as a multivariate regression tool.\n\nThe full documentation is hosted at http://partofthething.com/ace.\nThe source code, bug tracker, etc., can be found at: https://github.com/partofthething/ace\n\nWhat is it?\n===========\nACE can be used for a variety of purposes. With it, you can:\n\n - build easy-to-evaluate surrogate models of data. For example, if you are optimizing input\n   parameters to a complex and long-running simulation, you can feed the results of a parameter\n   sweep into ACE to get a model that will instantly give you predictions of results of any\n   combination of input within the parameter range.\n\n - expose interesting and meaningful relations between predictors and responses from complicated\n   data sets. For instance, if you have survey results from 1000 people and you and you want to\n   see how one answer is related to a bunch of others, ACE will help you.\n\nThe fascinating thing about ACE is that it is a *non-parametric* multivariate regression\ntool. This means that it doesn't make any assumptions about the functional form of the data.\nYou may be used to fitting polynomials or lines to data. Well, ACE doesn't do that. It\nuses an iteration with a variable-span scatterplot smoother (implementing local least\nsquares estimates) to figure out the structure of your data. As you'll see, that\nturns out to be a powerful difference.\n\nInstalling it\n=============\nOn Linux::\n\n\tsudo pip install ace\n\nOn Windows::\n\n\tpip install ace\n\n\nUsing it\n========\nTo use, get some sample data::\n\n    from ace.samples import wang04\n    x, y = wang04.build_sample_ace_problem_wang04(N=200)\n\nand run::\n\n    from ace import model\n    myace = model.Model()\n    myace.build_model_from_xy(x, y)\n    myace.eval([0.1, 0.2, 0.5, 0.3, 0.5])\n\nFor some plotting (matplotlib required), try::\n\n    from ace import ace\n    ace.plot_transforms(myace, fname = 'mytransforms.pdf')\n    myace.ace.write_transforms_to_file(fname = 'mytransforms.txt')\n\nMore details\n============\nThis implementation of ACE isn't as fast as the original FORTRAN version, but it can\nstill crunch through a problem with 5 independent variables having 1000 observations each\nin on the order of 15 seconds. Not bad.\n\nace also contains a pure-Python implementation of Friedman's SuperSmoother [Friedman82]_,\nthe variable-span smoother mentioned above. This can be useful on its own\nfor smoothing scatterplot data.\n\nReferences\n==========\n.. [Breiman85] L. BREIMAN and J. H. FRIEDMAN, \"Estimating optimal transformations for multiple regression and\n   correlation,\" Journal of the American Statistical Association, 80, 580 (1985).\n   `[PDF at JSTOR] <http://www.jstor.org/discover/10.2307/2288477?uid=2&uid=4&sid=21104902100507>`_\n\n.. [Friedman82] J. H. FRIEDMAN and W. STUETZLE, \"Smoothing of scatterplots,\" ORION-003, Stanford\n   University, (1982). `[PDF at Stanford] <http://www.slac.stanford.edu/cgi-wrap/getdoc/slac-pub-3013.pdf>`_",
        "url": "http://pypi.python.org/pypi/ace",
        "summary": "Non-parametric multivariate regressions by Alternating Conditional Expectations",
        "command": "pip install 'ace'"
      },
      "AceMorse": {
        "name": "acemorse",
        "description": "AceMorse\n=======================\n\nAceMorse is designed for encoding and decoding strings of Morse code.\n\nExample usage of AceMorse::\n\n    from acemorse import MorseCode\n\n    morse = MorseCode()\n\n    text = 'Hello world!'\n\n    print('Original text: {}'.format(text))\n    message = morse.generate(text)\n\n    print('Morse code: {}'.format(message))\n    translate = morse.translate(message)\n\n    print('Back to English: {}'.format(translate))",
        "url": "http://pypi.python.org/pypi/AceMorse",
        "summary": "Library for encoding and decoding Morse code.",
        "command": "pip install 'AceMorse'"
      },
      "AC-Flask-HipChat": {
        "name": "ac-flask-hipchat",
        "description": "AC-Flask-HipChat\n-------------\n\nA library to help write a Flask-based HipChat add-on",
        "url": "http://pypi.python.org/pypi/AC-Flask-HipChat",
        "summary": "Atlassian Connect library based on Flask for HipChat",
        "command": "pip install 'AC-Flask-HipChat'"
      },
      "ach": {
        "name": "ach",
        "description": "python-ach\n==========\n\n.. image:: https://travis-ci.org/travishathaway/python-ach.svg?branch=master\n    :target: https://travis-ci.org/travishathaway/python-ach\n\nACH file generator module for python. So far, this has been tested with\n“PPD” and “CCD” batches with addenda records.\n\nExample\n=======\n\nBelow is an example of how to use the module:\n\n.. code:: python\n\n\n    from ach.builder import AchFile\n\n    settings = {\n        'immediate_dest' : '123456789', # Your bank's routing number \n        'immediate_org' : '123456789', # Bank assigned routing number\n        'immediate_dest_name' : 'YOUR BANK',\n        'immediate_org_name' : 'YOUR COMPANY',\n        'company_id' : '1234567890', #tax number\n    }\n\n    ach_file = AchFile('A',settings) #file Id mod\n\n    entries = [\n        {\n            'type'           : '22', # type of\n            'routing_number' : '12345678',\n            'account_number' : '11232132',\n            'amount'         : '10.00',\n            'name'           : 'Alice Wanderdust',\n            'addenda' : [\n                {\n                    'payment_related_info': 'Here is some additional information',\n                },\n            ],\n        },\n        {\n            'type'           : '27',\n            'routing_number' : '12345678',\n            'account_number' : '234234234',\n            'amount'         : '150.00',\n            'name'           : 'Billy Holiday',\n        },\n        {\n            'type'           : '22',\n            'routing_number' : '12323231',\n            'account_number' : '123123123',\n            'amount'         : '12.13',\n            'name'           : 'Rachel Welch',\n        },\n    ]\n\n    ach_file.add_batch('PPD', entries, credits=True, debits=True)\n\n    print ach_file.render_to_string()\n\nThis returns the following NACHA file:\n\n::\n\n    101 123456789 1234567891407141745A094101YOUR BANK              YOUR COMPANY                   \n    5220YOUR COMPANY                        1234567890PPDPAYROLL         140714   1123456780000001\n    62212345678011232132         0000001000               ALICE WANDERDUST        1123456780000001\n    705HERE IS SOME ADDITIONAL INFORMATION                                             00000000001\n    622123456780234234234        0000015000               BILLY HOLIDAY           0123456780000002\n    622123232315123123123        0000001213               RACHEL WELCH            0123456780000003\n    822000000400370145870000000000000000000172131234567890                         123456780000001\n    9000001000001000000040037014587000000000000000000017213                                       \n    9999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999\n    9999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999999",
        "url": "http://pypi.python.org/pypi/ach",
        "summary": "Library to create and parse ACH files (NACHA)",
        "command": "pip install 'ach'"
      },
      "AChemKit": {
        "name": "achemkit",
        "description": "######\r\nReadme\r\n######\r\n\r\nDescription\r\n===========\r\n\r\nPyAChemKit is a collection of Artificial Chemistry software written in Python - a library and collection of tools. \r\n\r\nArtificial Chemistry (AChem) is a spin-off topic of Artificial Life. AChem is aimed at emergence of life from\r\nnon-living environment - primordial soup etc.\r\n\r\n\r\nInstallation\r\n============\r\n\r\nTo install on Ubuntu Linux, run ::\r\n\r\n  sudo easy_install -U AChemKit\r\n\r\nThis package should work on other Linux distributions and versions of Windows, but is untested.\r\n\r\nThis package requires the following:\r\n\r\n* Python   >= 2.6   http://www.python.org/\r\n    \r\nSome features use the following:\r\n\r\n* NetworkX\r\n* GraphViz http://www.graphviz.org/\r\n    \r\nOptionally, the following can be installed to improve performance:\r\n\r\n* Psyco http://psyco.sourceforge.net\r\n* PyPy  http://codespeak.net/pypy\r\n        \r\nSource\r\n======\r\n\r\nThe latest version of the source code is available from https://github.com/afaulconbridge/PyAChemKit\r\n\r\nThe source code additionally requires the following:\r\n\r\n* Sphinx   >= 1.0   http://sphinx.pocoo.org/\r\n* Graphviz          http://www.graphviz.org/\r\n* Make              http://www.gnu.org/software/make/\r\n* LaTeX             http://www.latex-project.org/\r\n* PyLint   >=0.13.0 http://www.logilab.org/project/pylint/\r\n* Coverage          http://nedbatchelder.com/code/coverage/\r\n\r\n\r\nFor a Debian-based Linux distrbution --- e.g. Debian, Ubuntu --- these can be installed / updated with::\r\n\r\n  make setup\r\n    \r\n(Note, LaTeX is not installed via this method because it is very large. Run ``sudo apt-get install texlive-full`` if you want to be able to compile the PDF documentation.)\r\n\r\n\r\nThere is a makefile that will run some useful tasks for you (generate documentation, test, benchmark). This can be accessed by running the following command::\r\n\r\n    make help\r\n    \r\nCopyright\r\n=========\r\n\r\nThis project is licensed under a modified-BSD license. See the fie ``COPYRIGHT`` for details.",
        "url": "http://pypi.python.org/pypi/AChemKit",
        "summary": "An Artificial Chemistry Tookit",
        "command": "pip install 'AChemKit'"
      },
      "Achoo": {
        "name": "achoo",
        "description": "Achoo is a fluent interface for testing Python objects. It makes\r\nmaking assertions about objects (is this object equal to this other one?)\r\nand function and method calls (does calling this function with these\r\narguments raise an error?) easy.",
        "url": "http://pypi.python.org/pypi/Achoo",
        "summary": "A fluent interface for testing Python objects.",
        "command": "pip install 'Achoo'"
      },
      "acid": {
        "name": "acid",
        "command": "pip install 'acid'"
      },
      "acidfile": {
        "name": "acidfile",
        "description": "acidfile\n========\n\n`acidfile` module provides the ACIDFile object. This object can be used as a\nregular file object but instead of write one copy of the data, it will write\nseveral copies to disk in an ACID manner.\n\nThis algorithm was explained by `Elvis Pfützenreuter`_ in his blog post\n`Achieving ACID transactions with common files`_.\n\nLatest stable version can be found on `PyPI`_.\n\n.. image:: https://travis-ci.org/nilp0inter/acidfile.png?branch=develop\n    :target: https://travis-ci.org/nilp0inter/acidfile\n\n.. image:: https://pypip.in/v/acidfile/badge.png\n    :target: https://pypi.python.org/pypi/acidfile\n    :alt: Latest PyPI version\n\n.. image:: https://pypip.in/d/acidfile/badge.png\n    :target: https://pypi.python.org/pypi/acidfile\n    :alt: Number of PyPI downloads\n\n`acidfile` is compatible with python 2.6, 2.7, 3.2, 3.3, 3.4 and pypy\n\nContribute:\n\n.. image:: http://api.flattr.com/button/flattr-badge-large.png\n    :target: https://flattr.com/submit/auto?user_id=nilp0inter&url=https://github.com/nilp0inter/acidfile&title=acidfile&language=&tags=github&category=software\n    :alt: Flattr this git repo\n\nInstallation\n------------\n\nLatest version can be installed via `pip`\n\n.. code-block:: bash\n\n   $ pip install --upgrade acidfile\n\n\nRunning the tests\n-----------------\n\nClone this repository and install the develop requirements.\n\n.. code-block:: bash\n\n   $ git clone https://github.com/nilp0inter/acidfile.git\n   $ cd acidfile\n   $ pip install -r requirements/develop.txt\n   $ python setup.py develop\n   $ tox\n\n\nUsage examples\n--------------\n\n\nBasic usage\n+++++++++++\n\n.. code-block:: python\n\n   >>> from acidfile import ACIDFile\n\n   >>> myfile = ACIDFile('/tmp/myfile.txt', 'w')\n   >>> myfile.write(b'Some important data.')\n   >>> myfile.close()\n\nAt the close invocation two copies will be written to disk: *myfile.txt.0* and\nbelow *myfile.txt.1*. Each one will have an creation timestamp and a HMAC\nsignature.\n\n.. code-block:: python\n\n   >>> myfile = ACIDFile('/tmp/myfile.txt', 'r')\n   >>> print myfile.read()\n   'Some important data.'\n   >>> myfile.close()\n\nIf any of the files is damaged due to turning off without proper shutdown or\ndisk failure, manipulation, etc. It will be detected by the internal HMAC and\nthe other's file data would be used instead.\n\n.. note:: If you want to read an `acidfile`, never pass the full path of the\n   real file, instead use the file name that you use in the creation step.\n\n   | ✗ ACIDFile('/tmp/myfile.txt.0', 'r')\n   | ✗ ACIDFile('/tmp/myfile.txt.1', 'r')\n   | ✓ ACIDFile('/tmp/myfile.txt', 'r')\n\n\nContext manager\n+++++++++++++++\n\nACIDFile can (and should) be used as a regular context manager:\n\n.. code-block:: python\n\n   >>> with ACIDFile('/tmp/myfile.txt', 'w') as myfile:\n   ...     myfile.write(b'Some important data.')\n\n\nNumber of copies\n++++++++++++++++\n\nThe number of inner copies of the data can be configured through the **copies**\nparameter.\n\n\nChecksum Key\n++++++++++++\n\nThe key used for compute and check the internal HMAC signature can be setted\nby the **key** parameter.\n\nIt's recommended to change that key in order to protect against fraud, making\nmore difficult for a tamperer to put a fake file in place of the legitimate\none.\n\n.. _PyPI: https://pypi.python.org/pypi/acidfile\n.. _Elvis Pfützenreuter: epx@epx.com.br\n.. _Achieving ACID transactions with common files: http://epx.com.br/artigos/arqtrans_en.php\n\n\n.. This is your project NEWS file which will contain the release notes.\n.. Example: http://www.python.org/download/releases/2.6/NEWS.txt\n.. The content of this file, along with README.rst, will appear in your\n.. project's PyPI page.\n\nNews\n====\n\n\n1.2.1\n-----\n\n* Using io.open in setup.py to read README and NEWS. This fix some\n  problems installing the package.\n+ Python 3.4 support.\n\n\n1.2.0\n-----\n\n+ Python 2.6 support.\n+ Added Python 3.2 and pypy to tox tests.\n+ Added flattr button :D\n* Fixed flake8 and pylint warnings.\n\n\n1.1.0\n-----\n\n+ Python 3 support.\n+ Changed testing framework to `behave` because python 3 support.\n+ Using `tox` for multiple python version testing.\n\n\n1.0.0\n-----\n\n* First stable release.\n+ Documentation.\n\n\n0.0.1\n-----\n\n* Initial development.",
        "url": "http://pypi.python.org/pypi/acidfile",
        "summary": "ACID transaction with common files",
        "command": "pip install 'acidfile'"
      },
      "acidfs": {
        "name": "acidfs",
        "description": "AcidFS allows interaction with the filesystem using transactions with ACID \nsemantics.  `Git` is used as a back end, and `AcidFS` integrates with the \n`transaction <http://pypi.python.org/pypi/transaction>`_ package allowing use of\nmultiple databases in a single transaction.  AcidFS makes concurrent persistent\nto the filesystem  safe and reliable.\n\nFull documentation is available at `Read the Docs \n<http://acidfs.readthedocs.org/>`_.\n\n\nChange Log\n==========\n\n1.0 (2013-01-03)\n----------------\n\nInitial release.",
        "url": "http://pypi.python.org/pypi/acidfs",
        "summary": "ACID semantics for the filesystem.",
        "command": "pip install 'acidfs'"
      },
      "acitoolkit": {
        "name": "acitoolkit",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/acitoolkit",
        "summary": "This library allows basic Cisco ACI APIC configuration.",
        "command": "pip install 'acitoolkit'"
      },
      "ackg": {
        "name": "ackg",
        "description": "With ackg for Linux you can search folders\nof your harddrive for source files containing a given pattern, similar\nto grep.",
        "url": "http://pypi.python.org/pypi/ackg",
        "summary": "Script wrapping GNU find, xargs/parallel,grep to search code for pattern",
        "command": "pip install 'ackg'"
      },
      "acky": {
        "name": "acky",
        "description": "%%%%%%%%%%%%\nAcky Library\n%%%%%%%%%%%%\n\n.. image:: https://travis-ci.org/RetailMeNot/acky.svg?branch=master\n   :target: https://travis-ci.org/RetailMeNot/acky\n   :alt: Build Status\n\nThe Acky library provides a consistent interface to AWS. Based on botocore, it\nabstracts some of the API work involved and allows the user to interact with AWS\nAPIs in a consistent way with minimal overhead.\n\nAcky takes a different approach to the API from libraries like the venerable\n`Boto <https://github.com/boto/boto>`. Rather than model AWS objects as Python\nobjects, Acky simply wraps the API to provide a more consistent interface. Most\nobjects in AWS are represented as collections in Acky, with get(), create(),\nand destroy() methods. The get() method always accepts a filter map, no matter\nif the underlying API method does.\n\nIn cases where the API's multitude of parameters would make for awkward method\ncalls (as is the case with EC2's RunInstances), Acky provides a utility class\nwhose attributes can be set before executing the API call.\n\n\n%%%%%%%%%%\nUsing Acky\n%%%%%%%%%%\n\nAcky uses a botocore-style AWS credential configuration, the same as the\nofficial AWS CLI. Before you use Acky, you'll need to `set up your config\n<http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html>`.\n\nOnce your credentials are set up, using acky is as simple as creating an\ninstance of the AWS object::\n\n    from acky.aws import AWS\n    aws = AWS(region, profile)\n    instances = aws.ec2.Instances.get(filters={'tag:Name': 'web-*'})\n    print('Found {} web servers'.format(len(instances)))\n    for instance in instances:\n        print('  {}'.format(instance['PublicDnsName'])\n\n\n%%%%%%%%%%%%%%%%\nModule Structure\n%%%%%%%%%%%%%%%%\n\nThe expected module structure for Acky follows. Many APIs are not yet\nimplemented, but those that are can be considered stable.\n\n* AWS\n\n  * username (property)\n  * userinfo (property)\n  * account_id (property)\n  * environment (property)\n  * ec2\n\n    * regions\n    * zones\n    * ACEs\n    * ACLs\n    * ElasticIPs\n    * Instances\n    * IpPermissions\n    * KeyPairs\n    * PlacementGroups\n    * SecurityGroups\n    * Snapshots\n    * Subnets\n    * VPCs\n    * Volumes\n\n  * iam\n\n    * Users\n    * Groups\n    * Keys\n\n  * rds\n\n    * engine_versions\n    * Instances\n    * Snapshots\n    * EventSubscriptions\n    * SecurityGroups\n    * SecurityGroupRules\n\n  * sqs\n\n    * Queues\n    * Messages\n\n  * sts\n\n    * GetFederationToken\n    * GetSessionToken\n\nOther services will be added in future versions.\n\n%%%%%%%%%%%%%%%%%%\nInstalling acky\n%%%%%%%%%%%%%%%%%%\n\nacky is available in PyPI and is installable via pip::\n\n    pip install acky\n\nYou may also install acky from source, perhaps from the GitHub repo::\n\n    git clone https://github.com/RetailMeNot/acky.git\n    cd acky\n    python setup.py install",
        "url": "http://pypi.python.org/pypi/acky",
        "summary": "A consistent API to AWS",
        "command": "pip install 'acky'"
      },
      "acl": {
        "name": "acl",
        "description": "Network access control list parsing library.\n\nThis library contains various modules that allow for parsing, manipulation, and\nmanagement of network access control lists (ACLs). It will parse a complete ACL\nand return an ACL object that can be easily translated to any supported vendor\nsyntax.",
        "url": "http://pypi.python.org/pypi/acl",
        "summary": "Network access control list parsing library.",
        "command": "pip install 'acl'"
      },
      "aclhound": {
        "name": "aclhound",
        "description": "[link_documentation]: https://github.com/job/aclhound/blob/master/DOCUMENTATION.md\n\n\n\nACLHOUND\n========\n\n[![Build Status](https://travis-ci.org/job/aclhound.svg?branch=master)](https://travis-ci.org/job/aclhound)\n[![Coverage Status](https://coveralls.io/repos/job/aclhound/badge.svg?branch=master)](https://coveralls.io/r/job/aclhound?branch=master)\n\nSummary\n-------\n\nACLHound takes as input policy language following a variant of the [AFPL2] [1]\nsyntax and compiles a representation specific for the specified vendor which\ncan be deployed on firewall devices.\n\nTable of contents\n-----------------\n\n- [Design goals](#design-goals)\n- [Supported devices](#supported-devices)\n- [Installation notes](#installation-notes)\n- [Copyright and license](#copyright-and-license)\n\nDesign goals\n------------\n\nACLHound is designed to assist humans in managing hundreds of ACLs across \ntens of devices. One key focus point is maximum re-usability of ACL \ncomponents such as groups of hosts, groups of ports and the policies \nthemselves.\n\nSupported devices \n-----------------\n\n* Cisco ASA\n    * No support for ASA 9.1.2 or higher (yet)\n* Cisco IOS\n    * Will autodetect IPv6 support through ```show ipv6 cef```\n* Juniper (planned)\n\nInstallation notes\n------------------\n\nStep 1: get the code\n\n```\nsudo pip install aclhound\n```\n\nDocumentation\n-------------\n\nDocumentation can be found [here][link_documentation]. This describes directory structure, ACLhound language syntax and examples.\n\nCopyright and license\n---------------------\n\nCopyright 2014,2015 Job Snijders. Code and documentation released under the BSD\n2-Clause license.\n\nACLHound's inception was commissioned by the eBay Classifieds Group.\n\n[1]: http://www.lsi.us.es/~quivir/sergio/DEPEND09.pdf \"AFPL2\"\n[2]: http://jenkins-ci.org/ \"Jenkins\"\n[3]: https://wiki.jenkins-ci.org/display/JENKINS/Gerrit+Trigger \"Gerrit Trigger\"",
        "url": "http://pypi.python.org/pypi/aclhound",
        "summary": "ACL Compiler",
        "command": "pip install 'aclhound'"
      },
      "aclust": {
        "name": "aclust",
        "description": "Aclust\n======\nStreaming agglomerative clustering with custom distance and correlation\n\n\n*Agglomerative clustering* is a very simple algorithm.\nThe function `aclust` provided here is an attempt at a simple implementation\nof a modified version that allows a stream of input so that data is not\nrequired to be read into memory all at once. Most clustering algorithms operate\non a matrix of correlations which may not be feasible with high-dimensional\ndata.\n\n`aclust` **defers** some complexity to the caller by relying on a stream of\nobjects that support an interface (I know, I know) of:\n\n    obj.distance(other) -> numeric\n    obj.is_correlated(other) -> bool\n\nWhile this does add some infrastructure, we can imagine a class with\nposition and values attributes, where the former is an integer and the\nlatter is a list of numeric values. Then, those methods would be implemented\nas:\n\n    def distance(self, other):\n        return self.position - other.position\n\n    def is_correlated(self, other):\n        return np.corrcoef(self.values, other.values)[0, 1] > 0.5\n\nThis allows the `aclust` function to be used on **any** kind of data. We can\nimagine that distance might return the Levenshtein distance between 2 strings\nwhile is\\_correlated might indicate their presence in the same sentence or in\nsentences with the same sentiment.\n\nSince the input can be- and the output is- streamed, it is assumed the the objs\nare in sorted order. This is important for things like genomic data, but may be\nless so in text, where the max\\_skip parameter can be set to a large value to\ndetermine how much data is kept in memory.\n\nSee the function docstring for examples and options. The function signature is:\n\n   aclust(object\\_stream, max\\_dist,\n          max\\_skip=1, linkage='single', multi\\_member=False)\n\nIt yields clusters (lists) of objects from the input object stream.\n\n`multi\\_member` allows a feature to be a member of multiple clusters as long as\nit meets the distance and correlation constraints. The default is to only\nallow a feature to be added to the *nearest* cluster with which it is\ncorrelated.\n\nUses\n====\n\n+  Clustering methylation data which we know to be locally correlated. We can\n   use this to reduce the number of tests (of association) from 1 test per CpG,\n   to 1 test per correlated unit.\n   See: https://github.com/brentp/aclust/blob/master/examples/methylation-clustering-asthma.py for a full example.\n\n```\n    chrom   start   end n_probes   probes                asthma.pvalue   asthma.tstat    asthma.coef\n    chr1    566570  567501  8   chr1:566570,chr1:566731,chr1:567113,chr1:567206,chr1:567312,chr1:567348,chr1:567358,chr1:567501 0.4566  -0.74   -0.06\n    chr1    713985  714021  3   chr1:713985,chr1:714012,chr1:714021 0.1185  -1.56   -0.13\n    chr1    845810  846195  3   chr1:845810,chr1:846155,chr1:846195 0.5913  0.54    0.04\n    chr1    848379  848440  3   chr1:848379,chr1:848409,chr1:848440 0.3399  -0.95   -0.06\n    chr1    854766  855046  7   chr1:854766,chr1:854824,chr1:854838,chr1:854918,chr1:854951,chr1:854966,chr1:855046 0.7482  -0.32   -0.02\n    chr1    870791  871546  8   chr1:870791,chr1:870810,chr1:870958,chr1:871033,chr1:871057,chr1:871308,chr1:871441,chr1:871546 0.2198  -1.23   -0.11\n    chr1    892857  892948  3   chr1:892857,chr1:892914,chr1:892948 0.2502  -1.15   -0.05\n    chr1    901062  901799  5   chr1:901062,chr1:901449,chr1:901685,chr1:901725,chr1:901799 0.6004  0.52    0.04\n    chr1    946875  947091  4   chr1:946875,chr1:947003,chr1:947018,chr1:947091 0.9949  0.01    0.00\n```\n   So we can filter on the asthma.pvalue to find regions associated with asthma.\n  \n\nINSTALL\n=======\n\n`aclust` is available on pypi, as such it can be installed with:\n\n    pip install aclust\n\n\nAcknowledgments\n===============\n\nThe idea of this is taken from this paper:\n\n    Sofer, T., Schifano, E. D., Hoppin, J. A., Hou, L., & Baccarelli, A. A. (2013). A-clustering: A Novel Method for the Detection of Co-regulated Methylation Regions, and Regions Associated with Exposure. Bioinformatics, btt498.\n\nThe example uses a pull-request implementing GEE for python's statsmodels:\n    https://github.com/statsmodels/statsmodels/pull/928",
        "url": "http://pypi.python.org/pypi/aclust",
        "summary": "streaming agglomerative clustering",
        "command": "pip install 'aclust'"
      },
      "acme": {
        "name": "acme",
        "command": "pip install 'acme'"
      },
      "acme.dchat": {
        "name": "acme.dchat",
        "description": "===========\nacme.dchat\n===========\n\nWhat API ?\n==========\n`NTT docomo <https://www.nttdocomo.co.jp/>`_ has `a chatting API <https://dev.smt.docomo.ne.jp/?p=docs.api.page&api_docs_id=17>`_.\n\nThis software provides a client for the api.\n\nHow to use?\n===========\n1. Get API KEY.\n2. Call client.\n\n   .. code-block:: python\n\n      >>> from acme.dchat import DocomoChatClient\n      >>> c = DocomoChatClient('some api key')\n      >>> c.talk('hello, world.')\n      'Helloを聞くようです'",
        "url": "http://pypi.python.org/pypi/acme.dchat",
        "summary": "This software aim to provide a chatting tool with the NTT docomo API",
        "command": "pip install 'acme.dchat'"
      },
      "acme.hello": {
        "name": "acme.hello",
        "description": "==========\nacme.hello\n==========\nThis is a test program for namespace_packages.\n\nHow to use\n==========\n.. code-block:: console\n\n   $ python -m acme.hello\n   acme.hello",
        "url": "http://pypi.python.org/pypi/acme.hello",
        "summary": "This is a test program for namespace_packages.",
        "command": "pip install 'acme.hello'"
      },
      "acme.sql": {
        "name": "acme.sql",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/acme.sql",
        "summary": "UNKNOWN",
        "command": "pip install 'acme.sql'"
      },
      "aco2sass": {
        "name": "aco2sass",
        "description": "About\n=====\n\n*aco2sass* is a small python script which converts photoshop `.aco` swatch files \nto a list of the corresponding swatch colors formatted as SASS varibles.\n\nThe implementation is based on the file format specified by `Adobe` here::\n\n    https://www.adobe.com/devnet-apps/photoshop/fileformatashtml/#50577411_pgfId-1055819\n",
        "url": "http://pypi.python.org/pypi/aco2sass",
        "summary": "About\n=====\n\n*aco2sass* is a small python script which converts photoshop `.aco` swatch files \nto a list of the corresponding swatch colors formatted as SASS varibles.\n\nThe implementation is based on the file format specified by `Adobe` here::\n\n    https://www.adobe.com/devnet-apps/photoshop/fileformatashtml/#50577411_pgfId-1055819",
        "command": "pip install 'aco2sass'"
      },
      "acollections": {
        "name": "acollections",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/acollections",
        "summary": "Advanced storage classes",
        "command": "pip install 'acollections'"
      },
      "acolytegm": {
        "name": "acolytegm",
        "description": "",
        "url": "http://pypi.python.org/pypi/acolytegm",
        "summary": "A tool to help tabletop RPG game masters plan and run their games.",
        "command": "pip install 'acolytegm'"
      },
      "acomms": {
        "name": "acomms",
        "description": "===========\npyAcomms\n===========\n\npyAcomms provides a Python interface to Micromodem and Micromodem-2 hardware from the\n`Acoustic Communications Group <http://acomms.whoi.edu/>`_ at the `Woods Hole Oceanographic Institution <http://www.whoi.edu/>`_.\n\n\nDocumentation is currently lacking for this beta release, but will improve.\n\nSee examples in the ``/examples`` and ``/bin`` directories.",
        "url": "http://pypi.python.org/pypi/acomms",
        "summary": "WHOI Micromodem Interface Library and Tools",
        "command": "pip install 'acomms'"
      },
      "ACO-Pants": {
        "name": "aco-pants",
        "description": "=====\nPants\n=====\n\nA Python3 implementation of the Ant Colony Optimization Meta-Heuristic\n\n--------\nOverview\n--------\n\n**Pants** provides you with the ability to quickly determine how to\nvisit a collection of interconnected nodes such that the work done is\nminimized. Nodes can be any arbitrary collection of data while the edges\nrepresent the amount of \"work\" required to travel between two nodes.\nThus, **Pants** is a tool for solving traveling salesman problems.\n\nThe world is built from a list of nodes and a function responsible for\nreturning the length of the edge between any two given nodes. The length\nfunction need not return actual length. Instead, \"length\" refers to that \nthe amount of \"work\" involved in moving from the first node to the second\nnode - whatever that \"work\" may be. For a silly, random example, it could\neven be the number of dishes one must wash before moving to the next \nstation at a least dish-washing dish washer competition.\n\nSolutions are found through an iterative process. In each iteration,\nseveral ants are allowed to find a solution that \"visits\" every node of\nthe world. The amount of pheromone on each edge is updated according to\nthe length of the solutions in which it was used. The ant that traveled the\nleast distance is considered to be the local best solution. If the local\nsolution has a shorter distance than the best from any previous\niteration, it then becomes the global best solution. The elite ant(s)\nthen deposit their pheromone along the path of the global best solution\nto strengthen it further, and the process repeats.\n\nYou can read more about `Ant Colony Optimization on\nWikipedia <http://en.wikipedia.org/wiki/Ant_colony_optimization_algorithms>`_.\n\n------------\nInstallation\n------------\n\nInstallation via ``pip``\n\n.. code-block:: console\n\n    $ pip3 install ACO-Pants\n\n-----\nUsage\n-----\n\nUsing **Pants** is simple. The example here uses Euclidean distance\nbetween 2D nodes with ``(x, y)`` coordinates, but there are no real\nrequirements for node data of any sort.\n\n1) Import **Pants** (along with any other packages you'll need).\n\n   .. code-block:: python\n\n        import pants\n        import math\n        import random\n\n2) Create your data points; these become the nodes. Here we create some\n   random 2D points. The only requirement for a node is that it is\n   distinguishable from all of the other nodes.\n\n   .. code-block:: python\n\n      nodes = []\n      for _ in range(20):\n        x = random.uniform(-10, 10)\n        y = random.uniform(-10, 10)\n        nodes.append((x, y))\n\n\n3) Define your length function. This function must accept two nodes and\n   return the amount of \"work\" between them. In this case, Euclidean \n   distance works well.\n\n   .. code-block:: python\n\n      def euclidean(a, b):\n          return math.sqrt(pow(a[1] - b[1], 2) + pow(a[0] - b[0], 2))\n\n4) Create the ``World`` from the nodes and the length function. \n\n   .. code-block:: python\n\n        world = pants.World(nodes, euclidean)\n\n5) Create the ``Solver``.\n\n   .. code-block:: python\n\n        solver = pants.Solver()\n\n6) Solve the ``World`` with the ``Solver``. Two methods are provided for\n   finding solutions: ``solve()`` and ``solutions()``. The former\n   returns the best solution found, whereas the latter returns each\n   solution found if it is the best thus far.\n\n   .. code-block:: python\n\n        solution = solver.solve(world)\n        # or\n        solutions = solver.solutions(world)\n\n7) Inspect the solution(s).\n\n   .. code-block:: python\n\n        print(solution.distance)\n        print(solution.tour)    # Nodes visited in order\n        print(solution.path)    # Edges taken in order\n        # or\n        best = float(\"inf\")\n        for solution in solutions:\n          assert solution.distance < best\n          best = solution.distance\n\nRun the Demo\n------------\n\nIncluded is a 33 \"city\" demo script that can be run from the command line.\n\n.. code-block:: console\n    \n    user@host:~$ pants-demo -h\n    usage: pants-demo [-h] [-V] [-a A] [-b B] [-l L] [-p P] [-e E] [-q Q] [-t T]\n                      [-c N] [-d D]\n\n    Script th;at demos the ACO-Pants package.\n\n    optional arguments:\n      -h, --help         show this help message and exit\n      -V, --version      show program's version number and exit\n      -a A, --alpha A    relative importance placed on pheromones; default=1\n      -b B, --beta B     relative importance placed on distances; default=3\n      -l L, --limit L    number of iterations to perform; default=100\n      -p P, --rho P      ratio of evaporated pheromone (0 <= P <= 1); default=0.8\n      -e E, --elite E    ratio of elite ant's pheromone; default=0.5\n      -q Q, --Q Q        total pheromone capacity of each ant (Q > 0); default=1\n      -t T, --t0 T       initial amount of pheromone on every edge (T > 0);\n                         default=0.01\n      -c N, --count N    number of ants used in each iteration (N > 0); default=10\n      -d D, --dataset D  specify a particular set of demo data; default=33\n\n    For best results:\n      * 0.5 <= A <= 1\n      * 1.0 <= B <= 5\n      * A < B\n      * L >= 2000\n      * N > 1\n\n    For more information, please visit https://github.com/rhgrant10/Pants.\n    user@host:~$ pants-demo\n    Solver settings:\n    limit=100\n    rho=0.8, Q=1\n    alpha=1, beta=3\n    elite=0.5\n\n    Time Elapsed              Distance                 \n    --------------------------------------------------\n               0:00:00.017490 0.7981182992833705       \n               0:00:00.034784 0.738147755518648        \n               0:00:00.069041 0.694362159048816        \n               0:00:00.276027 0.6818083968312925       \n               0:00:00.379039 0.6669398280432167       \n               0:00:00.465924 0.6463548571712562       \n               0:00:00.585685 0.6416519698864324       \n               0:00:01.563389 0.6349308484274142       \n    --------------------------------------------------\n    Best solution:\n             0 = (34.02115, -84.267249)\n             9 = (34.048194, -84.262126)\n             6 = (34.044915, -84.255772)\n            22 = (34.061518, -84.243566)\n            23 = (34.062461, -84.240155)\n            18 = (34.060461, -84.237402)\n            17 = (34.060164, -84.242514)\n            12 = (34.04951, -84.226327)\n            11 = (34.048679, -84.224917)\n             8 = (34.046006, -84.225258)\n             7 = (34.045483, -84.221723)\n            13 = (34.051529, -84.218865)\n            14 = (34.055487, -84.217882)\n            16 = (34.059412, -84.216757)\n            25 = (34.066471, -84.217717)\n            24 = (34.064489, -84.22506)\n            20 = (34.063814, -84.225499)\n            10 = (34.048312, -84.208885)\n            15 = (34.056326, -84.20058)\n             5 = (34.024302, -84.16382)\n            32 = (34.118162, -84.163304)\n            31 = (34.116852, -84.163971)\n            30 = (34.109645, -84.177031)\n            29 = (34.10584, -84.21667)\n            28 = (34.071628, -84.265784)\n            27 = (34.068647, -84.283569)\n            26 = (34.068455, -84.283782)\n            19 = (34.061281, -84.334798)\n            21 = (34.061468, -84.33483)\n             2 = (34.022585, -84.36215)\n             3 = (34.022718, -84.361903)\n             4 = (34.023101, -84.36298)\n             1 = (34.021342, -84.363437)\n    Solution length: 0.6349308484274142\n    Found at 0:00:01.563389 out of 0:00:01.698616 seconds.\n    user@host:~$\n\nKnown Bugs\n----------\n\nNone of which I am currently aware. Please let me know if you find \notherwise.\n\nTroubleshooting\n---------------\n\nCredits\n-------\n\n-  Robert Grant rhgrant10@gmail.com\n\nLicense\n-------\n\nGPL",
        "url": "http://pypi.python.org/pypi/ACO-Pants",
        "summary": "A Python3 implementation of the ACO Meta-Heuristic",
        "command": "pip install 'ACO-Pants'"
      },
      "acor": {
        "name": "acor",
        "description": "ACOR\n====\n\nThis is a direct port of a C++ routine by\n`Jonathan Goodman <http://www.math.nyu.edu/faculty/goodman/index.html>`_ (NYU)\ncalled `ACOR <http://www.math.nyu.edu/faculty/goodman/software/acor/>`_ that\nestimates the autocorrelation time of time series data very quickly.\n\n`Dan Foreman-Mackey <http://danfm.ca>`_ (NYU) made a few surface changes to\nthe interface in order to write a Python wrapper (with the permission of the\noriginal author).\n\nInstallation\n------------\n\nJust run ::\n\n    pip install acor\n\nwith ``sudo`` if you really need it.\n\nOtherwise, download the source code\n`as a tarball <https://github.com/dfm/acor/tarball/master>`_\nor clone the git repository from `GitHub <https://github.com/dfm/acor>`_: ::\n\n    git clone https://github.com/dfm/acor.git\n\nThen run ::\n\n    cd acor\n    python setup.py install\n\nto compile and install the module ``acor`` in your Python path. The only\ndependency is `NumPy <http://numpy.scipy.org/>`_ (including the\n``python-dev`` and ``python-numpy-dev`` packages which you might have to\ninstall separately on some systems).\n\nUsage\n-----\n\nGiven some time series ``x``, you can estimate the autocorrelation time\n(``tau``) using: ::\n\n    import acor\n    tau, mean, sigma = acor.acor(x)\n\nReferences\n----------\n\n* http://www.math.nyu.edu/faculty/goodman/software/acor/index.html\n* http://www.stat.unc.edu/faculty/cji/Sokal.pdf",
        "url": "http://pypi.python.org/pypi/acor",
        "summary": "Estimate the autocorrelation time of a time series quickly.",
        "command": "pip install 'acor'"
      },
      "acora": {
        "name": "acora",
        "description": "Acora\r\n======\r\n\r\n.. contents:: :local:\r\n\r\nWhat is Acora?\r\n---------------\r\n\r\nAcora is 'fgrep' for Python, a fast multi-keyword text search engine.\r\n\r\nBased on a set of keywords, it generates a search automaton (DFA) and\r\nruns it over string input, either unicode or bytes.\r\n\r\nIt is based on the Aho-Corasick algorithm and an NFA-to-DFA powerset\r\nconstruction.\r\n\r\nAcora comes with both a pure Python implementation and a fast binary\r\nmodule written in Cython. However, note that the current construction\r\nalgorithm is not suitable for really large sets of keywords (i.e. more\r\nthan a couple of thousand).\r\n\r\nYou can find the `latest source code <https://github.com/scoder/acora>`_ on\r\ngithub.\r\n\r\nTo report a bug or request new features, use the `github bug tracker\r\n<https://github.com/scoder/acora/issues>`_.  Please try to provide a\r\nshort test case that reproduces the problem without requiring too much\r\nexperimentation or large amounts of data.  The easier it is to\r\nreproduce the problem, the easier it is to solve it.\r\n\r\n\r\nFeatures\r\n---------\r\n\r\n* works with unicode strings and byte strings\r\n* about 2-3x as fast as Python's regular expression engine for most input\r\n* finds overlapping matches, i.e. all matches of all keywords\r\n* support for case insensitive search (~10x as fast as 're')\r\n* frees the GIL while searching\r\n* additional (slow but short) pure Python implementation\r\n* support for Python 2.5+ and 3.x\r\n* support for searching in files\r\n* permissive BSD license\r\n\r\n\r\nHow do I use it?\r\n-----------------\r\n\r\nImport the package::\r\n\r\n    >>> from acora import AcoraBuilder\r\n\r\nCollect some keywords::\r\n\r\n    >>> builder = AcoraBuilder('ab', 'bc', 'de')\r\n    >>> builder.add('a', 'b')\r\n\r\nGenerate the Acora search engine for the current keyword set::\r\n\r\n    >>> ac = builder.build()\r\n\r\nSearch a string for all occurrences::\r\n\r\n    >>> ac.findall('abc')\r\n    [('a', 0), ('ab', 0), ('b', 1), ('bc', 1)]\r\n    >>> ac.findall('abde')\r\n    [('a', 0), ('ab', 0), ('b', 1), ('de', 2)]\r\n\r\nIterate over the search results as they come in::\r\n\r\n    >>> for kw, pos in ac.finditer('abde'):\r\n    ...     print(\"%2s[%d]\" % (kw, pos))\r\n     a[0]\r\n    ab[0]\r\n     b[1]\r\n    de[2]\r\n\r\nAcora also has direct support for parsing files (in binary mode)::\r\n\r\n    >>> keywords = ['Import', 'FAQ', 'Acora', 'NotHere'.upper()]\r\n\r\n    >>> builder = AcoraBuilder([s.encode('ascii') for s in keywords])\r\n    >>> ac = builder.build()\r\n\r\n    >>> found = set(kw for kw, pos in ac.filefind('README.rst'))\r\n    >>> len(found)\r\n    3\r\n\r\n    >>> sorted(str(s.decode('ascii')) for s in found)\r\n    ['Acora', 'FAQ', 'Import']\r\n\r\n\r\nFAQs and recipes\r\n-----------------\r\n\r\n#) how do I run a greedy search for the longest matching keywords?\r\n\r\n    >>> builder = AcoraBuilder('a', 'ab', 'abc')\r\n    >>> ac = builder.build()\r\n\r\n    >>> for kw, pos in ac.finditer('abbabc'):\r\n    ...     print(kw)\r\n    a\r\n    ab\r\n    a\r\n    ab\r\n    abc\r\n\r\n    >>> from itertools import groupby\r\n    >>> from operator import itemgetter\r\n\r\n    >>> def longest_match(matches):\r\n    ...     for pos, match_set in groupby(matches, itemgetter(1)):\r\n    ...         yield max(match_set)\r\n\r\n    >>> for kw, pos in longest_match(ac.finditer('abbabc')):\r\n    ...     print(kw)\r\n    ab\r\n    abc\r\n\r\n#) how do I parse line-by-line with arbitrary line endings?\r\n\r\n    >>> def group_by_lines(s, *keywords):\r\n    ...     builder = AcoraBuilder('\\r', '\\n', *keywords)\r\n    ...     ac = builder.build()\r\n    ...\r\n    ...     current_line_matches = []\r\n    ...     last_ending = None\r\n    ...\r\n    ...     for kw, pos in ac.finditer(s):\r\n    ...         if kw in '\\r\\n':\r\n    ...             if last_ending == '\\r' and kw == '\\n':\r\n    ...                 continue # combined CRLF\r\n    ...             yield tuple(current_line_matches)\r\n    ...             del current_line_matches[:]\r\n    ...             last_ending = kw\r\n    ...         else:\r\n    ...             last_ending = None\r\n    ...             current_line_matches.append(kw)\r\n    ...     yield tuple(current_line_matches)\r\n\r\n    >>> kwds = ['ab', 'bc', 'de']\r\n    >>> for matches in group_by_lines('a\\r\\r\\nbc\\r\\ndede\\n\\nab', *kwds):\r\n    ...     print(matches)\r\n    ()\r\n    ()\r\n    ('bc',)\r\n    ('de', 'de')\r\n    ()\r\n    ('ab',)\r\n\r\n\r\n#) how do I find whole lines that contain keywords, as fgrep does?\r\n\r\n    >>> def match_lines(s, *keywords):\r\n    ...     builder = AcoraBuilder('\\r', '\\n', *keywords)\r\n    ...     ac = builder.build()\r\n    ...\r\n    ...     line_start = 0\r\n    ...     matches = False\r\n    ...     for kw, pos in ac.finditer(s):\r\n    ...         if kw in '\\r\\n':\r\n    ...             if matches:\r\n    ...                  yield s[line_start:pos]\r\n    ...                  matches = False\r\n    ...             line_start = pos + 1\r\n    ...         else:\r\n    ...             matches = True\r\n    ...     if matches:\r\n    ...         yield s[line_start:]\r\n\r\n    >>> kwds = ['x', 'de', '\\nstart']\r\n    >>> text = 'a line with\\r\\r\\nsome text\\r\\ndede\\n\\nab\\n start 1\\nstart\\n'\r\n    >>> for line in match_lines(text, *kwds):\r\n    ...     print(line)\r\n    some text\r\n    dede\r\n    start\r\n\r\n\r\nChangelog\r\n----------\r\n\r\n* 1.8 [2014-02-12]\r\n\r\n  - pickle support for the pre-built search engines\r\n  - performance optimisations in builder\r\n  - Unicode parsing is optimised for Python 3.3 and later\r\n  - no longer recompiles sources when Cython is installed, unless\r\n    ``--with-cython`` option is passed to setup.py (requires Cython 0.20+)\r\n  - build failed with recent Cython versions\r\n  - built using Cython 0.20.1\r\n\r\n* 1.7 [2011-08-24]\r\n\r\n  - searching binary strings for byte values > 127 was broken\r\n  - built using Cython 0.15+\r\n\r\n* 1.6 [2011-07-24]\r\n\r\n  - substantially faster automaton building\r\n  - no longer includes .hg repo in source distribution\r\n  - built using Cython 0.15 (rc0)\r\n\r\n* 1.5 [2011-01-24]\r\n\r\n  - Cython compiled NFA-2-DFA construction runs substantially faster\r\n  - always build extension modules even if Cython is not installed\r\n  - ``--no-compile`` switch in ``setup.py`` to prevent extension module building\r\n  - built using Cython 0.14.1 (rc2)\r\n\r\n* 1.4 [2009-02-10]\r\n\r\n  - minor speed-up in inner search engine loop\r\n  - some code cleanup\r\n  - built using Cython 0.12.1 (final)\r\n\r\n* 1.3 [2009-01-30]\r\n\r\n  - major fix for file search\r\n  - built using Cython 0.12.1 (beta0)\r\n\r\n* 1.2 [2009-01-30]\r\n\r\n  - deep-copy support for AcoraBuilder class\r\n  - doc/test fixes\r\n  - include .hg repo in source distribution\r\n  - built using Cython 0.12.1 (beta0)\r\n\r\n* 1.1 [2009-01-29]\r\n\r\n  - doc updates\r\n  - some cleanup\r\n  - built using Cython 0.12.1 (beta0)\r\n\r\n* 1.0 [2009-01-29]\r\n\r\n  - initial release",
        "url": "http://pypi.python.org/pypi/acora",
        "summary": "Fast multi-keyword search engine for text strings",
        "command": "pip install 'acora'"
      },
      "acos-client": {
        "name": "acos-client",
        "description": "# ACOS Client\n\nA10 github repos:\n\n- [a10-openstack-lbaas](https://github.com/a10networks/a10-openstack-lbaas) - OpenStack LBaaS driver, \nidentical to the files that are currently merged into Juno.  Also supports Icehouse.  Pypi package \n'a10-openstack-lbaas'.\n- [a10-openstack-lbaas, havana branch](https://github.com/a10networks/a10-openstack-lbaas/tree/havana) - OpenStack \nLBaaS driver, for the Havana release.  Pypi package 'a10-openstack-lbaas-havana'.\n- [a10-neutron-lbaas](https://github.com/a10networks/a10-neutron-lbaas) - Middleware sitting between the \nopenstack driver and our API client, mapping openstack constructs to A10's AxAPI.\n- [acos-client](https://github.com/a10networks/acos-client) - AxAPI client used by A10's OpenStack driver.\n- [neutron-thirdparty-ci](https://github.com/a10networks/neutron-thirdparty-ci) - Scripts used by \nour Jenkins/Zuul/Devstack-Gate setup, used to test every openstack code review submission against \nA10 appliances and our drivers.\n- [a10_lbaas_driver](https://github.com/a10networks/a10_lbaas_driver) - An older revision of A10's \nLBaaS driver; no longer supported.\n\n## Installation\n\n### Install using pip\n\n```sh\n$ pip install acos-client\n```\n\n### Install from source\n\n```sh\n$ git clone https://github.com/a10networks/acos-client.git\n$ cd acos-client\n$ python setup.py install\n```\n\n## Usage\n\n```python\nc = acos_client.Client('somehost.example.com', acos_client.AXAPI_21,\n                       'admin', 'password')\n```\n\n#### Example setting up an SLB:\n\n```python\nimport acos_client as acos\n\nc = acos.Client('1.2.3.4', acos.AXAPI_21, 'admin', 'password')\nc.slb.server.create('s1', '1.1.1.1')\nc.slb.server.create('s2', '1.1.1.2')\nc.slb.service_group.create('pool1',\n                           c.slb.service_group.TCP,\n                           c.slb.service_group.ROUND_ROBIN)\nc.slb.virtual_server.create('vip1', '1.1.1.3')\nc.slb.hm.create('hm1', c.slb.hm.HTTP, 5, 5, 5, 'GET', '/', '200', 80)\nc.slb.service_group.update('pool1', health_monitor='hm1')\nc.slb.service_group.member.create('pool1', 's1', 80)\nc.slb.service_group.member.create('pool1', 's2', 80)\n```\n\n## Contributing\n\n1. Fork it\n2. Create your feature branch (`git checkout -b my-new-feature`)\n3. Commit your changes (`git commit -am 'Add some feature'`)\n4. Push to the branch (`git push origin my-new-feature`)\n5. Create new Pull Request\n\n## Testing\n\nThis project uses [tox](https://pypi.python.org/pypi/tox) for testing. To run\nthe test suite simply:\n\n```sh\n$ sudo pip install tox  # use pip2 if using Arch Linux\n$ cd /path/to/acos_client\n$ tox\n```\n\n[pypy](http://pypy.org/index.html) needs to be installed as well as Python 2.6\nside by side 2.7 7. We recommend\n[deadsnakes](http://coreygoldberg.blogspot.com/2013/10/deadsnakes-using-old-versions-of-python.html)\nif you're on Ubuntu, and the [python26 AUR\npackage](https://aur.archlinux.org/packages/python26/) if you use Arch Linux.\n\n## Supported Versions\n\n  * axapi 2.1, ACOS 2.7.2+ (2.7.1 works if you avoid partitions)\n  * axapi 3.0, ACOS 4.0.0+",
        "url": "http://pypi.python.org/pypi/acos-client",
        "summary": "A10 Networks ACOS API Client",
        "command": "pip install 'acos-client'"
      },
      "acoular": {
        "name": "acoular",
        "description": ".. README.rst\n\nAcoular\n=======\n\nacoular is a Python module for acoustic beamforming that is distributed under the new BSD license. \n\nIt is aimed at applications in acoustic testing. Multichannel data recorded by a microphone array can be processed and analyzed in order generate mappings of sound source distributions. The maps (acoustic photographs) can then be used to  locate sources of interest and to characterize them using their spectra. \n\nFeatures\n========\n\n    * covers several beamforming algorithms \n    * different advanced deconvolution algorithms\n    * both time-domain and frequency-domain operation included\n    * 3D mapping possible\n    * application for stationary and for moving targets\n    * supports both scripting and graphical user interface\n    * efficient: intelligent caching, parallel computing with OpenMP\n    * easily extendible and well documented\n\nDependencies\n============\n\nacoular runs under Linux, Windows and possibly other OS (untested), a Python 2.7 installation is needed with the latest Numpy, Scipy, Traits, Chaco, scikit-learn, pytables packages available.",
        "url": "http://pypi.python.org/pypi/acoular",
        "summary": "Library for acoustic beamforming",
        "command": "pip install 'acoular'"
      },
      "acoustics": {
        "name": "acoustics",
        "description": "# python-acoustics\n\nThe `python-acoustics` module is a Python module with useful tools for acousticians.\n\n## Documentation\nDocumentation can be found [here](http://python-acoustics.github.io/python-acoustics/).\n\n## License\n`python-acoustics` is distributed under the BSD 3-clause license. See LICENSE for more information.",
        "url": "http://pypi.python.org/pypi/acoustics",
        "summary": "Acoustics module for Python.",
        "command": "pip install 'acoustics'"
      },
      "acousticsim": {
        "name": "acousticsim",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/acousticsim",
        "summary": "Analyze acoustic similarity in Python",
        "command": "pip install 'acousticsim'"
      },
      "acplugins4python": {
        "name": "acplugins4python",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/acplugins4python",
        "summary": "Python api layer for Assetto Corsa's UDP server API. Developed and tested with AC 1.2.3 on python 3.3.x",
        "command": "pip install 'acplugins4python'"
      },
      "acpr": {
        "name": "acpr",
        "description": "Get `these data <https://www.regafi.fr/spip.php?rubrique3>`_ for\n`this mission <http://missions.opencorporates.com/missions/565/claim>`_.\nRun like so. ::\n\n    acpr > acpr.jsonlines\n",
        "url": "http://pypi.python.org/pypi/acpr",
        "summary": "Download ACPR Banque de France - Regafi (Financial Firms Register)",
        "command": "pip install 'acpr'"
      },
      "acq4": {
        "name": "acq4",
        "description": "ACQ4 is a python-based platform for experimental neurophysiology. \n\nIt includes support for standard electrophysiology, multiphoton imaging, \nscanning laser photostimulation, and many other experimental techniques. ACQ4 is\nhighly modular and extensible, allowing support to be added for new types of\ndevices, techniques, user-interface modules, and analyses.",
        "url": "http://pypi.python.org/pypi/acq4",
        "summary": "Neurophysiology acquisition and analysis platform",
        "command": "pip install 'acq4'"
      },
      "AcquireRouterIP": {
        "name": "acquirerouterip",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AcquireRouterIP",
        "summary": "Acquire the IP address on the router's wan port",
        "command": "pip install 'AcquireRouterIP'"
      },
      "Acquisition": {
        "name": "acquisition",
        "description": "Environmental Acquisiton\n========================\n\nThis package implements \"environmental acquisiton\" for Python, as\nproposed in the OOPSLA96_ paper by Joseph Gil and David H. Lorenz:\n\n    We propose a new programming paradigm, environmental acquisition in\n    the context of object aggregation, in which objects acquire\n    behaviour from their current containers at runtime. The key idea is\n    that the behaviour of a component may depend upon its enclosing\n    composite(s). In particular, we propose a form of feature sharing in\n    which an object \"inherits\" features from the classes of objects in\n    its environment.  By examining the declaration of classes, it is\n    possible to determine which kinds of classes may contain a\n    component, and which components must be contained in a given kind of\n    composite. These relationships are the basis for language constructs\n    that supports acquisition.\n\n.. _OOPSLA96: http://www.cs.virginia.edu/~lorenz/papers/oopsla96/>`_:\n\n.. contents::\n\nIntroductory Example\n--------------------\n\nZope implements acquisition with \"Extension Class\" mix-in classes. To\nuse acquisition your classes must inherit from an acquisition base\nclass. For example::\n\n  >>> import ExtensionClass, Acquisition\n\n  >>> class C(ExtensionClass.Base):\n  ...     color = 'red'\n\n  >>> class A(Acquisition.Implicit):\n  ...     def report(self):\n  ...         print(self.color)\n  ...\n  >>> a = A()\n  >>> c = C()\n  >>> c.a = a\n\n  >>> c.a.report()\n  red\n\n  >>> d = C()\n  >>> d.color = 'green'\n  >>> d.a = a\n\n  >>> d.a.report()\n  green\n\n  >>> a.report() # raises an attribute error\n  Traceback (most recent call last):\n    ...\n  AttributeError: color\n\nThe class ``A`` inherits acquisition behavior from\n``Acquisition.Implicit``. The object, ``a``, \"has\" the color of\nobjects ``c`` and d when it is accessed through them, but it has no\ncolor by itself. The object ``a`` obtains attributes from its\nenvironment, where its environment is defined by the access path used\nto reach ``a``.\n\nAcquisition Wrappers\n--------------------\n\nWhen an object that supports acquisition is accessed through an\nextension class instance, a special object, called an acquisition\nwrapper, is returned. In the example above, the expression ``c.a``\nreturns an acquisition wrapper that contains references to both ``c``\nand ``a``. It is this wrapper that performs attribute lookup in ``c``\nwhen an attribute cannot be found in ``a``.\n\nAcquisition wrappers provide access to the wrapped objects through the\nattributes ``aq_parent``, ``aq_self``, ``aq_base``.  Continue the\nexample from above::\n\n  >>> c.a.aq_parent is c\n  True\n  >>> c.a.aq_self is a\n  True\n\nExplicit and Implicit Acquisition\n---------------------------------\n\nTwo styles of acquisition are supported: implicit and explicit\nacquisition.\n\nImplicit acquisition\n--------------------\n\nImplicit acquisition is so named because it searches for attributes\nfrom the environment automatically whenever an attribute cannot be\nobtained directly from an object or through inheritance.\n\nAn attribute can be implicitly acquired if its name does not begin\nwith an underscore.\n\nTo support implicit acquisition, your class should inherit from the\nmix-in class ``Acquisition.Implicit``.\n\nExplicit Acquisition\n--------------------\n\nWhen explicit acquisition is used, attributes are not automatically\nobtained from the environment. Instead, the method aq_acquire must be\nused. For example::\n\n  >>> print(c.a.aq_acquire('color'))\n  red\n\nTo support explicit acquisition, your class should inherit from the\nmix-in class ``Acquisition.Explicit``.\n\nControlling Acquisition\n-----------------------\n\nA class (or instance) can provide attribute by attribute control over\nacquisition. Your should subclass from ``Acquisition.Explicit``, and set\nall attributes that should be acquired to the special value\n``Acquisition.Acquired``. Setting an attribute to this value also allows\ninherited attributes to be overridden with acquired ones. For example::\n\n  >>> class C(Acquisition.Explicit):\n  ...     id = 1\n  ...     secret = 2\n  ...     color = Acquisition.Acquired\n  ...     __roles__ = Acquisition.Acquired\n\nThe only attributes that are automatically acquired from containing\nobjects are color, and ``__roles__``. Note that the ``__roles__``\nattribute is acquired even though its name begins with an\nunderscore. In fact, the special ``Acquisition.Acquired`` value can be\nused in ``Acquisition.Implicit`` objects to implicitly acquire\nselected objects that smell like private objects.\n\nSometimes, you want to dynamically make an implicitly acquiring object\nacquire explicitly. You can do this by getting the object's\naq_explicit attribute. This attribute provides the object with an\nexplicit wrapper that replaces the original implicit wrapper.\n\nFiltered Acquisition\n--------------------\n\nThe acquisition method, ``aq_acquire``, accepts two optional\narguments. The first of the additional arguments is a \"filtering\"\nfunction that is used when considering whether to acquire an\nobject. The second of the additional arguments is an object that is\npassed as extra data when calling the filtering function and which\ndefaults to ``None``. The filter function is called with five\narguments:\n\n* The object that the aq_acquire method was called on,\n\n* The object where an object was found,\n\n* The name of the object, as passed to aq_acquire,\n\n* The object found, and\n\n* The extra data passed to aq_acquire.\n\nIf the filter returns a true object that the object found is returned,\notherwise, the acquisition search continues.\n\nHere's an example::\n\n  >>> from Acquisition import Explicit\n\n  >>> class HandyForTesting:\n  ...     def __init__(self, name):\n  ...         self.name = name\n  ...     def __str__(self):\n  ...         return \"%s(%s)\" % (self.name, self.__class__.__name__)\n  ...     __repr__=__str__\n  ...\n  >>> class E(Explicit, HandyForTesting): pass\n  ...\n  >>> class Nice(HandyForTesting):\n  ...     isNice = 1\n  ...     def __str__(self):\n  ...         return HandyForTesting.__str__(self)+' and I am nice!'\n  ...     __repr__ = __str__\n  ...\n  >>> a = E('a')\n  >>> a.b = E('b')\n  >>> a.b.c = E('c')\n  >>> a.p = Nice('spam')\n  >>> a.b.p = E('p')\n\n  >>> def find_nice(self, ancestor, name, object, extra):\n  ...     return hasattr(object,'isNice') and object.isNice\n\n  >>> print(a.b.c.aq_acquire('p', find_nice))\n  spam(Nice) and I am nice!\n\nThe filtered acquisition in the last line skips over the first\nattribute it finds with the name ``p``, because the attribute doesn't\nsatisfy the condition given in the filter.\n\nFiltered acquisition is rarely used in Zope.\n\nAcquiring from Context\n----------------------\n\nNormally acquisition allows objects to acquire data from their\ncontainers. However an object can acquire from objects that aren't its\ncontainers.\n\nMost of the examples we've seen so far show establishing of an\nacquisition context using getattr semantics. For example, ``a.b`` is a\nreference to ``b`` in the context of ``a``.\n\nYou can also manually set acquisition context using the ``__of__``\nmethod. For example::\n\n  >>> from Acquisition import Implicit\n  >>> class C(Implicit): pass\n  ...\n  >>> a = C()\n  >>> b = C()\n  >>> a.color = \"red\"\n  >>> print(b.__of__(a).color)\n  red\n\nIn this case, ``a`` does not contain ``b``, but it is put in ``b``'s\ncontext using the ``__of__`` method.\n\nHere's another subtler example that shows how you can construct an\nacquisition context that includes non-container objects::\n\n  >>> from Acquisition import Implicit\n\n  >>> class C(Implicit):\n  ...     def __init__(self, name):\n  ...         self.name = name\n\n  >>> a = C(\"a\")\n  >>> a.b = C(\"b\")\n  >>> a.b.color = \"red\"\n  >>> a.x = C(\"x\")\n\n  >>> print(a.b.x.color)\n  red\n\nEven though ``b`` does not contain ``x``, ``x`` can acquire the color\nattribute from ``b``. This works because in this case, ``x`` is accessed\nin the context of ``b`` even though it is not contained by ``b``.\n\nHere acquisition context is defined by the objects used to access\nanother object.\n\nContainment Before Context\n--------------------------\n\nIf in the example above suppose both a and b have an color attribute::\n\n  >>> a = C(\"a\")\n  >>> a.color = \"green\"\n  >>> a.b = C(\"b\")\n  >>> a.b.color = \"red\"\n  >>> a.x = C(\"x\")\n\n  >>> print(a.b.x.color)\n  green\n\nWhy does ``a.b.x.color`` acquire color from ``a`` and not from ``b``?\nThe answer is that an object acquires from its containers before\nnon-containers in its context.\n\nTo see why consider this example in terms of expressions using the\n``__of__`` method::\n\n  a.x -> x.__of__(a)\n\n  a.b -> b.__of__(a)\n\n  a.b.x -> x.__of__(a).__of__(b.__of__(a))\n\nKeep in mind that attribute lookup in a wrapper is done by trying to\nlook up the attribute in the wrapped object first and then in the\nparent object. So in the expressions above proceeds from left to\nright.\n\nThe upshot of these rules is that attributes are looked up by\ncontainment before context.\n\nThis rule holds true also for more complex examples. For example,\n``a.b.c.d.e.f.g.attribute`` would search for attribute in ``g`` and\nall its containers first. (Containers are searched in order from the\ninnermost parent to the outermost container.) If the attribute is not\nfound in ``g`` or any of its containers, then the search moves to\n``f`` and all its containers, and so on.\n\nAdditional Attributes and Methods\n---------------------------------\n\nYou can use the special method ``aq_inner`` to access an object\nwrapped only by containment. So in the example above,\n``a.b.x.aq_inner`` is equivalent to ``a.x``.\n\nYou can find out the acquisition context of an object using the\naq_chain method like so:\n\n  >>> [obj.name for obj in a.b.x.aq_chain]\n  ['x', 'b', 'a']\n\nYou can find out if an object is in the containment context of another\nobject using the ``aq_inContextOf`` method. For example:\n\n  >>> a.b.aq_inContextOf(a)\n  1\n\n.. Note: as of this writing the aq_inContextOf examples don't work the\n   way they should be working. According to Jim, this is because\n   aq_inContextOf works by comparing object pointer addresses, which\n   (because they are actually different wrapper objects) doesn't give\n   you the expected results. He acknowledges that this behavior is\n   controversial, and says that there is a collector entry to change\n   it so that you would get the answer you expect in the above. (We\n   just need to get to it).\n\nAcquisition Module Functions\n----------------------------\n\nIn addition to using acquisition attributes and methods directly on\nobjects you can use similar functions defined in the ``Acquisition``\nmodule. These functions have the advantage that you don't need to\ncheck to make sure that the object has the method or attribute before\ncalling it.\n\n``aq_acquire(object, name [, filter, extra, explicit, default, containment])``\n    Acquires an object with the given name.\n\n    This function can be used to explictly acquire when using explicit\n    acquisition and to acquire names that wouldn't normally be\n    acquired.\n\n    The function accepts a number of optional arguments:\n\n    ``filter``\n        A callable filter object that is used to decide if an object\n        should be acquired.\n\n        The filter is called with five arguments:\n\n        * The object that the aq_acquire method was called on,\n\n        * The object where an object was found,\n\n        * The name of the object, as passed to aq_acquire,\n\n        * The object found, and\n\n        * The extra argument passed to aq_acquire.\n\n        If the filter returns a true object that the object found is\n        returned, otherwise, the acquisition search continues.\n\n    ``extra``\n        Extra data to be passed as the last argument to the filter.\n\n    ``explicit``\n        A flag (boolean value) indicating whether explicit acquisition\n        should be used. The default value is true. If the flag is\n        true, then acquisition will proceed regardless of whether\n        wrappers encountered in the search of the acquisition\n        hierarchy are explicit or implicit wrappers. If the flag is\n        false, then parents of explicit wrappers are not searched.\n\n        This argument is useful if you want to apply a filter without\n        overriding explicit wrappers.\n\n    ``default``\n        A default value to return if no value can be acquired.\n\n    ``containment``\n        A flag indicating whether the search should be limited to the\n        containment hierarchy.\n\n    In addition, arguments can be provided as keywords.\n\n``aq_base(object)``\n    Return the object with all wrapping removed.\n\n``aq_chain(object [, containment])``\n    Return a list containing the object and it's acquisition\n    parents. The optional argument, containment, controls whether the\n    containment or access hierarchy is used.\n\n``aq_get(object, name [, default, containment])``\n    Acquire an attribute, name. A default value can be provided, as\n    can a flag that limits search to the containment hierarchy.\n\n``aq_inner(object)``\n    Return the object with all but the innermost layer of wrapping\n    removed.\n\n``aq_parent(object)``\n    Return the acquisition parent of the object or None if the object\n    is unwrapped.\n\n``aq_self(object)``\n    Return the object with one layer of wrapping removed, unless the\n    object is unwrapped, in which case the object is returned.\n\nIn most cases it is more convenient to use these module functions\ninstead of the acquisition attributes and methods directly.\n\nAcquisition and Methods\n-----------------------\n\nPython methods of objects that support acquisition can use acquired\nattributes. When a Python method is called on an object that is\nwrapped by an acquisition wrapper, the wrapper is passed to the method\nas the first argument. This rule also applies to user-defined method\ntypes and to C methods defined in pure mix-in classes.\n\nUnfortunately, C methods defined in extension base classes that define\ntheir own data structures, cannot use aquired attributes at this\ntime. This is because wrapper objects do not conform to the data\nstructures expected by these methods. In practice, you will seldom\nfind this a problem.\n\nConclusion\n----------\n\nAcquisition provides a powerful way to dynamically share information\nbetween objects. Zope 2 uses acquisition for a number of its key\nfeatures including security, object publishing, and DTML variable\nlookup. Acquisition also provides an elegant solution to the problem\nof circular references for many classes of problems. While acquisition\nis powerful, you should take care when using acquisition in your\napplications. The details can get complex, especially with the\ndifferences between acquiring from context and acquiring from\ncontainment.\n\n\nChangelog\n=========\n\n4.2.2 (2015-05-19)\n------------------\n\n- Make the pure-Python Acquirer objects cooperatively use the\n  superclass ``__getattribute__`` method, like the C implementation.\n  See https://github.com/zopefoundation/Acquisition/issues/7.\n\n- The pure-Python implicit acquisition wrapper allows wrapped objects\n  to use ``object.__getattribute__(self, name)``. This differs from\n  the C implementation, but is important for compatibility with the\n  pure-Python versions of libraries like ``persistent``. See\n  https://github.com/zopefoundation/Acquisition/issues/9.\n\n4.2.1 (2015-04-23)\n------------------\n\n- Correct several dangling pointer uses in the C extension,\n  potentially fixing a few interpreter crashes. See\n  https://github.com/zopefoundation/Acquisition/issues/5.\n\n4.2 (2015-04-04)\n----------------\n\n- Add support for PyPy, PyPy3, and Python 3.2, 3.3, and 3.4.\n\n4.1 (2014-12-18)\n----------------\n\n- Bump dependency on ``ExtensionClass`` to match current release.\n\n4.0.3 (2014-11-02)\n------------------\n\n- Skip readme.rst tests when tests are run outside a source checkout.\n\n4.0.2 (2014-11-02)\n------------------\n\n- Include ``*.rst`` files in the release.\n\n4.0.1 (2014-10-30)\n------------------\n\n- Tolerate Unicode attribute names (ASCII only).  LP #143358.\n\n- Make module-level ``aq_acquire`` API respect the ``default`` parameter.\n  LP #1387363.\n\n- Don't raise an attribute error for ``__iter__`` if the fallback to\n  ``__getitem__`` succeeds.  LP #1155760.\n\n\n4.0 (2013-02-24)\n----------------\n\n- Added trove classifiers to project metadata.\n\n4.0a1 (2011-12-13)\n------------------\n\n- Raise `RuntimeError: Recursion detected in acquisition wrapper` if an object\n  with a `__parent__` pointer points to a wrapper that in turn points to the\n  original object.\n\n- Prevent wrappers to be created while accessing `__parent__` on types derived\n  from Explicit or Implicit base classes.\n\n2.13.8 (2011-06-11)\n-------------------\n\n- Fixed a segfault on 64bit platforms when providing the `explicit` argument to\n  the aq_acquire method of an Acquisition wrapper. Thx to LP #675064 for the\n  hint to the solution. The code passed an int instead of a pointer into a\n  function.\n\n2.13.7 (2011-03-02)\n-------------------\n\n- Fixed bug: When an object did not implement ``__unicode__``, calling\n  ``unicode(wrapped)`` was calling ``__str__`` with an unwrapped ``self``.\n\n2.13.6 (2011-02-19)\n-------------------\n\n- Add ``aq_explicit`` to ``IAcquisitionWrapper``.\n\n- Fixed bug: ``unicode(wrapped)`` was not calling a ``__unicode__``\n  method on wrapped objects.\n\n2.13.5 (2010-09-29)\n-------------------\n\n- Fixed unit tests that failed on 64bit Python on Windows machines.\n\n2.13.4 (2010-08-31)\n-------------------\n\n- LP 623665: Fixed typo in Acquisition.h.\n\n2.13.3 (2010-04-19)\n-------------------\n\n- Use the doctest module from the standard library and no longer depend on\n  zope.testing.\n\n2.13.2 (2010-04-04)\n-------------------\n\n- Give both wrapper classes a ``__getnewargs__`` method, which causes the ZODB\n  optimization to fail and create persistent references using the ``_p_oid``\n  alone. This happens to be the persistent oid of the wrapped object. This lets\n  these objects to be persisted correctly, even though they are passed to the\n  ZODB in a wrapped state.\n\n- Added failing tests for http://dev.plone.org/plone/ticket/10318. This shows\n  an edge-case where AQ wrappers can be pickled using the specific combination\n  of cPickle, pickle protocol one and a custom Pickler class with an\n  ``inst_persistent_id`` hook. Unfortunately this is the exact combination used\n  by ZODB3.\n\n2.13.1 (2010-02-23)\n-------------------\n\n- Update to include ExtensionClass 2.13.0.\n\n- Fix the ``tp_name`` of the ImplicitAcquisitionWrapper and\n  ExplicitAcquisitionWrapper to match their Python visible names and thus have\n  a correct ``__name__``.\n\n- Expand the ``tp_name`` of our extension types to hold the fully qualified\n  name. This ensures classes have their ``__module__`` set correctly.\n\n2.13.0 (2010-02-14)\n-------------------\n\n- Added support for method cache in Acquisition. Patch contributed by\n  Yoshinori K. Okuji. See https://bugs.launchpad.net/zope2/+bug/486182.\n\n2.12.4 (2009-10-29)\n-------------------\n\n- Fix iteration proxying to pass `self` acquisition-wrapped into both\n  `__iter__` as well as `__getitem__` (this fixes\n  https://bugs.launchpad.net/zope2/+bug/360761).\n\n- Add tests for the __getslice__ proxying, including open-ended slicing.\n\n2.12.3 (2009-08-08)\n-------------------\n\n- More 64-bit fixes in Py_BuildValue calls.\n\n- More 64-bit issues fixed: Use correct integer size for slice operations.\n\n2.12.2 (2009-08-02)\n-------------------\n\n- Fixed 64-bit compatibility issues for Python 2.5.x / 2.6.x.  See\n  http://www.python.org/dev/peps/pep-0353/ for details.\n\n2.12.1 (2009-04-15)\n-------------------\n\n- Update for iteration proxying: The proxy for `__iter__` must not rely on the\n  object to have an `__iter__` itself, but also support fall-back iteration via\n  `__getitem__` (this fixes https://bugs.launchpad.net/zope2/+bug/360761).\n\n2.12 (2009-01-25)\n-----------------\n\n- Release as separate package.",
        "url": "http://pypi.python.org/pypi/Acquisition",
        "summary": "Acquisition is a mechanism that allows objects to obtain attributes from the containment hierarchy they're in.",
        "command": "pip install 'Acquisition'"
      },
      "acr": {
        "name": "acr",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/acr",
        "summary": "ACRCms is an open source Python web content management system based on Turbogears and libacr",
        "command": "pip install 'acr'"
      },
      "AcraNetwork": {
        "name": "acranetwork",
        "description": "AcraNetwork\r\n===========\r\n\r\nSummary\r\n~~~~~~~~\r\nA collection of classes for use in de-com of iNetX packets. Applies to both pcap files and straight from the network\r\n* iNetX : Class for packing and unpacking iNetX packets\r\n* IENA  : Class for packing and unpacking IENA packets\r\n* SimpleEthernet : A very simplified set of classes for Ethernet, IP, UDP, AFDX packets. These are not fully featured but\r\n\tcan do the job for what we need\r\n* Pcap : Class and helper methods for reading pcap files\r\n* McastSocket : Class to bind to ports to capture multicast packets\r\n\r\nINSTALL\r\n~~~~~~~~\r\nInstall using the standard setuptools install method\r\n> python setup.py install\r\n\r\n\r\nUSAGE\r\n~~~~~~~~~\r\nThe examples show some basic usage of the Classes.\r\npcap_to_ascii.py will read in pcap files and dump out ascii representations of the module\r\n",
        "url": "http://pypi.python.org/pypi/AcraNetwork",
        "summary": "Classes and utilities to support Flight Test Instrumentation Ethernet networks",
        "command": "pip install 'AcraNetwork'"
      },
      "acrylamid": {
        "name": "acrylamid",
        "description": "Welcome to Acrylamid\n====================\n\nAcrylamid is a mixture of `nanoc <http://nanoc.stoneship.org/>`_, `Pyblosxom\n<http://pyblosxom.bluesock.org/>`_ and `Pelican <http://blog.getpelican.com/>`_\nlicensed under BSD Style, 2 clauses. It is actively developed at\nhttps://github.com/posativ/acrylamid/.\n\n|Build Status|_\n\n.. _Build Status: http://travis-ci.org/posativ/acrylamid\n.. |Build Status| image:: https://secure.travis-ci.org/posativ/acrylamid.png?branch=legacy/0.7\n\n\nWhy?\n----\n\n- it is really *fast* due incremental builds\n- support for Jinja2_ and Mako_ templates\n- many Markdown_ extensions and custom reStructuredText_ directives\n- MathML_, enhanced typography and hyphenation using soft-hyphens\n\nOh, and it can also generate a static blog with articles, static pages, tags,\nRSS/Atom feeds (also per tag), article listing and a sitemap.\n\n.. _Jinja2: http://jinja.pocoo.org/\n.. _Mako: http://www.makotemplates.org/\n.. _MathML: http://www1.chapman.edu/~jipsen/mathml/asciimath.html\n\nWhy the name “Acrylamid”?\n-------------------------\n\nI'm studying bioinformatics and I was experimenting with Acrylamide at this\ntime. I'm really bad at naming. If you have a better name, please tell me!\nTwo requirements: reasonably speakable and tab-completion after 3 characters.\n\nOverview\n--------\n\nWith Acrylamid you can write your weblog entries with your editor of choice in\nMarkdown, reStructuredText or textile. With several content filters you can\npimp your HTML (typography, math, hyphenation). Acrylamid provides a very\nsophisticated CLI and integrates perfectly with any DVCes. It generates\ncompletely static HTML you can host everywhere.\n\nsupported markup languages\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n- Markdown_ and additional extensions (support for MathML_, deletion/insertion,\n  sub- and supscript, syntax highlighting …)\n- reStructuredText_ with directives for syntax highlighting and youtube video\n  embedding\n- textile_, discount_, all dialects supported by pandoc_ and plain HTML\n\nYou miss one? Extend Acrylamid in `less than 30 LoC`_!\n\n.. _Markdown: http://daringfireball.net/projects/markdown/\n.. _reStructuredText: http://docutils.sourceforge.net/rst.html\n.. _textile: https://en.wikipedia.org/wiki/Textile_%28markup_language%29\n.. _discount: http://www.pell.portland.or.us/~orc/Code/discount/\n.. _pandoc: http://johnmacfarlane.net/pandoc/\n.. _less than 30 LoC: https://posativ.org/git/acrylamid/blob/master/acrylamid/filters/pytextile.py\n\nother filters\n~~~~~~~~~~~~~\n\n- support for Jinja2 and Mako directly in postings (before they get processed)\n- typography_ (and smartypants_)\n- TeX hyphenation\n- summarize ability\n- `acronym detection`_  that automatically replace acronyms and abbreviations\n\n.. _typography: https://code.google.com/p/typogrify/\n.. _smartypants: http://daringfireball.net/projects/smartypants/\n.. _acronym detection: http://pyblosxom.github.io/Documentation/1.5/plugins/acronyms.html\n\nblogging features\n~~~~~~~~~~~~~~~~~\n\n- you like the `YAML front matter`_ from Jekyll_ or nanoc_? First choice in Acrylamid!\n- coming from Pelican_? Acrylamid has also support for metadata in the native\n  format of Markdown, reStructuredText and even Pandoc.\n- support for translations (oh, and did I mention the language dependend\n  hyphenation feature?).\n- a few HTML5 themes, see `Theming <http://posativ.org/acrylamid/theming.html>`_.\n- internal webserver with automatic compiling when something has changed.\n- assets management, including LESS_ and SASS_ conversion.\n- uni-directional PingBack support.\n- static site search.\n\n.. _YAML front matter: https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter\n.. _Jekyll: http://jekyllrb.com/\n.. _nanoc: http://nanoc.stoneship.org/\n.. _LESS: http://lesscss.org/\n.. _SASS: http://sass-lang.com/\n\nwhat is missing\n~~~~~~~~~~~~~~~\n\n- No comments. You have to use Disqus_ or `this approach`_.\n\n.. _Disqus: http://disqus.com/\n.. _this approach: http://hezmatt.org/~mpalmer/blog/2011/07/19/static-comments-in-jekyll.html\n.. _Sphinx: http://sphinx.pocoo.org/latest/\n\nQuickstart\n----------\n\n::\n\n    easy_install -U acrylamid\n\nThis installs Acrylamid with Jinja2_ as templating engine. For Mako_ use\n``easy_install -U acrylamid[mako]``. This installs two additional but not\nrequired dependencies: ``Markdown`` and ``translitcodec``. To get a list of\nall supported modules, head over to `additional supported modules`_.\n\nIf you rather use non-ascii characters, you're better off with:\n\n::\n\n    easy_install -U acrylamid python-magic unidecode\n\n.. _additional supported modules: http://posativ.org/acrylamid/installation.html#additional-supported-modules\n\nInitialize the base structure, edit *conf.py* and *layouts/* and compile with:\n\n::\n\n    $ acrylamid init myblog  # --mako, defaults to --jinja2\n        create  myblog/conf.py\n        ...\n    $ cd myblog/\n    $ acrylamid compile && acrylamid view\n        create  [0.05s] output/articles/index.html\n        create  [0.37s] output/2012/die-verwandlung/index.html\n        create  [0.00s] output/index.html\n        create  [0.00s] output/tag/die-verwandlung/index.html\n        create  [0.00s] output/tag/franz-kafka/index.html\n        create  [0.03s] output/atom/index.html\n        create  [0.04s] output/rss/index.html\n        create  [0.00s] output/sitemap.xml\n        create  output/style.css\n    9 new, 0 updated, 0 skipped [0.72s]\n       * Running on http://127.0.0.1:8000/\n\nReal World Examples?\n~~~~~~~~~~~~~~~~~~~~\n\n- `Practicing web development <http://www.vlent.nl/>`_ – Mark van Lent\n  [`source <https://github.com/markvl/www.vlent.nl>`__]\n- `mecker. mecker. mecker. <http://blog.posativ.org/>`_ – Martin Zimmermann\n  [`source <https://github.com/posativ/blog.posativ.org/>`__]\n- `Groovematic <http://groovematic.com/>`_ –  Isman Firmansyah\n  [`source <https://github.com/iromli/groovematic>`__]\n- `Christoph Polcin <http://www.christoph-polcin.com/>`_ – Christoph Polcin\n  [`source <http://git.christoph-polcin.com/blog/>`__, `theme <http://git.christoph-polcin.com/acrylamid-theme-bipolar/>`__]\n\nCommands\n--------\n\nSee `commands <https://posativ.org/acrylamid/commands.html>`_ for a detailed\noverview.\n\n::\n\n    $ acrylamid --help\n    usage: acrylamid [-h] [-v] [-q] [-C] [--version]  ...\n\n    positional arguments:\n\n        init          initializes base structure in DIR\n        compile       compile blog\n        view          fire up built-in webserver\n        autocompile   automatic compilation and serving\n        new           create a new entry\n        check         run W3C or validate links\n        deploy        run task\n        import        import content from URL or FILE\n        info          short summary\n        ping          notify ressources\n\n    optional arguments:\n      -h, --help      show this help message and exit\n      -v, --verbose   more verbose\n      -q, --quiet     less verbose\n      -C, --no-color  disable color\n      --version       show program's version number and exit\n\nNeed Help?\n----------\n\nJoin ``#acrylamid`` on Freenode_! If you found a bug, please report it on\n`GitHub Issues`_. The project has also a mailing list [Archive_], just send\nan email to ``acrylamid@librelist.com`` and you have subscribed .\n\n.. _Freenode: http://freenode.net/\n.. _Github Issues: https://github.com/posativ/acrylamid/issues?state=open\n.. _Archive: http://librelist.com/browser/acrylamid/",
        "url": "http://pypi.python.org/pypi/acrylamid",
        "summary": "static blog compiler with incremental updates",
        "command": "pip install 'acrylamid'"
      },
      "acrylic": {
        "name": "acrylic",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/acrylic",
        "summary": "Simple tabular data with Python.",
        "command": "pip install 'acrylic'"
      },
      "acsone.recipe.odoo.pydev": {
        "name": "acsone.recipe.odoo.pydev",
        "description": "========================\r\nacsone.recipe.odoo.pydev\r\n========================\r\n\r\n|Version|\r\n\r\nAn extension to `anybox.recipe.odoo\r\n<http://pythonhosted.org/anybox.recipe.odoo>`_\r\nthat generates `Odoo <https://www.odoo.com>`_ \r\nprojects for the `Eclipse PyDev <http://pydev.org/>`_ IDE.\r\n\r\n.. contents::\r\n\r\n- Code repository: http://github.com/acsone/acsone.recipe.odoo.pydev\r\n- Report bugs at http://github.com/acsone/acsone.recipe.odoo.pydev/issues\r\n\r\n\r\nWhat it is\r\n==========\r\n\r\nThis buildout  recipe is\r\nan extension to the fully featured recipe developed by Anybox:\r\n`anybox.recipe.odoo\r\n<http://pythonhosted.org/anybox.recipe.odoo>`_.\r\n\r\nIt generates a ready-to-use Eclipse PyDev Project, \r\npointing to all dependencies required to develop, run\r\nand debug your `Odoo <https://www.odoo.com>`_ server \r\nas well as your own addons.\r\n\r\nThe generated project is fully configured, including a preset\r\nPYTHONPATH so as to support debugging, pep8 import checks, auto completion\r\n\r\nHow to use it\r\n=============\r\n\r\nSince the recipe is an extension to `anybox.recipe.odoo\r\n<http://pythonhosted.org/anybox.recipe.odoo>`_, the first step, if not done,\r\nis to add your `anybox.recipe.odoo\r\n<http://pythonhosted.org/anybox.recipe.odoo>`_, configuration to ``buildout.cfg`` \r\nand include it in ``${buildout:parts}``. \r\n\r\nAn example::\r\n\r\n    [buildout]\r\n    ...\r\n    parts = ... openerp\r\n\r\n    [openerp]\r\n    recipe = anybox.recipe.odoo:server\r\n    version = git https://github.com/odoo/odoo.git odoo 7.0\r\n    addons = ...\r\n    ....\r\n\r\n\r\nAnother example using git and Odoo V8::\r\n\r\n    [buildout]\r\n    ...\r\n    parts = ... openerp\r\n\r\n    [openerp]\r\n    recipe = anybox.recipe.odoo[bzr]:server\r\n    version = git https://github.com/odoo/odoo.git odoo 8.0\r\n    addons = ...\r\n    ....\r\n\r\n\r\nA good practice is to use the inheritance mechanism of buildout to define your\r\ndevelopment environment in an other file such as ``devel.cfg``::\r\n\r\n    [buildout]\r\n    extends = buildout.cfg\r\n    parts = ... pydevproject\r\n\r\n    [pydevproject]\r\n    <= openerp\r\n    recipe = acsone.recipe.odoo.pydev\r\n    project-name = my_project_name\r\n    python-version = python 2.7\r\n    python-interpreter = Default\r\n    eggs += any_additional_egg_you_want\r\n\r\nThen prepare your virtualenv and install zc.buildout\r\n\r\n    $ virtualenv\r\n    \r\n    $ bin/pip install zc.buildout\r\n    \r\nTo run the recipe and generate your project, run\r\n\r\n    $ bin/buildout install pydevproject\r\n\r\nThe launch eclipse, import the project and you are ready to go.\r\nTo debug, use bin/start_openerp_pydev in the eclipse debug configuration.\r\n\r\nSupported options\r\n=================\r\nThese match the options of a PyDev Project.\r\n\r\nname\r\n  The project name. This is just for Eclipse and can be anything you want.\r\npython-version\r\n  The combination of interpreter and grammar version. E.g. *python 2.7* \r\n  (default is *python 2.7*)\r\npython-interpreter\r\n  The interpreter name, as configured in the the Eclipse Preferences for PyDev. \r\n  Usually *Default* is fine.  (default is *Default*)\r\n\r\nBehind the curtain\r\n==================\r\n\r\nIn addition to the startup scripts and configuration file generated by\r\n`anybox.recipe.odoo\r\n<http://pythonhosted.org/anybox.recipe.odoo>`_., this recipe\r\ngenerates the two files that define a PyDev Project:\r\n\r\n- .project \r\n- .pydevproject.\r\n\r\nWhile eggs and their dependencies are declared as external libraries, \r\nthe server and its addons are declared as source folders. In the same time,\r\nthe recipe uses in background the `collective.recipe.omelette \r\n<https://pypi.python.org/pypi/collective.recipe.omelette>`_ recipe to build\r\na unified directory structure of declared addons, symlinking to the actual \r\ncontents, in order to allow proper pep8 check and auto completion. \r\nThis directory structure is also declared as external dependency to avoid \r\nconfusion between source folder and the unified directory structure.\r\n\r\nIt's a know issue that when same addons are both in the PYTHONPATH and \r\naddons_path (it's the case with the generated project definition), \r\nit's not possible to start the server due to import errors. To avoid\r\nthis problem, the recipe adds to the generated scripts , specific code \r\nto remove parts of sys.path that are also in addons_path.\r\n\r\n.. |Version| image:: https://badge.fury.io/py/acsone.recipe.odoo.pydev.svg?\r\n   :target: http://badge.fury.io/py/acsone.recipe.odoo.pydev\r\n   \r\n\r\nContributors\r\n************\r\n\r\nLaurent Mignon (ACSONE SA/NV), Author\r\n\r\n\r\nChange history\r\n**************\r\n\r\n2.0 (2014-12-08)\r\n----------------\r\n\r\n- `github #5 <https://github.com/acsone/acsone.recipe.odoo.pydev/issues/5>`_:\r\n  Extends anybox.recipe.odoo in place of anybox.recipe.opener\r\n\r\n\r\n1.2 (2014-10-13)\r\n----------------\r\n\r\n- `github #4 <https://github.com/acsone/acsone.recipe.odoo.pydev/issues/4>`_:\r\n  Pydev > 3.7 and Odoo 8.0 compatibility\r\n\r\n- `github #3 <https://github.com/acsone/acsone.recipe.odoo.pydev/issues/3>`_:\r\n  Incorrect Pythonpath in Eclipse\r\n\r\n1.1 (2014-09-08)\r\n----------------\r\n\r\n- `github #1 <https://github.com/acsone/acsone.recipe.odoo.pydev/issues/1>`_: \r\n  support new addons layout on github. The eclipse syntax analyser\r\n  also scan addons directory at root of the cloned directory if exists. BTW,\r\n  code completion is fully functionnal with odoo sources distribution from \r\n  github.\r\n\r\n\r\n1.0 (2014-05-30)\r\n----------------\r\n\r\n- First release\r\n  [ACSONE SA/NV]\r\n\r\nDownload\r\n********",
        "url": "http://pypi.python.org/pypi/acsone.recipe.odoo.pydev",
        "summary": "A buildout recipe to install and configure a PyDev project for Openerp",
        "command": "pip install 'acsone.recipe.odoo.pydev'"
      },
      "ACSpy": {
        "name": "acspy",
        "description": "ACSpy\n=====\n\nA Python package for working with ACS motion controllers.\n\nInstallation\n------------\n  - `git clone https://github.com/petebachant/ACSpy.git`\n  - `python setup.py install`\n\nUsage\n-----\n### Using the `acsc` module\nThe `acsc` module is designed to mimic the syntax of the ACS C library that it wraps. \n\n```python\n>>> from acspy import acsc\n>>> hcomm = acsc.openCommDirect()\n>>> acsc.enable(hcomm, 0)\n>>> acsc.getMotorState(hcomm, 0)\n{'moving': False, 'enabled': True, 'in position': True, 'accelerating': False}\n>>> acsc.closeComm(hcomm)\n```\n\n### Using the `Controller` object\nThe `control` module provides an object-oriented interface to the controller, making\ncode development more intuitive. \nAn example of its use:\n\n```python\n>>> from acspy.control import Controller\n>>> controller = Controller(contype=\"simulator\", n_axes=4)\n>>> controller.connect()\n>>> axis0 = controller.axes[0]\n>>> axis0.enable()\n>>> axis0.enabled\nTrue\n>>> axis0.ptp(500.5)\n>>> axis0.rpos\n500.5\n>>> axis0.disable()\n>>> controller.disconnect()\n```\n\nLicense\n-------\n\nACSpy Copyright (c) 2013-2014 Peter Bachant\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.",
        "url": "http://pypi.python.org/pypi/ACSpy",
        "summary": "Package for working with ACS motion controllers.",
        "command": "pip install 'ACSpy'"
      },
      "acstools": {
        "name": "acstools",
        "description": "Release notes for 1.7.3:\r\n\r\n- TEAL interfaces for running the new ACSCTE step from CALACS was added to the package.\r\n\r\n- The following bugs in acs_destripe were fixed:\r\n    - No longer crashes while processing WFC polarizer (subarray) data\r\n    - DARKFILE now correctly handled\r\n    - Now saves the corrected image if FLATCORR or DARKCORR is not COMPLETED\r\n\r\n- Documentation included with the package has been updated to reflect the latest changes.",
        "url": "http://pypi.python.org/pypi/acstools",
        "summary": "Python Tools for ACS (Advanced Camera for Surveys) Data",
        "command": "pip install 'acstools'"
      },
      "act_as_executable": {
        "name": "act_as_executable",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/act_as_executable",
        "summary": "A Python wrapper to build CLI wrappers",
        "command": "pip install 'act_as_executable'"
      },
      "act-bb-usage": {
        "name": "act-bb-usage",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/act-bb-usage",
        "summary": "Fetch the total internet usage for the month\n                   from ACT broadband portal",
        "command": "pip install 'act-bb-usage'"
      },
      "actdiag": {
        "name": "actdiag",
        "description": "`actdiag` generate activity-diagram image file from spec-text file.\n\n.. image:: https://drone.io/bitbucket.org/blockdiag/actdiag/status.png\n   :target: https://drone.io/bitbucket.org/blockdiag/actdiag\n   :alt: drone.io CI build status\n\n.. image:: https://pypip.in/v/actdiag/badge.png\n   :target: https://pypi.python.org/pypi/actdiag/\n   :alt: Latest PyPI version\n\n.. image:: https://pypip.in/d/actdiag/badge.png\n   :target: https://pypi.python.org/pypi/actdiag/\n   :alt: Number of PyPI downloads\n\n\nFeatures\n========\n\n* Generate activity-diagram from dot like text (basic feature).\n* Multilingualization for node-label (utf-8 only).\n\nYou can get some examples and generated images on \n`blockdiag.com <http://blockdiag.com/actdiag/build/html/index.html>`_ .\n\nSetup\n=====\n\nUse easy_install or pip::\n\n   $ sudo easy_install actdiag\n\n   Or\n\n   $ sudo pip actdiag\n\n\nspec-text setting sample\n========================\n\nFew examples are available.\nYou can get more examples at\n`blockdiag.com`_ .\n\nsimple.diag\n------------\n\nsimple.diag is simply define nodes and transitions by dot-like text format::\n\n    diagram {\n      A -> B -> C;\n      lane you {\n        A; B;\n      }\n      lane me {\n        C;\n      }\n    }\n\n\nUsage\n=====\n\nExecute actdiag command::\n\n   $ actdiag simple.diag\n   $ ls simple.png\n   simple.png\n\n\nRequirements\n============\n* Python 2.6, 2.7, 3.2, 3.3, 3.4\n* Pillow 2.2.1 or later\n* funcparserlib 0.3.6 or later\n* reportlab (optional)\n* wand and imagemagick (optional)\n* setuptools\n\n\nLicense\n=======\nApache License 2.0\n\n\nHistory\n=======\n\n0.5.4 (2015-01-01)\n------------------\n* Follow blockdiag-1.5.0 interface\n\n0.5.3 (2014-07-02)\n------------------\n* Change interface of docutils node (for sphinxcontrib module)\n\n0.5.2 (2014-06-24)\n------------------\n* Add options to blockdiag directive (docutils extension)\n   - :width:\n   - :height:\n   - :scale:\n   - :align:\n   - :name:\n   - :class:\n   - :figwidth:\n   - :figclass:\n\n0.5.1 (2013-10-22)\n------------------\n* Fix bugs\n\n0.5.0 (2013-10-05)\n------------------\n* Support python 3.2 and 3.3 (thanks to @masayuko)\n* Drop supports for python 2.4 and 2.5\n* Replace dependency: PIL -> Pillow\n\n0.4.3 (2013-02-10)\n------------------\n* Fix bugs\n\n0.4.2 (2013-02-10)\n------------------\n* Fix bugs\n\n0.4.1 (2012-10-28)\n------------------\n* Fix bugs\n\n0.4.0 (2012-10-22)\n------------------\n* Optimize algorithm for rendering shadow\n* Add options to docutils directive\n* Fix bugs\n\n0.3.4 (2012-09-29)\n------------------\n* Fix bugs\n\n0.3.3 (2012-04-23)\n------------------\n* Set hyperlinks to header of lanes on SVG image\n* Fill background of lane header with lane.color attribute\n\n0.3.2 (2012-03-15)\n------------------\n* Fix bugs\n\n0.3.1 (2012-02-15)\n------------------\n* Add autolane plugin\n* Update to new package structure (blockdiag >= 1.1.2)\n\n0.3.0 (2011-11-19)\n------------------\n* Add fontfamily attribute for switching fontface\n* Fix bugs\n\n0.2.4 (2011-11-10)\n------------------\n* Fix dependencies (do not depend PIL directly for pillow users)\n\n0.2.3 (2011-11-06)\n------------------\n* Add docutils exetension\n* Fix bugs\n\n0.2.2 (2011-11-01)\n------------------\n* Add class feature (experimental)\n\n0.2.1 (2011-11-01)\n------------------\n* Follow blockdiag-0.9.7 interface\n\n0.2.0 (2011-10-19)\n------------------\n* Follow blockdiag-0.9.5 interface \n\n0.1.9 (2011-10-11)\n------------------\n* Fix bugs\n\n0.1.8 (2011-09-30)\n------------------\n* Add diagram attribute: default_text_color\n\n0.1.7 (2011-07-05)\n------------------\n* Fix bugs\n\n0.1.6 (2011-07-03)\n------------------\n* Support input from stdin\n\n0.1.5 (2011-05-15)\n------------------\n* Fix bugs\n\n0.1.4 (2011-05-14)\n------------------\n* Change license to Apache License 2.0\n* Support blockdiag 0.8.1 core interface \n\n0.1.3 (2011-04-19)\n------------------\n* Fix bugs\n\n0.1.2 (2011-04-11)\n------------------\n* Fix bugs\n\n0.1.1 (2011-04-10)\n------------------\n* Fix bugs\n\n0.1.0 (2011-04-09)\n------------------\n* First release",
        "url": "http://pypi.python.org/pypi/actdiag",
        "summary": "actdiag generates activity-diagram image from text",
        "command": "pip install 'actdiag'"
      },
      "acted.projects": {
        "name": "acted.projects",
        "description": ".. contents::\n\n.. Note!\n   -----\n   Update the following URLs to point to your:\n\n   - code repository\n   - bug tracker\n   - questions/comments feedback mail\n   (do not set a real mail, to avoid spams)\n\n   Or remove it if not used.\n\n- Code repository: http://svn.somewhere.com/...\n- Questions and comments to somemailing_list\n- Report bugs at http://bug.somewhere.com/..\n\n\nChange history\n**************\n\nChangelog\n=========\n\n0.1 (xxxx-xx-xx)\n----------------\n\nInitial Release\n- Created recipe with ZopeSkel\n  [Ivan Price]\n\nDetailed Documentation\n**********************\n\nIntroduction\n============\n\nThis is a full-blown functional test. The emphasis here is on testing what\nthe user may input and see, and the system is largely tested as a black box.\nWe use PloneTestCase to set up this test as well, so we have a full Plone site\nto play with. We *can* inspect the state of the portal, e.g. using \nself.portal and self.folder, but it is often frowned upon since you are not\ntreating the system as a black box. Also, if you, for example, log in or set\nroles using calls like self.setRoles(), these are not reflected in the test\nbrowser, which runs as a separate session.\n\nBeing a doctest, we can tell a story here.\n\nFirst, we must perform some setup. We use the testbrowser that is shipped\nwith Five, as this provides proper Zope 2 integration. Most of the \ndocumentation, though, is in the underlying zope.testbrower package.\n\n    >>> from Products.Five.testbrowser import Browser\n    >>> browser = Browser()\n    >>> portal_url = self.portal.absolute_url()\n\nThe following is useful when writing and debugging testbrowser tests. It lets\nus see all error messages in the error_log.\n\n    >>> self.portal.error_log._ignored_exceptions = ()\n\nWith that in place, we can go to the portal front page and log in. We will\ndo this using the default user from PloneTestCase:\n\n    >>> from Products.PloneTestCase.setup import portal_owner, default_password\n\n    >>> browser.open(portal_url)\n\nWe have the login portlet, so let's use that.\n\n    >>> browser.getControl(name='__ac_name').value = portal_owner\n    >>> browser.getControl(name='__ac_password').value = default_password\n    >>> browser.getControl(name='submit').click()\n\nHere, we set the value of the fields on the login form and then simulate a\nsubmit click.\n\nWe then test that we are still on the portal front page:\n\n    >>> browser.url == portal_url\n    True\n\nAnd we ensure that we get the friendly logged-in message:\n\n    >>> \"You are now logged in\" in browser.contents\n    True\n\n\n-*- extra stuff goes here -*-\nThe ACTED Project content type\n===============================\n\nIn this section we are tesing the ACTED Project content type by performing\nbasic operations like adding, updadating and deleting ACTED Project content\nitems.\n\nAdding a new ACTED Project content item\n--------------------------------\n\nWe use the 'Add new' menu to add a new content item.\n\n    >>> browser.getLink('Add new').click()\n\nThen we select the type of item we want to add. In this case we select\n'ACTED Project' and click the 'Add' button to get to the add form.\n\n    >>> browser.getControl('ACTED Project').click()\n    >>> browser.getControl(name='form.button.Add').click()\n    >>> 'ACTED Project' in browser.contents\n    True\n\nNow we fill the form and submit it.\n\n    >>> browser.getControl(name='title').value = 'ACTED Project Sample'\n    >>> browser.getControl('Save').click()\n    >>> 'Changes saved' in browser.contents\n    True\n\nAnd we are done! We added a new 'ACTED Project' content item to the portal.\n\nUpdating an existing ACTED Project content item\n---------------------------------------\n\nLet's click on the 'edit' tab and update the object attribute values.\n\n    >>> browser.getLink('Edit').click()\n    >>> browser.getControl(name='title').value = 'New ACTED Project Sample'\n    >>> browser.getControl('Save').click()\n\nWe check that the changes were applied.\n\n    >>> 'Changes saved' in browser.contents\n    True\n    >>> 'New ACTED Project Sample' in browser.contents\n    True\n\nRemoving a/an ACTED Project content item\n--------------------------------\n\nIf we go to the home page, we can see a tab with the 'New ACTED Project\nSample' title in the global navigation tabs.\n\n    >>> browser.open(portal_url)\n    >>> 'New ACTED Project Sample' in browser.contents\n    True\n\nNow we are going to delete the 'New ACTED Project Sample' object. First we\ngo to the contents tab and select the 'New ACTED Project Sample' for\ndeletion.\n\n    >>> browser.getLink('Contents').click()\n    >>> browser.getControl('New ACTED Project Sample').click()\n\nWe click on the 'Delete' button.\n\n    >>> browser.getControl('Delete').click()\n    >>> 'Item(s) deleted' in browser.contents\n    True\n\nSo, if we go back to the home page, there is no longer a 'New ACTED Project\nSample' tab.\n\n    >>> browser.open(portal_url)\n    >>> 'New ACTED Project Sample' in browser.contents\n    False\n\nAdding a new ACTED Project content item as contributor\n------------------------------------------------\n\nNot only site managers are allowed to add ACTED Project content items, but\nalso site contributors.\n\nLet's logout and then login as 'contributor', a portal member that has the\ncontributor role assigned.\n\n    >>> browser.getLink('Log out').click()\n    >>> browser.open(portal_url)\n    >>> browser.getControl(name='__ac_name').value = 'contributor'\n    >>> browser.getControl(name='__ac_password').value = default_password\n    >>> browser.getControl(name='submit').click()\n    >>> browser.open(portal_url)\n\nWe use the 'Add new' menu to add a new content item.\n\n    >>> browser.getLink('Add new').click()\n\nWe select 'ACTED Project' and click the 'Add' button to get to the add form.\n\n    >>> browser.getControl('ACTED Project').click()\n    >>> browser.getControl(name='form.button.Add').click()\n    >>> 'ACTED Project' in browser.contents\n    True\n\nNow we fill the form and submit it.\n\n    >>> browser.getControl(name='title').value = 'ACTED Project Sample'\n    >>> browser.getControl('Save').click()\n    >>> 'Changes saved' in browser.contents\n    True\n\nDone! We added a new ACTED Project content item logged in as contributor.\n\nFinally, let's login back as manager.\n\n    >>> browser.getLink('Log out').click()\n    >>> browser.open(portal_url)\n    >>> browser.getControl(name='__ac_name').value = portal_owner\n    >>> browser.getControl(name='__ac_password').value = default_password\n    >>> browser.getControl(name='submit').click()\n    >>> browser.open(portal_url)\n\n\n\n\nContributors\n************\n\nIvan Price, Author\n\n\nDownload\n********",
        "url": "http://pypi.python.org/pypi/acted.projects",
        "summary": "Plone DB of ACTED Projects",
        "command": "pip install 'acted.projects'"
      },
      "actionbar.babble": {
        "name": "actionbar.babble",
        "description": "Introduction\n============\n\nactionbar.babble is the Babble chat client integration package for \nthe ActionBar, an extensible floating panel with links at the \nbottom of your Plone site.\n\nFor more information regarding Babble and ActionBar, please see their\nrespective packages: babble.client, babble.server and actionbar.panel.\n\n\nAdditional info:\n----------------\n\nFor additional info, please read the documentation at \nhttp://opkode.net/babbledocs/actionbar.babble/index.html \n\nChangelog\n=========\n\n0.3b3 (2012-03-23)\n------------------\n\n- Compatibility fixes for babble.client 2.0b1 [jcbrand]\n\n\n0.3b2 (2011-11-20)\n------------------\n\n- Compatibility fixes with babble.client 2.0a4 [jcbrand]\n\n\n0.3b1 (2011-10-18)\n------------------\n\n- Compatibility fixes. [jcbrand]\n\n\n0.2 (2011-10-05)\n----------------\n\n- Add timestamp support. [jcbrand]\n\n\n0.1b2 (2011-04-04)\n------------------\n\n- Fixed an IE javascript bug #2038 [deroiste]\n\n\n0.1b1 (2011-01-18)\n------------------\n\n- Added support for babble.client 1.4 [jcbrand]\n\n\n0.1a3 (2010-04-28)\n------------------\n\n- Fixed for ajax calls in the context of portal_factory [jcbrand]\n- Tweak babblefeeder.css to be loaded after chat.css [jcbrand]\n- Fixed AJAX call problems [jcbrand]\n\n0.1a2 (2010-04-08)\n------------------\n\n- Tweaked jsregistry.xml to gain Plone3 compatibility [jcbrand]\n\n0.1a1 (2010-04-08)\n------------------\n\n- Initial release [jcbrand]",
        "url": "http://pypi.python.org/pypi/actionbar.babble",
        "summary": "A actionbar.panel integration package for the Babble instant messaging system.",
        "command": "pip install 'actionbar.babble'"
      },
      "actionbar.panel": {
        "name": "actionbar.panel",
        "description": "Introduction\n============\n\nactionbar.panel provides an admin/action panel at the bottom of your Plone\nsite, similar to the one used on the now old facebook style.\n\nI took a lot of the css from Soh Tanaka's excellent tutorial:\n* http://www.sohtanaka.com/web-design/facebook-style-footer-admin-panel-part-1/\n\nAdding new actions:\n-------------------\n\nThe actionbar is fully extendible. It is a viewlet manager, with the name\n'actionbar.panel'. This means that you can add new actions and links to the \npanel by creating and registering viewlets for it in your own Plone add-ons.\n\nSee actionbar/panel/browser/configure.zcml for widget registrations.\n\nIf you want to publish eggs with add-on actions for the actionbar, please consider\nreleasing them under the actionbar.* namespace.\n\nInstalling:\n-----------\n\nactionbar.panel should be a 'drop-in' installation. Just add 'actionbar.panel'\nto your eggs section in your buildout.cfg. Then use Plone's control panel, or\nthe portal_quickinstaller in the Zope management interface to install the\npackage.\n\nOnce you've done this, the panel and some default actions should be visible in\nPlone.\n\nConfiguring:\n------------\n\nYou can hide or rearrange the actions on the panel. You can also hide the\nentire panel itself. To do this, go to the viewlet managent screen by appending\n'/@@manage-viewlets' to the root URL of your Plone site. The panel\nviewlet manager and its actions will be near the bottom of the page.\n\nCompatibility:\n--------------\n\nactionbar.panel has been tested on Plone 4 and Plone 3.3.5.\nIt should work on older versions of Plone 3 as well. \n\nIcons:\n------\n\nThe icons used in this release were created by Liam McKay\n(http://wefunction.com/) and are released under the GPL.\n\nhttp://www.woothemes.com/2009/09/woofunction-178-amazing-web-design-icons/\n\nContact:\n--------\n\nPlease contact me if you have any questions, compatibility problems or improvement suggestions.\n\n- brand at syslab dot com\n\n\n\nChangelog\n=========\n\n1.2.1 (2010-10-01)\n------------------\n\n- Adding some padding so that the overlay won't hide lower borders\n  of overlays [do3cc]\n\n\n1.2 (2010-05-05)\n----------------\n\n- Fixed the 'User Profile' widget to point to the login_form when view\n  anonymously [jcbrand]\n\n1.1 (2010-03-23)\n----------------\n\n- Fixed the package name in the INSTALL.txt and LICENSE.txt files [jcbrand]\n\n1.0 (2010-03-18)\n----------------\n\n- Initial release [jcbrand]",
        "url": "http://pypi.python.org/pypi/actionbar.panel",
        "summary": "Provides a (old) facebook style action panel at the bottom of your  Plone site",
        "command": "pip install 'actionbar.panel'"
      },
      "actionkit": {
        "name": "actionkit",
        "description": "",
        "url": "http://pypi.python.org/pypi/actionkit",
        "summary": "REST API client for ActionKit.",
        "command": "pip install 'actionkit'"
      },
      "ActionServer": {
        "name": "actionserver",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ActionServer",
        "summary": "UNKNOWN",
        "command": "pip install 'ActionServer'"
      },
      "ActionTree": {
        "name": "actiontree",
        "description": "ActionTree is a Python (2.7+ and 3.3+) library to execute (long) actions in parallel, respecting dependencies between those actions.\nYou create the graph of the actions to be executed and then call the ``execute`` method of its root,\nspecifying how many actions must be run in parallel and if errors should stop the execution.\n\nIt's licensed under the `MIT license <http://choosealicense.com/licenses/mit/>`__.\nIt's available on the `Python package index <http://pypi.python.org/pypi/ActionTree>`__,\nits `documentation is hosted by Python <http://pythonhosted.org/ActionTree>`__\nand its source code is on `GitHub <https://github.com/jacquev6/ActionTree>`__.\n\nQuestions? Remarks? Bugs? Want to contribute? `Open an issue <https://github.com/jacquev6/ActionTree/issues>`__!\n\n.. image:: https://img.shields.io/travis/jacquev6/ActionTree/master.svg\n    :target: https://travis-ci.org/jacquev6/ActionTree\n\n.. image:: https://img.shields.io/coveralls/jacquev6/ActionTree/master.svg\n    :target: https://coveralls.io/r/jacquev6/ActionTree\n\n.. image:: https://img.shields.io/codeclimate/github/jacquev6/ActionTree.svg\n    :target: https://codeclimate.com/github/jacquev6/ActionTree\n\n.. image:: https://img.shields.io/scrutinizer/g/jacquev6/ActionTree.svg\n    :target: https://scrutinizer-ci.com/g/jacquev6/ActionTree\n\n.. image:: https://img.shields.io/pypi/dm/ActionTree.svg\n    :target: https://pypi.python.org/pypi/ActionTree\n\n.. image:: https://img.shields.io/pypi/l/ActionTree.svg\n    :target: https://pypi.python.org/pypi/ActionTree\n\n.. image:: https://img.shields.io/pypi/v/ActionTree.svg\n    :target: https://pypi.python.org/pypi/ActionTree\n\n.. image:: https://img.shields.io/pypi/pyversions/ActionTree.svg\n    :target: https://pypi.python.org/pypi/ActionTree\n\n.. image:: https://img.shields.io/pypi/status/ActionTree.svg\n    :target: https://pypi.python.org/pypi/ActionTree\n\n.. image:: https://img.shields.io/github/issues/jacquev6/ActionTree.svg\n    :target: https://github.com/jacquev6/ActionTree/issues\n\n.. image:: https://badge.waffle.io/jacquev6/ActionTree.png?label=ready&title=ready\n    :target: https://waffle.io/jacquev6/ActionTree\n\n.. image:: https://img.shields.io/github/forks/jacquev6/ActionTree.svg\n    :target: https://github.com/jacquev6/ActionTree/network\n\n.. image:: https://img.shields.io/github/stars/jacquev6/ActionTree.svg\n    :target: https://github.com/jacquev6/ActionTree/stargazers\n\nQuick start\n===========\n\nInstall from PyPI::\n\n    $ pip install ActionTree\n\nImport:\n\n>>> from ActionTree import *\n>>> from ActionTree.stock import *\n\nExecute some action:\n\n>>> link = CallSubprocess([\"g++\", \"-o\", \"test\", \"a.o\", \"b.o\"])\n>>> link.add_dependency(CallSubprocess([\"g++\", \"-c\", \"doc/a.cpp\", \"-o\", \"a.o\"]))\n>>> link.add_dependency(CallSubprocess([\"g++\", \"-c\", \"doc/b.cpp\", \"-o\", \"b.o\"]))\n>>> link.execute(jobs=2)\n",
        "url": "http://pypi.python.org/pypi/ActionTree",
        "summary": "Executes (long) actions in parallel, respecting dependencies between those actions",
        "command": "pip install 'ActionTree'"
      },
      "Active-Alchemy": {
        "name": "active-alchemy",
        "description": "==================\nActive-Alchemy\n==================\n\nA framework agnostic wrapper for SQLAlchemy that makes it really easy\nto use by implementing a simple active record like api, while it still uses the db.session underneath\n\n:copyright: © 2014/2015 by `Mardix`.\n:license: MIT, see LICENSE for more details.",
        "url": "http://pypi.python.org/pypi/Active-Alchemy",
        "summary": "==================\nActive-Alchemy\n==================\n\nA framework agnostic wrapper for SQLAlchemy that makes it really easy\nto use by implementing a simple active record like api, while it still uses the db.session underneath\n\n:copyright: © 2014/2015 by `Mardix`.\n:license: MIT, see LICENSE for more details.",
        "command": "pip install 'Active-Alchemy'"
      },
      "activecache": {
        "name": "activecache",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/activecache",
        "summary": "Active in-memory cache object for Python.",
        "command": "pip install 'activecache'"
      },
      "activedirectory": {
        "name": "activedirectory",
        "description": ".. image:: https://api.travis-ci.org/pycontribs/activedirectory.png?branch=master\n        :target: https://travis-ci.org/pycontribs/activedirectory\n\n.. image:: https://coveralls.io/repos/pycontribs/activedirectory/badge.png?branch=master\n        :target: https://coveralls.io/r/pycontribs/activedirectory\n\n.. image:: https://pypip.in/d/activedirectory/badge.png\n        :target: https://pypi.python.org/pypi/activedirectory/\n\n.. image:: https://pypip.in/v/activedirectory/badge.png\n        :target: https://pypi.python.org/pypi/activedirectory/\n\n.. image:: https://pypip.in/egg/activedirectory/badge.png\n        :target: https://pypi.python.org/pypi/activedirectory/\n\n.. image:: https://pypip.in/wheel/activedirectory/badge.png\n        :target: https://pypi.python.org/pypi/activedirectory/\n\n.. image:: https://pypip.in/license/activedirectory/badge.png\n        :target: https://pypi.python.org/pypi/activedirectory/\n\nactivedirectory\n===============\n\nEasiest way to interact with ActiveDirectory / AD / LDAP Servers from Python, pure python approach.",
        "url": "http://pypi.python.org/pypi/activedirectory",
        "summary": "Easiest way to interact with ActiveDirectory / AD / LDAP Servers from Python, pure python approach.",
        "command": "pip install 'activedirectory'"
      },
      "ActivePapers.Py": {
        "name": "activepapers.py",
        "description": "ActivePapers is a tool for working with executable papers, which\ncombine data, code, and documentation in single-file packages,\nsuitable for publication as supplementary material or on sites such as\n[figshare](http://figshare.com).",
        "url": "http://pypi.python.org/pypi/ActivePapers.Py",
        "summary": "Executable papers containing Python code",
        "command": "pip install 'ActivePapers.Py'"
      },
      "active_redis": {
        "name": "active_redis",
        "description": "# Example:\n\nfrom active_redis import ActiveRedis, ActiveRedisModel, UUIDGenerator\n\nclass Movie(ActiveRedisModel):\n    stored_attrs = ['title', 'year', 'author']\n\n    def __init__(self, uuid, title, year, author):\n        self.uuid = uuid\n        self.title, self.year, self.author = title, year, author\n\n\nif __name__ == '__main__':\n    ActiveRedis.config = {\n        'connexion': {'db': 3},\n        'namespace_prefix': 'mycinema'\n    }\n\n    assert Movie.delete_all()\n    assert 0, Movie.count()\n\n    topgun = Movie(UUIDGenerator.generate(), 'TopGun', 1987, 'Tony S.')\n    assert topgun.save()\n\n    titanic = Movie(UUIDGenerator.generate(), 'Titanic', 1997, 'James C.')\n    assert titanic.save()\n\n    topgun.update_attr('title', 'Top Gun')\n    assert 'Top Gun', Movie.find(topgun.uuid).title\n\n    assert 2, Movie.count()\n    assert 2, len(Movie.find_all())\n\n    m = Movie.find(topgun.uuid)\n    m.delete()\n\n    assert 1, Movie.count()\n    assert 1, len(Movie.find_all())",
        "url": "http://pypi.python.org/pypi/active_redis",
        "summary": "Simple ActiveRecord pattern for Redis",
        "command": "pip install 'active_redis'"
      },
      "Active-SQLAlchemy": {
        "name": "active-sqlalchemy",
        "description": "==================\nActive-SQLAlchemy\n==================\n\nA framework agnostic wrapper for SQLAlchemy that makes it really easy\nto use by implementing a simple active record like api, while it still uses the db.session underneath\n\n:copyright: © 2014/2015 by `Mardix`.\n:license: MIT, see LICENSE for more details.",
        "url": "http://pypi.python.org/pypi/Active-SQLAlchemy",
        "summary": "==================\nActive-SQLAlchemy\n==================\n\nA framework agnostic wrapper for SQLAlchemy that makes it really easy\nto use by implementing a simple active record like api, while it still uses the db.session underneath\n\n:copyright: © 2014/2015 by `Mardix`.\n:license: MIT, see LICENSE for more details.",
        "command": "pip install 'Active-SQLAlchemy'"
      },
      "active-subspaces": {
        "name": "active-subspaces",
        "description": "Python utilities for working with active subspaces.\r\n\r\nWARNING: Development is very active right now, so the interfaces are far from\r\nstable. It should settle down by mid-March, when the Active Subspaces book\r\ncomes out.\r\n\r\nRight now I'm using Enthought's Python Distribution and Canopy for development.\r\nYou'll need numpy and scipy for these tools.\r\n\r\nYou also need a linear program and quadratic program solver. I'm using Gurobi;\r\nyou can see the gurobi_wrapper.py that solves the problems I need. To get\r\nGurobi's Python interface working with Enthought/Canopy, take a look at this\r\nthread:\r\nhttps://groups.google.com/forum/#!searchin/gurobi/canopy/gurobi/ArCkf4a40uU/R9U1XFuMJEkJ\r\n\r\nQuestions? Contact Paul Constantine at Colorado School of Mines. Google me\r\nfor contact info.",
        "url": "http://pypi.python.org/pypi/active-subspaces",
        "summary": "Tools to apply active subspaces to analyze their models and data.",
        "command": "pip install 'active-subspaces'"
      },
      "activiti": {
        "name": "activiti",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/activiti",
        "summary": "An SDK that helps with interacting with Activiti.",
        "command": "pip install 'activiti'"
      },
      "activitisdk": {
        "name": "activitisdk",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/activitisdk",
        "summary": "An SDK that helps with interacting with Activiti.",
        "command": "pip install 'activitisdk'"
      },
      "activity-feed": {
        "name": "activity-feed",
        "description": "Activity Feed\n---\n\nAn Activity Feed for Python using Redis.",
        "url": "http://pypi.python.org/pypi/activity-feed",
        "summary": "An Activity Feed for python",
        "command": "pip install 'activity-feed'"
      },
      "activity-monitor": {
        "name": "activity-monitor",
        "description": "# Activity monitor\n\n[![Build Status](https://travis-ci.org/tBaxter/activity-monitor.svg?branch=master)](https://travis-ci.org/tBaxter/activity-monitor)\n\nA sort of tumblelog-y activity feed thing heavily based on other people's work. I'd credit them if I could remember where I got this stuff.\n\n--------\n\nModels you wish to monitor should be registered in your settings.py:\n\nExample:\n\n    ACTIVITY_MONITOR_MODELS = (\n      {'model': 'comments.comment',      # Required: the model to watch, in app_label.model format.\n        'date_field': 'post_date',     # Optional: the datetime field to watch. Defaults to \"created\"\n        'user_field': 'submitted_by',    # Optional: a related user to watch\n        'verb':  \"commented on\",         # The default verb string to be recorded.\n        'check': 'approved',             # Optional: a boolean field that must be true for the activity to register\n        'manager': 'SoftDeleteManager'   # Optional: if there is a custom manager, you can use it. If not, defaults to \"objects\"\n       },\n     {\n        'model': 'djangoratings.vote',\n        'date_field': 'date_added',\n      },\n     {\n        'model': 'auth.user',\n        'date_field': 'date_joined',\n        'check': 'is_active',\n      },\n    )\n\n\nIn the absence of 'user_field', it will assume whatever is defined in AUTH_USER_MODEL is the user. That defaults to auth.user, just in case you didn't set it either.\n\n--------\n\n### About the settings\n`Model` is required: it lets Activity Monitor know which models to watch. All models should be registered as `app_label.model`.\n\n`date_field` says when the activity happened -- when the new thing was created or updated. If undefined, Activity Monitor will look for a \"created\" field. Failing that, it will use the current time.\n\n`user_field` tells what field the actor can be found in. If undefined, Activity Monitor will look for a 'user' field. If no user field is found at all, Activity Monitor will fall back to request.user. The result is stored as \"actor\" on the activity.\n\n`verb` is the verb string to use. By default, strings will be output as \"{actor} {verb} {model.__unicode__()}\", or \"Joe Cool commented on '10 reasons beagles are awesome.'\"\n\n`override_string` overrides the normal output altogether.\n\n`check` allows you to say, \"Make sure this boolean is true on the object before adding the activity.\" For example, you wouldn't want any activities registering on unpublished blog posts, so you would check against the \"published\" field. If this field is false for the activity, no activity is registered.\n\n`manager` allows passing a custom manager to be used. Defaults to `objects`.\n\n`filter_superuser` suppresses registering activities if a superuser performed them. Useful if the superuser's changes should go unnoted, particularly if you're watching for updates.\n\n`filter_staff` suppresses registering activities if a staff member performed them. Like `filter_superuser`, this is useful if the changes should go unnoted, particularly if you're watching for updates.\n\n\n\n### What happens when the settings are defined\n\nOnce the settings are defined, the models are passed to follow_model() in activity_monitor.managers, which will send a signal on object creation or deletion.\n\nWhen an object is created or deleted, the signal is sent and an activity object is created with the object,\nthe user and the time of the event.\n\nThis is done in activity_monitor.signals.create_or_update, which does the bulk of the work. Among other things, it:\n\n* Uses the \"check\" field to determine if an object should or shouldn't be shown.\n* Checks if the user is superuser. If so, you don't want to show it in the user activity monitor.\n* Sorts out user field and determines a valid user object.\n* Checks if the object has a future timestamp (such as future-published blog entries) before adding.\n* Throws away activities if the related object is deleted or otherwise removed.\n* Makes sure the activity does not already exist.\n* Saves who did it (actor), what they did, what they did it to, and when.\n\nTo minimize queries, you can access the related user via 'actor', or just a unicode representation of their name with 'actor_name'. Similarly the target object is available as 'content_object', but a simple unicode representation is available as \"target\"\n\n\n### Simple Output\nActivity monitor supports several ways to output the activities.\n* You can have a simple chronological list\n* You can group activities by the target being acted on. In this case, output would be something like \"Joe Cool and Conrad commented on Woodstock.\"\n\n\n### Customizing output\nYou can define also define custom template snippets for the target content object. In this case, the template should live in `/templates/activity_monitor/includes/models/applabel_modelname.html`. An example is included.\n\nYou do not have to define all your content types. If you do not, activity monitor will safely fall back on a default output.\n\n**NOTE**: Loading these custom templates can lead to more database queries than you'd like. Custom templates should be used sparingly, and if you have a lot of them, you should at least cache the results.",
        "url": "http://pypi.python.org/pypi/activity-monitor",
        "summary": "A sort of tumblelog-y thing heavily based on code I got somewhere",
        "command": "pip install 'activity-monitor'"
      },
      "activitysim": {
        "name": "activitysim",
        "description": "ActivitySim\n===========\nActivitySim is an open platform for activity-based travel modeling.  It emerged from a consortium of Metropolitan Planning Organizations (MPOs) and other transportation planning agencies that wanted to build a shared, open, platform that could be easily adapted to their individual needs, but would share a robust, efficient, and well-maintained common core.\n\nActivitySim is being built on the same methodology and software stack that UrbanSim is based on, and will initially have dependencies on UrbanSim, but these may eventually be eliminated by refactoring UrbanSim and creating a common core that both UrbanSim and ActivitySim depend on.\n\n[![Build Status](https://travis-ci.org/synthicity/activitysim.svg?branch=master)](https://travis-ci.org/synthicity/activitysim) [![Coverage Status](https://coveralls.io/repos/synthicity/activitysim/badge.png?branch=master)](https://coveralls.io/r/synthicity/activitysim?branch=master)\n\n",
        "url": "http://pypi.python.org/pypi/activitysim",
        "summary": "Travel modeling",
        "command": "pip install 'activitysim'"
      },
      "ActivityStream": {
        "name": "activitystream",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ActivityStream",
        "summary": "UNKNOWN",
        "command": "pip install 'ActivityStream'"
      },
      "activity-tracker": {
        "name": "activity-tracker",
        "description": "A library to perform daily-active-user (and similar) tracking",
        "url": "http://pypi.python.org/pypi/activity-tracker",
        "summary": "DAU/MAU tracker",
        "command": "pip install 'activity-tracker'"
      },
      "ActivityTracker": {
        "name": "activitytracker",
        "description": "===============\nActivityTracker\n===============\n\nA tool for querying various sources to see what time was worked on specific\ntasks.  Contains various plugins for Tomboy notes and text files.\n\nUsage\n=====\n\nThe basic workflow with ActivityTracker is to define a \"group\" of\nfiles that contain time-based task intervals in some format.  At\nthe moment, ActivityTracker comes with three different parsers:\n\n  1. Emacs OrgMode_ files\n  2. Tomboy notes\n  3. Plain text files\n\nSetting Up\n----------\n\n  1. Create a new directory, ``/home/myhomedir/.activitytracker``\n  2. Setup a new file, ``/home/myhomedir/.activitytracker/config.ini``\n  3. Add group entries to ``config.ini``\n\nOrgMode_\n--------\n\nAn entry for a group of OrgMode_ files looks like this::\n\n  [File Group: Emacs OrgMode Files]\n  base_dir = /somedir/org-files\n  filename_match = [-_a-zA-Z0-9]*[.]org$\n  parser_name = activitytracker.plugins.orgmode.EmacsOrgModeParser\n\nPlease see the OrgMode_ home page for specifics on the OrgMode_\nformat.  ActivityTracker's OrgMode parser has two requirements:\n\n  1. Headings meant to be recorded/queried should have the **book** tag\n  2. The second line after a heading with **book** tag should have a\n     timestamp indicating the length of time worked\n\nHere is an example entry:\n\n  ** ActivityTracker :book:\n  <2011-04-16 Sat 10:00-14:00>\n  Working on orgmode support\n\nTomboy\n------\n\nAn entry for a group of Tomboy_ notes on a recent Gnome configuration\nwould look like this:\n\n  [File Group: Tomboy Notes]\n  base_dir = /home/myhomedir/.local/share/tomboy\n  filename_match = [a-zA-Z-0-9]*?[.]note\n  parser_name = activitytracker.plugins.tomboy.TomboyFileParser\n\nPlain Text Files\n----------------\n\nAn entry for a group of plain text files would look like this:\n\n  [File Group: Legacy Journal Files]\n  base_dir = /home/myhomedir/Documents/journal\n  filename_match = month-[a-zA-Z]+-[0-9]+[.]txt$\n  parser_name = activitytracker.plugins.text.TextFileParser\n\n\n.. _OrgMode: http://orgmode.org/\n.. _Tomboy: http://projects.gnome.org/tomboy/?pagewanted=all\n\nWriting Plugins\n===============\n\nThe ActivityTracker plugin mechanism expects a *callable* to\nbe named as the ``parser_name`` value in a file entry group.\n\nWhile checking files, the *callable* will be invoked (with no\narguments).  The *callable* must return an object with a\n``parse_input`` function.  The ``parse_input`` function\nwill be invoked for every file matching the criteria.\n\nAfter ``parse_input`` is invoked at least once, the object must\nensure it has a ``projects`` attribute as an iterable of\n*Project* instances.\n\nURLs\n====\n\n  * http://pypi.python.org/pypi/ActivityTracker\n  * http://src.serverzen.com/activitytracker\n\n\nCredits\n=======\n\n  * Created and maintained by Rocky Burt <rocky AT serverzen DOT com>.\n\n\nChanges\n=======\n\n1.0 (Dec-18-2012)\n-----------------\n\n  * setup pypi and bitbucket pages\n\n0.5 (unreleased)\n----------------\n\n  * first release",
        "url": "http://pypi.python.org/pypi/ActivityTracker",
        "summary": "Task and time logging",
        "command": "pip install 'ActivityTracker'"
      },
      "actmon": {
        "name": "actmon",
        "description": "This package provides a user idle timer for X11.",
        "url": "http://pypi.python.org/pypi/actmon",
        "summary": "This package provides a user idle timer for X11.",
        "command": "pip install 'actmon'"
      },
      "actors": {
        "name": "actors",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/actors",
        "summary": "UNKNOWN",
        "command": "pip install 'actors'"
      },
      "actr6_jni": {
        "name": "actr6_jni",
        "description": "TODO!",
        "url": "http://pypi.python.org/pypi/actr6_jni",
        "summary": "A high level library wrapper for the ACT-R JNI using Twisted.",
        "command": "pip install 'actr6_jni'"
      },
      "actuariat_python": {
        "name": "actuariat_python",
        "description": ".. _l-README:\n\nREADME / Changes\n================\n\n.. image:: https://travis-ci.org/sdpython/actuariat_python.svg?branch=master\n    :target: https://travis-ci.org/sdpython/actuariat_python\n    :alt: Build status\n\n.. image:: https://badge.fury.io/py/actuariat_python.svg\n    :target: http://badge.fury.io/py/actuariat_python\n      \n.. image:: http://img.shields.io/pypi/dm/actuariat_python.png\n    :alt: PYPI Package\n    :target: https://pypi.python.org/pypi/actuariat_python  \n    \n.. image:: http://img.shields.io/github/issues/sdpython/actuariat_python.png\n    :alt: GitHub Issues\n    :target: https://github.com/sdpython/actuariat_python/issues\n    \n.. image:: https://img.shields.io/badge/license-MIT-blue.svg\n    :alt: MIT License\n    :target: http://opensource.org/licenses/MIT    \n   \n**Links:**\n    * `pypi/actuariat_python <https://pypi.python.org/pypi/actuariat_python/>`_\n    * `GitHub/actuariat_python <https://github.com/sdpython/actuariat_python/>`_\n    * `documentation <http://www.xavierdupre.fr/app/actuariat_python/helpsphinx/index.html>`_\n    * `Windows Setup <http://www.xavierdupre.fr/site2013/index_code.html#actuariat_python>`_\n    * `Travis <https://travis-ci.org/sdpython/actuariat_python>`_\n    * `Blog <http://www.xavierdupre.fr/app/actuariat_python/helpsphinx/blog/main_0000.html#ap-main-0>`_\n\n\nDescription        \n-----------\n\nPython et actuariat.\n\n\nContributions\n-------------\n\nStarted in 2015/02.\n\n\nVersions\n--------\n\n* **0.1 - 2015/??/??**\n    * **new:** first version",
        "url": "http://pypi.python.org/pypi/actuariat_python",
        "summary": "Helpers for teaching purposes (includes sqllite helpers)",
        "command": "pip install 'actuariat_python'"
      },
      "acute-dbapi": {
        "name": "acute-dbapi",
        "description": "Welcome to the home page for acute-dbapi, a DB-API compliance test suite.  Acute is still in it's infancy, but it's reached the level of maturity that it would benefit from community input.  It currently contains 71 tests, and many more will be added soon.\n\nComments, suggestions, and patches are all warmly welcome.  There are several TODOs listed in the [TODO] file, and many more generously sprinkled throughout the code; if you'd like to help out but don't know where to begin, feel free to take a crack at one of them!\n\nPlease read the project's [README] for an introduction to the suite.  You'll also find usage, architecture, and project philosophy information there.\n\nIf you just want to see the results, take a look at TestResults, and DriverFeatures on the project wiki.",
        "url": "http://pypi.python.org/pypi/acute-dbapi",
        "summary": "Python DB-API testsuite",
        "command": "pip install 'acute-dbapi'"
      },
      "ad": {
        "name": "ad",
        "description": "``ad`` Package Documentation\n============================\n\n.. image:: https://travis-ci.org/tisimst/ad.png?branch=master\n\nOverview\n--------\n\nThe ``ad`` package allows you to **easily** and **transparently** perform \n**first and second-order automatic differentiation**. Advanced math \ninvolving trigonometric, logarithmic, hyperbolic, etc. functions can also \nbe evaluated directly using the ``admath`` sub-module. \n\n**All base numeric types are supported** (``int``, ``float``, ``complex``, \netc.). This package is designed so that the underlying numeric types will \ninteract with each other *as they normally do* when performing any \ncalculations. Thus, this package acts more like a \"wrapper\" that simply helps \nkeep track of derivatives while **maintaining the original functionality** of \nthe numeric calculations.\n\nFrom the Wikipedia entry on `Automatic differentiation`_ (AD):\n\n    \"AD exploits the fact that every computer program, no matter how \n    complicated, executes a sequence of elementary arithmetic operations \n    (addition, subtraction, multiplication, division, etc.) and elementary \n    functions (exp, log, sin, cos, etc.). By applying the chain rule \n    repeatedly to these operations, derivatives of arbitrary order can be \n    computed automatically, and accurate to working precision.\"\n\nSee the `package documentation`_ for details and examples.\n\nMain Features\n-------------\n\n- **Transparent calculations with derivatives: no or little \n  modification of existing code** is needed, including when using\n  the `Numpy`_ module.\n\n- **Almost all mathematical operations** are supported, including\n  functions from the standard math_ module (sin, cos, exp, erf, \n  etc.) and cmath_ module (phase, polar, etc.) with additional convenience \n  trigonometric, hyperbolic, and logarithmic functions (csc, acoth, ln, etc.).\n  Comparison operators follow the **same rules as the underlying numeric \n  types**.\n\n- **Real and complex** arithmetic handled seamlessly. Treat objects as you\n  normally would using the `math`_ and `cmath`_ functions, but with their new \n  ``admath`` counterparts.\n  \n- **Automatic gradient and hessian function generator** for optimization \n  studies using `scipy.optimize`_ routines with ``gh(your_func_here)``.\n\n- **Compatible Linear Algebra Routines** in the ``ad.linalg`` submodule, \n  similar to those found in NumPy's ``linalg`` submodule, that are not \n  dependent on LAPACK. There are currently:\n  \n  a. Decompositions\n     \n     1. ``chol``: Cholesky Decomposition\n     2. ``lu``: LU Decomposition\n     3. ``qr``: QR Decomposition\n  \n  b. Solving equations and inverting matrices\n     \n     1. ``solve``: General solver for linear systems of equations\n     2. ``lstsq``: Least-squares solver for linear systems of equations\n     3. ``inv``: Solve for the (multiplicative) inverse of a matrix\n\nInstallation\n------------\n\nYou have several easy, convenient options to install the ``ad`` package \n(administrative privileges may be required):\n\n1. Download the package files below, unzip to any directory, and run \n   ``python setup.py install`` from the command-line.\n   \n2. Simply copy the unzipped ``ad-XYZ`` directory to any other location \n   that python can find it and rename it ``ad``.\n   \n3. If ``setuptools`` is installed, run ``easy_install --upgrade ad`` \n   from the command-line.\n   \n4. If ``pip`` is installed, run ``pip install --upgrade ad`` from the \n   command-line.\n\n5. Download the *bleeding-edge* version on GitHub_\n\nContact\n-------\n\nPlease send **feature requests, bug reports, or feedback** to \n`Abraham Lee`_.\n\nAcknowledgements\n----------------\n\nThe author expresses his thanks to :\n\n- `Eric O. LEBIGOT (EOL)`_, author of the `uncertainties`_ package, for providing \n  code insight and inspiration\n- Stephen Marks, professor at Pomona College, for useful feedback concerning \n  the interface with optimization routines in ``scipy.optimize``.\n- Wendell Smith, for updating testing functionality and numerous other useful\n  function updates\n- Jonathan Terhorst, for catching a bug that made derivatives of logarithmic\n  functions (base != e) give the wrong answers.\n- GitHub user ``fhgd`` for catching a mis-calculation in ``admath.atan2``\n\n\n.. _NumPy: http://numpy.scipy.org/\n.. _math: http://docs.python.org/library/math.html\n.. _cmath: http://docs.python.org/library/cmath.html\n.. _Automatic differentiation: http://en.wikipedia.org/wiki/Automatic_differentiation\n.. _Eric O. LEBIGOT (EOL): http://www.linkedin.com/pub/eric-lebigot/22/293/277\n.. _uncertainties: http://pypi.python.org/pypi/uncertainties\n.. _scipy.optimize: http://docs.scipy.org/doc/scipy/reference/optimize.html\n.. _Abraham Lee: mailto:tisimst@gmail.com\n.. _package documentation: http://pythonhosted.org/ad\n.. _GitHub: https://github.com/tisimst/ad",
        "url": "http://pypi.python.org/pypi/ad",
        "summary": "Fast, transparent first- and second-order automatic differentiation",
        "command": "pip install 'ad'"
      },
      "ad3": {
        "name": "ad3",
        "description": "AD3 (approximate MAP decoder with Alternating Direction Dual Decomposition)\nCopyright (C) 2012\nAndre Martins\nPriberam Labs, Lisbon, Portugal &\nInstituto de Telecomunicacoes, Instituto Superior Tecnico, Lisbon, Portugal\nAll Rights Reserved.\n\nhttp://www.ark.cs.cmu.edu/AD3\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU Lesser General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU Lesser General Public License for more details.\n\nYou should have received a copy of the GNU Lesser General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n\nThis is a README for AD3 v2.0\n=================================\n\nAD3 (Alternating Directions Dual Decomposition) is an LP-MAP decoder for\nundirected constrained factor graphs. In other words, it is an approximate MAP\ndecoder that retrieves the solution of an LP relaxation of the original problem.\nIt applies the ADMM method which is described in refs. [1,3,4,5,6] below.\n\nThe input is a factor graph, which may contain both soft factors, associated\nwith log-potentials, and hard constraint factors, associated with a logic\nfunction. Factors can be dense, sparse, or combinatorial. Specialized factors\ncan be implemented by the practicioner (see below for instructions and\nexamples).\n\nThe output is the LP-MAP assignment, with a posterior value for each variable.\nIf all variables are integer, the relaxation is tight and the solution is the\ntrue MAP. Otherwise, some entries can be in the unit interval. External tools\ncan be used to obtain a valid solution using rounding heuristics. Optionally,\na flag can be set that applies a branch-and-bound procedure and retrieves the\ntrue MAP (but it can be slow if the relaxation has many fractional components).\n\n\nNew features since AD3 v1.0:\n============================\n\n* AD3 v2.0 can handle dense, sparse, and combinatorial factors, with binary or \nmulti-valued variables. This comes in addition to the PAIR and logic factors \n(XOR, OR, OR-with-output, and ATMOSTONE) already handled by AD3 v1.0. The \nsubproblems for these factors are addressed with the active set method described \nin ref. [6] below.\n\n* AD3 v2.0 allows the practicioner to implement her own specialized factor, \nwhich will be automatically handled by the AD3 algorithm. The practicioner only \nneeds to implement a method for computing the local MAP for that factor. We \ninclude example files to illustrate how this can be done for sequential factors, \ntree factors and head automaton factors (used in dependency parsing). \n\n* AD3 v2.0 can now process input UAI files (see \nhttp://www.cs.huji.ac.il/project/PASCAL/fileFormat.php), in addition to the FG \nfiles already processed by AD3 v1.0. A standalone tool is included to decode the \nfactor graphs encoded in these files.\n\n* AD3 v2.0 can also be compiled as a library (libad3), whose methods can be \ncalled from an external program. See below for usage examples.\n\n\n1. Requirements\n===============\nRunning AD3 v2.0 requires a standard C++ compiler. The code is self-contained. \nThe only dependency is Eigen (http://eigen.tuxfamily.org/), which is included in \nthe release (current version is Eigen 3.1.1). It has been tested on Linux, but \nit should run in other platforms with minor adaptations.\n\n\n2. Contents\n===========\nThis tarball contains a folder called ad3_v2, which we will refer to as the \n\"root\" folder. Underneath it, there are the following files and folders:\n\nad3_multi.cpp\n    Source file for the standalone application.\n    \nad3/\n    Folder containing the source and header files for AD3.\n\ndata/\n    Folder containing some example input files.\n    \nexamples/\n    Folder containing some example implementations that use libad3.\n\nEigen/\n    Folder containing the Eigen header files (downloaded from \n    http://eigen.tuxfamily.org/)\n\nMakefile\n    Makefile for generating all the executables and library files.\n\nLICENSE\n    Text of the GNU Lesser General Public License, Version 3.\n\nREADME\n    This file.\n\n\n\n3. Installation\n===============\n\nAD3 v2.0 can be downloaded from http://www.ark.cs.cmu.edu/AD3. \nTo compile the code, cd the root folder and type:\n\n> make\n\nThis will create an executable file ad3_multi in the root folder, a static \nlibrary libad3 in the ad3 folder, and several executables in the example \nfolders. To test, type:\n\n> ./ad3_multi\n\nwhich should produce the following output:\n\n    Usage: ad3_multi --format=[ad3(*)|uai] --file_graphs=[IN] \\\n    --file_posteriors=[OUT] --algorithm=[ad3(*)|psdd|mplp] \\\n    (--max_iterations=[NUM] --eta=[NUM] --adapt_eta=[true(*)|false] \\\n    --residual_threshold=[NUM] --convert_to_binary=[true|false(*)] \\\n    --exact=[true|false(*)])\n\nThen, type:\n\n    > ./ad3_multi --format=uai --file_graphs=data/30markers.uai \\\n    --file_posteriors=posteriors.out | tail -4\n\nIt should print something like:\n\n    Solution value after 37 iterations (AD3) = -1005.47\n    Took 0.296 sec.\n    Solution is integer.\n    Elapsed time: 0.296 sec.\n\nand a file named \"posteriors.out\" should be created in the root folder.\n\n\n\n4. Input flags\n==============\n\nThe following flags can be set:\n\n    Usage: ad3_multi --format=[ad3(*)|uai] --file_graphs=[IN] \\\n    --file_posteriors=[OUT] --algorithm=[ad3(*)|psdd|mplp] \\\n    (--max_iterations=[NUM] --eta=[NUM] --adapt_eta=[true(*)|false] \\\n    --residual_threshold=[NUM] --convert_to_binary=[true|false(*)] \\\n    --exact=[true|false(*)])\n\n--file_graphs=[IN]\n    Specifies the path to the input file, containing the structure of the factor graphs \n    and their log-potentials. \n\n--format=[ad3(*)|uai]\n    Specifies the format of the input file. Default is \"ad3\" which is described \n    below. An alternative for factor graphs with dense factors, is the \"uai\" \n    format, which is described at \n    http://www.cs.huji.ac.il/project/PASCAL/fileFormat.php.\n   \n--file_posteriors=[OUT] \n    Specifies the path to the output file, containing the LP-MAP or MAP solution. \n    See below for an description of the format of this file.\n\n--algorithm=[ad3(*)|psdd|mplp]\n    Decoding algorithm. Default is AD3, other choices are the projected \n    subgradient algorithm and generalized MPLP. \n         \n--max_iterations=[NUM]\n    Maximum number of iterations, for any of the algorithms above. \n    Default is 1000.\n\n--eta=[NUM] \n    Value of the penalty constant in AD3, or the initial stepsize in the \n    projected subgradient algorithm. In AD3, if adapt_eta is true, this is the \n    initial penalty, otherwise every iteration will apply this amount of penalty. \n    Default is 0.1.\n   \n--adapt_eta=[true(*)|false]\n    If true, adapt eta using the strategy described in ref. [2] below. \n    Default is true.\n\n--residual_threshold=[NUM]\n    Threshold for the primal and dual residuals in AD3. The algorithm will be \n    stopped if both residuals are below this threshold. \n    Default is 1e-6.\n\n--exact=[true|false(*)]\n    If true, apply a branch-and-bound procedure for obtaining the exact MAP \n    (note: this can be quite slow if the relaxation is \"too fractional\"). \n    Default is false.\n   \n--convert_to_binary=[true|false(*)]\n    If true, convert a factor graph with multi-valued variables to one which \n    only containts binary variables and hard constraints. This is an alternative\n    to the active set method, but it is usually much slower.\n    Default is false.\n\n\n\n5. AD3 format for the input files\n=================================\n\nNOTE: for factor graphs with dense factors and multi-valued variables, we \nrecommend using the (more standard) UAI file format instead. However, the AD3\nfile format is recommended for factor graphs with hard constraint logic factors.\nThey also allow specifying multiple factor graphs in a single file.\n\nIMPORTANT NOTE: AD3 files contain log-potentials, while UAI file contain \npotentials.\n\nAD3 files are in ASCII format and contain the following information: \n\n    [BLOCK DESCRIBING FACTOR GRAPH 1]\n\n    [BLOCK DESCRIBING FACTOR GRAPH 2]\n\n    ...\n\n    [BLOCK DESCRIBING FACTOR GRAPH K]\n\nThat is, each block is a description of a single factor graph, and blocks are \nseparated by empty lines.\n\nEach block should be of the following format:\n\n    [NUMBER OF VARIABLES]\n    [NUMBER OF FACTORS]\n    Log-potential of variable 1\n    Log-potential of variable 2\n    ...\n    Log-potential of variable N\n    [LINE DESCRIBING FACTOR 1]\n    [LINE DESCRIBING FACTOR 2]\n    ...\n    [LINE DESCRIBING FACTOR M]\n\nThe line describing each factor should have the following fields, separated by \nwhitespaces: \n    [FACTOR TYPE] [FACTOR DEGREE] [INDEX OF VAR 1] ... [INDEX OF VAR L] ([FACTOR LOG-POTENTIAL])\n\nThe meaning of these fields is the following:\n    [FACTOR TYPE] can be one of XOR, OR, OROUT, ATMOSTONE, or PAIR.\n    [FACTOR DEGREE] is the number of variables linked to the factor (always 2 \n        for PAIR factors).\n    [INDEX OF VAR i] contains one-based indices of the variables. For the logic \n        factors (i.e., all the above except PAIR) a dash used as a prefix means \n        that the variable is negated. \n    [FACTOR POTENTIAL] is optional and should be included iff FACTOR TYPE is \n        \"PAIR\", in which case it contains a score for the configuration where \n        both input variables are TRUE (the other three configurations receive a \n        score of zero).\n        \nSome examples:\n\n    \"XOR 3 15 1417 -1419\"\n        A XOR factor linked to three variables (15, 1417 and 1419) where the \n        last variable is negated. This is actually equivalent to \n        XOR-with-output. The feasible configurations are (TRUE, FALSE, TRUE), \n        (FALSE, TRUE, TRUE) and (FALSE, FALSE, FALSE).\n        \n    \"ATMOSTONE 3 15 1417 1419\"\n        A ATMOSTONE factor linked to three variables (15, 1417 and 1419). The \n        feasible configurations are (TRUE, FALSE, FALSE), (FALSE, TRUE, FALSE), \n        (FALSE, FALSE, TRUE) and (FALSE, FALSE, FALSE).\n\n    \"OR 2 1 2\"\n        A OR factor linked to two variables (1 and 2). All configurations are \n        feasible except (FALSE, FALSE).\n        \n    \"OROUT 3 10 20 30\"\n        A OR-with-output factor with two inputs (10 and 20) and one output (30). \n        If either 10 or 20 are TRUE, 30 must be TRUE; otherwise 30 must be FALSE.\n\n    \"OROUT 3 -10 -20 -30\"\n        A OR-with-output factor with two negated inputs (10 and 20) and one \n        negated output (30). This is actually equivalent to a AND-with-output. \n        If both 10 or 20 are TRUE, 30 must be TRUE; otherwise 30 must be FALSE.\n        \n    \"PAIR 2 25 26 0.048103\"\n        A PAIR factor connecting variables 25 and 26. The potential function \n        evaluates to 0.048103 if both variables are TRUE, and to 0 otherwise.\n\nSome examples of input files:\n\n1) Example of input file (example1.fg) for a constrained factor graph consisting \nof three variables connected by a OR factor:\n\n     3\n     1\n     0.75\n     1.25\n     -0.5\n     OR 3 1 2 3\n\nIn this case the probability distribution is \n\n     P(y1,y2,y3) = 0,                                    if y1 = y2 = y3 = 0\n                   1/Z exp(0.75*y1 + 1.25*y2 - 0.5*y3),  otherwise.\n\n     \n2) Example of input file (example2.fg) that in addition have the two first \nvariables connected by a PAIR factor:\n\n     3\n     2\n     0.75\n     1.25\n     -0.5\n     OR 3 1 2 3\n     PAIR 2 1 2 -1.05\n\nIn this case the probability distribution is \n\n     P(y1,y2,y3) = \n         0,                                                 if y1 = y2 = y3 = 0\n         1/Z exp(0.75*y1 + 1.25*y2 - 0.5*y3 - 1.05*y1*y2),  otherwise.\n\n3) Example of input file (coref.fg) for a toy coreference task with transitivity \nconstraints and some constraints requiring that each entity cluster has at least \na noun (all expressable as OR factors). Here the LP-MAP is fractional, but the \nbranch and bound procedure (flag --exact=true) is able to retrieve the true MAP.\n\n4) Example of input file (parsing_excerpt.fg) for dependency parsing in Slovene, \ntaken from ref. [4] below. This is for a single sentence, and the LP-MAP is \ninteger.\n\n5) Input file used in ref. [5] below, for FrameNet semantic parsing. Contains \nseveral factor graphs, one per predicate in the dev-set, with various \nconstraints regarding the kind of roles and their spans associated with the \npredicate frame. (Thanks to Dipanjan Das for generating this file.)\n\n\n\n6. Output file\n==============\n\nThe output file contains one floating point number per line, and as many lines \nas the number of binary variables (or states of multi-valued variables) plus the \nnumber of factor log-potential values (e.g., a PAIR factor has one log-potential\nvalue, a DENSE factor with 5 variables and 3 states each has 3^5 log-potential\nvalues). The values in each line contain the LP-MAP value for each variable, \nby order of index, followed by the LP-MAP values for each factor configuration, \nby order of appearance.\n\nNOTE: Internally, multi-valued variables are treated as arrays of binary \nvariables, one per state. \n\n\n\n7. Using the static library\n============================\n\nTo use AD3 in your C++ project, either copy the source/header files in the\nad3 folder, or link statically with libad3. You can look at the makefiles\nin the example folders. \n\nAs a simple example, the following code will create a fully connected Potts \nmodel with 3 variables with 5 states each, and will run AD3 on it. Other \nsimple examples are in the example folders, including one for non-projective \ndependency parsing with head automata, one for co-reference resolution, and \nanother for decoding Potts grids.\n\n#include \"ad3/FactorGraph.h\"\n\nint main(int argc, char **argv) {\n  // Create the factor graph.\n  AD3::FactorGraph factor_graph;\n\n  // Create 3 multi-valued variables with 5 states each.\n  std::vector<AD3::MultiVariable*> multi_variables(3);\n  for (int i = 0; i < 3; ++i) {\n    multi_variables[i] = factor_graph.CreateMultiVariable(5);\n\n    // Set uniform log-potentials.\n    for (int k = 0; k < 5; ++k) {\n      score = 0.0;\n      multi_variables[i]->SetLogPotential(k, score);\n    }\n  }\n\n  // Set the factor log-potentials.\n  vector<double> additional_log_potentials;\n  double alpha = 0.5; // The \"smoothness\" degree.\n  for (int k = 0; k < 5; ++k) {\n    for (int l = 0; l < 5; ++l) {\n      additional_log_potentials.push_back((k == l)? alpha : 0.0);\n    }\n  }\n  \n  // Create 3 factors connecting all the variables pairs.\n  vector<AD3::MultiVariable*> multi_variables_local(2);\n  multi_variables_local[0] = multi_variables[0];\n  multi_variables_local[1] = multi_variables[1];\n  factor_graph.CreateFactorDense(multi_variables_local,\n                                 additional_log_potentials);\n  multi_variables_local[0] = multi_variables[0];\n  multi_variables_local[1] = multi_variables[2];\n  factor_graph.CreateFactorDense(multi_variables_local,\n                                 additional_log_potentials);\n  multi_variables_local[0] = multi_variables[1];\n  multi_variables_local[1] = multi_variables[2];\n  factor_graph.CreateFactorDense(multi_variables_local,\n                                 additional_log_potentials);\n\n\n  vector<double> posteriors;\n  vector<double> additional_posteriors;\n  double value;\n\n  // Run AD3.\n  factor_graph.SetEtaAD3(0.1);\n  factor_graph.AdaptEtaAD3(true);\n  factor_graph.SetMaxIterationsAD3(1000);\n  factor_graph.SolveLPMAPWithAD3(&posteriors, &additional_posteriors, &value);\n  \n  return 0;\n}\n\n \n\n8. Contributing to AD3\n=======================\n\nTo contribute to AD3, you can fork the following github repository:\n\nhttp://github.com/andre-martins/AD3.\n\n\n9. Further Reading\n==================\n\nIf this code is used, please cite the paper [3] below. \n\n[1] André F. T. Martins, Noah A. Smith, Eric P. Xing, Pedro M. Q. Aguiar, and Mário A. T. Figueiredo.\n\"Augmented Dual Decomposition for MAP Inference.\"\nNIPS Workshop in Optimization for Machine Learning, Whistler, Canada, December 2010.\n\n[2] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein.\n\"Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers.\"\nFoundations and Trends in Machine Learning, Michael Jordan, Editor in Chief, 3(1):1–122, 2011. \n\n[3] André F. T. Martins, Mário A. T. Figueiredo, Pedro M. Q. Aguiar, Noah A. Smith, and Eric P. Xing.\n\"An Augmented Lagrangian Approach to Constrained MAP Inference.\"\nInternational Conference on Machine Learning (ICML'11), Bellevue, Washington, USA, June 2011.\n\n[4] André F. T. Martins, Noah A. Smith, Mário A. T. Figueiredo, Pedro M. Q. Aguiar.\n\"Dual Decomposition With Many Overlapping Components.\"\nEmpirical Methods in Natural Language Processing (EMNLP'11), Edinburgh, UK, July 2011.\n\n[5] Dipanjan Das, André F. T. Martins, and Noah A. Smith.\n\"An Exact Dual Decomposition Algorithm for Shallow Semantic Parsing with Constraints\"\nProceedings of *SEM 2012.\n      \n[6] André F. T. Martins. \n\"The Geometry of Constrained Structured Prediction: Applications to Natural Language Syntax.\"\nPhD thesis, Carnegie Mellon University and Instituto Superior Tecnico, 2012. \n\n\n8. Contact\n==========\nIf you find any bugs or have questions, please email André Martins (afm@cs.cmu.edu).\n\n\n9. Version History\n==================\n1.0 - First public release (2012-06-01)\n2.0 - Second public release (2012-09-08)\n\n",
        "url": "http://pypi.python.org/pypi/ad3",
        "summary": "UNKNOWN",
        "command": "pip install 'ad3'"
      },
      "Ada": {
        "name": "ada",
        "description": "Python common tools set and CLI helpers.",
        "url": "http://pypi.python.org/pypi/Ada",
        "summary": "Better living with Python scripts & libraries.",
        "command": "pip install 'Ada'"
      },
      "Adafruit_BBIO": {
        "name": "adafruit_bbio",
        "description": "**PLEASE NOTE:  This library may have breaking changes as development continues.  Please read the changelog anytime you update the library!**\n\n**The PWM Duty Cycle range was reversed in 0.0.15 from 100(off)-0(on) to 0(off)-100(on).  Please update your code accordingly.**\n\n**Adafruit's BeagleBone IO Python Library**\n\nThis is a set of Python tools to allow GPIO, PWM, and ADC access on the BeagleBone using the Linux 3.8 Kernel and above (latest releases).\n\nIt has been tested on the 5-20 and 6-6 Angstrom image on the BeagleBone Black.\n\n**Note: BBIO has been renamed to Adafruit_BBIO.**\n\n**Installation on Angstrom**\n\nEasiest::\n\n    /usr/bin/ntpdate -b -s -u pool.ntp.org\n    opkg update && opkg install python-pip python-setuptools\n    pip install Adafruit_BBIO\n    \nManual::\n\n    git clone git://github.com/adafruit/adafruit-beaglebone-io-python.git \n    #set the date and time \n    /usr/bin/ntpdate -b -s -u pool.ntp.org \n    #install dependency \n    opkg update && opkg install python-distutils \n    cd adafruit-beaglebone-io-python \n    python setup.py install\n\n**Installation on Ubuntu/Debian**\n\nEasiest::\n\n    sudo ntpdate pool.ntp.org\n    sudo apt-get update\n    sudo apt-get install build-essential python-dev python-pip -y\n    #easy_install -U distribute  //debian only\n    sudo pip install Adafruit_BBIO\n    \nManual::\n\n    sudo ntpdate pool.ntp.org\n    sudo apt-get update\n    sudo apt-get install build-essential python-dev python-pip -y\n    git clone git://github.com/adafruit/adafruit-beaglebone-io-python.git\n    cd adafruit-beaglebone-io-python\n    sudo python setup.py install\n    cd ..\n    sudo rm -rf adafruit-beaglebone-io-python\n    \n**Usage**\n\nUsing the library is very similar to the excellent RPi.GPIO library used on the Raspberry Pi. Below are some examples.\n\n**GPIO Setup** \n\nImport the library, and setup as GPIO.OUT or GPIO.IN::\n\n    import Adafruit_BBIO.GPIO as GPIO\n    GPIO.setup(\"P8_14\", GPIO.OUT)\n\nYou can also refer to the pin names::\n\n    GPIO.setup(\"GPIO0_26\", GPIO.OUT)\n\n**GPIO Output** \n\nSetup the pin for output, and write GPIO.HIGH or GPIO.LOW. Or you can use 1 or 0.::\n\n    import Adafruit_BBIO.GPIO as GPIO\n    GPIO.setup(\"P8_14\", GPIO.OUT) GPIO.output(\"P8_14\", GPIO.HIGH)\n    \n**GPIO Input**\n\nInputs work similarly to outputs.::\n\n    import Adafruit_BBIO.GPIO as GPIO\n    GPIO.setup(\"P8_14\", GPIO.IN)\n    \nPolling inputs::\n    \n    if GPIO.input(\"P8_14\"):\n      print(\"HIGH\")\n    else:\n      print(\"LOW\")\n\nWaiting for an edge (GPIO.RISING, GPIO.FALLING, or GPIO.BOTH::\n\n    GPIO.wait_for_edge(channel, GPIO.RISING)\n\nDetecting events::\n\n    GPIO.add_event_detect(\"P9_12\", GPIO.FALLING) \n    #your amazing code here \n    #detect wherever: \n    if GPIO.event_detected(\"P9_12\"):\n      print \"event detected!\"\n\n**PWM**::\n\n    import Adafruit_BBIO.PWM as PWM \n    #PWM.start(channel, duty, freq=2000, polarity=0) \n    #duty values are valid 0 (off) to 100 (on) \n    PWM.start(\"P9_14\", 50)\n    PWM.set_duty_cycle(\"P9_14\", 25.5) \n    PWM.set_frequency(\"P9_14\", 10)\n\n    PWM.stop(\"P9_14\")\n    PWM.cleanup()\n    \n    #set polarity to 1 on start:\n    PWM.start(\"P9_14\", 50, 2000, 1)\n\n**ADC**::\n\n    import Adafruit_BBIO.ADC as ADC\n    ADC.setup()\n\n    #read returns values 0-1.0 \n    value = ADC.read(\"P9_40\")\n\n    #read_raw returns non-normalized value \n    value = ADC.read_raw(\"P9_40\")\n\n**Running tests**\n\nInstall py.test to run the tests. You'll also need the python compiler package for py.test.::\n\n    opkg update && opkg install python-compiler \n    #Either pip or easy_install \n    pip install -U pytest \n    easy_install -U pytest\n\nExecute the following in the root of the project::\n\n    py.test\n    \n**Credits**\n\nThe BeagleBone IO Python library was originally forked from the excellent MIT Licensed [RPi.GPIO](https://code.google.com/p/raspberry-gpio-python) library written by Ben Croston.\n\n**License**\n\nWritten by Justin Cooper, Adafruit Industries. BeagleBone IO Python library is released under the MIT License.\n0.0.30\n---\n* Merge Python 3 compatibility fixes from Github user westphahl.\n* Moved old Angstrom build fix for missing py_compile from setup.py to separate file.\n\n0.0.20\n----\n* Fix for SPI not loading spidevX.X correctly based on load order\n* Initialize ctrl_dir in unload_device_tree #63\n* Clean up unused/dead code\n\n0.0.19\n----\n* Fix for SPI.xfer crashes python after 3 calls\n* Added a retry to reading for the analog inputs to avoid a bug where reading back and forth between two analog inputs would cause the resource to be unavailable every 16 scans (zthorson)\n* Updated the build_path to be more selective over what paths it chooses (zthorson)\n* Update Debian installation instructions in README (justinledwards)\n* Increase the size of the buffer used for storing device tree names (SaintGimp)\n\n0.0.18\n----\n* UART - Include UART overlays, and compile upon installation\n* UART - Rename UART overlays\n* Adafruit_I2C - Remove readU16Rev and readS16Rev\n* Adafruit_I2C - Updated readU16/readS16 for correct 16-bit reads\n\n0.0.17\n----\n* Fix SPI memory leaks\n* Clean up of PWM code (bit-hacker, jwcooper)\n* Remove UART debug statements\n\n0.0.16\n----\n* Add polarity as optional fourth parameter to PWM.start().  Valid values are 0 and 1.  Default is still 0.\n* Fix for actually setting the polarity in start.\n* Add new unit tests to check that the polarity is being set properly, and valid values passed in.\n\n0.0.15\n----\n* Fix PWM duty cycle so 0 is off and 100 is on.  Set polarity to 0 by default.\n* Give extra buffer space in export, and unexport functions for gpio that are more than 2 digits (Chris Desjardins)\n* Add new test case for 3 digit gpio (Chris Desjardins)\n* Fix for test_direction_readback. gpio_get_direction wasn't properly null terminating the direction string (Chris Desjardins)\n\n0.0.14\n----\n* Fix GPIO.gpio_function to work with the IO name (zthorson)\n* Fix IOErrors not getting raised when fopen fails while loading overlays into device tree (bradfordboyle, jwcooper)\n* Add new UART tests\n\n0.0.13\n----\n* Remove the gpio parameter from callbacks (cdesjardins)\n\n0.0.12\n----\n* Bump version due to pypi issues\n\n0.0.11\n----\n* New UART module to export UART overlays\n* Alpha support for SPI\n* Add small delay after loading any device tree overlays\n\n0.0.10\n____\n* Fix direction for event detection code\n* Fix for segmentation faults on add_event_detect\n\n0.0.9\n____\n* Fix for ADC Segmentation Faults\n\n0.0.8\n____\n* Temp remove overlay compilation.  Ubuntu failures.\n\n0.0.7\n____\n* Refactor and clean up adc and pwm\n* Fix tests for Adafruit_BBIO rename\n\n0.0.6\n____\n* Include Adafruit_I2C.py as top-level module\n\n0.0.5\n----\n* Rename from BBIO to Adafruit_BBIO to reduce library conflicts and confusion.\n\n0.0.4\n----\n* Support for pip and easy_install\n\n0.0.3\n____\n* ADC enabled\n\n0.0.2\n____\n* PWM enabled\n\n0.0.1\n____\n* Initial Commit\n* GPIO mostly working\n* Initial GPIO unit tests\n* PWM in progress",
        "url": "http://pypi.python.org/pypi/Adafruit_BBIO",
        "summary": "A module to control BeagleBone IO channels",
        "command": "pip install 'Adafruit_BBIO'"
      },
      "adafruit_lcd_plate_menu": {
        "name": "adafruit_lcd_plate_menu",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/adafruit_lcd_plate_menu",
        "summary": "A simple yet powerful menu library for Adafruit's LCD plates",
        "command": "pip install 'adafruit_lcd_plate_menu'"
      },
      "Adafruit_Libraries": {
        "name": "adafruit_libraries",
        "description": "Adafruit's Raspberry-Pi Python Code Library\n============\n  Here is a growing collection of libraries and example python scripts\n  for controlling a variety of Adafruit electronics with a Raspberry Pi\n  \n  In progress!\n\n  Adafruit invests time and resources providing this open source code,\n  please support Adafruit and open-source hardware by purchasing\n  products from Adafruit!\n\n  Written by Limor Fried, Kevin Townsend and Mikey Sklar for Adafruit Industries.\n  BSD license, all text above and below must be included in any redistribution\n  \n  To download, we suggest logging into your Pi with Internet accessibility and typing:\n  git clone https://github.com/adafruit/Adafruit-Raspberry-Pi-Python-Code.git\n  cd Adafruit-Raspberry-Pi-Python-Code\n  python setup.py install\n  \n============\nCopyright (c) 2012-2013 Limor Fried, Kevin Townsend and Mikey Sklar for Adafruit Industries.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of the <organization> nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/Adafruit_Libraries",
        "summary": "Libraries for using Adafruit Hardware on a Raspberry Pi or BeagleBone Black",
        "command": "pip install 'Adafruit_Libraries'"
      },
      "adage": {
        "name": "adage",
        "description": "Adage - A DAG Executor\n\nThis is a small experimental package to see how one could describe workflows that are not completely known at definition time.\n\nTasks are run asynchronously either via a multiprocessing pool or celery\n\nRead more at:\nhttps://github.com/lukasheinrich/adage\n",
        "url": "http://pypi.python.org/pypi/adage",
        "summary": "running dynamic DAG workflows",
        "command": "pip install 'adage'"
      },
      "adagios": {
        "name": "adagios",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/adagios",
        "summary": "Web Based Nagios Configuration",
        "command": "pip install 'adagios'"
      },
      "adal": {
        "name": "adal",
        "description": "Microsoft Azure Active Directory Authentication Library (ADAL) for Python\n=========================================================================\n\n.. image:: https://pypip.in/d/adal/badge.svg\n        :target: https://pypi.python.org/pypi/adal/\n\nThe ADAL for python library makes it easy for python applications to authenticate to AAD in order to access AAD protected web resources.  It supports 3 authentication modes shown in the quickstart code below.\n\nSamples and Documentation\n-------------------------\n[We provide a full suite of sample applications and documentation on GitHub](https://github.com/AzureADSamples) to help you get started with learning the Azure Identity system. This includes tutorials for native clients such as Windows, Windows Phone, iOS, OSX, Android, and Linux. We also provide full walkthroughs for authentication flows such as OAuth2, OpenID Connect, Graph API, and other awesome features. \n\nCommunity Help and Support\n--------------------------\n\nWe leverage [Stack Overflow](http://stackoverflow.com/) to work with the community on supporting Azure Active Directory and its SDKs, including this one! We highly recommend you ask your questions on Stack Overflow (we're all on there!) Also browser existing issues to see if someone has had your question before. \n\nWe recommend you use the \"adal\" tag so we can see it! Here is the latest Q&A on Stack Overflow for ADAL: [http://stackoverflow.com/questions/tagged/adal](http://stackoverflow.com/questions/tagged/adal)\n\nContributing\n------------\n\nAll code is licensed under the Apache 2.0 license and we triage actively on GitHub. We enthusiastically welcome contributions and feedback. You can clone the repo and start contributing now. \n\nQuick Start\n-----------\n\nInstallation\n############\n\n``` $ pip install adal ```",
        "url": "http://pypi.python.org/pypi/adal",
        "summary": "Azure Active Directory Library for Python",
        "command": "pip install 'adal'"
      },
      "Adamanteus": {
        "name": "adamanteus",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Adamanteus",
        "summary": "Database Backups with Version Control",
        "command": "pip install 'Adamanteus'"
      },
      "adamo_calibrator": {
        "name": "adamo_calibrator",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/adamo_calibrator",
        "summary": "A touchscreen calibrator.",
        "command": "pip install 'adamo_calibrator'"
      },
      "ADAM-Tools": {
        "name": "adam-tools",
        "description": "ADAM-Tools\n===========\n\nSome words about the **ADAM Tools** here.\n\nMore info can be found at the ADAM website here: http://www.noveltis.fr/adam-demo/\n\n\nInstalling\n----------\n\nThe ADAM-Tools are implemented in pure python, meaning there is no need to 'install' them as such, they can be simply imported into your Python scripts and used. This may be the best option if you plan on modifying the ADAM-Tools source code yourself for example, as you can store the code wherever you like.\n\nIf you do not intend to make modifications to the tools the best option is to let Python install them in a central location so all your scripts will be able to import them without specifying where they are.\n\nTo install using the Python module manager \"easy_install\", issue from the command line (linux users may need to preceed command with \"sudo\")::\n\n    $ easy_install -U ADAM-Tools\n\nThe -U switch means that easy_install will try to install the latest available version, overwriting any existing versions on your computer.\n\nNote this assumes that easy_install is in your path. If you are using windows and the result of the above is \"Bad command or file name\" you need to include the specific path to easy_install, something like this::\n\n    # windows with no python in path:\n    c:\\python26\\scripts\\easy_install ADAM-Tools\n    \n\nIf for some reason easy_install does not work, ADAM-Tools can be installed manually. To do this, download and unzip the source package below. Start a command prompt in the install directory, and issue::\n\n    $ python setup.py install\n    \n\n\n\n    \nUsage\n----------\n\nConfiguration\n^^^^^^^^^^^^^\nSince version 0.13dev, the configuration parameters of the ADAM Tools can be supplied as parameters when instantiating a new job. This allows the entire ADAM codebase to be replaced during an upgrade without losing site-specific config information.\n\nFor example, we start all ADAM scripts like this::\n\n    import adam\n    import adam_config\n\n    my_path_data       = 'c://ADAM-data/'\n    my_output_root_dir = 'c://ADAM-output/'\n    # get an instance of an adam 'config' object, this will be attached to any jobs we run\n    my_config = adam_config.adam_config(path_data = my_path_data, output_root_dir = my_output_root_dir)\n\nADAM Jobs\n^^^^^^^^^\nOnce created, the config is then used as a parameter for all the jobs that follow.\n\nFor example, a spectrum graph can be generated like this (note the cfg = my_config)::\n\n    request_dict = {'fieldOperationType': 'spectrum',\n                    'fieldMonth'        : 'jan',\n                    'fieldSunZenith'    : 40,\n                    'fieldViewZenith'   : 30,\n                    'fieldRelAzimuth'   : 0,\n                    'fieldCorner1Lat'   : 36.2,\n                    'fieldCorner1Lon'   : -5.5,\n                    'fieldCorner2Lat'   : 36,\n                    'fieldCorner2Lon'   : -5.2\n    }\n    job = adam.adam_job( cfg = my_config )\n    if not job.validate_input(request_dict):\n        raise Exception('request input invalid !')\n    job.load_data()\n    job.process_reflectance()\n    job.process_brdf()\n    # make graph of land pixels (stored in the output directory specified in our configuration)\n    job.graph_main_ref_spectra(case='pixels', indices=job.data['idx_land'], title='Land pixel statistics')\n    # save results to a netCDF (stored in the output directory specified in our configuration)\n    job.save_netcdf()\n    \nCommand Line Example\n^^^^^^^^^^^^^^^^^^^^\nAn example of launching an ADAM calculation from the command line is provided, brdf_commandline.py.\n\nAn example of its usage is given here::\n\n    $ python brdf_commandline.py --sza 30.0 --vza 40.0 --phi 0.0 --lat1 36.0 --lon1 5.2 \\\n      --lat2 36.2 --lon2 5.5 --wave-min 437 --wave-max 437 --month jan -ot brdf --netcdf-output /mydata/output.nc\n\n\nMore information about the commandline tool can be had by viewing the help::\n\n    $ python brdf_commandline.py --help\n    usage: brdf_commandline.py [-h] [--sza SZA] [--vza VZA]\n                                     [--phi PHI] --lat1 LAT1 --lon1 LON1\n                                     --lat2 LAT2 --lon2 LON2\n                                     [--wave-min WAVE_MIN]\n                                     [--wave-max WAVE_MAX]\n                                     [--month {jan,feb,mar,apr,may,jun,jul,aug,sep,oct,nov,dec}]\n                                     --operation-type {brdf,spectrum}\n                                     [--netcdf-output NETCDF_OUTPUT]\n\n    ADAM commandline options\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      --sza SZA             Sun Zenith Angle (default 45)\n      --vza VZA             View Zenith Angle (default 45)\n      --phi PHI             Phi (default 0)\n      --lat1 LAT1           Latitude 1\n      --lon1 LON1           Longitude 1\n      --lat2 LAT2           Latitude 2\n      --lon2 LON2           Longitude 1\n      --wave-min WAVE_MIN   Wavelength min\n      --wave-max WAVE_MAX   Wavelength max\n      --month {jan,feb,mar,apr,may,jun,jul,aug,sep,oct,nov,dec}\n                            Month\n      --operation-type {brdf,spectrum}\n                            Type of operation to perform\n      --netcdf-output NETCDF_OUTPUT\n                            Name of netcdf output filename\n    \n\n    \nOther Examples\n^^^^^^^^^^^^^^\n\nThere are a collection of example scripts using the toolkit provided in the test/ folder in the downloadable.\n\n\n\n\nMore info can be found at the ADAM website here: http://www.noveltis.fr/adam-demo/",
        "url": "http://pypi.python.org/pypi/ADAM-Tools",
        "summary": "ADAM Reflectance Database Toolkit",
        "command": "pip install 'ADAM-Tools'"
      },
      "Adapt": {
        "name": "adapt",
        "description": "A framework for Python command line tools. It converts existing scripts into command line tools, and \r\noptionally converts command line tools into RESTFUL web services.  Plans to eventually support PyQT \r\napplication creation as well.",
        "url": "http://pypi.python.org/pypi/Adapt",
        "summary": "Framework For Creating Commandline Tools and Web Services from Config File",
        "command": "pip install 'Adapt'"
      },
      "Adaptation": {
        "name": "adaptation",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Adaptation",
        "summary": "Another implementation of adaptation [Proprietary ATM]",
        "command": "pip install 'Adaptation'"
      },
      "adaptfilt": {
        "name": "adaptfilt",
        "description": "Adaptfilt\r\n=========\r\n\r\nAdaptfilt is an adaptive filtering module for Python. It includes simple, procedural implementations of the following filtering algorithms:\r\n\r\n* **Least-mean-squares (LMS)** - including traditional and leaky filtering\r\n* **Normalized least-mean-squares (NLMS)** - including traditional and leaky filtering with recursively updated input energy\r\n* **Affine projection (AP)** - including traditional and leaky filtering\r\n\r\nThe algorithms are implemented using Numpy for computational efficiency. Further optimization have also been done, but this is very limited and only on the most computationally intensive parts of the source code. Future implementation of the following algorithms is currently planned:\r\n\r\n* **Recursive least squares (RLS)**\r\n* **Steepest descent (SD)**\r\n\r\n| **Authors**: Jesper Wramberg & Mathias Tausen\r\n| **Version**: 0.2\r\n| **PyPI**: https://pypi.python.org/pypi/adaptfilt\r\n| **GitHub**: https://github.com/Wramberg/adaptfilt\r\n| **License**: MIT\r\n\r\nInstallation\r\n------------\r\nTo install from PyPI using pip simply run::\r\n\r\n   sudo pip install adaptfilt\r\n\r\nAlternatively, the module can also be downloaded at https://pypi.python.org/pypi/adaptfilt or \r\nhttps://github.com/Wramberg/adaptfilt. The latter is also used for issue tracking. Note that adaptfilt requires Numpy to be installed (tested using version 1.9.0).\r\n\r\nUsage\r\n-----\r\nOnce installed, the module should be available for import by calling::\r\n\r\n   import adaptfilt\r\n\r\nFollowing the reference sections, examples are provided to show the modules functionality.\r\n\r\nFunction Reference\r\n------------------\r\nIn this section, the functions provided by adaptfilt are described. The descriptions correspond with excerpts from the function docstrings and are only included here for your convenience.\r\n\r\n**y, e, w = lms(u, d, M, step, leak=0., initCoeffs=None, N=None, returnCoeffs=False)**\r\n\r\n    Perform least-mean-squares (LMS) adaptive filtering on u to minimize error\r\n    given by e=d-y, where y is the output of the adaptive filter.\r\n\r\n    Parameters\r\n        u : array-like\r\n            One-dimensional filter input.\r\n        d : array-like\r\n            One-dimensional desired signal, i.e., the output of the unknown FIR\r\n            system which the adaptive filter should identify. Must have length >=\r\n            len(u), or N+M-1 if number of iterations are limited (via the N\r\n            parameter).\r\n        M : int\r\n            Desired number of filter taps (desired filter order + 1), must be\r\n            non-negative.\r\n        step : float\r\n            Step size of the algorithm, must be non-negative.\r\n\r\n    Optional Parameters\r\n        leak : float\r\n            Leakage factor, must be equal to or greater than zero and smaller than\r\n            one. When greater than zero a leaky LMS filter is used. Defaults to 0,\r\n            i.e., no leakage.\r\n        initCoeffs : array-like\r\n            Initial filter coefficients to use. Should match desired number of\r\n            filter taps, defaults to zeros.\r\n        N : int\r\n            Number of iterations, must be less than or equal to len(u)-M+1\r\n            (default).\r\n        returnCoeffs : boolean\r\n            If true, will return all filter coefficients for every iteration in an\r\n            N x M matrix. Does not include the initial coefficients. If false, only\r\n            the latest coefficients in a vector of length M is returned. Defaults\r\n            to false.\r\n\r\n    Returns\r\n        y : numpy.array\r\n            Output values of LMS filter, array of length N.\r\n        e : numpy.array\r\n            Error signal, i.e, d-y. Array of length N.\r\n        w : numpy.array\r\n            Final filter coefficients in array of length M if returnCoeffs is\r\n            False. NxM array containing all filter coefficients for all iterations\r\n            otherwise.\r\n\r\n    Raises\r\n        TypeError\r\n            If number of filter taps M is not type integer, number of iterations N\r\n            is not type integer, or leakage leak is not type float/int.\r\n        ValueError\r\n            If number of iterations N is greater than len(u)-M, number of filter\r\n            taps M is negative, or if step-size or leakage is outside specified\r\n            range.\r\n\r\n**y, e, w = nlmsru(u, d, M, step, eps=0.001, leak=0, initCoeffs=None, N=None, returnCoeffs=False)**\r\n\r\n    Same as nlms but updates input energy recursively for faster computation. Note that this can cause instability due to rounding errors.\r\n\r\n**y, e, w = nlms(u, d, M, step, eps=0.001, leak=0, initCoeffs=None, N=None, returnCoeffs=False)**\r\n\r\n    Perform normalized least-mean-squares (NLMS) adaptive filtering on u to\r\n    minimize error given by e=d-y, where y is the output of the adaptive\r\n    filter.\r\n\r\n    Parameters\r\n        u : array-like\r\n            One-dimensional filter input.\r\n        d : array-like\r\n            One-dimensional desired signal, i.e., the output of the unknown FIR\r\n            system which the adaptive filter should identify. Must have length >=\r\n            len(u), or N+M-1 if number of iterations are limited (via the N\r\n            parameter).\r\n        M : int\r\n            Desired number of filter taps (desired filter order + 1), must be\r\n            non-negative.\r\n        step : float\r\n            Step size of the algorithm, must be non-negative.\r\n\r\n    Optional Parameters\r\n        eps : float\r\n            Regularization factor to avoid numerical issues when power of input\r\n            is close to zero. Defaults to 0.001. Must be non-negative.\r\n        leak : float\r\n            Leakage factor, must be equal to or greater than zero and smaller than\r\n            one. When greater than zero a leaky LMS filter is used. Defaults to 0,\r\n            i.e., no leakage.\r\n        initCoeffs : array-like\r\n            Initial filter coefficients to use. Should match desired number of\r\n            filter taps, defaults to zeros.\r\n        N : int\r\n            Number of iterations to run. Must be less than or equal to len(u)-M+1.\r\n            Defaults to len(u)-M+1.\r\n        returnCoeffs : boolean\r\n            If true, will return all filter coefficients for every iteration in an\r\n            N x M matrix. Does not include the initial coefficients. If false, only\r\n            the latest coefficients in a vector of length M is returned. Defaults\r\n            to false.\r\n\r\n    Returns\r\n        y : numpy.array\r\n            Output values of LMS filter, array of length N.\r\n        e : numpy.array\r\n            Error signal, i.e, d-y. Array of length N.\r\n        w : numpy.array\r\n            Final filter coefficients in array of length M if returnCoeffs is\r\n            False. NxM array containing all filter coefficients for all iterations\r\n            otherwise.\r\n\r\n    Raises\r\n        TypeError\r\n            If number of filter taps M is not type integer, number of iterations N\r\n            is not type integer, or leakage leak is not type float/int.\r\n        ValueError\r\n            If number of iterations N is greater than len(u)-M, number of filter\r\n            taps M is negative, or if step-size or leakage is outside specified\r\n            range.\r\n\r\n\r\n**y, e, w = ap(u, d, M, step, K, eps=0.001, leak=0, initCoeffs=None, N=None, returnCoeffs=False)**\r\n\r\n    Perform affine projection (AP) adaptive filtering on u to minimize error\r\n    given by e=d-y, where y is the output of the adaptive filter.\r\n\r\n    Parameters\r\n        u : array-like\r\n            One-dimensional filter input.\r\n        d : array-like\r\n            One-dimensional desired signal, i.e., the output of the unknown FIR\r\n            system which the adaptive filter should identify. Must have length >=\r\n            len(u), or N+M-1 if number of iterations are limited (via the N\r\n            parameter).\r\n        M : int\r\n            Desired number of filter taps (desired filter order + 1), must be\r\n            non-negative.\r\n        step : float\r\n            Step size of the algorithm, must be non-negative.\r\n        K : int\r\n            Projection order, must be integer larger than zero.\r\n\r\n    Optional Parameters\r\n        eps : float\r\n            Regularization factor to avoid numerical issues when power of input\r\n            is close to zero. Defaults to 0.001. Must be non-negative.\r\n        leak : float\r\n            Leakage factor, must be equal to or greater than zero and smaller than\r\n            one. When greater than zero a leaky LMS filter is used. Defaults to 0,\r\n            i.e., no leakage.\r\n        initCoeffs : array-like\r\n            Initial filter coefficients to use. Should match desired number of\r\n            filter taps, defaults to zeros.\r\n        N : int\r\n            Number of iterations to run. Must be less than or equal to len(u)-M+1.\r\n            Defaults to len(u)-M+1.\r\n        returnCoeffs : boolean\r\n            If true, will return all filter coefficients for every iteration in an\r\n            N x M matrix. Does not include the initial coefficients. If false, only\r\n            the latest coefficients in a vector of length M is returned. Defaults\r\n            to false.\r\n\r\n    Returns\r\n        y : numpy.array\r\n            Output values of LMS filter, array of length N.\r\n        e : numpy.array\r\n            Error signal, i.e, d-y. Array of length N.\r\n        w : numpy.array\r\n            Final filter coefficients in array of length M if returnCoeffs is\r\n            False. NxM array containing all filter coefficients for all iterations\r\n            otherwise.\r\n\r\n    Raises\r\n        TypeError\r\n            If number of filter taps M is not type integer, number of iterations N\r\n            is not type integer, or leakage leak is not type float/int.\r\n        ValueError\r\n            If number of iterations N is greater than len(u)-M, number of filter\r\n            taps M is negative, or if step-size or leakage is outside specified\r\n            range.\r\n\r\n\r\nHelper Function Reference\r\n-------------------------\r\n**mswe = mswe(w, v)**\r\n\r\n    Calculate mean squared weight error between estimated and true filter\r\n    coefficients, in respect to iterations.\r\n\r\n    Parameters\r\n        v : array-like\r\n            True coefficients used to generate desired signal, must be a\r\n            one-dimensional array.\r\n        w : array-like\r\n            Estimated coefficients from adaptive filtering algorithm. Must be an\r\n            N x M matrix where N is the number of iterations, and M is the number\r\n            of filter coefficients.\r\n\r\n    Returns\r\n        mswe : numpy.array\r\n            One-dimensional array containing the mean-squared weight error for\r\n            every iteration.\r\n\r\n    Raises\r\n        TypeError\r\n            If inputs have wrong dimensions\r\n\r\n    Note\r\n        To use this function with the adaptive filter functions set the optional\r\n        parameter returnCoeffs to True. This will return a coefficient matrix w\r\n        corresponding with the input-parameter w.\r\n\r\n\r\nExamples\r\n--------\r\nThe following examples illustrate the use of the adaptfilt module. Note that the matplotlib.pyplot module is required to run them. \r\n\r\nAcoustic echo cancellation\r\n++++++++++++++++++++++++++\r\n::\r\n\r\n  \"\"\"\r\n  Acoustic echo cancellation in white background noise with NLMS.\r\n\r\n  Consider a scenario where two individuals, John and Emily, are talking over the\r\n  Internet. John is using his loudspeakers, which means Emily can hear herself\r\n  through John's microphone. The speech signal that Emily hears, is a distorted\r\n  version of her own. This is caused by the acoustic path from John's\r\n  loudspeakers to his microphone. This path includes attenuated echoes, etc.\r\n\r\n  Now for the problem!\r\n\r\n  Emily wishes to cancel the echo she hears from John's microphone. Emily only\r\n  knows the speech signal she sends to him, call that u(n), and the speech signal\r\n  she receives from him, call that d(n). To successfully remove her own echo\r\n  from d(n), she must approximate the acoustic path from John's loudspeakers to\r\n  his microphone. This path can be approximated by a FIR filter, which means an\r\n  adaptive NLMS FIR filter can be used to identify it. The model which Emily uses\r\n  to design this filter looks like this:\r\n\r\n        u(n) ------->->------+----------->->-----------\r\n                             |                        |\r\n                    +-----------------+      +------------------+\r\n                +->-| Adaptive filter |      |    John's Room   |\r\n                |   +-----------------+      +------------------+\r\n                |            | -y(n)                  |\r\n                |            |           d(n)         |\r\n        e(n) ---+---<-<------+-----------<-<----------+----<-<---- v(n)\r\n\r\n  As seen, the signal that is sent to John is also used as input to the adaptive\r\n  NLMS filter. The output of the filter, y(n), is subtracted from the signal\r\n  received from John, which results in an error signal e(n) = d(n)-y(n). By\r\n  feeding the error signal back to the adaptive filter, it can minimize the error\r\n  by approximating the impulse response (that is the FIR filter coefficients) of\r\n  John's room. Note that so far John's speech signal v(n) has not been taken into\r\n  account. If John speaks, the error should equal his speech, that is, e(n)\r\n  should equal v(n). For this simple example, however, we assume John is quiet\r\n  and v(n) is equal to white Gaussian background noise with zero-mean.\r\n\r\n  In the following example we keep the impulse response of John's room constant.\r\n  This is not required, however, since the advantage of adaptive filters, is that\r\n  they can be used to track changes in the impulse response.\r\n  \"\"\"\r\n\r\n  import numpy as np\r\n  import matplotlib.pyplot as plt\r\n  import adaptfilt as adf\r\n\r\n  # Get u(n) - this is available on github or pypi in the examples folder\r\n  u = np.load('speech.npy')\r\n\r\n  # Generate received signal d(n) using randomly chosen coefficients\r\n  coeffs = np.concatenate(([0.8], np.zeros(8), [-0.7], np.zeros(9),\r\n                           [0.5], np.zeros(11), [-0.3], np.zeros(3),\r\n                           [0.1], np.zeros(20), [-0.05]))\r\n\r\n  d = np.convolve(u, coeffs)\r\n\r\n  # Add background noise\r\n  v = np.random.randn(len(d)) * np.sqrt(5000)\r\n  d += v\r\n\r\n  # Apply adaptive filter\r\n  M = 100  # Number of filter taps in adaptive filter\r\n  step = 0.1  # Step size\r\n  y, e, w = adf.nlms(u, d, M, step, returnCoeffs=True)\r\n\r\n  # Calculate mean square weight error\r\n  mswe = adf.mswe(w, coeffs)\r\n\r\n  # Plot speech signals\r\n  plt.figure()\r\n  plt.title(\"Speech signals\")\r\n  plt.plot(u, label=\"Emily's speech signal, u(n)\")\r\n  plt.plot(d, label=\"Speech signal from John, d(n)\")\r\n  plt.grid()\r\n  plt.legend()\r\n  plt.xlabel('Samples')\r\n\r\n  # Plot error signal - note how the measurement noise affects the error\r\n  plt.figure()\r\n  plt.title('Error signal e(n)')\r\n  plt.plot(e)\r\n  plt.grid()\r\n  plt.xlabel('Samples')\r\n\r\n  # Plot mean squared weight error - note that the measurement noise causes the\r\n  # error the increase at some points when Emily isn't speaking\r\n  plt.figure()\r\n  plt.title('Mean squared weight error')\r\n  plt.plot(mswe)\r\n  plt.grid()\r\n  plt.xlabel('Samples')\r\n\r\n  # Plot final coefficients versus real coefficients\r\n  plt.figure()\r\n  plt.title('Real coefficients vs. estimated coefficients')\r\n  plt.plot(w[-1], 'g', label='Estimated coefficients')\r\n  plt.plot(coeffs, 'b--', label='Real coefficients')\r\n  plt.grid()\r\n  plt.legend()\r\n  plt.xlabel('Samples')\r\n\r\n  plt.show()\r\n\r\n.. image:: https://raw.githubusercontent.com/Wramberg/adaptfilt/master/examples/echocancel-input.png\r\n.. image:: https://raw.githubusercontent.com/Wramberg/adaptfilt/master/examples/echocancel-error.png\r\n.. image:: https://raw.githubusercontent.com/Wramberg/adaptfilt/master/examples/echocancel-mswe.png\r\n.. image:: https://raw.githubusercontent.com/Wramberg/adaptfilt/master/examples/echocancel-coeffs.png\r\n\r\n\r\nConvergence comparison\r\n++++++++++++++++++++++\r\n::\r\n\r\n   \"\"\"\r\n   Convergence comparison of different adaptive filtering algorithms (with\r\n   different step sizes) in white Gaussian noise.\r\n   \"\"\"\r\n   \r\n   import numpy as np\r\n   import matplotlib.pyplot as plt\r\n   import adaptfilt as adf\r\n   \r\n   # Generating input and desired signal\r\n   N = 3000\r\n   coeffs = np.concatenate(([-4, 3.2], np.zeros(20), [0.7], np.zeros(33), [-0.1]))\r\n   u = np.random.randn(N)\r\n   d = np.convolve(u, coeffs)\r\n   \r\n   # Perform filtering\r\n   M = 60  # No. of taps to estimate\r\n   mu1 = 0.0008  # Step size 1 in LMS\r\n   mu2 = 0.0004  # Step size 1 in LMS\r\n   beta1 = 0.08  # Step size 2 in NLMS and AP\r\n   beta2 = 0.04  # Step size 2 in NLMS and AP\r\n   K = 3  # Projection order 1 in AP\r\n   \r\n   # LMS\r\n   y_lms1, e_lms1, w_lms1 = adf.lms(u, d, M, mu1, returnCoeffs=True)\r\n   y_lms2, e_lms2, w_lms2 = adf.lms(u, d, M, mu2, returnCoeffs=True)\r\n   mswe_lms1 = adf.mswe(w_lms1, coeffs)\r\n   mswe_lms2 = adf.mswe(w_lms2, coeffs)\r\n   \r\n   # NLMS\r\n   y_nlms1, e_nlms1, w_nlms1 = adf.nlms(u, d, M, beta1, returnCoeffs=True)\r\n   y_nlms2, e_nlms2, w_nlms2 = adf.nlms(u, d, M, beta2, returnCoeffs=True)\r\n   mswe_nlms1 = adf.mswe(w_nlms1, coeffs)\r\n   mswe_nlms2 = adf.mswe(w_nlms2, coeffs)\r\n   \r\n   # AP\r\n   y_ap1, e_ap1, w_ap1 = adf.ap(u, d, M, beta1, K, returnCoeffs=True)\r\n   y_ap2, e_ap2, w_ap2 = adf.ap(u, d, M, beta2, K, returnCoeffs=True)\r\n   mswe_ap1 = adf.mswe(w_ap1, coeffs)\r\n   mswe_ap2 = adf.mswe(w_ap2, coeffs)\r\n   \r\n   # Plot results\r\n   plt.figure()\r\n   plt.title('Convergence comparison of different adaptive filtering algorithms')\r\n   plt.plot(mswe_lms1, 'b', label='LMS with stepsize=%.4f' % mu1)\r\n   plt.plot(mswe_lms2, 'b--', label='LMS with stepsize=%.4f' % mu2)\r\n   plt.plot(mswe_nlms1, 'g', label='NLMS with stepsize=%.2f' % beta1)\r\n   plt.plot(mswe_nlms2, 'g--', label='NLMS with stepsize=%.2f' % beta2)\r\n   plt.plot(mswe_ap1, 'r', label='AP with stepsize=%.2f' % beta1)\r\n   plt.plot(mswe_ap2, 'r--', label='AP with stepsize=%.2f' % beta2)\r\n   plt.legend()\r\n   plt.grid()\r\n   plt.xlabel('Iterations')\r\n   plt.ylabel('Mean-squared weight error')\r\n   plt.show()\r\n\r\n.. image:: https://raw.githubusercontent.com/Wramberg/adaptfilt/master/examples/convergence-result.png\r\n\r\nRelease History\r\n---------------\r\n0.2\r\n+++\r\n| Included NLMS filtering function with recursive updates of input energy.\r\n| Included acoustic echo cancellation example\r\n\r\n0.1\r\n+++\r\n| Initial module with LMS, NLMS and AP filtering functions.",
        "url": "http://pypi.python.org/pypi/adaptfilt",
        "summary": "Adaptive filtering module for Python",
        "command": "pip install 'adaptfilt'"
      },
      "adapya": {
        "name": "adapya",
        "description": "What is adapya?\r\n---------------\r\nWith adapya you can access Adabas databases from Python programs using\r\nthe Adabas API.\r\n        \r\nIt comes with sample programs to show its use and demonstrates new\r\nAdabas features like reading and storing of large binary objects using\r\nthe extended Adabas API (ACBX).      \r\n        \r\nAdabas is a commercial database system that runs on Windows,\r\nUnix and mainframe systems. For more information see\r\n   http://en.wikipedia.org/wiki/Adabas and\r\n   http://www.softwareag.com/corporate/products/adabas/default.asp\r\n        \r\nIn the download area you may also find an Adabas community version for\r\nWindows. \r\n        \r\nHere is the Adabas product documentation\r\n    http://documentation.softwareag.com/adabas/\r\n      \r\nPython is a scripting language that allows rapid prototyping,\r\nobject-oriented or functional style programming. It is open \r\nsource and is used in a large number of projects.\r\n        \r\n  Note: adapya does not implement a SQL interface as defined with the\r\n        Python DBAPI. You may do Adabas DBAPI access with the product \r\n        ADABAS SQL Gateway via the ODBC interface.\r\n        \r\n        adapya requires a good knowledge of the Adabas API.\r\n        \r\nadapya is a pure Python package: it does not require compilation of\r\nextensions. It should work on all platforms where CPython and Adabas are available.\r\nIt has been tested on Windows, Solaris and z/Linux.\r\nIt can access local Adabas databases and with the product NET-WORK     \r\nremote Adabas databases on all platforms including mainframe \r\nz/OS, VSE, BS2000).\r\n        \r\nPrerequisite for adapya is Python version 2.5, or Python version 2.3 and           \r\n2.4 where it requires the extra ctypes package.\r\n        \r\nadapya can be downloaded from\r\n           http://tech.forums.softwareag.com/viewforum.php?f=171&C=11\r\n\r\nadapya license\r\n--------------\r\n\r\nLicensed under the Apache License, Version 2.0 (the \"License\");           \r\nyou may not use this file except in compliance with the License.          \r\nYou may obtain a copy of the License at                                   \r\n                                                                          \r\n    http://www.apache.org/licenses/LICENSE-2.0                            \r\n                                                                          \r\nUnless required by applicable law or agreed to in writing, software       \r\ndistributed under the License is distributed on an \"AS IS\" BASIS,         \r\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \r\nSee the License for the specific language governing permissions and       \r\nlimitations under the License.",
        "url": "http://pypi.python.org/pypi/adapya",
        "summary": "adapya - Adabas database API for Python",
        "command": "pip install 'adapya'"
      },
      "adb": {
        "name": "adb",
        "description": "This repository contains a pure-python implementation of the Android\nADB and Fastboot protocols, using libusb1 for USB communications.\n\nThis is a complete replacement and rearchitecture of the Android\nproject's ADB and fastboot code available at\nhttps://github.com/android/platform_system_core/tree/master/adb\n\nThis code is mainly targeted to users that need to communicate with\nAndroid devices in an automated fashion, such as in automated\ntesting. It does not have a daemon between the client and the device,\nand therefore does not support multiple simultaneous commands to the\nsame device. It does support any number of devices and never\ncommunicates with a device that it wasn't intended to, unlike the\nAndroid project's ADB.",
        "url": "http://pypi.python.org/pypi/adb",
        "summary": "A pure python implementation of the Android ADB and Fastboot protocols",
        "command": "pip install 'adb'"
      },
      "adb_android": {
        "name": "adb_android",
        "description": "Homepage: https://github.com/vmalyi/adb_android\r\n\r\nThis python package is a wrapper for standard android adb    implementation. It allows you to execute android adb commands in your     python script.\r\n\r\nVersion history: \r\n\r\n*************** \r\n0.4.0 \r\n\r\nAdd new command\r\n- adb wait-for-device\r\n\r\n\r\n*************** \r\n0.3.0 \r\n\r\nAdd support for following adb commands: \r\n- adb getserialno \r\n\r\nGeneral refactoring of both unit tests and module itself \r\n\r\n*************** \r\n0.2.0 \r\n\r\n- Add support of all options to install command \r\n- Add support of all options to uninstall command \r\n- Refactored unit tests \r\n\r\n*************** \r\n0.1.0 \r\n\r\nAdd support for following adb commands: \r\n- adb push \r\n- adb pull \r\n- adb shell \r\n- adb devices \r\n- adb install \r\n- adb uninstall",
        "url": "http://pypi.python.org/pypi/adb_android",
        "summary": "Enables android adb in your python script",
        "command": "pip install 'adb_android'"
      },
      "adblockparser": {
        "name": "adblockparser",
        "description": "adblockparser\n=============\n\n.. image:: https://img.shields.io/pypi/v/adblockparser.svg\n   :target: https://pypi.python.org/pypi/adblockparser\n   :alt: PyPI Version\n\n.. image:: https://img.shields.io/pypi/l/adblockparser.svg\n   :target: https://github.com/scrapinghub/adblockparser/blob/master/LICENSE.txt\n   :alt: License\n\n.. image:: https://img.shields.io/travis/scrapinghub/adblockparser/master.svg\n   :target: https://travis-ci.org/scrapinghub/adblockparser\n   :alt: Build Status\n\n\n``adblockparser`` is a package for working with `Adblock Plus`_ filter rules.\nIt can parse Adblock Plus filters and match URLs against them.\n\n.. _Adblock Plus: https://adblockplus.org\n\nInstallation\n------------\n\n::\n\n    pip install adblockparser\n\nIf you plan to use this library with a large number of filters\ninstalling pyre2_ library is highly recommended: the speedup\nfor a list of default EasyList_ filters can be greater than 1000x.\n\n    pip install 're2 >= 0.2.21'\n\nNote that pyre2 library requires C++ re2_ library installed.\nOn OS X you can get it using homebrew (``brew install re2``).\n\n.. _re2: https://github.com/google/re2\n.. _pyre2: https://github.com/axiak/pyre2\n.. _EasyList: https://easylist.adblockplus.org/en/\n\nUsage\n-----\n\nTo learn about Adblock Plus filter syntax check these links:\n\n* https://adblockplus.org/en/filter-cheatsheet\n* https://adblockplus.org/en/filters\n\n\n1. Get filter rules somewhere: write them manually, read lines from a file\n   downloaded from EasyList_, etc.::\n\n       >>> raw_rules = [\n       ...     \"||ads.example.com^\",\n       ...     \"@@||ads.example.com/notbanner^$~script\",\n       ... ]\n\n2. Create ``AdblockRules`` instance from rule strings::\n\n       >>> from adblockparser import AdblockRules\n       >>> rules = AdblockRules(raw_rules)\n\n3. Use this instance to check if an URL should be blocked or not::\n\n       >>> rules.should_block(\"http://ads.example.com\")\n       True\n\n   Rules with options are ignored unless you pass a dict with options values::\n\n       >>> rules.should_block(\"http://ads.example.com/notbanner\")\n       True\n       >>> rules.should_block(\"http://ads.example.com/notbanner\", {'script': False})\n       False\n       >>> rules.should_block(\"http://ads.example.com/notbanner\", {'script': True})\n       True\n\nConsult with Adblock Plus `docs <https://adblockplus.org/en/filters#options>`__\nfor options description. These options allow to write filters that depend\non some external information not available in URL itself.\n\nPerformance\n-----------\n\nRegex engines\n^^^^^^^^^^^^^\n\n``AdblockRules`` class creates a huge regex to match filters that\ndon't use options. pyre2_ library works better than stdlib's re\nwith such regexes. If you have pyre2_ installed then ``AdblockRules``\nshould work faster, and the speedup can be dramatic - more than 1000x\nin some cases.\n\nSometimes pyre2 prints something like\n``re2/dfa.cc:459: DFA out of memory: prog size 270515 mem 1713850`` to stderr.\nGive re2 library more memory to fix that::\n\n    >>> rules = AdblockRules(raw_rules, use_re2=True, max_mem=512*1024*1024)  # doctest: +SKIP\n\nMake sure you are using re2 0.2.20 installed from PyPI, it doesn't work.\n\nParsing rules with options\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nRules that have options are currently matched in a loop, one-by-one.\nAlso, they are checked for compatibility with options passed by user:\nfor example, if user didn't pass 'script' option (with a ``True`` or ``False``\nvalue), all rules involving ``script`` are discarded.\n\nThis is slow if you have thousands of such rules. To make it work faster,\nexplicitly list all options you want to support in ``AdblockRules`` constructor,\ndisable skipping of unsupported rules, and always pass a dict with all options\nto ``should_block`` method::\n\n    >>> rules = AdblockRules(\n    ...    raw_rules,\n    ...    supported_options=['script', 'domain'],\n    ...    skip_unsupported_rules=False\n    ... )\n    >>> options = {'script': False, 'domain': 'www.mystartpage.com'}\n    >>> rules.should_block(\"http://ads.example.com/notbanner\", options)\n    False\n\nThis way rules with unsupported options will be filtered once, when\n``AdblockRules`` instance is created.\n\nLimitations\n-----------\n\nThere are some known limitations of the current implementation:\n\n* element hiding rules are ignored;\n* matching URLs against a large number of filters can be slow-ish,\n  especially if pyre2_ is not installed and many filter options are enabled;\n* ``match-case`` filter option is not properly supported (it is ignored);\n* ``document`` filter option is not properly supported;\n* rules are not validated *before* parsing, so invalid rules may raise\n  inconsistent exceptions or silently work incorrectly;\n* regular expressions in rules are not supported.\n\nIt is possible to remove all these limitations. Pull requests are welcome\nif you want to make it happen sooner!\n\nContributing\n------------\n\n* source code: https://github.com/scrapinghub/adblockparser\n* issue tracker: https://github.com/scrapinghub/adblockparser/issues\n\nIn order to run tests, install `tox <http://tox.testrun.org>`_ and type\n\n::\n\n    tox\n\nfrom the source checkout.\n\nThe license is MIT.\n\n\nChanges\n=======\n\n0.4 (2015-03-29)\n----------------\n\n* AdblockRule now caches the compiled regexes (thanks\n  https://github.com/mozbugbox);\n* Fixed an issue with \"domain\" option handling\n  (thanks https://github.com/nbraem for the bug report and a test case);\n* cleanups and test improvements.\n\n0.3 (2014-07-11)\n----------------\n\n* Switch to setuptools;\n* better ``__repr__`` for ``AdblockRule``;\n* Python 3.4 support is confirmed;\n* testing improvements.\n\n0.2 (2014-03-20)\n----------------\n\nThis release provides much faster `AdblockRules.should_block()` method\nfor rules without options and rules with 'domain' option.\n\n* better combined regex for option-less rules that makes re2 library\n  always use DFA without falling back to NFA;\n* an index for rules with domains;\n* ``params`` method arguments are renamed to ``options`` for consistency.\n\n0.1.1 (2014-03-11)\n------------------\n\nBy default ``AdblockRules`` autodetects re2 library and uses\nit if a compatible version is detected.\n\n0.1 (2014-03-03)\n----------------\n\nInitial release.",
        "url": "http://pypi.python.org/pypi/adblockparser",
        "summary": "Parser for Adblock Plus rules",
        "command": "pip install 'adblockparser'"
      },
      "adbpy": {
        "name": "adbpy",
        "description": "adbpy\n=====\n\n.. image:: https://travis-ci.org/noahgoldman/adbpy.svg?branch=master\n    :target: https://travis-ci.org/noahgoldman/adbpy\n\nAn python ADB client that uses the actual ADB TCP server to communicate with devices.\n\n`Documentation <http://adbpy.readthedocs.org/en/latest/index.html>`_\n",
        "url": "http://pypi.python.org/pypi/adbpy",
        "summary": "A library to communicate with ADB through it's internal socket interface, rather than the commandline.",
        "command": "pip install 'adbpy'"
      },
      "add_asts": {
        "name": "add_asts",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/add_asts",
        "summary": "UNKNOWN",
        "command": "pip install 'add_asts'"
      },
      "adder": {
        "name": "adder",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/adder",
        "summary": "An AI library",
        "command": "pip install 'adder'"
      },
      "adderall": {
        "name": "adderall",
        "description": "a miniKanren implementation in Hy.",
        "url": "http://pypi.python.org/pypi/adderall",
        "summary": "a miniKanren implementation in Hy.",
        "command": "pip install 'adderall'"
      },
      "addhrefs": {
        "name": "addhrefs",
        "description": "addhrefs.py\n---------------------\n\nTurns plain text into HTML with links on URLs and email addresses\n\nRecommended: Python 2.3 or later",
        "url": "http://pypi.python.org/pypi/addhrefs",
        "summary": "Adds HTML links to text",
        "command": "pip install 'addhrefs'"
      },
      "addhundred": {
        "name": "addhundred",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/addhundred",
        "summary": "A simple function that prints your number plus one hundred.",
        "command": "pip install 'addhundred'"
      },
      "addic7ed-cli": {
        "name": "addic7ed-cli",
        "description": "============\naddic7ed-cli\n============\n\nThis is a little command-line utility to fetch subtitles from addic7ed.\n\nInstall\n=======\n\n>From pypi\n---------\n\nInstall latest stable version with::\n\n    $ pip install addic7ed-cli\n\nUse :code:`--upgrade` to upgrade.\n\nLatest\n------\n\nInstall latest development version with::\n\n    $ pip install https://github.com/BenoitZugmeyer/addic7ed-cli/archive/master.zip\n\nArchLinux\n---------\n\nAn `AUR package`_ is waiting for you.\n\n\nUsage\n=====\n\nExample, if you speak french and english::\n\n    $ addic7ed -l french -l english The.Serie.S02E23.MDR.mkv\n\n\nHelp::\n\n    $ addic7ed --help\n\n\nAuthentification\n================\n\nYou can login with your addic7ed.com identifiers to increase your daily\ndownload quota:\n\n* Anonymous users are limited to 15 downloads per 24 hours on their IP\n  address\n\n* Registered users are limited to 40\n\n* VIPs get 80 downloads (please consider donating)\n\nConfiguration file\n==================\n\nYou can store frequently used options in a configuration file. Create a\nfile at :code:`~/.config/addic7ed` (Linux, OSX) or :code:`%APPDATA%/config` (Windows),\nand it will be parsed using the Python ConfigParser (see example below).\nIt can contain three sections:\n\n* [flags], to set a flag (verbose, hearing-impaired, overwrite, ignore,\n  batch or brute-batch)\n\n* [languages], to list prefered languages\n\n* [session], the session to use for authentification\n\nExample::\n\n    [flags]\n    hearing-impaired = no\n    batch\n\n    [languages]\n    french\n    english\n\n    [session]\n    abcdef\n\nVideo organizer\n===============\n\nvideo-organizer_ format is supported. If a \"filelist\" file is next to an\nepisode, it will use it to extract its real name and forge the good\nquery.\n\n.. _aur package: https://aur.archlinux.org/packages/addic7ed-cli\n.. _video-organizer: https://github.com/JoelSjogren/video-organizer",
        "url": "http://pypi.python.org/pypi/addic7ed-cli",
        "summary": "A commandline access to addic7ed subtitles",
        "command": "pip install 'addic7ed-cli'"
      },
      "addict": {
        "name": "addict",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/addict",
        "summary": "A Python Dict whos keys can be set both using attribute and item syntax",
        "command": "pip install 'addict'"
      },
      "addicted": {
        "name": "addicted",
        "description": "========\naddicted\n========\n\naddicted = addict ExtendeD\n\nThis library comes from ‘mewwts/addict‘ with some more features.\n\nDict\n----\n\nSame as Dict from ‘mewwts/addict‘ except that update() method accept list,tuple and kwargs like usual python dict.\nThe use of ‘inspect‘ module has been removed for performance reason.\n\n\nDictExt\n-------\n\nDict with these additional methods : ::\n\n    pprint()\n    find(pattern,**kwargs)\n    count_some_values(pattern,ignore_case=False)\n    count_some_keys(pattern,ignore_case=False)\n    count_some_items(filter)\n    iter_some_items(pattern,ignore_case=False)\n    iter_some_values(pattern,ignore_case=False)\n    iter_some_keys(pattern,ignore_case=False)\n    get_some_items(pattern,ignore_case=False)\n    get_some_values(pattern,ignore_case=False)\n    get_some_keys(pattern,ignore_case=False)\n    mget(*key_list)\n    extract(key_list)\n    parse_booleans(key_list)\n    parse_numbers(key_list)\n\nNoAttrDict\n----------\n\nWorks like DictExt, except that it returns a ‘NoAttr‘ value when an attribute is missing.\nPlease read `noattr <https://pypi.python.org/pypi/noattr/>`_ package notes for explaination about ‘NoAttr‘ ::\n\n    from addicted import Dict,NoAttrDict\n    d1 = DictExt()\n    d2 = NoAttrDict()\n\n    print type(d1.a.b.c.d)\n    >>> <class 'addicted.DictExt'>\n\n    print type(d2.a.b.c.d)\n    >>> <class 'noattr.NoAttrType'>\n\n\n\nNews\n====\n0.0.4 (2015-08-06)\n------------------\nadd __all__ list\n\n0.0.3 (2015-08-04)\n------------------\nmewwts/addict source code has been included directly into elapouya/addicted to remove the use of 'inspect' module for performance reason\nthe isgenerator() function has been coded another way.\nupdate() method has been changed to accept list,tuple and kwargs\n\n0.0.2 (2015-07-31)\n------------------\nAdd some methods\n\n0.0.1 (2015-07-30)\n------------------\nFirst version",
        "url": "http://pypi.python.org/pypi/addicted",
        "summary": "addict ExtendeD",
        "command": "pip install 'addicted'"
      },
      "addok": {
        "name": "addok",
        "description": "[![Build Status](https://travis-ci.org/etalab/addok.svg?branch=master)](https://travis-ci.org/etalab/addok)\n[![Requirements Status](https://requires.io/github/etalab/addok/requirements.svg?branch=master)](https://requires.io/github/etalab/addok/requirements/?branch=master)\n[![PyPi version](https://img.shields.io/pypi/v/addok.svg)](https://pypi.python.org/pypi/addok/)\n\n# Addok\n\nSearch engine for address. Only address.\n\n\n### Dependencies\n\n- Redis\n- Python 3.4\n\n### Documentation\n\nhttp://addok.readthedocs.org/en/latest/\n\n### Demo\n\nhttp://adresse.data.gouv.fr/map/ (France database)",
        "url": "http://pypi.python.org/pypi/addok",
        "summary": "Search engine for address. Only address.",
        "command": "pip install 'addok'"
      },
      "addonlist": {
        "name": "addonlist",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/addonlist",
        "summary": "AddonList Addons package placeholder",
        "command": "pip install 'addonlist'"
      },
      "addonpy": {
        "name": "addonpy",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/addonpy",
        "summary": "A simple addon/plug-in module",
        "command": "pip install 'addonpy'"
      },
      "AddOns": {
        "name": "addons",
        "description": "========================================\nSeparating Concerns Using Object Add-Ons\n========================================\n\n(NEW in version 0.6: the``Registry`` base class, and the\n``ClassAddOn.for_frame()`` classmethod.)\n\nIn any sufficiently-sized application or framework, it's common to end up\nlumping a lot of different concerns into the same class.  For example, you\nmay have business logic, persistence code, and UI all jammed into a single\nclass.  Attribute and method names for all sorts of different operations get\nshoved into a single namespace -- even when using mixin classes.\n\nSeparating concerns into different objects, however, makes it easier to write\nreusable and separately-testable components.  The AddOns package\n(``peak.util.addons``) lets you manage concerns using ``AddOn`` classes.\n\n``AddOn`` classes are like dynamic mixins, but with their own private attribute\nand method namespaces.  A concern implemented using add-ons can be added at\nruntime to any object that either has a writable ``__dict__`` attribute, or\nis weak-referenceable.\n\n``AddOn`` classes are also like adapters, but rather than creating a new\ninstance each time you ask for one, an existing instance is returned if\npossible.  In this way, add-ons can keep track of ongoing state.  For example,\na ``Persistence`` add-on might keep track of whether its subject has been saved\nto disk yet::\n\n    >>> from peak.util.addons import AddOn\n\n    >>> class Persistence(AddOn):\n    ...     saved = True\n    ...     def changed(self):\n    ...         self.saved = False\n    ...     def save_if_needed(self):\n    ...         if not self.saved:\n    ...             print \"saving\"\n    ...             self.saved = True\n\n    >>> class Thing: pass\n    >>> aThing = Thing()\n\n    >>> Persistence(aThing).saved\n    True\n    >>> Persistence(aThing).changed()\n    >>> Persistence(aThing).saved\n    False\n    >>> Persistence(aThing).save_if_needed()\n    saving\n    >>> Persistence(aThing).save_if_needed() # no action taken\n\nThis makes it easy for us to, for example, write a loop that saves a bunch of\nobjects, because we don't need to concern ourselves with initializing the\nstate of the persistence add-on.  A class doesn't need to inherit from a\nspecial base in order to be able to have this state tracked, and it doesn't\nneed to know *how* to initialize it, either.\n\nOf course, in the case of persistence, a class does need to know *when* to call\nthe persistence methods, to indicate changedness and to request saving.\nHowever, a library providing such an add-on can also provide decorators and\nother tools to make this easier, while still remaining largely independent of\nthe objects involved.\n\nIndeed, the AddOns library was actually created to make it easier to implement\nfunctionality using function or method decorators.  For example, one can create\na ``@synchronized`` decorator that safely locks an object -- see the example\nbelow under `Threading Concerns`_.\n\nIn summary, the AddOns library provides you with a basic form of AOP, that lets\nyou attach (or \"introduce\", in AspectJ terminology) additional attributes and\nmethods to an object, using a private namespace.  (If you also want to do\nAspectJ-style \"advice\", the PEAK-Rules package can be used to do \"before\",\n\"after\", and \"around\" advice in combination with add-ons.)\n\n\n.. contents:: **Table of Contents**\n\n\nBasic API\n---------\n\nIf you need to, you can query for the existence of an add-on::\n\n    >>> Persistence.exists_for(aThing)\n    True\n\nAnd by default, it won't exist::\n\n    >>> anotherThing = Thing()\n    >>> Persistence.exists_for(anotherThing)\n    False\n\nUntil you refer to it directly, e.g.::\n\n    >>> Persistence(aThing) is Persistence(anotherThing)\n    False\n\nAt which point it will of course exist::\n\n    >>> Persistence.exists_for(anotherThing)\n    True\n\nAnd maintain its state, linked to its subject::\n\n    >>> Persistence(anotherThing) is Persistence(anotherThing)\n    True\n\nUntil/unless you delete it (or its subject is garbage collected)::\n\n    >>> Persistence.delete_from(anotherThing)\n    >>> Persistence.exists_for(anotherThing)\n    False\n\n\nAddOn Keys and Instances\n------------------------\n\nAdd-ons are stored either in their subject's ``__dict__``, or if it does not\nhave one (or is a type object with a read-only ``__dict__``), they are\nstored in a special dictionary linked to the subject via a weak reference.\n\nBy default, the dictionary key is the add-on class, so there is exactly one\nadd-on instance per subject::\n\n    >>> aThing.__dict__\n    {<class 'Persistence'>: <Persistence object at...>}\n\nBut in some cases, you may wish to have more than one instance of a given\nadd-on class for a subject.  (For example, PEAK-Rules uses add-ons to represent\nindexes on different expressions contained within rules.)  For this purpose,\nyou can redefine your AddOn's ``__init__`` method to accept additional\narguments besides its subject.  The additional arguments become part of the key\nthat instances are stored under, such that more than one add-on instance can\nexist for a given object::\n\n    >>> class Index(AddOn, dict):\n    ...     def __init__(self, subject, expression):\n    ...         self.expression = expression\n\n    >>> something = Thing()\n    >>> Index(something, \"x>y\")[\"a\"] = \"b\"\n    >>> dir(something)\n    ['__doc__', '__module__', (<class 'Index'>, 'x>y')]\n\n    >>> \"a\" in Index(something, \"z<22\")\n    False\n\n    >>> Index(something, \"x>y\")\n    {'a': 'b'}\n\n    >>> Index(something, \"x>y\").expression\n    'x>y'\n\n    >>> dir(something)\n    ['__doc__', '__module__', (<class 'Index'>, 'x>y'), (<class 'Index'>, 'z<22')]\n\n    >>> Index.exists_for(something, 'x>y')\n    True\n\n    >>> Index.exists_for(anotherThing, 'q==42')\n    False\n\nBy default, an add-on class' key is either the class by itself, or a tuple\ncontaining the class, followed by any arguments that appeared in the\nconstructor call after the add-on's subject.  However, you can redefine the\n``addon_key()`` classmethod in your subclass, and change it to do something\ndifferent.  For example, you could make different add-on classes generate\noverlapping keys, or you could use attributes of the arguments to generate the\nkey.  You could even generate a string key, to cause the add-on to be attached\nas an attribute!::\n\n    >>> class Leech(AddOn):\n    ...     def addon_key(cls):\n    ...         return \"__leech__\"\n    ...     addon_key = classmethod(addon_key)\n\n    >>> something = Thing()\n\n    >>> Leech(something) is something.__leech__\n    True\n\nThe ``addon_key`` method only receives the arguments that appear *after* the\nsubject in the constructor call.  So, in the case above, it receives no\narguments.  Had we called it with additional arguments, we'd have gotten an\nerror::\n\n    >>> Leech(something, 42)\n    Traceback (most recent call last):\n      ...\n    TypeError: addon_key() takes exactly 1 argument (2 given)\n\nNaturally, your ``addon_key()`` and ``__init__()`` (and/or ``__new__()``)\nmethods should also agree on how many arguments there can be, and what they\nmean!\n\nIn general, you should include your add-on class (or some add-on class) as part\nof your key, so as to make collisions with other people's add-on classes\nimpossible.  Keys should also be designed for thread-safety, where applicable.\n(See the section below on `Threading Concerns`_ for more details.)\n\n\nRole Storage and Garbage Collection\n-----------------------------------\n\nBy the way, the approach above of using an string as an add-on key won't always\nmake the add-on into an attribute of the subject!  If an object doesn't have a\n``__dict__``, or that ``__dict__`` isn't writable (as in the case of type\nobjects), then the add-on is stored in a weakly-keyed dictionary, maintained\nelsewhere::\n\n    >>> class NoDict(object):\n    ...     __slots__ = '__weakref__'\n\n    >>> dictless = NoDict()\n\n    >>> Leech(dictless)\n    <Leech object at ...>\n\n    >>> dictless.__leech__\n    Traceback (most recent call last):\n      ...\n    AttributeError: 'NoDict' object has no attribute '__leech__'\n\nOf course, if an object doesn't have a dictionary *and* isn't\nweak-referenceable, there's simply no way to store an add-on for it::\n\n    >>> ob = object()\n    >>> Leech(ob)\n    Traceback (most recent call last):\n      ...\n    TypeError: cannot create weak reference to 'object' object\n\nHowever, there is an ``addons_for()`` function in the ``peak.util.addons``\nmodule that you can extend using PEAK-Rules advice.  Once you add a method to\nsupport a type that otherwise can't be used with add-ons, you should be able to\nuse any and all kinds of add-on objects with that type.  (Assuming, of course,\nthat you can implement a suitable storage mechanism!)\n\nFinally, a few words regarding garbage collection.  If you don't want to create\na reference cycle, don't store a reference to your subject in your add-on. Even\nthough the ``__init__`` and ``__new__`` messages get the subject passed in, you\nare not under any obligation to *store* the subject, and often won't need to.\nUsually, the code that is accessing the add-on knows what subject is in use,\nand can pass the subject to the add-on's methods if needed.  It's rare that the\nadd-on really needs to keep a reference to the subject past the ``__new__()``\nand ``__init__()`` calls.\n\nAdd-on instances will usually be garbage collected at the same time as their\nsubject, unless there is some other reference to them.  If they keep a\nreference to their subject, their garbage collection may be delayed until\nPython's cycle collector is run.  But if they don't keep a reference, they will\nusually be deleted as soon as the subject is::\n\n    >>> def deleting(r):\n    ...     print \"deleting\", r\n\n    >>> from weakref import ref\n\n    >>> r = ref(Leech(something), deleting)\n    >>> del something\n    deleting <weakref at ...; dead>\n\n(Add-ons that are stored outside the instance dictionary of their subject,\nhowever, may take slightly longer, as Python processes weak reference\ncallbacks.)\n\nIt is also *not* recommended that you have ``__del__`` methods on your add-on\nobjects, especially if you keep a reference to your subject.  In such a case,\ngarbage collection may become impossible, and both the add-on and its subject\nwould \"leak\" (i.e., take up memory forever without being recoverable).\n\n\nClass Add-Ons\n-------------\n\nSometimes, it's useful to attach add-ons to classes instead of instances.  You\ncould use normal ``AddOn`` classes, of course, as they work just fine with both\nclassic classes and new-style types -- even built-ins::\n\n    >>> Persistence.exists_for(int)\n    False\n\n    >>> Persistence(int) is Persistence(int)\n    True\n\n    >>> Persistence.exists_for(int)\n    True\n\n    >>> class X: pass\n\n    >>> Persistence.exists_for(X)\n    False\n\n    >>> Persistence(X) is Persistence(X)\n    True\n\n    >>> Persistence.exists_for(X)\n    True\n\nBut, sometimes you have add-ons that are specifically intended for adding\nmetadata to classes -- perhaps by way of class or method decorators.  In such\na case, you need a way to access the add-on *before* its subject even exists!\n\nThe ``ClassAddOn`` base class provides a mechanism for this.  It adds an extra\nclassmethod, ``for_enclosing_class()``, that you can use to access the add-on\nfor the class that is currently being defined in the scope that invoked the\ncaller.  For example, suppose we want to have a method decorator that adds\nthe method to some class-level registry::\n\n    >>> from peak.util.addons import ClassAddOn\n\n    >>> class SpecialMethodRegistry(ClassAddOn):\n    ...     def __init__(self, subject):\n    ...         self.special_methods = {}\n    ...         super(SpecialMethodRegistry, self).__init__(subject)\n\n    >>> def specialmethod(func):\n    ...     smr = SpecialMethodRegistry.for_enclosing_class()\n    ...     smr.special_methods[func.__name__] = func\n    ...     return func\n\n    >>> class Demo:\n    ...     def dummy(self, foo):\n    ...         pass\n    ...     dummy = specialmethod(dummy)\n\n    >>> SpecialMethodRegistry(Demo).special_methods\n    {'dummy': <function dummy at ...>}\n\n    >>> class Demo2(object):\n    ...     def dummy(self, foo):\n    ...         pass\n    ...     dummy = specialmethod(dummy)\n\n    >>> SpecialMethodRegistry(Demo2).special_methods\n    {'dummy': <function dummy at ...>}\n\nYou can of course use the usual add-on API for class add-ons::\n\n    >>> SpecialMethodRegistry.exists_for(int)\n    False\n\n    >>> SpecialMethodRegistry(int).special_methods['x'] = 123\n\n    >>> SpecialMethodRegistry.exists_for(int)\n    True\n\nExcept that you cannot explicitly delete them, they must be garbage collected\nnaturally::\n\n    >>> SpecialMethodRegistry.delete_from(Demo)\n    Traceback (most recent call last):\n      ...\n    TypeError: ClassAddOns cannot be deleted\n\n\nDelayed Initialization\n~~~~~~~~~~~~~~~~~~~~~~\n\nWhen a class add-on is initialized, the class may not exist yet.  In this case,\n``None`` is passed as the first argument to the ``__new__`` and ``__init__``\nmethods.  You must be able to handle this case correctly, if your add-on will\nbe accessed inside a class definition with ``for_enclosing_class()``.\n\nYou can, however, define a ``created_for()`` instance method that will be\ncalled as soon as the actual class is available.  It is also called by the\ndefault ``__init__`` method, if the add-on is initially created for a class\nthat already exists.  Either way, the ``created_for()`` method should be called\nat most once for any given add-on instance.  For example::\n\n    >>> class SpecialMethodRegistry(ClassAddOn):\n    ...     def __init__(self, subject):\n    ...         print \"init called for\", subject\n    ...         self.special_methods = {}\n    ...         super(SpecialMethodRegistry, self).__init__(subject)\n    ...\n    ...     def created_for(self, cls):\n    ...         print \"created for\", cls.__name__\n\n    >>> class Demo:\n    ...     def dummy(self, foo):\n    ...         pass\n    ...     dummy = specialmethod(dummy)\n    init called for None\n    created for Demo\n\nAbove, ``__init__`` was called with ``None`` since the type didn't exist yet.\nHowever, accessing the add-on for an existing type (that doesn't have the add-\non yet) will call ``__init__`` with the type, and the default implementation of\n``ClassAddOn.__init__`` will also call ``created_for()`` for us, when it sees\nthe subject is not ``None``::\n\n    >>> SpecialMethodRegistry(float)\n    init called for <type 'float'>\n    created for float\n    <SpecialMethodRegistry object at ...>\n\n    >>> SpecialMethodRegistry(float)    # created_for doesn't get called again\n    <SpecialMethodRegistry object at ...>\n\nOne of the most useful features of having this ``created_for()`` method is\nthat it allows you to set up class-level metadata that involves inherited\nsettings from base classes.  In ``created_for()``, you have access to the\nclass' ``__bases__`` and or ``__mro__``, and you can just ask for an instance\nof the same add-on for those base classes, then incorporate their data into\nyour own instance as appropriate.  You are guaranteed that any such add-ons you\naccess will already be initialized, including having their ``created_for()``\nmethod called.\n\nSince this works recursively, and because class add-ons can be attached even to\nbuilt-in types like ``object``, the work of creating a correct class metadata\nregistry is immensely simplified, compared to having to special case such base\nclasses, check for bases where no metadata was added or defined, etc.\n\nInstead, classes that didn't define any metadata will just have an add-on\ninstance containing whatever was setup by your add-on's ``__init__()`` method,\nplus whatever additional data was added by its ``created_for()`` method.\n\nThus, metadata accumulation using class add-ons can actually be simpler than\ndoing the same things with metaclasses, since metaclasses can't be\nretroactively added to existing classes.  Of course, class add-ons can't\nentirely replace metaclasses or base class mixins, but for the things they\n*can* do, they are much easier to implement correctly.\n\n\nKeys, Decoration, and ``for_enclosing_class()``\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nClass add-ons can have add-on keys, just like regular add-ons, and they're\nimplemented in the same way.  And, you can pass the extra arguments as\npositional arguments to ``for_enclosing_class()``.  For example::\n\n    >>> class Index(ClassAddOn):\n    ...     def __init__(self, subject, expr):\n    ...         self.expr = expr\n    ...         self.funcs = []\n    ...         super(Index, self).__init__(subject)\n\n    >>> def indexedmethod(expr):\n    ...     def decorate(func):\n    ...         Index.for_enclosing_class(expr).funcs.append(func)\n    ...         return func\n    ...     return decorate\n\n    >>> class Demo:\n    ...     def dummy(self, foo):\n    ...         pass\n    ...     dummy = indexedmethod(\"x*y\")(dummy)\n\n    >>> Index(Demo, \"x*y\").funcs\n    [<function dummy at ...>]\n\n    >>> Index(Demo, \"y+z\").funcs\n    []\n\nNote, by the way, that you do not need to use a function decorator to add\nmetadata to a class.  You just need to be calling ``for_enclosing_class()``\nin a function called directly from the class body::\n\n    >>> def special_methods(**kw):\n    ...     smr = SpecialMethodRegistry.for_enclosing_class()\n    ...     smr.special_methods.update(kw)\n\n    >>> class Demo:\n    ...     special_methods(x=23, y=55)\n    init called for None\n    created for Demo\n\n    >>> SpecialMethodRegistry(Demo).special_methods\n    {'y': 55, 'x': 23}\n\nBy default, the ``for_enclosing_class()`` method assumes is it being called by\na function that is being called directly from the class suite, such as a\nmethod decorator, or a standalone function call as shown above.  But if you\nmake a call from somewhere else, such as outside a class statement, you will\nget an error::\n\n    >>> special_methods(z=42)\n    Traceback (most recent call last):\n      ...\n    SyntaxError: Class decorators may only be used inside a class statement\n\nSimilarly, if you have a function that calls ``for_enclosing_class()``, but\nthen you call that function from another function, it will still fail::\n\n    >>> def sm(**kw):\n    ...     special_methods(**kw)\n\n    >>> class Demo:\n    ...     sm(x=23, y=55)\n    Traceback (most recent call last):\n      ...\n    SyntaxError: Class decorators may only be used inside a class statement\n\nThis is because ``for_enclosing_class()`` assumes the class is being defined\ntwo stack levels above its frame.  You can change this assumption, however,\nby using the ``level`` keyword argument::\n\n    >>> def special_methods(level=2, **kw):\n    ...     smr = SpecialMethodRegistry.for_enclosing_class(level=level)\n    ...     smr.special_methods.update(kw)\n\n    >>> def sm(**kw):\n    ...     special_methods(level=3, **kw)\n\n    >>> class Demo:\n    ...     sm(x=23)\n    ...     special_methods(y=55)\n    init called for None\n    created for Demo\n\n    >>> SpecialMethodRegistry(Demo).special_methods\n    {'y': 55, 'x': 23}\n\nAlternately, you can pass a specific Python frame object via the ``frame``\nkeyword argument to ``for_enclosing_class()``, or use the ``for_frame()``\nclassmethod instead.  ``for_frame()`` takes a Python stack frame, followed by\nany extra positional arguments needed to create the key.\n\n\nClass Registries (NEW in version 0.6)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nFor many of common class add-on use cases, you just want a dict-like object\nwith \"inheritance\" for the values in base classes.  The ``Registry`` base class\nprovides this behavior, by subclassing ``ClassAddOn`` and the Python ``dict``\nbuiltin type, to create a class add-on that's also a dictionary.  It then\noverrides the ``created_for()`` method to automatically populate itself with\nany inherited values from base classes.\n\nLet's define a ``MethodGoodness`` registry that will store a \"goodness\"\nrating for methods::\n\n    >>> from peak.util.addons import Registry\n\n    >>> class MethodGoodness(Registry):\n    ...     \"\"\"Dictionary of method goodness\"\"\"\n\n    >>> def goodness(value):\n    ...     def decorate(func):\n    ...         MethodGoodness.for_enclosing_class()[func.__name__]=value\n    ...         return func\n    ...     return decorate\n\n    >>> class Demo(object):\n    ...     def aMethod(self, foo):\n    ...         pass\n    ...     aMethod = goodness(17)(aMethod)\n    ...     def another_method(whinge, spam):\n    ...         woohoo\n    ...     another_method = goodness(-99)(another_method)\n\n    >>> MethodGoodness(Demo)\n    {'aMethod': 17, 'another_method': -99}\n\nSo far, so good.  Let's see what happens with a subclass::    \n\n    >>> class Demo2(Demo):\n    ...     def another_method(self, fixed):\n    ...         pass\n    ...     another_method = goodness(42)(another_method)\n\n    >>> MethodGoodness(Demo2)\n    {'another_method': 42, 'aMethod': 17}\n\nValues set in base class registries are automatically added to the current\nclass' registry of the same type and key, if the current class doesn't have\nan entry defined.  Python's new-style method resolution order is used to\ndetermine the precedence of inherited attributes.  (For classic classes, a\ntemporary new-style class is created that inherits from the classic class, in\norder to determine the resolution order, then discarded.)\n\nOnce the class in question has been created, the registry gets an extra\nattribute, ``defined_in_class``, which is a dictionary listing the entries that\nwere actually defined in the corresponding class, e.g.::\n\n    >>> MethodGoodness(Demo).defined_in_class\n    {'aMethod': 17, 'another_method': -99}\n    \n    >>> MethodGoodness(Demo2).defined_in_class\n    {'another_method': 42}\n\nAs you can see, this second dictionary contains only the values registered in\nthat class, and not any inherited values.\n\nFinally, note that ``Registry`` objects have one additional method that can\nbe useful to call from a decorator: ``set(key, value)``.  This method will\nraise an error if a different value already exists for the given key, and is\nuseful for catching errors in class definitions, e.g.:\n\n    >>> def goodness(value):\n    ...     def decorate(func):\n    ...         MethodGoodness.for_enclosing_class().set(func.__name__, value)\n    ...         return func\n    ...     return decorate\n\n    >>> class Demo3(object):\n    ...     def aMethod(self, foo):\n    ...         pass\n    ...     aMethod = goodness(17)(aMethod)\n    ...     def aMethod(self, foo):\n    ...         pass\n    ...     aMethod = goodness(27)(aMethod)\n    Traceback (most recent call last):\n      ...\n    ValueError: MethodGoodness['aMethod'] already contains 17; can't set to 27\n\n\nThreading Concerns\n------------------\n\nAdd-on lookup and creation is thread-safe (i.e. race-condition free), so long\nas the add-on key contains no objects with ``__hash__`` or ``__equals__``\nmethods involve any Python code (as opposed to being pure C code that doesn't\ncall any Python code).  So, unkeyed add-ons, or add-ons whose keys consist only\nof instances of built-in types (recursively, in the case of tuples) or types\nthat inherit their ``__hash__`` and ``__equals__`` methods from built-in types,\ncan be initialized in a thread-safe manner.\n\nThis does *not* mean, however, that two or more add-on instances can't be\ncreated for the same subject at the same time!  Code in an add-on class'\n``__new__`` or ``__init__`` methods **must not** assume that it will in fact be\nthe only add-on instance attached to its subject, if you wish the code to be\nthread-safe.\n\nThis is because the ``AddOn`` access machinery allows multiple threads to\n*create* an add-on instance at the same time, but only one of those objects\nwill *win* the race to become \"the\" add-on instance, and no thread can know in\nadvance whether it will win.  Thus, if you wish your ``AddOn`` instances to do\nsomething *to* their constructor arguments at initialization time, you must\neither give up on your add-on being thread-safe, or use some other locking\nmechanism.\n\nOf course, add-on initialization is only one small part of the overall thread-\nsafety puzzle.  Unless your add-on exists only to compute some immutable\nmetadata about its subject, the rest of your add-on's methods need to be\nthread-safe also.\n\nOne way to do that, is to use a ``@synchronized`` decorator, combined with a\n``Locking`` add-on::\n\n    >>> class Locking(AddOn):\n    ...     def __init__(self, subject):\n    ...         from threading import RLock\n    ...         self.lock = RLock()\n    ...     def acquire(self):\n    ...         print \"acquiring\"\n    ...         self.lock.acquire()\n    ...     def release(self):\n    ...         self.lock.release()\n    ...         print \"released\"\n\n    >>> def synchronized(func):\n    ...     def wrapper(self, *__args,**__kw):\n    ...         Locking(self).acquire()\n    ...         try:\n    ...             func(self, *__args,**__kw)\n    ...         finally:\n    ...             Locking(self).release()\n    ...\n    ...     from peak.util.decorators import rewrap\n    ...     return rewrap(func, wrapper)\n\n    >>> class AnotherThing:\n    ...     def ping(self):\n    ...         print \"ping\"\n    ...     ping = synchronized(ping)\n\n    >>> AnotherThing().ping()\n    acquiring\n    ping\n    released\n\nIf the ``Locking()`` add-on constructor were not thread-safe, this decorator\nwould not be able to do its job correctly, because two threads accessing an\nobject that didn't *have* the add-on yet, could end up locking two different\nlocks, and proceeding to run the supposedly-\"synchronized\" method at the same\ntime!\n\n(In general, thread-safety is harder than it looks.  But at least you don't have\nto worry about this one tiny part of correctly implementing it.)\n\nOf course, synchronized methods will be slower than normal methods, which is\nwhy AddOns doesn't do anything besides that one small part of the thread-safety\npuzzle, to avoid penalizing non-threaded code.  As the PEAK motto says,\nSTASCTAP! (Simple Things Are Simple, Complex Things Are Possible.)\n\n\nMailing List\n------------\n\nQuestions, discussion, and bug reports for this software should be directed to\nthe PEAK mailing list; see http://www.eby-sarna.com/mailman/listinfo/PEAK/\nfor details.",
        "url": "http://pypi.python.org/pypi/AddOns",
        "summary": "Dynamically extend other objects with AddOns (formerly ObjectRoles)",
        "command": "pip install 'AddOns'"
      },
      "addremoveoptions": {
        "name": "addremoveoptions",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/addremoveoptions",
        "summary": "Turbogears widget that creates a selectbox in which you can add and remove options",
        "command": "pip install 'addremoveoptions'"
      },
      "address": {
        "name": "address",
        "description": "address\n=========\n\naddress is an address parsing library, taking the guesswork out of\nusing addresses in your applications. We use it as part of our apartment\nsearch and apartment spider applications.\n\nInstallation\n------------\n\n::\n\n    pip install address\n\nExample\n-------\n\nFirst, we create an AddressParser. AddressParser allows us to feed in\nlists of cities, streets, and address suffixes. Then we call\nparse\\_address on our address string, which returns an Address instance\nwith all the attributes filled out. From there, we can print parts of\nthe address, change them, validate them, create a database model to\nstore them, or anything else.\n\n::\n\n    from address import AddressParser, Address\n\n    ap = AddressParser()\n    address = ap.parse_address('123 West Mifflin Street, Madison, WI, 53703')\n    print \"Address is: {0} {1} {2} {3}\".format(address.house_number, address.street_prefix, address.street, address.street_suffix)\n\n    > Address is: 123 W. Mifflin St.\n\nAddressParser\n-------------\n\n``AddressParser(self, suffixes=None, cities=None, streets=None)``\n\nsuffixes, cities, and streets all accept lists as arguments. If you\nleave them as none, they will read default files from the package,\nnamely suffixes.csv, cities.csv, and streets.csv. Streets is\nintentionally blank.\n\nYou can provide lists of acceptable suffixes, cities, and streets to\nlower your false positives. If you know all the addresses you are\nprocessing are in a small area, you can provide a list of the cities in\nthe area and should get more accurate results. If you are only doing one\ncity, you could provide that single city in a list, and a list of all\nstreets in that city.\n\nAddress\n-------\n\nAddresses get returned by AddressParser.parser\\_address(). They have the\nfollowing attributes:\n\n``house_number``\n\nThe number on a house. This is required for all valid addresses. E.g.\n**123** W. Mifflin St.\n\n``street_prefix``\n\nThe direction before the street name. Always represented as one or two\nletters followed by a period. Not required. E.g. 123 **W.** Mifflin St.\n\n``street``\n\nThe name of the street. Potentially multiple words. This is required for\na valid address. E.g. 123 W. **Mifflin** St.\n\n``street_suffix``\n\nThe ending of a street. This will always be the USPS abbreviation\nfollowed by a period. Not required, but highly recommended. E.g. 123 W.\nMifflin **St.**\n\n``apartment``\n\nApartment number or unit style or any number of things signifying a\nspecific part of an address. Not required. E.g. 123 W. Mifflin St. **Apt\n10**\n\n``buiding``\n\nSometimes addresses are grouped into buildings, or are more commonly\nknown as by building names. Not required, and often in parathenses. E.g.\n123 W. Mifflin St. Apt 10 **(The Estates)**\n\n``city``\n\nThe city part of the address, preferably following a comma. E.g. 123 W.\nMifflin St., **Madison**, WI 53703\n\n``state``\n\nThe state of the address, preferably following the city and a comma.\nAlways two capitalized letters. E.g. 123 W. Mifflin St., Madison, **WI**\n53703\n\n``zip``\n\nThe 5 digit zip code of the address, preferably following the state. 9\ndigit zips not yet supported. E.g. 123 W. Mifflin St., Madison, WI\n**53703**\n\n``full_address()``\n\nReturns a human readable version of the address for display. Follows the\nsame style rules as the above attributes. Example return: (The Estates)\n123 W. Mifflin St. Apt 10, Madison, WI 53703\n\nTodo\n----\n\n-  Add verification of an address through Google Maps API, given an API\n   key.\n\n-  Allow custom validation conditions in AddressParser for what counts\n   as a correct address or not.\n\n-  Add exceptions for incorrect addresses instead of silent failing and\n   letting user validate.\n\nGitHub\n------\n\nFile support requests and obtain the source from\nhttps://github.com/SwoopSearch/pyaddress\n\nAuthors\n-------\n\n-  Josh Gachnang\n\n-  Rob Jauquet\n\nLicense and Copyright\n---------------------\n\nCopyright (c) 2013 Swoop Search LLC.\n\nThis library is released under the New BSD License.",
        "url": "http://pypi.python.org/pypi/address",
        "summary": "address is an address parsing library, taking the guesswork out of using addresses in your applications.",
        "command": "pip install 'address'"
      },
      "addressable": {
        "name": "addressable",
        "description": "``addressable`` is a silly little utility that allows you to access\nitems inside of a list using one or more indices as keys. You pretty\nmuch get to pretend pretend that a list is a souped-up dictionary.\n\n::\n\n    artists = [{\n        'id': '0488', \n        'name': 'Lambchop', \n        'members': ['Kurt Wagner'], \n    }, {\n        'id': '9924', \n        'name': 'Dire Straits', \n        'members': ['Mark Knopfler'], \n    }]\n\n    # keys are matched against one or more indices\n    artists = List(artists, indices=('id', 'name'))\n    print artists['0488'] == artists['Lambchop']\n\n    # fuzzy matching\n    artists = List(artists, indices=('id', 'title'), fuzzy=True)\n    print artists['strait']\n\n    # extract the value, not the metadata\n    artists = List(artists, indices=('id', 'title'), facet='title')\n    print artists['9924'] == 'Dire Straits'\n\nSo why would you want to do any of this? You probably don't.\n\n``addressable`` can be useful for certain DSL or library code where you\nwant to give the end users some freedom to code things their way, when\nyou need to be able to very easily refer to certain things that are\nweirdly named or when there's multiple common ways of referring to\nsomething and you want the flexibility to mix-and-match.",
        "url": "http://pypi.python.org/pypi/addressable",
        "summary": "Use lists like you would dictionaries.",
        "command": "pip install 'addressable'"
      },
      "address_book_lansry": {
        "name": "address_book_lansry",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/address_book_lansry",
        "summary": "a command-line address-book program using to browse, add, modify, delete or search for your contacts",
        "command": "pip install 'address_book_lansry'"
      },
      "addresscleaner": {
        "name": "addresscleaner",
        "description": "# Betwen the Bars address cleaner\n\nThis is a simple library to clean and normalize textual addresses.  It is\nbiased toward the sorts of addresses people in prison are given.\n\n## Example usage\n\n    from addresscleaner import parse_address, format_address\n\n    >>> parsed = parse_address(\"\"\"John Dough\n    ... #1234567\n    ... 7819 228th St.\n    ... Raiford, FL 32026-1120\"\"\")\n    >>> print parsed\n    {'name': 'John Dough', 'address1': '#1234567', 'address2': '7819 228th St.', 'city': 'Raiford',  'state': 'FL', 'zip': '32026-1120'}\n\n    >>> format_address(parsed)\n    u'John Dough\\n#1234567\\n7819 228th St.\\nRaiford, FL  32026-1120'\n\nAn exception of type ``addresscleaner.AddressException`` is raised if the\nparser is unable to figure out something about the address.  The exception's\nmessage tries to explain as much as possible where it went wrong.",
        "url": "http://pypi.python.org/pypi/addresscleaner",
        "summary": "Utility for normalizing (Prisoner-centric) street addresses",
        "command": "pip install 'addresscleaner'"
      },
      "addressify": {
        "name": "addressify",
        "description": "Addressify Python Client\n========================\n\n.. image:: https://travis-ci.org/snowball-one/addressify.svg\n    :target: https://travis-ci.org/snowball-one/addressify\n\n\nThis is a simply Python client for the `addressify.com.au`_ API.\n\n*\"Addressify is a cloud based web API that allows web site, web application and\ndesktop application developers to easily implement free address verification,\nvalidation, checking, parsing and autocomplete for Australia in their\napplications.\"*\n\n.. _addressify.com.au: http://www.addressify.com.au\n\nInstallation\n------------\n\nSince the Python addressify client has not yet been released to pypi, you will\nneed to install it from git. This can still be done using pip::\n\n    pip install git+https://github.com/snowball-one/addressify.git\n\n\n\nUsage Quickstart\n----------------\n\nThe Addressify Python client currently covers all the available api calls of\n`addressify.com.au`_. e.g.:\n\n.. code-block:: Python\n    from addressify import Client\n\n    client = Client(your_api_key)\n    results = client.auto_complete('109/175 Sturt Street, SOUTH')\n\n\nAPI Calls Available\n-------------------\n\nclient.auto_complete\n++++++++++++++++++++\n\nGets a list of addresses that begin with the given term.\n\nArguments:\n\nterm (Required)\n   The start of an address.\n\nstate (Optional)\n   The state to search for addresses in. ('NSW', 'ACT', 'VIC', 'QLD', 'SA',\n   'WA', 'NT', 'TAS')\n\npostcode (Optional)\n   The postcode to search for addresses in.\n\nmax_results (Optional)\n   The maximum number of results to return (minumum: 1, maximum: 20,\n   default: 10).\n\n\nExample Response::\n\n    [\n        \"1 GEORGE ST, TAHMOOR NSW 2573\",\n        \"1 GEORGE ST, TELARAH NSW 2320\",\n        \"1 GEORGE ST, TEMORA NSW 2666\",\n        \"1 GEORGE ST, TENTERFIELD NSW 2372\",\n        \"1 GEORGE ST, THE ROCKS NSW 2000\"\n    ]\n\n\nclient.address_line_auto_complete\n+++++++++++++++++++++++++++++++++\n\nGets a list of address lines that begin with the given term.\n\nArguments:\n\nterm (Required)\n   The start of an address line.\n\nstate (Optional)\n   The state to search for addresses in. ('NSW', 'ACT', 'VIC', 'QLD', 'SA',\n   'WA', 'NT', 'TAS')\n\npostcode (Optional)\n   The postcode to search for addresses in.\n\nmax_results (Optional)\n   The maximum number of results to return (minumum: 1, maximum: 20,\n   default: 10).\n\nExample Response::\n\n    [\n        \"1 GEORDIE ST\",\n        \"1 GEORGANN ST\",\n        \"1 GEORGE AVE\",\n        \"1 GEORGE CL\",\n        \"1 GEORGE CRES\"\n    ]\n\nclient.suburb_auto_complete\n++++++++++++++++++++++++++++\n\nGets a list of suburbs that begin with the given term.\n\nArguments:\n\nterm (Required)\n   The start of a suburb name\n\nstate (Optional)\n   The state to search for addresses in. ('NSW', 'ACT', 'VIC', 'QLD', 'SA',\n   'WA', 'NT', 'TAS')\n\npostcode (Optional)\n   The postcode to search for addresses in.\n\nmax_results (Optional)\n   The maximum number of results to return (minumum: 1, maximum: 20,\n   default: 10).\n\nExample Response::\n\n    [\n        \"SUFFOLK PARK\",\n        \"SUGARLOAF\",\n        \"SUMMER HILL\",\n        \"SUMMER HILL CREEK\",\n        \"SUMMER ISLAND\"\n    ]\n\nclient.suburb_state_postcode_auto_complete\n++++++++++++++++++++++++++++++++++++++++++\n\nGets a list of suburbs and postcodes where the suburb begins with the given\nterm.\n\nArguments:\n\nterm (Required)\n   The start of a suburb name.\n\nstate (Optional)\n   The state to search for addresses in. ('NSW', 'ACT', 'VIC', 'QLD', 'SA',\n   'WA', 'NT', 'TAS')\n\npostcode (Optional)\n   The postcode to search for addresses in.\n\nmax_results (Optional)\n   The maximum number of results to return (minumum: 1, maximum: 20,\n   default: 10).\n\n\nExample Response::\n\n    [\n        \"SUMMER HILL, NSW 2130\",\n        \"SUMMER HILL, NSW 2421\",\n        \"SUMMER HILL CREEK, NSW 2800\",\n        \"SUMMER ISLAND, NSW 2440\",\n        \"SUMMERHILL, TAS 7250\"\n    ]\n\nclient.suburbs_for_postcode\n+++++++++++++++++++++++++++\n\nGets a list of suburbs for the given postcode.\n\nArguments:\n\npostcode (Required)\n   The postcode.\n\n\nExample Response::\n\n    [\n        \"BARANGAROO, NSW 2000\",\n        \"DAWES POINT, NSW 2000\",\n        \"HAYMARKET, NSW 2000\",\n        \"MILLERS POINT, NSW 2000\",\n        \"SYDNEY, NSW 2000\",\n        \"SYDNEY SOUTH, NSW 2000\",\n        \"THE ROCKS, NSW 2000\"\n    ]\n\nclient.state_for_postcode\n+++++++++++++++++++++++++\n\nGets the state in which the given postcode is located.\n\nArguments:\n\npostcode (Required)\n   The postcode.\n\nExample Response::\n    \"NSW\"\n\n\nclient.parse_address\n++++++++++++++++++++\n\nParses the given address into it's individual address fields.\n\nArguments:\n\naddress_line (Required)\n   The address to parse.\n\nExample Response::\n\n    addressify.client.Address(\n        number=\"680\",\n        street=\"GEORGE\",\n        street_type=\"ST\",\n        suburb=\"SYDNEY\",\n        street_suffix=None,\n        state=\"NSW\",\n        street_line=\"680 GEORGE ST\",\n        unit_type=None\n        unit_number=None,\n        postcode=\"2000\"\n    )\n\nclient.get_similar\n++++++++++++++++++\n\nGets a list of valid addresses that are similar to the given term, can be used\nto match invalid addresses to valid addresses.\n\nArguments:\n\naddress_line (Required)\n   The address to find similar addresses for\n\nmax_results (Optional)\n   The maximum number of results to return (minumum: 1, maximum: 10,\n   default: 10).\n\nExample Response::\n\n    [\n        \"1 GEORGE ST, SYDNEY NSW 2000\"\n    ]\n\nclient.validate\n+++++++++++++++\n\nChecks whether the given address is valid. Please note that validation is only\nperformed on the street, suburb, state and postcode. Street and unit numbers\nare not checked for validity.\n\nArguments\n\naddress_line (Required)\n   The address to validate.\n\nExample Response::\n    true\n\nclient.daily_call_count\n+++++++++++++++++++++++\n\nGets the current daily API call count for your account. This counter will reset\nat midnight AEST. When this counter reaches the daily API call limit for your\naccount type all other Addressify API calls will fail until the counter resets.\n\nWill return -1 if the api_key does not exist.\n\nExample Response::\n    1000",
        "url": "http://pypi.python.org/pypi/addressify",
        "summary": "A Python wrapper around Addressify.com.au's APIs",
        "command": "pip install 'addressify'"
      },
      "address_parser": {
        "name": "address_parser",
        "description": "Address Parser\n======================\n\nYet another python address parser. \n\n    from address_parser import Parser\n    import csv\n\n    parser = Parser()\n\n    ps = parser.parse('1089-1099 Carlsbad Village Dr, Carlsbad, CA')\n\n    print ps.dict # Dictionary form, with all components\n\n    print ps.args # Simple dictionary, for use in arguments lists. \n\nA complete dictionary output looks like:\n\n    {'hash': '34c56b214a1dd719227f829278755d1b',\n     'locality': {'city': 'Carlsbad', 'state': 'CA', 'type': 'P', 'zip': None},\n     'number': {'end_number': None,\n                'fraction': None,\n                'is_block': False,\n                'number': 1089,\n                'suite': None,\n                'tnumber': '1089',\n                'type': 'P'},\n     'road': {'direction': '',\n              'name': 'Carlsbad Village',\n              'suffix': 'Dr',\n              'type': 'P'},\n     'text': '1089 Carlsbad Village Dr, Carlsbad, CA'}\n     \nThe argument form looks like: \n\n    {'city': 'Carlsbad',\n     'direction': '',\n     'name': 'Carlsbad Village',\n     'number': 1089,\n     'state': 'CA',\n     'suffix': 'Dr',\n     'zip': None}",
        "url": "http://pypi.python.org/pypi/address_parser",
        "summary": "Address parser",
        "command": "pip install 'address_parser'"
      },
      "addthis": {
        "name": "addthis",
        "description": "==============\npython-addthis\n==============\n.. image:: https://pypip.in/version/addthis/badge.svg\n    :target: https://pypi.python.org/pypi/addthis/\n    :alt: Latest Version\n\n.. image:: https://travis-ci.org/creafz/python-addthis.svg?branch=master\n    :target: https://travis-ci.org/creafz/python-addthis\n\n.. image:: https://coveralls.io/repos/creafz/python-addthis/badge.png?branch=master\n    :target: https://coveralls.io/r/creafz/python-addthis?branch=master\n\nA Python wrapper for the `AddThis Analytics API <http://support.addthis.com/customer/portal/articles/381264-addthis-analytics-api/>`_.\n\nRequirements\n------------\n* Python 2.6, 2.7 or 3.2+\n* `python-requests <https://pypi.python.org/pypi/requests/>`_ library\n\nInstallation\n------------\nInstall from PyPI::\n\n    pip install addthis\n\nUsage\n-----\n\n::\n\n    from addthis import Addthis\n\n    # create an AddThis instance using userid and password from your AddThis account and optionally provide a pubid\n    addthis = Addthis(userid=\"YOUR_USER_ID\", password=\"YOUR_PASSWORD\", pubid=\"YOUR_PUB_ID\")\n\n    # get the number of shares for the last day\n    print addthis.shares.day()\n\n    # get the number of shares by day for the last week\n    print addthis.shares.day(period=\"week\")\n\n\nYou can see a full description of all supported metrics and dimensions at http://support.addthis.com/customer/portal/articles/381264-addthis-analytics-api\n\nA few more examples\n~~~~~~~~~~~~~~~~~~~\n\n**How many times was my content shared on Twitter, by day, over the last week?**\n::\n\n    >>> addthis.shares.day(period=\"week\", service=\"twitter\")\n\n**What were my top shared urls for the pubid=\"MY_PUB_ID\"?**\n::\n\n    >>> addthis.shares.url(pubid=\"MY_PUB_ID\")\n\n**How many users shared my content this month, broken down by their interests?**\n::\n\n    >>> addthis.sharers.interest(period=\"month\")\n\n**Which sharing services sent the most clicks back to my site this week?**\n::\n\n    >>> addthis.clicks.service(period=\"week\")\n\nExceptions\n----------\n\nAddthisValidationError\n~~~~~~~~~~~~~~~~~~~~~~\nAddthis object expects to be called with 2 parameters - \"metric\" and \"dimension\"::\n\n    addthis.<metric>.<dimension>()\n\n\nFor example::\n\n     >>> addthis.shares.day() # \"shares\" is a metric and \"day\" is a dimension\n\n\nIf it gets another number of parameters (e.g. addthis.shares() or addthis.shares.day.week()) it will raise an **AddthisValidationError**.\n\n::\n\n    from addthis import Addthis, AddthisValidationError\n\n    addthis = Addthis(userid=\"YOUR_USER_ID\", password=\"YOUR_PASSWORD\", pubid=\"YOUR_PUB_ID\")\n\n    try:\n        addthis.shares()\n    except AddthisValidationError as e:\n        print e # \"Incorrect number of parameters are given. Expected 2 but got 1.\"\n\n\n\n\nAddthisError\n~~~~~~~~~~~~\n**AddthisError** is raised when AddThis service returns a response with a HTTP status code other than 200. The exception object has 4 attributes:\n\n* *status_code*: Code from the HTTP response.\n* *code*, *message*, *attachment*: Error attributes from the AddThis response body. (see the “Error\" section in the `AddThis Analytics API documentation <http://support.addthis.com/customer/portal/articles/381264-addthis-analytics-api/>`_ for more information).\n\n::\n\n    from addthis import Addthis, AddthisError\n\n    addthis = Addthis(userid=\"INCORRECT_USER_ID\", password=\"INCORRECT_PASSWORD\", pubid=\"INCORRECT_PUB_ID\")\n\n    try:\n        addthis.shares.day()\n    except AddthisError as e:\n        print e # \"401 Error (code = '80', message='authentication failed', attachment='{u'nonce': None, u'realm': u'AddThis', u'opaque': None})'.\"\n        print e.status_code # 401\n        print e.code # 80\n        print e.message # \"authentication failed\"\n        print e.attachment # {u'nonce': None, u'realm': u'AddThis', u'opaque': None}",
        "url": "http://pypi.python.org/pypi/addthis",
        "summary": "A Python wrapper for the AddThis Analytics API",
        "command": "pip install 'addthis'"
      },
      "Adept": {
        "name": "adept",
        "description": "## Adept \n\n### Installation\n\n`pip install git+ssh://git@github.com/fictivekin/adept-python.git`\n\n### Using the package\n\nImport the Adept class from the package, pass through your account credentials\n\n```\nfrom adept import Adept\na = Adept(\n    accound_id='9b5dd41deff8ae7e3767fc6566cb25ff3ca66438',\n    account_key='251692b3899f1e30fe4b7037185488aad37c46f8',\n    cloudfront_hostname='some.cloudfront.host.com'\n)\n```\n\nYou can then generate a URL for given image operations on an S3 asset (and specified bucket) or image URL.\n\nAn example using an S3 asset:\n\n```\noperations = ['maxwidth-400', 'cropcenter-400x300']\na.generate_url(\n    bucket='gimmebar-assets',\n    asset_key='526fc2761c899.jpg',\n    operations=operations,\n)\n```",
        "url": "http://pypi.python.org/pypi/Adept",
        "summary": "Simple binding for Adept",
        "command": "pip install 'Adept'"
      },
      "AdHoc": {
        "name": "adhoc",
        "description": "AdHoc Standalone Python Script Generator\n########################################\n\nThe *AdHoc* compiler can be used as a program (see `Script Usage`_)\nas well as a module (see :class:`adhoc.AdHoc`).\n\nSince the *AdHoc* compiler itself is installed as a compiled *AdHoc*\nscript, it serves as its own usage example.\n\nAfter installation of the *adhoc.py* script, the full source can be\nobtained in directory ``__adhoc__``, by executing::\n\n    adhoc.py --explode\n\nPurpose\n=======\n\n*AdHoc* provides python scripts with\n\n- template facilities\n- default file generation\n- standalone module inclusion\n\n*AdHoc* has been designed to provide an implode/explode cycle:\n\n========  =======  =========  =======  =========\nsource_0                               xsource_0\nsource_1  implode             explode  xsource_1\n...       ------>  script.py  ------>  ...\nsource_n                               xsource_n\n========  =======  =========  =======  =========\n\nwhere ``xsource_i === source_i``. I.e., ``diff source_i xsource_i``\ndoes not produce any output.\n\nQuickstart\n==========\n\nmodule.py:\n\n    # -*- coding: utf-8 -*-\n    mvar = 'value'\n\nscript.py:\n\n    # -*- coding: utf-8 -*-\n    # @:adhoc_run_time:@\n    import module # @:adhoc:@\n    print('mvar: ' + module.mvar)\n\nCompilation::\n\n    adhoc.py --compile script.py >/tmp/script-compiled.py\n\nExecution outside source directory::\n\n    cd /tmp && python script-compiled.py\n\nshows::\n\n    mvar: value\n\nDecompilation::\n\n    cd /tmp && \\\n    mkdir -p __adhoc__ && \\\n    adhoc.py --decompile <script-compiled.py >__adhoc__/script.py",
        "url": "http://pypi.python.org/pypi/AdHoc",
        "summary": "Standalone Package Generator",
        "command": "pip install 'AdHoc'"
      },
      "adhocracy": {
        "name": "adhocracy",
        "description": "Adhocracy\n=========\n\n\nAbout\n-----\n\nAdhocracy is a web based software tool which facilitates cooperative policy\ndrafting, proposal discussion and decisions in distributed groups.\n\nIt is primarily developed by the `Liquid Democracy e.V. <http://liqd.de>`_ as a\nplatform to implement Liquid Democracy concepts, as well as to provide a simple\nand working general purpose online participation platform.\n\n\nTechnology\n----------\n\nAdhocracy is mostly written in Python 2. It's built on top of many free\nsoftware projects, such as the Pylons web framework, the Solr search platform,\nMemcached, Redis, many Python libraries and more.\n\n\nInstalling\n----------\n\nAdhocracy is known to run on current Linux systems, such as Debian Squeeze. It\nmight run on FreeBSD or OS X, but this hasn't been tested recently.\n\nInstallation is usually done through buildout or through an installer script\nfor Debian based systems. In either case, read `INSTALLATION.rst\n<INSTALLATION.rst>`_.\n\n\nDevelopment\n-----------\n\nAdhocracy is openly developed as free software and distributed for the common\ngood under the `AGPLv3 license <http://www.gnu.org/licenses/agpl-3.0.html>`_.\n\nSource code hosting, bug tracking and planned feature discussion is done `on\nGitHub <https://github.com/liqd/adhocracy>`_.\n\nCommunication also takes place on the `adhocracy-dev mailing list\n<http://lists.liqd.net/cgi-bin/mailman/listinfo/adhocracy-dev>`_.\n\nDocumentation is included in the source code and can be read online `on\nreadthedocs <http://adhocracy.readthedocs.org>`_.\n\nWe're very open for contributions, please drop us a note on the mailing list or\ncreate a pull request on GitHub.\n\n\nSupport\n-------\n\nCommunity support is available through the `adhocracy-dev mailing list\n<http://lists.liqd.net/cgi-bin/mailman/listinfo/adhocracy-dev>`_.\n\nCommercial support (installation, hosting, customization, training) is offered\nby the Liquid Democracy e.V. - you can reach us at `info(at)liqd(dot)de`.\n\nAdhocracy installation\n======================\n\nAdhocracy makes heavy use of\n`buildout <https://pypi.python.org/pypi/zc.buildout>`_, a Python build\ntool. It downloads, configures and builds nearly all dependencies to\ncreate a repeatable and isolated environment. In addition it sets up the\nsupervisord service manager, which allows to easily start and stop the\nservices which Adhocracy needs to run:\n\n-  adhocracy (http server that runs Adhocracy with Spawning/WSGI)\n-  adhocracy\\_worker (background queue processing)\n-  solr (searching)\n-  memcached (key-value cache)\n-  redis (internal messaging queue)\n\nAdhocracy is known to work on all modern Linux distributions, but should\nalso run on OS X and FreeBSD with minor modifications.\n\nThere are two supported ways of installing Adhocracy:\n\n-  A fully automatic installation, which downloads and sets up\n   everything, is available for Debian, Ubuntu and Arch Linux. This is\n   basically a wrapper around buildout.\n\n-  The manual installation, which directly uses the buildout commands.\n\nBoth are described in the following.\n\nIn any case you will need the following MIME types in ``/etc/mime.types``::\n\n    # webfonts\n    application/x-font-woff woff\n    application/font-truetype ttf\n\n    # socialshareprivacy 1.5 language files\n    application/json lang\n\nAutomatic installation on debian, Ubuntu or Arch Linux with build.sh\n--------------------------------------------------------------------\n\nOn debian, Ubuntu, or Arch you can simply execute the following in a\nterminal:\n\n::\n\n    wget -nv https://raw.github.com/liqd/adhocracy/develop/build.sh -O build.sh && sh build.sh\n\nThe script will use sudo to install the required dependencies, and\ninstall, set up, and start the required services.\n\nAdd ``-c hhu`` to install with the preconfiguration for HHU Düsseldorf.\n\nManual installation\n-------------------\n\nPreparations\n````````````\n\nInstall required system packages (Debian Squeeze example):\n\n::\n\n    $ sudo apt-get install gcc make build-essential bin86 unzip libpcre3-dev mercurial git libssl-dev libbz2-dev pkg-config\n    $ sudo apt-get install python python-setuptools\n    $ sudo apt-get install libsqlite3-dev postgresql-server-dev-9.1\n    $ sudo apt-get install openjdk-6-jre\n    $ sudo apt-get install ruby rubygems ruby-dev\n\nTo make the apache vhost config work run:\n\n::\n\n    $ sudo apt-get install libapache2-mod-proxy-html\n    $ sudo a2enmod proxy proxy_http proxy_html\n\nCheck out Adhocracy:\n\n::\n\n    $ git clone https://github.com/liqd/adhocracy\n    $ cd adhocracy\n\n    $ git submodule init\n    $ git submodule update\n\nSetup an isolated python environment to run Adhocracy\n`````````````````````````````````````````````````````\nTo install Adhocracy you need python (2.6|2.7) with PIL (python imaging) but\nno other system-packages.\n\nCompile python and PIL with the included python buildout::\n\n    $ cd python\n    $ python bootstrap.py\n    $ bin/buildout\n    $ cd ..\n\nConfigure Adhocracy as desired\n``````````````````````````````\n\nCreate a custom buildout file and customize it as desired::\n\n    $ cp buildout buildout-my.cfg\n    $ vi buildout-my.cfg\n\nInstall and start Adhocracy\n```````````````````````````\n\nRun buildout:\n\n::\n\n    $ bin/python bootstrap.py\n    $ bin/buildout -c buildout-my.cfg\n\nStart Adhocracy and dependent servers:\n\n::\n\n    $ bin/supervisord\n\nIf you do not use the buildout to compile and start the database system\n(currently only possible for PostgreSQL, but disabled by default), you\nhave to setup the Adhocracy database manually:\n\n::\n\n    $ bin/paster setup-app etc/adhocracy.ini --name=content\n\nRun Adhocracy\n-------------\n\nStart Adhocracy and all dependent servers:\n\n::\n\n    $ bin/supervisord\n\nRestart servers:\n\n::\n\n    $ bin/supervisorctl reload\n\nView the status of all servers:\n\n::\n\n    $ bin/supervisorctl status\n\nTo start/stop one server:\n\n::\n\n    $ bin/supervisorctl stop <name>\n\nStart the Adhocracy server in foreground mode:\n\n::\n\n    $ bin/supervisorctl stop adhocracy\n    $ bin/paster serve etc/adhocracy.ini\n\nBuildout configuration\n----------------------\n\n-  Read ``buildout_commmon.cfg`` and ``buildout_development.cfg`` to\n   learn all buildout configuration options.\n-  Customize ``buildout.cfg`` to change the domains, ports and server\n   versions.\n-  Instead of compiling all dependencies (postgres, solr,..) you can\n   also use system packages.\n-  Use your custom buildout file to remove the included files you do not\n   need:\n\n::\n\n    [buildout] extends = buildout\\_development.cfg parts -= postgresql\n\nDeveloper instructions\n----------------------\n\nTo use your own `fork <https://help.github.com/articles/fork-a-repo>`_\ninstead of the regular(\"upstream\") adhocracy, use\n`git remote <http://www.kernel.org/pub/software/scm/git/docs/git-remote.html>`_:\n\n::\n\n    $ git remote -v\n    origin  https://github.com/liqd/adhocracy (fetch)\n    origin  https://github.com/liqd/adhocracy (push)\n    $ git remote add USERNAME https://github.com/USERNAME/adhocracy\n    $ git push USERNAME\n\nYou can now execute ``git pull origin`` to update your local copy with\nnew upstream changes. Use\n`commit <http://www.kernel.org/pub/software/scm/git/docs/git-commit.html>`_\nand\n`push <http://www.kernel.org/pub/software/scm/git/docs/git-push.html>`_\nto record and publish your changes. As soon as you are confident that\nyou have implemented a feature or corrected a bug, create a `pull\nrequest <https://help.github.com/articles/using-pull-requests>`_ to ask\nthe core developers to incorporate your changes.\n\nAdhocracy Changelog\n===================\n\n\n2.5.3 (2015-03-08)\n------------------\n\nImprovements:\n\n- Hide google openid (deprecated by Google)\n\n- Upgrade various dependencies\n\n- Allow to not list global members in instance.members (#945)\n\n- Autoactivate Shibboleth users (#944)\n\nBug fixes:\n\n- Fix amendment w/o selection (#952)\n\n- Fix came_from encoding after register (#948)\n\n- Fix creation of static pages with database backend\n\n\n2.5.2 (2014-10-13)\n------------------\n\nImprovements:\n\n- Allow to define post_logout_url.\n\n- Allow to hide category navigation item.\n\n- Allow to restrict locale choice.\n\n- Sort milestones by date, secondarily by title.\n\nBug fixes:\n\n- Fix badge form in overlay after validation error. (#943)\n\n- Fix \"Comment\" translation. (#941)\n\n- Redirect to entity_url after badge edit. (#940)\n\n- Fix propose_join in non-instance case.\n\n\n2.5.1 (2014-08-06)\n------------------\n\nImprovements:\n\n- Allow to disable SSL verification for Velruse.\n\n- Show short category description in category description view. (#934)\n\nBug fixes:\n\n- Disable broken mako debugging. (#939)\n\n- Fix config.get_value allow_overwrite for non-instance cases. (#938, #937)\n\n- Fix display of user role in listing. (#936)\n\n- Fix AuthCheck.propose_login. (#935)\n\n- Fix test suite by making Adhocracy egg depend on raven.\n\n\n2.5.0 (2014-07-20)\n------------------\n\nImprovements:\n\n- Allow to log to sentry. (#930, #933)\n\n- Allow to hide milestone timeline. (#931)\n\n\nBug fixes:\n\n- No email uniqueness on database level (#932, fixes #790, #364)\n\n- Load captchasdotnet with SSL.\n\n- Raise meaningful exception if amendment doesn't have a selection. (#929)\n\n- Fix category page if long description is empty. (#928)\n\n- Fix category events. (#927)\n\n- Fix iframe setup. (#926)\n\n\n2.4.6 (2014-06-23)\n------------------\n\nThis release contains an alembic migration which doesn't work on SQLite. SQLite\nusers can safely stamp their alembic setup instead of migrating:\n\n    bin/alembic -c etc/adhocracy.ini stamp 1e296c7f5e8c\n\n\nImprovements:\n\n- Avoid multiple submits (e.g. double-click). (#925)\n\n- Add traditional chines (Taiwan). Thanks to Charles Chuang. (#918, #924)\n\n- Allow to hide proposal comments. (#919)\n\n- Hide proposal rate_poll results (experimental). (#916)\n\n- Add permission poll.show_result.\n\n- Generic instance setting overwrites (#915). This is by default enabled for\n  the following settings:\n\n  - adhocracy.hide_individual_votes\n  - adhocracy.listings.instance_proposal.sorting\n  - adhocracy.comment_wording\n\n- Better flash messages after sending of activation links - with spam hint.\n  (#914)\n\n\nBug fixes:\n\n- Fix custom submit handlers in JavaScript in iframes.\n\n- Fix data-baseurl in overlays. This fixes JavaScript issues in overlays.\n\n- Fix pluralization issues when compiling translations.\n  (see upstream: camptocamp/c2c.recipe.msgfmt#3).\n\n\n2.4.5 (2014-06-13)\n------------------\n\nImprovements:\n\n- Better flash messages after sending of activation links - with spam hint\n\n- Allow to add html in category long_description (#913)\n\n- Open formatting links in new tab\n\nBug fixes:\n\n- Fix non-instance user badge form\n\n- Fix abuse message function\n\n- Allow advisors and higher to delete own comments by default\n\n\n2.4.4 (2014-06-05)\n------------------\n\nImprovements:\n\n- Improve fix-autojoin flash message if autojoin isn't needed.\n\nBug fixes:\n\n- Autojoin imported users after activation. (#911, #907)\n\n- Don't show sentiment in sectionpage comment edit form (#910, #899)\n\n- Proper membership check in can.proposal.create (#908)\n\n\n2.4.3 (2014-05-31)\n------------------\n\nImprovements:\n\n- Allow to disable proposal pagination on instance level. (#906)\n\n- Optionally require user to accept terms on register. (#903)\n\n- Allow to define 'hide_individual_votes' on instance level. (#897)\n\nBug fixes:\n\n- The guard decorator was not thread-safe. This allowed perpetrators to\n  let other users execute controller functions with manipulated\n  parameters. However, we could not find any siginifcant exploits based on\n  this bug. (#905)\n\n- Fix some permission checks in the context of containerpages. (#901)\n\n- Fix userbadge assignment within overlay. (#900)\n\n- Don't try to solr index form-feed characters.\n\n- Don't allow amendment creation for non-joined members.\n\n\n2.4.2 (2014-05-18)\n------------------\n\nImprovements:\n\n- Show comment and sectionpage events in category event view. (#896)\n\n- Use icon font for event and milestone icons.\n\n- New tiny row type for event view (#888)\n\n- Automatically choose button and various other colors  based on contrast.\n  (#889)\n\n- Allow to show instance list as tiles. (#890)\n\nBug fixes:\n\n- Fix Brazilian translation. (#895)\n\n- Fix regression in feedback form.\n\n- Fix message in username choice dialog after OpenID login. (#892)\n\n- Proper font invalidation\n\n- Strip HTML from description in milestone row\n\n\n2.4.1 (2014-04-30)\n------------------\n\nRelease 2.4.0 had two minor bugs which are fixed in this patch release.\n\nBug fixes:\n\n- The 2.4.0 release notes contained an error - solr reindexing requires a -c\n  parameter.\n\n- Do not fail displaying error messages.\n\n\n2.4.0 (2014-04-30)\n------------------\n\nThis update requires some manual adjustments:\n\n- The translation files (.mo) are no longer included in the repository.\n  Please run `bin/buildout install translations` to create them automatically.\n\n- A Solr reindexing is necessary: `bin/paster index -c etc/adhocracy.ini`\n\n- Due to a bug, some notifications failed to be created in the past. Please\n  run `bin/adhocpy scripts/replay_notifications.py etc/adhocracy.ini` to\n  create the missing notifications.\n\nImprovements:\n\n- Allow to configure separate domains per instance. This does not yet invlove\n  single-sign-on between different domains. (#886)\n\n- Improve error pages. (#884)\n\n- Add description, events and milestones views for categories. They are mostly\n  useful for embedding. (#883)\n\n- Add captchas.net captcha verification. (#878)\n\n- Scroll into view if needed after overlay resize. (#870)\n\n- Solr-based milestone proposal pager (#865)\n\n- Make maximum category long description length configurable. (#863)\n\n- Add a new proposal sorting which is a combination of support and impact.\n  (#858)\n\n- Document adhocracy's mime type requirements. (#862)\n\n- Document all settings in adhocracy.ini. (#857)\n\n- Allow to configure default proposal sorting. (#860, #868)\n\n- Responsive Search widget (#854)\n\n- The translation files (.mo) are now built automatically when running\n  buildout. (#741)\n\n- Show item count in a tooltip in tagcloud facet. (#851)\n\n- Better handling of connection erros with the external navigation. (#848)\n\n- Instance specific static pages (#845)\n\n- Link to category pages from proposal and page sidebars. (#847, #850)\n\n- Gitignore generated CSS. (#839)\n\n- Distinct styling for different kinds of show-hide buttons. (#841)\n\n- Hide old dates on event carousel. (#838)\n\nBug fixes:\n\n- Add a workaround for a caching issue with proposal lists if the description\n  is displayed inline.\n\n- Show 404 errors instead of blank pages on nonexistent instance subdomains.\n  (#881)\n\n- Avoid unnecessary requests on startup. (#882)\n\n- Add missing documentation for upgrading an existing adhocracy installation\n  in UPGRADING.rst . (#879)\n\n- Avoid uneccessary delegateable invalidation. This significantly improves the\n  performance of creation and update of proposals, norms and instances. (#876)\n\n- Replace only specific message variables in mass messages. This avoids errors\n  when using {}. (#875)\n\n- Allow global admins to send mass messages in hidden instances as well.\n\n- Warn user about exposing her email address when creating a message. (#873)\n\n- Fix multiple bugs in traverse_watchlist, which resulted in missing\n  notifications. (#871)\n\n- Fix multiple small issues with mass messages. (#869)\n\n- Don't query static pages in the same locale multiple times.\n\n- Make sure badge impact is commited before proposal update. (#866)\n\n- Fix some wrong redirects in badge management. (#831)\n\n- Prevent moderators to elevate their permissions. (#840)\n\n- Provide a fallback if `came_from` is missing in the velruse controller. (#853)\n\n- Fix page/proposal title validation. (#849, #852)\n\n- Various syntax fixes in INSTALL.rst, thanks to Rowan Thorpe (#843)\n\n- Fix some issues with entity deletion. (#842, #846)\n\n\n2.3.0 (2014-03-31)\n------------------\n\nImprovements:\n\n- Add external StaticPage backend which can be used with the adhocracy.kotti\n  or the adhocracy.plone backend.\n\n- Add Brazilian Portuguese translation, thanks to Fabiano Rocha. (#817)\n\n- The permission for user badge management is now separated from user group\n  management. (#837)\n\n- More work on responsive design. (#798)\n\n- Enable sectionpages by default.\n\n- Add script which allows to merge instances. (#806)\n\n- Move mass message button to members list. (#822)\n\n- Add preset \"planning ideas\". (#828)\n\n- Allow to not show instance settings after instance create.\n\n- Preview of a simple oEmbed API. (#795)\n\nBug fixes:\n\n- Fix wrong redirect after badge management. (#831)\n\n- Don't close overlay after badge management.\n\n- Fix redirect after Velruse (Facebook) login. (#830)\n\n- Fix warning if OpenID and Velruse login is disabled.\n\n- Full width instance background. (#820)\n\n- Fix certain links in overlays. (#816)\n\n- Fix advanced settings for instance admins. (#821)\n\n- Fix missing dependency in installation documentation.\n\n- Fix register page.\n\n\n2.2.1 (2014-03-21)\n------------------\n\nImprovements:\n\n- Moderators can change the instance description and some other things by\n  default.\n\n- Instance overview now displays a button to the form where it can be edited\n  for anyone with sufficient authorization.\n\n- Instance Settings now contain an embed code for the event carousel.\n\n- Several improvements concerning Facebook Login. (#813, #810)\n\n- Compass and SASS are updated to the latest versions. (#812)\n\n- Instance overview can be replaced by static pages. (#814)\n\nBug fixes:\n\n- Fix URL query parameter encoding. (#808)\n\n- Fix avatar for usernames with underscores. (#811)\n\n\n2.2.0 (2014-03-19)\n------------------\n\nImprovements:\n\n- Facebook login (#807)\n\n- Admins can give other users the permission to edit and manage badges;\n  moderators can edit and manage instances badges by default. (#805)\n\n- Clean up notification priorities and user interface for selecting a\n  priority over which users will receive an email. (#804)\n\n- You can send a message to supporters/opponents/creators of proposals. (#679)\n\n- All messages are now available in the dashboard. (#801)\n\n- Allow to display instance logo as background image instead. (#793)\n\n- Allow instance admins to choose from multiple themes. (#791)\n\n- Add a profiling middleware for simple debugging. (#792)\n\n- Allow to display tag facet filter as tag cloud. (#799)\n\n- Prepare for responsive design. (Not all widgets have been converted yet)\n  (#779, #780)\n\n- Add a event carousel widget. (#776, #794)\n\n- Allow to filter event stream by event type. (#776, #797)\n\n- Show abstract instead of truncate content in page tiles. (#777)\n\n- Add context variable \"body_css_classes\" to append context specific css\n  classes to the body tag. The default classes are:\n  * logged_in|not_logged_in,\n  * instance_key_<key>,\n  * global_nav_home|global_nav_instances,\n  * added_static_content,\n  * css_classes from the static pages backend.\n  * instance-<instance_key>\n  * controller-<controller_identifier>\n  * area-<area_identifier>\n  [joka] (#772)\n\n- Update proposal list design. (#773)\n\n- Update category page design to look more like the proposal list. (#774)\n\nBug fixes:\n\n- Rewrite internal links in overlays to point to overlays. (#571)\n\n- Avoid generic 403 error pages and display useful information instead. (#786)\n\n- Fix unicode issues with urlquote. (#782)\n\n- Strip markdown syntax on truncated texts. (#775)\n\n\n2.1.3 (2014-02-21)\n------------------\n\nImprovements:\n\n- Adopt breadcrumbs if proposal tab is disabled and category pages are enabled\n  (#768)\n\n- Hide dashboard instance chooser in single instance settings through\n  instance.index permission. (#766)\n\n- Sort milestone select items by date. (#769)\n\n- Show milestone date in milestone select. (#770)\n\n- Make user max bio length configurable. (#771)\n\nBug fixes:\n\n- Fix broken solr connection with non-ascii characters (regression introduced\n  in 2.1.2).\n\n- Fix broken registration (regression introduced in 2.1.2).\n\n- Fix build issues with non-ascii characters in scss files. (#761)\n\n- Fix flex based grid tiles in Safari. (#763)\n\n- Fix section page display issue with touch devices. (#764)\n\n\n2.1.2 (2014-02-18)\n------------------\n\nThis is mainly a bugfix release.\n\nImprovements:\n\n- a11y: Updated js.socialshareprivacy to 1.5 permits keyboard navigation.\n  (#755)\n\n- Sort instance member lists by member, not user age. (#750)\n\n- More configuration options for Shibboleth authentication.\n\nBug fixes:\n\n- Proper fallback on non-existant sort order entry. (#758)\n\n- Only display locally relevant user badges in event stream. (#754)\n\n- Remove user from member list after user left instance. (#753)\n\n- Fix instance selector in user profile. (#751)\n\n- Fix regression causing instance join to raise a 403 error.\n\n- Fix adding subcomments on touch devices. (#748)\n\n- Nicer display of grid tiles. (#757)\n\n- Fix editing of database backed static pages.\n\n\n2.1.1 (2014-02-04)\n------------------\n\nThis is a patch release which actually allows upgrading to 2.1.x with the\ninstructions given below in the `2.1.0` sections. When upgrading from 2.0.0\nto 2.1.x, simply jump to 2.1.1 directly by doing `git checkout 2.1.1`.\n\nChanges:\n\n- Make sure the `src/adhocracy/alembic/versions` directory actually exists in\n  order to make `bin/paster setup-app ...` work.\n\n- Update some dependencies.\n\n- Fix search box placeholder for instances with quotes in title. (#740)\n\n\n2.1.0 (2014-02-04)\n------------------\n\nThis upgrade only splits the SQLAlchemy-related changes from the 2.0.0 release\nin order to make sure all migrations are executed and the database remains in\na consistent state.\n\nChanges:\n\n- Update SQLAlchemy from 0.7.10 to 0.9.1.\n\n- Switch from sqlalchemy-migrate to Alembic. (#219)\n\n\nUpgrade instructions:\n~~~~~~~~~~~~~~~~~~~~~\n\nIf you haven't upgraded for a long time (say six months or more), it's best to\ndelete ``parts``, ``eggs``, ``python/python-2.7`` and ``python/parts``\ndirectories and rebuild everything according to ``INSTALLATION.rst``.\n\nIn any case, don't upgrade to 2.1.0 in one go, but upgrade to 2.0.0 first by\nrunning::\n\n    git checkout 2.0.0\n    bin/buildout\n    bin/paster setup-app etc/adhocracy.ini --name=content\n\nAnd upgrade to 2.1.0 in a second step::\n\n    git checkout 2.1.0\n    bin/buildout\n    bin/paster setup-app etc/adhocracy.ini --name=content\n\nThis makes sure the remaining sqlalchemy-migration based migrations are\nexecuted in the first step, and the Alembic environment is initialized properly\nin the second step.\n\n\n2.0.0 (2014-02-03)\n------------------\n\n- Start doing releases using semantic versioning (#77). This release's\n  changelog contains many changes from the past two years, but rather\n  incomplete.\n\n- Allow to list norms in a tiled fashion. (#714)\n\n- Add container pages. These special norms act as containers of other norms.\n  (#709)\n\n- Proposal descriptions can now be shown directly in proposal lists. (#733)\n\n- It is now possible to translate the English source strings through Transifex\n  as it is done in all other languages. In Transifex, the `en_GB` language\n  is used as the \"translated\" English langauage in contrast to the \"source\"\n  English langauage and doesn't imply that british English shall be used.\n  (#102)\n\n- Automatically crop and center uploaded images (logos etc) to the desired\n  size. (#711)\n\n- Badges can now be managed in context. (#713)\n\n- Add images and long description texts to categories. Categories can now be\n  listed and individually displayed, each showing all assigned proposals.\n  (#695)\n\n- Added user import script. (#649)\n\n- We redesigned the instance settings. The most notable change is the added\n  possibility to select presets on instance creation. (#680)\n\n  The user import and massmessage services have been moved.  They can be found\n  on the members index and instance overview, respectively.\n\n- It is now possible to follow instances. (#655)\n\n- All milestones now must have a date. (#658)\n\n- Added installation option to freeze the complete installation. (#289)\n\n- It is possible to select whether other users can edit a proposal.\n  We added an instance option to set the default value of that option. (#632)\n\n- a11y improvements.\n\n- Added replay notification script, which recreates notifications inside the\n  database which would have been created before notifications were stored in\n  the database. (#624)\n\n- We completely redesigned the user profile (#430) and dashboard (#429): User\n  can upload an avatar now (#641) and view notifications online.\n\n- Email texts are now wrapped at 78 characters per line. Long links are\n  preserved. (#593)\n\n- Added travis configuration which automatically builds Adhocracy using\n  build.sh and runs the test suite.\n\n- It is now possible to assign user badges in user import.\n  It is also possible to define additional variables which can be used in\n  the welcome email.\n\n- Added an installation option to redirect to an instance instead of showing\n  the front page. This is useful for single-instance installations. (#431)\n\n- New comment design.\n\n- Subnorms can now be displayed as sections. This way you can add a large\n  document consisting of multiple sections and have each of these sections\n  discussed separately.\n\n- It is now possible to show all open proposals in the proposal list of future\n  milestones. For milestones in the past, this doesn't have any effect. (#562)\n\n  This will be used in the following scenario:\n\n  - There's regular (offline) board meetings. These are entered as milestones.\n    During a meeting, the board shall work on as many of the highest rated,\n    non-frozen proposals as time permits.\n  - All covered proposals will be assigned to the respective milestone, marked\n    as frozen and badged as \"implemented\" (or whatever).\n  - All not covered proposals will be covered in successive meetings.\n\n- It is now possible to freeze single proposals. (#559)\n\n- Overlays have their own urls now, so you can link to them. (#553)\n\n- Add warning to users of unsupported browsers. (#111)\n\n- Better user settings layout. (#174)\n\n- Allow footer customization through static URLs. (#472)\n\n- Add custom \"show more\" markdown extension. (#120)\n\n- build.sh now has Fedora support\n\n- Refactor all CSS and some of the templates to make development and\n  theming easier. We also switched to SCSS.\n\n- Added varnish reverse proxy [joka]\n\n- Readd bin/test to run tests (wrapper for py.test) [joka]\n\n- Update python from 2.7.4 to 2.7.5. Please rebuild python:\n\n    * cd python\n    * bin/buildout\n\n  [joka]\n\n- Use pytest testrunner instead of nose. (#343)\n\n- Add shibboleth based authentication. (#359)\n\n- Allow to disable tutorials installation-wide. (#54)\n\n- Update buildout from 1.7 to 2.1.0 (#241). Rerun buildout with::\n\n      bin/buildout -n\n\n  If you have versions conflicts with distribute delete the old one::\n\n      rm -r eggs/distribute..\".\n\n  [joka]\n\n- The default way to isolate your python environment is now to compile\n  python and PIL now instead of using virtualenv::\n\n    Upgrade manual installation:\n    ----------------------------\n\n    Checkout python buildout\n\n    * git submodule init\n    * git submodule update\n\n    Compile python:\n\n    * cd python\n    * python boostrap.py && bin/buildout\n\n    Reinstall Adhocracy:\n\n    * cd ../\n    * rm -rf eggs/*\n    * bin/python bootstrap.py\n    * bin/buildout\n\n    Upgrade build.sh:\n    -----------------\n\n    * rm -rf eggs/*\n    * sh build.sh -u\n    * sh build.sh -s\n\n    [joka]\n\n- Add controversy sorting method to proposals. (#258)\n\n- Allow to hide voting lists from the UI. (#189)\n\n- Badges with thumbnails. (#191)\n\n- Option to disable registration. (#43)\n\n- Login via email address\n\n- Hierarchical categories. (#95)\n\n- Formatted norms. (#192)\n\n- Replace RabbitMQ/amqp with redis/rq (#220). This means that you have to\n  provide a working redis instance if you want to use asyncronous\n  jobs (highly recommended in production).\n  The background process that processes the jobs is renamed from\n  'background' to 'worker'. You can call it with\n  `bin/paster --plugin=adhocracy worker -c etc/adhocracy.ini`\n\n  Configuration changes:\n\n  * dropped: adhocracy.amqp.* settings are not required anymore.\n  * new: adhocracy.redis.host: An IP address redis can bind to\n    (not a hostname!)\n  * new: adhocracy.redis.port: The port redis will open\n  * new: adhocracy.redis.queue: The queue name\n\n- Mandatory email validation. (#142)\n\n- Invisible badges. (#116)\n\n- Instance-based user rating sorting. (#190)\n\n- Disallow multiple usernames with only case differences. (#171)\n\n- Dashboard style instance overview page. (#90)\n\n- Support path based instances instead of subdomain only. (#62)\n\n- Feedback instance pull in form. (#88)\n\n- Lamson mailserver dummy for development purposes.\n\n- Added facet search to the instance listing. The listing is based on solr now,\n  please reindex. [joka]\n\n- Instances can have badges now. To create instance badges use the\n  site-administration -> badges form. To assign badges use the\n  instance listing. [joka]\n\n- New config option \"adhocracy.registration.email.blacklist\" that\n  accepts a whitespace seperated list of email address and\n  blocks registrations with those. Dots will be stripped before\n  the test (to catch gmail addresses where dots are ignored by gmail).\n  [csenger]\n\n- New config option \"adhocracy.listings.instance.sorting\" that makes\n  the sort options for the instance listing configurable. This\n  possible values are: OLDEST, NEWEST, ACTIVITY and ALPHA. [csenger]\n\n- Permission change: When we test the 'norm.create' permission\n  (permission to create Norms/Topics/Themen we do no longer\n  restrict it to users who also have 'instance.admin'. The main\n  permission we check now is 'page.create'.\n\n  Please check the permission 'page.create' in your permission\n  settings (<base_url>/admin -> Permissions). [csenger]\n\n- Give the users the option to permanently activate the twitter,\n  facebook or google+ buttons. Save the setting in a wildcard\n  subdomain cookie so it is valid across all instances.\n\n  This requires a updated js.socialshareprivacy to work with\n  our auth cookie. [csenger]\n\n- Add the possibility to overwrite templates in <adhocracy.site>/templates\n  directory (like it's possible for static resources and static pages already.\n  New templates there need a server restart to be picked up.\n  [csenger]\n\n- Deliver (almost) all resources with fanstatic. [csenger]\n\n- Delegateables can have category badges. [joka]\n\n- Instances can have badges, they are only valid inside that instance. [joka]\n\n- Added option to set the smtp port. [joka]\n\n- Many bugfixes.\n\n- Many other unmentioned improvements.\n\n\n1.2a4\n-----\n\n- Tooltips use jquery tools now. [joka]\n- Open helper link, login and register form with overlay. [joka]\n- Recaptcha support (disabled by default). [joka]\n- Proposals can have badgets #263. [joka]\n\n\n1.2a1\n-----\n\n- Users can have badgets #214. [carsten]\n- Proposal listing with natural sort #212. [joka]\n\n\n1.1 (2010-12-05)\n----------------\n\n- Join \"Goal\" and \"Implementation\" pages on proposals.\n- Migrate from whoosh to solr.\n- Allow single-instance mode of operation.\n- Allow per-instance deactivation of norms.\n- Remove wiki from system.\n- Change from cron-initiated regular background processing.\n  to continuous background queue polling process.\n- Add INSTALL.txt and CHANGES.txt.\n- Change from BSD license to AGPL-3.\n- Update to SQLAlchemy 0.6.\n- Many smaller bug fixes.\n\n\n1.0 (2010-07-24)\n----------------\n\n- Initial stable release.\n\nAdhocracy is licensed under the GNU Affero General Public License, Version 3,\nwhich can be found in LICENSE.txt\n\nAdhocracy is Copyright 2009, 2010, 2011, 2012, 2013, 2014 by\n\nFriedrich Lindenberg\nJoscha Krutzki\nCarsten Senger\nNicolas Dietrich\nPhilipp Hagemeister\nTobias Bengfort\n\nand others. Check git history to get a list of all contributors.",
        "url": "http://pypi.python.org/pypi/adhocracy",
        "summary": "Policy drafting and decision-making web platform",
        "command": "pip install 'adhocracy'"
      },
      "adhocracy-Pylons": {
        "name": "adhocracy-pylons",
        "description": "Pylons\n======\n\nThe Pylons web framework is designed for building web applications and\nsites in an easy and concise manner. They can range from as small as a\nsingle Python module, to a substantial directory layout for larger and\nmore complex web applications.\n\nPylons comes with project templates that help boot-strap a new web\napplication project, or you can start from scratch and set things up\nexactly as desired.\n\n\nExample `Hello World`\n---------------------\n\n..\n\n    from paste.httpserver import serve\n    from pylons import Configurator, Response\n\n    class Hello(object):\n        def __init__(self, request):\n            self.request = request\n\n        def index(self):\n            return Response(body=\"Hello World!\")\n\n\n    if __name__ == '__main__':\n        config = Configurator()\n        config.begin()\n        config.add_handler('home', '/', handler=Hello, action='index')\n        config.end()\n        serve(config.make_wsgi_app(), host='0.0.0.0')\n\n\nCore Features\n-------------\n\n* A framework to make writing web applications in Python easy\n\n* Utilizes a minimalist, component-based philosophy that makes it easy to\n  expand on\n\n* Harness existing knowledge about Python\n\n* Extensible application design\n\n* Fast and efficient, an incredibly small per-request call-stack providing\n  top performance\n\n* Uses existing and well tested Python packages\n\n\nCurrent Status\n--------------\n\nPylons 1.0 series is stable and production ready. The Pylons Project now\nmaintains the Pyramid web framework for future development. Pylons 1.0 users\nshould strongly consider using it for their next project.\n\n\nDownload and Installation\n-------------------------\n\nPylons can be installed with `Easy Install\n<http://peak.telecommunity.com/DevCenter/EasyInstall>`_ by typing::\n\n    > easy_install Pylons\n\nDependant packages are automatically installed from\nthe `Pylons download page <http://pylonshq.com/download/>`_ .\n\n\nDevelopment Version\n-------------------\n\nPylons development uses the Mercuial distributed version control system (DVCS)\nwith BitBucket hosting the main repository here:\n\n    `Pylons Bitbucket repository <https://github.com/Pylons/pylons>`_",
        "url": "http://pypi.python.org/pypi/adhocracy-Pylons",
        "summary": "Pylons Web Framework",
        "command": "pip install 'adhocracy-Pylons'"
      },
      "adhocracy-pysqlite": {
        "name": "adhocracy-pysqlite",
        "description": "Python interface to SQLite 3\n\npysqlite is an interface to the SQLite 3.x embedded relational database engine.\nIt is almost fully compliant with the Python database API version 2.0 also\nexposes the unique features of SQLite.",
        "url": "http://pypi.python.org/pypi/adhocracy-pysqlite",
        "summary": "DB-API 2.0 interface for SQLite 3.x",
        "command": "pip install 'adhocracy-pysqlite'"
      },
      "adi.commons": {
        "name": "adi.commons",
        "description": "Introduction\n============\n\nSome very common filesystem-operations, wrapped into functions with names to\nbe easily remembered, and adjustments for wanted default behaviours, such as:\nWhen attempting to delete a file which doesn't exist, fail silently.\n\n\nChangelog\n=========\n\n0.5 (150921)\n-----------\n\n- Let addDirs() fail silently, if the directory to create, exists already.\n- Better hlp-msgs.\n\n\n0.4 (150920)\n-----------\n\n- Really adjust MANIFEST (good morning Kreuzberg)\n\n\n0.3 (150920)\n-----------\n\n- Adjust MANIFEST\n\n\n0.2 (150920)\n-----------\n\n- Add MANIFEST\n\n\n0.1 (150920)\n-----------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.commons",
        "summary": "Some helpers-methods for often repeating and general purposes, to be used of other eggs.",
        "command": "pip install 'adi.commons'"
      },
      "adict": {
        "name": "adict",
        "description": "Usage::\n\n    pip install adict\n    from adict import adict\n\n    d = adict(a=1)\n    assert d.a == d['a'] == 1\n\nSee all features, including ``ajson()`` in ``adict.py:test()``.\n\nhttps://github.com/denis-ryzhkov/adict/blob/master/adict.py#L46",
        "url": "http://pypi.python.org/pypi/adict",
        "summary": "Dict with attr access to keys.",
        "command": "pip install 'adict'"
      },
      "aDict2": {
        "name": "adict2",
        "description": "=====\naDict\n=====\n\naDict provides interface to reading and writing aDict dictionary format.\nTypical usage::\n\n    from adict import *                # data classes\n    from adict.parser import Parser    # text to data\n    from adict.printer import Printer  # data to text\n    \n    with open('some file') as f:\n        a = Article('Python')\n        a.classes.append('n')\n        a.transcriptions.append('Л€paЙЄОёЙ™n')\n        d1 = Definition('a kind of programming language')\n        d2 = Definition('a kind of Snake')\n        d2.links.append('hyperonym', 'Snake')\n        a.content = [d1, d2]\n        \n        dictionary = Parser(f).parse()\n        dictionary.articles.append(a)\n    \n    with open('some other file', 'w') as f:\n        f.write(str(Printer(dictionary)))\n\naDict format specification\n==========================\n\nвЂ¦in English has not written yet. :)\n\nHowever, I think, this format is pretty simple to understand by trial and error or by looking on this implementation.\n\n\nContributors\n============\n\nOnly me = arseniiv so far.",
        "url": "http://pypi.python.org/pypi/aDict2",
        "summary": "aDict dictionary format handling",
        "command": "pip install 'aDict2'"
      },
      "adi.devgen": {
        "name": "adi.devgen",
        "description": "Introduction\n============\n\nYet another command-line Plone-Add-On-Generator, just the way I like it:\n\nNo dependencies, no possible conflicts, some Python-methods, that's all.\n\n\n\nInstallation\n=============\n\n    pip install adi.devgen\n\n\nAlternatively add `adi.devgen` as an egg to your buildout, then\nthe `devgen`-executable should be available in its bin-directory.\n\n\n\nUsage\n=====\n\nType the command alone, to get a help-text, what it can do for you:\n\n    $ devgen\n\n\nThat'll also lists the available generator-functions, to get a function's help-text, type:\n\n    $ devgen [FUNCTION_NAME]\n\n\nExamples\n========\n\nCreate boilerplate for an addon, that can do nothing, but be installed in a Plonesite:\n\n    $ devgen addProfileSkel your.addon\n\n\nCreate it not in the directory, where you are, but somewhere else:\n\n    $ devgen addProfileSkel your.addon /some/where/else\n\n\nRegister another addon as a dependency to your addon:\n\n    $ devgen addDep collective.bestaddonever your.addon\n\nOr, first locate into your addon, then you can omit the appended path (defaults to '.'):\n\n    $ cd your.addon\n    $ devgen addDep collective.bestaddonever\n\n\nCreate an installable Plone-Addon, with a stylesheet, a javascript and a template in a skin folder:\n\n    $ devgen addSkinSkel your.addon\n\nIn contrary to browser-based resources, you won't need to empty the browser's cache on a reload, after changing your stylesheet or javascript.\n\n\nCreate an installable Plone-Addon, with a stylesheet and a javascript in a browser's resource-folder.\n\n    $ devgen addBrowserSkel your.addon\n\n\nAdd docs-folder and read defaults for setup.py of a config:\n\n    $ devgen addMetaSkel\n\nIf a file '~/.buildout/devgen.cfg' is present, values will be read of it and inserted to setup.py. Its format is expected to be like:\n\nauthor=Arbi Trary\n\nauthor_email=arbi@tra.ry\n\nurl=https://github.com/arbitrary/your.addon\n\n\nTODO\n====\n\n- Regard more than one dotted namespace for addon.\n\n- Split functions into smaller reusable chunks.\n\n- Possibly transfer:\nhttps://github.com/ida/skriptz/blob/master/plone/Dexterity/addField.py\n\n\nChangelog\n=========\n\n0.7 (150924)\n------------\n\n- Fix missing import and typo in setup.py-generation, which broke addons-installs.\n\n\n0.6 (150923)\n------------\n\n- Update README, improve installPlone().\n\n\n0.5 (150921)\n------------\n\n- Fix imports, better hlp-msgs, improve installPlone().\n\n\n0.4 (150920)\n------------\n\n- Update README\n\n\n0.3 (150920)\n------------\n\n- Fix changed import-paths.\n\n\n0.2 (150920)\n------------\n\n- Add adi.commons as dependency.\n\n\n0.1 (150920)\n------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.devgen",
        "summary": "Misc helper-scripts for creating and expanding Plone-Add-Ons.",
        "command": "pip install 'adi.devgen'"
      },
      "adi.dropdownmenu": {
        "name": "adi.dropdownmenu",
        "description": "Introduction\n============\n\nThis product uses Products.ContentWellPortlets to place a collective.portlet.sitemap above the columns and gives the dropdown-effect via css.\n\nThis way, your folder structure will be mirrowed in the dropdown \n\nThe depth and target-folder can be configured via the sitemap-portlets userinterface.\n\n\nInstallation\n============\n\nIn your buildout.cfg add 'adi.dropdownmenu'.\n\n\nDependencies\n============\n\n- Products.ContentWellPortlets\n\n- collective.portlet.sitemap\n\nCredits\n=======\n\nGlued together by Ida Ebkes.\n\nIn kind cooperation with Alterway, the creators of collective.portlet.sitemap, namely Gilles Lenfant.\n\nThe Weblion's crowd for developing Products.ContentWellPortlets.\n\nAnd of course the whole plone community, especially the core developers.\n\nChangelog\n=========\n\n0.5 (2012-05-16)\n-------------------\n\n- More decent CSS to give better starting point for own styling [ida]\n\n\n0.4 (2012-02-01)\n-------------------\n\n- really hide globalnav (forgot config in last release) [ida]\n\n0.3 (2012-01-29)\n-------------------\n\n- Deassign collective.portlet.sitemap in left column. [ida]\n\n- Hide default globalnav-viewlet. [ida] \n\n- Unlimited css-sublevel-depth-support. [ida]\n\n- Styling for top-ul and visualize selected toplevel. [ida]\n\n\n0.2 (2012-01-07)\n-------------------\n\n- Extended CSS to support up to two sublevels instead of one.\n\n\n0.1 (2012-01-05)\n-------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.dropdownmenu",
        "summary": "A dropdownmenu that is configurable for site administrators and mirrows your folderstructures.",
        "command": "pip install 'adi.dropdownmenu'"
      },
      "adi.fullscreen": {
        "name": "adi.fullscreen",
        "description": "Introduction\n============\n\nThis Plone-add-on supplies a fullscreen-button \nbelow the title of any plone article, symbolized with expanding\nand collapsing arrows.\n\nThe button consists of four unicode-arrow-characters, so can easily\nobtain visual control over the element via, f.e. change color, include \na background-image, or such.\n\nWhen clicked, left- and right-columns and top- and footer-elements are \nhidden and the main column expands to full width and height of the window.\n\nOn reload or calling another page, the view falls back to non-fullscreen \nin order to not accidently hide releveant context information, if the \nuser forgets being in fullscreenmode.\n\nPlease note, that the term 'fullscreen' here doesn't mean, the browserwindow \ndissapears, but any element but the actual article is hidden, which let's \nyou focus more on the content. For the former you can also just user the \nfulscreenmode of your browser, conventionally accessible via the F11-key.\n\nChangelog\n=========\n\n0.2 (2013-03-10)\n----------------\n\n- Also hide top- and footer-elements on fullscreen. [ida]\n\n- Replaced bg-img with unicode-characters (arrows). [ida]\n\n\n\n0.1 (2012-01-02)\n-------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.fullscreen",
        "summary": "Give the possibilty of fullscreenmode for plonsite by click.",
        "command": "pip install 'adi.fullscreen'"
      },
      "adi.init": {
        "name": "adi.init",
        "description": "Introduction\n============\n\nDeletes Plone's default contents:\n- Users, news, events and front-page\n\nDeletes Plone's default portlets:\n- Navigation, events and news\n\n\nChangelog\n=========\n\n0.4 (2012-12-02)\n----------------\n\n- Pypi release [ida]\n\n\n0.3 (2012-05-18)\n----------------\n\n- Added MAINIFEST.in [ida]\n\n\n0.2 (2012-05-18)\n----------------\n\n- Corrective release, missing files. [ida]\n\n\n0.1 (2012-05-17)\n----------------\n\n- Deletes Plone's default portlets 'navigation', 'events' and 'news'\n\n- Deletes Plone's default contents 'front-page', 'events', 'news' and 'Members'\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.init",
        "summary": "Deletes Plone's default contents",
        "command": "pip install 'adi.init'"
      },
      "adios": {
        "name": "adios",
        "description": "ADIOS Python/Numpy wrapper\n-----------------\n\nThis directory contains the codes for the ADIOS Python/Numpy wrapper\nto call the native ADIOS library. This module is built by Cython.\n\nThis module requires ADIOS built with the GNU C compiler with\nrelocatable codes. Add -fPIC flag to CFLAGS before configuring ADIOS.\n\n== Quick install with pip ==\n\nADIOS Python wrapper can be installed with pip. Check if pip is\ninstalled already. Otherwise, install pip first:\n\n$ wget https://bootstrap.pypa.io/get-pip.py\n$ sudo python get-pip.py\nOr,\n$ python get-pip.py --user\nto install in a local directory, $HOME/.local\n\nBefore installing ADIOS Python wrappers, make sure Numpy and MPI4Py\ninstalled. Otherwise, install them as follows:\n\n$ pip install numpy\n$ pip install mpi4py\n\nThen, install Adios and Adios-MPI wrapper as follows:\n\n$ pip install adios\n$ pip install adios_mpi\n\nIf you want to install in a custom directory, use the following:\n$ pip install --install-option=\"--prefix=$PREFIX\" adios\n$ pip install --install-option=\"--prefix=$PREFIX\" adios_mpi\n\n== Build and install with make ==\n\nA Makefile is included for building. The following commands will\ndisplay instructions on how to build and install python wrappers for\nAdios.\n\n$ make\n$ make install\n\nHave 'adios_config' and 'python' in the path and run\n\n$ make python\n\nIf you need a MPI-enabled ADIOS wrapper, which requires MPI4Py, type\nthe following:\n\n$ make MPI=y python\n\nAfter successful building, you can install in a python path. There are\nthree options\n\n$ python setup.py install\n\nwhich will install python's default installation location. This may\nrequire an admin privilege.\n\nYou may want to use a custom directory to install. Type\n\n$ python setup.py install --prefix=/dir/to/install\n\nand append the directory to the PYTHONPATH environment variable\n\nYou can also install in your local directory, run\n\n$ python setup.py install --user\n\n\n== Test cases and examples ==\n\nTest cases and example files are located in tests and example\ndirectory.\n\n\n== Compile with Cython (only for developers) ==\n\nThe C++ code (adios.cpp and adios_mpi.cpp) has been already generated\nby with Cython (version 0.20.1) and included here. Just in case to\nreproduce the C++ code, try the following command. Otherwise, one can\nskip this part.\n\n$ make CYTHON=y python\n\nfor the serial version of Adios wrapper. If you need to generated C++\nfor MPI-enabled version, try the following\n\n$ make CYTHON=y MPI=y python\n\n\n== Upload to PyPI ==\n\nCreate $HOME/.pypirc as follows:\n[distutils] \n    index-servers =\n        pypi\n\n[pypi]\n    repository: https://pypi.python.org/pypi\n    username: {{your_username}}\n    password: {{your_password}}\n\nThen, do the followings:\n$ python setup.py register \n$ python setup.py sdist upload\n\n\n== Build Document ==\n\nNeed sphinx. Install as follows:\n$ pip install Sphinx\n\n== Trouble Shooting ==\n\n-. Custom MPICC and MPICXX\n\nIf one needs to use a custom MPICC and MPICXX command (e.g., Titan),\nthen use the following command:\n\n$ python setup_mpi.py build_ext --mpicc=cc --mpicxx=CC\n\nOr, to do with pip, try:\n\n$ pip --global-option=build_ext \\\n      --global-option=--mpicc=cc --global-option=--mpicxx=CC adios\n\n-. Import error due to undefined \"clock_gettime\" symbol\n\nWhen getting the following error:\n\n$ python test_adios.py Traceback (most recent call last):\n  File \"test_adios.py\", line 8, in <module>\n      import adios as ad\n      ImportError: /path/to/adios.so: undefined symbol: clock_gettime\n\nTry to use the following command to install:\n\n$ pip install --global-option build_ext --global-option -lrt adios\n$ pip install --global-option build_ext --global-option -lrt adios_mpi\n\n-. \"Could not find any downloads that satisfy the requirement\" with pip\n\nIf the error is caused by a certificate error, then, try \n\n$ wget http://curl.haxx.se/ca/cacert.pem\n$ pip --cert cacert.pem search adios\n$ pip --cert cacert.pem install adios\n",
        "url": "http://pypi.python.org/pypi/adios",
        "summary": "Python Module for Adios",
        "command": "pip install 'adios'"
      },
      "adios_mpi": {
        "name": "adios_mpi",
        "description": "ADIOS Python/Numpy wrapper\n-----------------\n\nThis directory contains the codes for the ADIOS Python/Numpy wrapper\nto call the native ADIOS library. This module is built by Cython.\n\nThis module requires ADIOS built with the GNU C compiler with\nrelocatable codes. Add -fPIC flag to CFLAGS before configuring ADIOS.\n\n== Quick install with pip ==\n\nADIOS Python wrapper can be installed with pip. Check if pip is\ninstalled already. Otherwise, install pip first:\n\n$ wget https://bootstrap.pypa.io/get-pip.py\n$ sudo python get-pip.py\nOr,\n$ python get-pip.py --user\nto install in a local directory, $HOME/.local\n\nBefore installing ADIOS Python wrappers, make sure Numpy and MPI4Py\ninstalled. Otherwise, install them as follows:\n\n$ pip install numpy\n$ pip install mpi4py\n\nThen, install Adios and Adios-MPI wrapper as follows:\n\n$ pip install adios\n$ pip install adios_mpi\n\nIf you want to install in a custom directory, use the following:\n$ pip install --install-option=\"--prefix=$PREFIX\" adios\n$ pip install --install-option=\"--prefix=$PREFIX\" adios_mpi\n\n== Build and install with make ==\n\nA Makefile is included for building. The following commands will\ndisplay instructions on how to build and install python wrappers for\nAdios.\n\n$ make\n$ make install\n\nHave 'adios_config' and 'python' in the path and run\n\n$ make python\n\nIf you need a MPI-enabled ADIOS wrapper, which requires MPI4Py, type\nthe following:\n\n$ make MPI=y python\n\nAfter successful building, you can install in a python path. There are\nthree options\n\n$ python setup.py install\n\nwhich will install python's default installation location. This may\nrequire an admin privilege.\n\nYou may want to use a custom directory to install. Type\n\n$ python setup.py install --prefix=/dir/to/install\n\nand append the directory to the PYTHONPATH environment variable\n\nYou can also install in your local directory, run\n\n$ python setup.py install --user\n\n\n== Test cases and examples ==\n\nTest cases and example files are located in tests and example\ndirectory.\n\n\n== Compile with Cython (only for developers) ==\n\nThe C++ code (adios.cpp and adios_mpi.cpp) has been already generated\nby with Cython (version 0.20.1) and included here. Just in case to\nreproduce the C++ code, try the following command. Otherwise, one can\nskip this part.\n\n$ make CYTHON=y python\n\nfor the serial version of Adios wrapper. If you need to generated C++\nfor MPI-enabled version, try the following\n\n$ make CYTHON=y MPI=y python\n\n\n== Upload to PyPI ==\n\nCreate $HOME/.pypirc as follows:\n[distutils] \n    index-servers =\n        pypi\n\n[pypi]\n    repository: https://pypi.python.org/pypi\n    username: {{your_username}}\n    password: {{your_password}}\n\nThen, do the followings:\n$ python setup.py register \n$ python setup.py sdist upload\n\n\n== Build Document ==\n\nNeed sphinx. Install as follows:\n$ pip install Sphinx\n\n== Trouble Shooting ==\n\n-. Custom MPICC and MPICXX\n\nIf one needs to use a custom MPICC and MPICXX command (e.g., Titan),\nthen use the following command:\n\n$ python setup_mpi.py build_ext --mpicc=cc --mpicxx=CC\n\nOr, to do with pip, try:\n\n$ pip --global-option=build_ext \\\n      --global-option=--mpicc=cc --global-option=--mpicxx=CC adios\n\n-. Import error due to undefined \"clock_gettime\" symbol\n\nWhen getting the following error:\n\n$ python test_adios.py Traceback (most recent call last):\n  File \"test_adios.py\", line 8, in <module>\n      import adios as ad\n      ImportError: /path/to/adios.so: undefined symbol: clock_gettime\n\nTry to use the following command to install:\n\n$ pip install --global-option build_ext --global-option -lrt adios\n$ pip install --global-option build_ext --global-option -lrt adios_mpi\n\n-. \"Could not find any downloads that satisfy the requirement\" with pip\n\nIf the error is caused by a certificate error, then, try \n\n$ wget http://curl.haxx.se/ca/cacert.pem\n$ pip --cert cacert.pem search adios\n$ pip --cert cacert.pem install adios\n",
        "url": "http://pypi.python.org/pypi/adios_mpi",
        "summary": "Python Module for Adios MPI",
        "command": "pip install 'adios_mpi'"
      },
      "adi.playlist": {
        "name": "adi.playlist",
        "description": "Introduction\n============\n\nA Plone add-on to turn a folder holding audio-files into a playlist.\n\n\nUsage\n=====\n\nFill a folder with audiofiles, select 'adi_playlist' of the \"Display\"-dropdown-menu to change the view of the folder and a playlist will be shown.\n\nDefault behaviour is to play the list until its end, one track after another, optionally click the inifinity-symbol to play the list infinitely in a loop.\n\nYou can use the space-bar to play/pause the current track, the tab-key to walk through the tracks and Enter-key for starting the selected track.\n\n\nMotivation\n==========\n\nMy dear sister Angela, who likes to turn the tables and wanted a non-proprietary solution to have her sets \"in the cloud\" with a decent player avaible right away.\n\n\nBackground\n==========\n\nThis product takes advantage of browser-native audio-players, using the audio-tag introduced with HTML5 and the fact that all major browsers support this by now, dropping the need to provide a serverside-player.\n\nHowever there are restrictions of supporting all of the possible audio-file-formats, depending on the browser's capabilities or choosen lack of support.\n\nThe add-on was written to use in conjunction with OGG-formats ('.ogg'-extension), expressing the love of the author for open (=non-proprietary) standards, dropping support to Safari, the only major-browser not supporting Vorbis.\n\nThis leaves out support for Safari, yet it should be fairly easy enough extending this add-on to hold each track in two formats, the other satisfying Safari and distinct which format to use, by checking which browser the client uses.\n\n\nUsed technique\n==============\n\nECMAscript\n\n\nAuthor\n======\n\nIda Ebkes, 2014, <contact@ida-ebkes.eu>\n\n\nCredits\n=======\n\njQuery, which made writing this a breeze.\n\n\nFurthermore\n===========\n\nHave a look at collective.transcode.star, if you want your arbitrary audio-formats transformed to OGG-format (or another) during upload, using beloved ffmpeg.\n\nChangelog\n=========\n\n0.3 (2014-06-22)\n-------------------\n\n- Adjust MANIFEST and remove trash.\n\n\n\n0.2 (2014-06-22)\n-------------------\n\n- Add MANIFEST.in and repo-url.\n\n\n\n0.1 (2014-06-20)\n-------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.playlist",
        "summary": "Create a playlist in a folder filled with audio-files, using HTML5's audio-tag.",
        "command": "pip install 'adi.playlist'"
      },
      "ADiPy": {
        "name": "adipy",
        "description": "==============================================\nADiPy, Automatic Differentiation for Python\n==============================================\n\nADiPy is a fast, pure-python automatic differentiation (AD) library. This \npackage provides the following functionality:\n\n- Arbitrary order univariate differentiation\n- First-order multivariate differentiation\n- Univariate Taylor polynomial function generator\n- Jacobian matrix generator\n- Compatible linear algebra routines\n\nInstallation\n------------\n\nTo install ``adipy``, simply do one of the following in a terminal window \n(administrative priviledges may be required):\n\n- Download the tarball, unzip, then run ``python setup.py install`` in the \n  unzipped directory.\n- Run ``easy_install [--upgrade] adipy``\n- Run ``pip install [--upgrade] adipy``\n\nWhere to Start\n--------------\n\nTo start, we use the simple import::\n\n    from adipy import *\n\nThis imports the necessary constructors and elementary functions (sin, exp,\nsqrt, etc.) as well as ``np`` which is the root NumPy module.\n\nNow, we can construct AD objects using either ``ad(...)`` or ``adn(...)``. For\nmultivariate operations, it is recommended to construct them all at once using\nthe ``ad(...)`` function, but this is not required. The syntax is only a little\nmore complicated if they are initialized separately.\n\nUnivariate Examples\n-------------------\n\nHere are some examples of univariate operations::\n\n    # A single, first-order differentiable object\n    x = ad(1.5)\n    \n    y = x**2\n    print y\n    # output is: ad(2.25, array([3.0]))\n    \n    # What is dy/dx?\n    print y.d(1)  \n    # output is: 3.0\n    \n    z = x*sin(x**2)\n    print z  \n    # output is: ad(1.1671097953318819, array([-2.0487081053644052]))\n    \n    # What is dz/dx?\n    print z.d(1)  \n    # output is: -2.0487081053644052\n    \n    # A single, fourth-order differentiable object\n    x = adn(1.5, 4)\n    \n    y = x**2\n    print y  \n    # output is: ad(2.25, array([ 3.,  2.,  0., -0.]))\n    \n    # What is the second derivative of y with respect to x?\n    print y.d(2)  \n    # output is: 2.0\n    \n    z = x*sin(x**2)\n    print z  \n    # output is: \n    # ad(1.1671097953318819, array([  -2.04870811,  -16.15755076,  -20.34396265,  194.11618384]))\n    \n    # What is the fourth derivative of z with respect to x?\n    print z.d(4)  \n    # output is: 194.116183837\n\nAs can be seen in the examples, when an AD object is printed out, you see two\nsets of numbers. The first is the nominal value, or the zero-th derivative.\nThe next set of values are the 1st through the Nth order derivatives, evaluated\nat the nominal value.\n\nMultivariate Examples\n---------------------\n\nFor multivariate sessions, things look a little bit different and can only\nhandle first derivatives (for the time being), but behave similarly::\n\n    x = ad(np.array([-1, 2.1, 0.25]))\n    \n    y = x**2\n    print y\n    # output is: \n    # ad(array([ 1.    ,  4.41  ,  0.0625]), array([[[-2. ,  0. ,  0. ],\n    #                                                [-0. ,  4.2,  0. ],\n    #                                                [-0. ,  0. ,  0.5]]]))\n\nThis essentially just performed the ``**2`` operator on each object individually,\nso we can see the derivatives for each array index and how they are not\ndependent on each other. Using standard indexing operations, we can access the\nindividual elements of an AD multivariate object::\n\n    print x[0]\n    # output is:\n    # ad(-1, array([ 1., 0., 0.]))\n    \nWhat if we want to use more than one AD object in calculations? Let's see what \nhappens::\n\n    z = x[0]*sin(x[1]*x[2])\n    print z\n    # output is:\n    # ad(-0.50121300467379792, array([[ 0.501213  , -0.21633099, -1.81718028]]))\n\nThe result here shows both the nominal value for z, but also the partial\nderivatives for each of the x values. Thus, dz/dx[0] = 0.501213, etc. \n\nJacobian\n--------\n\nIf we have multiple outputs, like::\n\n    y = [0]*2\n    y[0] = x[0]*x[1]/x[2]\n    y[1] = -x[2]**x[0]\n\nwe can use the ``jacobian`` function to summarize the partial derivatives for\neach index of y::\n\n    print jacobian(y)\n    # output is: [[  8.4         -4.          33.6       ]\n    #             [  5.54517744   0.          16.        ]]\n\nJust as before, we can extract the first partial derivatives::\n\n    print z.d(1)\n    # output is: [ 0.501213   -0.21633099 -1.81718028]\n    \nFor the object y, we can't yet use the ``d(...)`` function yet, because it is\ntechnically a list at this point. However, we can convert it to a single,\nmultivariate AD object using the ``unite`` function, then we'll have access\nto the ``d(...)`` function. The ``jacobian`` function's result is the same in \nboth cases::\n\n    y = unite(y)\n    print y.d(1)\n    # output is: [[  8.4         -4.          33.6       ]\n    #             [  5.54517744   0.          16.        ]]\n\n    print jacobian(y)\n    # output is: [[  8.4         -4.          33.6       ]\n    #             [  5.54517744   0.          16.        ]]\n\nLike was mentioned before, multivariate sessions can initialize individual\nindependent AD objects, though not quite as conveniently as before, using\nthe following syntax::\n\n    x = ad(-1, np.array([1, 0, 0]))\n    y = ad(2.1, np.array([0, 1, 0]))\n    z = ad(0.25, np.array([0, 0, 1]))\n    \nThis allows all the partial derivatives to be tracked, noted at the respective\nunitary index at initialization. Conversely to singular construction, we can\nbreak-out the individual elements, if desired::\n\n    x, y, z = ad([np.array([-1, 2.1, 0.25]))\n    \nAnd the results are the same.\n\nUnivariate Taylor Series Approximation\n--------------------------------------\n\nFor univariate functions, we can use the ``taylorfunc`` function to generate\nan callable function that allows approximation to some specifiable order::\n\n    x = adn(1.5, 6)  # a sixth-order AD object\n    z = x*sin(x**2)\n    fz = taylorfunc(z, at=x.nom)  \n\nThe \"at\" keyword designates the point that the series is expanded about, which\nwill likely always be at the nominal value of the original independent AD\nobject (e.g., ``x.nom``). Now, we can use ``fz`` whenever we need to \napproximate ``x*sin(x**2)``, but know that the farther it is evaluated from\n``x.nom``, the more error there will be in the approximation.\n\nIf Matplotlib is installed, we can see the difference in the order of the\napproximating Taylor polynomials::\n\n    import matplotlib.pyplot as plt\n    xAD = [adn(1.5, i) for i in xrange(1, 7)] # a list of ith-order AD objects\n    def z(x):\n        return x*sin(x**2)\n\n    x = np.linspace(0.75, 2.25)\n    plt.plot(x, z(x), label='Actual Function')\n    for i in xrange(len(xAD)):\n        fz = taylorfunc(z(xAD[i]), at=xAD[i].nom)\n        plt.plot(x, fz(x), label='Order %d Taylor'%(i+1))\n\n    plt.legend(loc=0)\n    plt.show()\n\n.. image:: https://raw.github.com/tisimst/adipy/master/taylorfunc_example.png\n\nNotice that at x=1.5, all the approximations are perfectly accurate (as we \nwould expect) and error increases as the approximation moves farther from that\npoint, but less so with the increase in the order of the approximation.\n\nLinear Algebra\n--------------\n\nSeveral linear algebra routines are available that are AD-compatible:\n\n- Decompositions\n\n  - Cholesky (``chol``)\n  - QR (``qr``)\n  - LU (``lu``)\n\n- Linear System solvers\n\n  - General solver, with support for multiple outputs (``solve``)\n  - Least squares solver (``lstsq``)\n  - Matrix inverse (``inv``)\n  \n- Matrix Norms\n\n  - Frobenius norm, or 2-norm (``norm``)\n\nThese require a separate import ``import adipy.linalg``, then they can be\nusing something like ``adipy.linalg.solve(...)``.\n\nSee the source code for relevant documentation and examples. If you are \nfamiliar with NumPy's versions, you will find these easy to use.\n\nSupport\n-------\n\nPlease contact the `author`_ with any questions, comments, or good examples of\nhow you've used ``adipy``!\n\nLicense\n-------\n\nThis package is distributed under the BSD License. It is free for public and\ncommercial use and may be copied royalty free, provided the author is given\ncredit.\n\n.. _author: mailto:tisimst@gmail.com",
        "url": "http://pypi.python.org/pypi/ADiPy",
        "summary": "Automatic Differentiation for Python",
        "command": "pip install 'ADiPy'"
      },
      "adi.revertorder": {
        "name": "adi.revertorder",
        "description": "Introduction\n============\n\nSets the position of any new born content-item (Archetypes&Dexterity) to be\nthe first child of its parent, in order to prepend, instead of appending it,\nlike it is the default behaviour.\n\n\nChangelog\n=========\n\n1.2 (150924)\n-------------------\n\n- Also regard Dexterity-based contenttypes.\n\n\n1.1 (150924)\n-------------------\n\n- Typos, add author.\n\n\n1.0dev (unreleased)\n-------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.revertorder",
        "summary": "A Plone addon, to prepend any newly created content-item to its siblings, instead of appending it.",
        "command": "pip install 'adi.revertorder'"
      },
      "adi.samplecontent": {
        "name": "adi.samplecontent",
        "description": "Introduction\n============\n\nThis package is an add-on for Plone and part of the adi.simplesite-package-bundle.\n\nIt adds some sample content for simple sites to your portal: Welcome, About and Contact.\n\nThe default view of the portal will be a link, that redirects to Welcome.\n\n\nChangelog\n=========\n\n0.3 (2012-12-02)\n----------------\n\n- Re-release.\n\n\n\n0.1dev (unreleased)\n-------------------\n\n- Sets contact-info-view as default-view for folder 'contact'\n\n- Makes contact-info-view available for folders\n\n- Sets 'go-to-welcome' as default-view for the portal\n\n- Adds a static-text-portlet for the left and right column\n\n- Adds a link 'go-to-welcome' that directs to 'welcome'\n\n- Adds folders 'welcome', 'about' and 'contact'\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.samplecontent",
        "summary": "Deletes Plone's default content and adds some sample content",
        "command": "pip install 'adi.samplecontent'"
      },
      "adi.simplesite": {
        "name": "adi.simplesite",
        "description": "Introduction\n============\n\nThis is a Plone-4 add-on that aims to help especially smaller sites to get started quicker and easier.\n\nThe goal is to give the possibility to configure most common website-usecases via the webinterface for mortals. No programming needed.\n\nIt does this mainly by replacing viewlets with portlets.\n\nMost functionalities are pulled in by small splitted plone-add-ons, named below, so you can roll your own combinations, installing them individually, in case you don't need parts of the whole package.\n\n\n\nThe pulled subpackages are:\n\n\n- adi.init\nDeletes Plone's default contents\n\n- adi.simplestructure\nHides viewlets and adds some samaple portlets instead in top and footer via ContentWellPortlets.\n\n- adi.samplecontent\nAdds some samplecontent and sampleportlets in left- and right column.\n\n- adi.slickstyle\nAdds a decent CSS to the portal, let's you override col, bg-col and link-col globally.\n\n- adi.dropdownmenue\nAdds a main drodwonmenu on top, showing first-level-folders, replaces Plone's globalnav.\n\n\nSee their READMES for further details.\n\nChange history\n**************\n\nChangelog\n=========\n\n0.5 (2014-03-14)\n----------------\n\n- Corrected missing doc-folder.\n\n\n0.5 (2012-12-02)\n----------------\n\n- Typos in description.\n\n\n0.4 (2012-12-02)\n----------------\n\n- Better description of the package.\n\n\n0.3 (2012-12-02)\n----------------\n\n- Use adi.slickstyle instead of adi.simplestyle as theme.\n\n\n0.2 (2012-05-19)\n----------------\n\n- Corrective release, missing files. [ida]\n\n0.1 (2012-05-17)\n----------------\n\n- Show only folders in navigation\n\n- Pulls adi.dropdownmenu, adi.samplecontent, adi.init, adi.simplestyle and adi.simplestructure\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.simplesite",
        "summary": "Configs for small sites",
        "command": "pip install 'adi.simplesite'"
      },
      "adi.simplestructure": {
        "name": "adi.simplestructure",
        "description": "Introduction\n============\n\nThis package is an add-on for Plone and part of the adi.simplesite-package-bundle.\n\nAdd and place additional elements you need with ContentWellPortlets TTW, no viewlets-hassle.\n\nHidesPlone's default viewlets in top and footer area of the portal and adds some sample portlets there instead.\n\nChangelog\n=========\n\n0.4 (2013-04-10)\n----------------\n\n- Re-release on pypi, doc-folder still missing. [ida]\n\n\n0.3 (2012-12-02)\n----------------\n\n- Re-release. [ida]\n\n\n0.2 (2012-05-19)\n----------------\n\n- Corrective release, missing files. [ida]\n\n\n0.1 (2012-05-17)\n----------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.simplestructure",
        "summary": "Removes top and footer viewlets and adds portlets instead.",
        "command": "pip install 'adi.simplestructure'"
      },
      "adi.slickstyle": {
        "name": "adi.slickstyle",
        "description": "Introduction\n============\n\nThis is a Plone add-on and part of the adi.simplesite-package-bundle.\n\nadi.slickstyle is a theme add-on for Plone, which overrides the default styles (namely public.css) with some decent styles and let's you easily override font-color, link-styles and bg-color globally. \n\nSee the stylesheet (adi/slickstyle/adi_slick.css) for the collected selectors.\n\n\n\nChangelog\n=========\n\n1.0 (2012-12-02)\n-------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.slickstyle",
        "summary": "A slick style for Plone portals, easily extendable for your own styles.",
        "command": "pip install 'adi.slickstyle'"
      },
      "adisp": {
        "name": "adisp",
        "description": "Adisp is a library that allows structuring code with asynchronous calls and\r\ncallbacks without defining callbacks as separate functions. The code then\r\nbecomes sequential and easy to read. The library is not a framework by itself\r\nand can be used in other environments that provides asynchronous working model\r\n(see an example with Tornado server in proxy_example.py).\r\n\r\nUsage:\r\n\r\n## Organizing calling code\r\n\r\nAll the magic is done with Python 2.5 decorators that allow for control flow to\r\nleave a function, do sometihing else for some time and then return into the\r\ncalling function with a result. So the function that makes asynchronous calls\r\nshould look like this:\r\n\r\n    @process\r\n    def my_handler():\r\n        response = yield some_async_func()\r\n        data = parse_response(response)\r\n        result = yield some_other_async_func(data)\r\n        store_result(result)\r\n\r\nEach `yield` is where the function returns and lets the framework around it to\r\ndo its job. And the code after `yield` is what usually goes in a callback.\r\n\r\nThe @process decorator is needed around such a function. It makes it callable\r\nas an ordinary function and takes care of dispatching callback calls back into\r\nit.\r\n\r\n## Writing asynchronous function\r\n\r\nIn the example above functions \"some_async_func\" and \"some_other_async_func\"\r\nare those that actually run an asynchronous process. They should follow two\r\nconditions:\r\n\r\n- accept a \"callback\" parameter with a callback function that they should call\r\n  after an asynchronous process is finished\r\n- a callback should be called with one parameter -- the result\r\n- be wrapped in the @async decorator\r\n\r\nThe @async decorator makes a function call lazy allowing the @process that\r\ncalls it to provide a callback to call.\r\n\r\nUsing async with @-syntax is most convenient when you write your own\r\nasynchronous function (and can make your callback parameter to be named\r\n\"callback\"). But when you want to call some library function you can wrap it in\r\nasync in place.\r\n\r\n    # call http.fetch(url, callback=callback)\r\n    result = yield async(http.fetch)\r\n\r\n    # call http.fetch(url, cb=safewrap(callback))\r\n    result = yield async(http.fetch, cbname='cb', cbwrapper=safewrap)(url)\r\n\r\nHere you can use two optional parameters for async:\r\n\r\n- `cbname`: a name of a parameter in which the function expects callbacks\r\n- `cbwrapper`: a wrapper for the callback iself that will be applied before\r\n  calling it\r\n\r\n## Chain calls\r\n\r\n@async function can also be @process'es allowing to effectively chain\r\nasynchronous calls as it can be done with normal functions. In this case the\r\n@async decorator shuold be the outer one:\r\n\r\n    @async\r\n    @process\r\n    def async_calling_other_asyncs(arg, callback):\r\n        # ....\r\n\r\n## Multiple asynchronous calls\r\n\r\nThe library also allows to call multiple asynchronous functions in parallel and\r\nget all their result for processing at once:\r\n\r\n    @async\r\n    def async_http_get(url, callback):\r\n        # get url asynchronously\r\n        # call callback(response) at the end\r\n\r\n    @process\r\n    def get_stat():\r\n        urls = ['http://.../', 'http://.../', ... ]\r\n        responses = yield map(async_http_get, urls)\r\n\r\nAfter *all* the asynchronous calls will complete `responses` will be a list of\r\nresponses corresponding to given urls.",
        "url": "http://pypi.python.org/pypi/adisp",
        "summary": "Callback-less python async calls dispatcher",
        "command": "pip install 'adisp'"
      },
      "adi.suite": {
        "name": "adi.suite",
        "description": "Adi Suite \n==========\n\nThis product will add a content-type 'Suite' to your portal.\n\nIn a suite you can add several galleries, that will be displayed directly in a fancyboxbox-popup on click.\n\nA gallery can contain mixed contenttypes and file-formats and will also show it's items in a fancybox.\n\nPreviewimages can be provided via the contentleadimage-field of an item.\n\nA quickuploadportlet is assigned to every gallery for batch uploading.\n\n\nCurrently supported contenttypes in a popup-display:\n\n- Images\n- Files\n- Pages\n- News-Items\n- Links [if URL contains 'youtube' or' 'vimeo', movie will be embedded in a flowplayer-view]\n\nCurrently supported file-formats in a popup-display:\n\n- all common image-formats\n- mp4 and flv for movies\n- mp3 for audio\n- swf for flash-animations\n\n\nDependencies:\n\n- collective.fancybox\n- collective.contentleadimage\n- collective.quickupload\n\nFurther credits: \n\n- flowplayer  http://flowplayer.org\n- flashicon   http://www.freeiconsweb.com/Free-Downloads.asp?id=1403 by Barry Mieny\n\n\nChange history\n**************\n\nChangelog\n=========\n\n0.6 (2ß3-01-02)\n-------------------\n\n- Added video-embed-support for ATLink-destinations containing 'youtube' or 'vimeo'. [ida]\n\n- Show arrow-down on preview-title, if they are longer than one row. [ida]\n\n- Make item-title in gal-view a link. [ida]\n\n- Vertical alignment for image previews in suite- and gallery-view. [ida]\n\n\n0.5 (2012-09-07)\n-------------------\n\n- Fixed typo [ida]\n\n\n0.4 (2012-08-29)\n-------------------\n\n- Added support for popupview of links directly to target. [ida]\n\n\n0.3 (2012-02-06)\n-------------------\n\n- Removed not used templates. [ida]\n\n- Fixed doubled previewimage for galleries. [ida]\n\n- Don't show leadimage of a gallery in gallery_view. [ida]\n\n\n0.2 (2011-12-27)\n-------------------\n\n- Assigned quickuploadportlet to galleries\n\n- Added previewimages in galleryview using contentleadimages.\n\n- Added dependencies to be pulled automatically\n    collective.contentleadimage \n    collective.fancybox\n    collective.quickupload\n\n\n0.1 (2011-05-11)\n-------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.suite",
        "summary": "A suite for javascript multimedia galleries.",
        "command": "pip install 'adi.suite'"
      },
      "aditam.agent": {
        "name": "aditam.agent",
        "description": "====================\naditam.agent package\n====================\n\n.. contents::\n\nDescription\n===========\n\nADITAM is a remote task scheduler which facilitates mass task managing over heterogeneous network.\nThe project contains :\n\n- **adtitam.core** (Python) : the common parts of the Aditam agent and server\n- **aditam.server** (Python) : the server in charge of scheduling and distributing the tasks\n- **aditam.agent** (Python) : the agent handles orders sent by the tasks manager and execute the tasks sent by it\n- **aditam web gui** (php) : the aditam web interface http://www.aditam.org/downloads/cake.tar.gz\n\nThis package contains the agent of the ADITAM project. The agents are installed on every server of the farm.\nIt handles orders sent by the tasks manager and execute the tasks sent by it.\nThen the agent sends an activity report that is stored in database.\nData needed for tasks execution must be available locally or through a network file system.\n\nRequires\n========\n\n- Python 2.5 : http://www.python.org/download/\n- easy_install : http://peak.telecommunity.com/DevCenter/EasyInstall#installing-easy-install\n\nYou must add C:\\\\Python2.5 and C:\\Python2.5\\\\Scripts in your Path on Windows.\n\nOS Independent installation\n===========================\n\nModule installation\n-------------------\n\nEnter in a console::\n\n    easy_install aditam.agent\n\nConfigure the agent\n-------------------\n\nEnter in a console::\n\n   aditam-admin.py --agent\n\nFollow the instructions.",
        "url": "http://pypi.python.org/pypi/aditam.agent",
        "summary": "Automated and DIstributed TAsk Manager agent part.",
        "command": "pip install 'aditam.agent'"
      },
      "aditam.core": {
        "name": "aditam.core",
        "description": "===================\naditam.core package\n===================\n\nDescription\n===========\n\nADITAM is a remote task scheduler which facilitates mass task managing over heterogeneous network.\nThe project contains :\n\n- **adtitam.core** (Python) : the common parts of the Aditam agent and server\n- **aditam.server** (Python) : the server in charge of scheduling and distributing the tasks\n- **aditam.agent** (Python) : the agent handles orders sent by the tasks manager and execute the tasks sent by it\n- **aditam web gui** (php) : the aditam web interface http://www.aditam.org/downloads/cake.tar.gz\n\nThis package is the common part of the aditam packages and it contains a script to configure\nthe agent, the server and the database.",
        "url": "http://pypi.python.org/pypi/aditam.core",
        "summary": "Automated and DIstributed TAsk Manager core part.",
        "command": "pip install 'aditam.core'"
      },
      "aditam.server": {
        "name": "aditam.server",
        "description": "=====================\naditam.server package\n=====================\n\n.. contents::\n\nDescription\n===========\n\nADITAM is a remote task scheduler which facilitates mass task managing over heterogeneous network.\nThe project contains :\n\n- **adtitam.core** (Python) : the common parts of the Aditam agent and server\n- **aditam.server** (Python) : the server in charge of scheduling and distributing the tasks\n- **aditam.agent** (Python) : the agent handles orders sent by the tasks manager and execute the tasks sent by it\n- **aditam web gui** (php) : the aditam web interface http://www.aditam.org/downloads/cake.tar.gz\n\nThis package contains the server of the ADITAM project. It is in charge of scheduling and distributing the tasks.\nInformations are stored in database and gave to the agents when tasks are to be executed.\n\nRequires\n========\n\n- Python 2.5 : http://www.python.org/download/\n- easy_install : http://peak.telecommunity.com/DevCenter/EasyInstall#installing-easy-install\n\nYou must add C:\\\\Python2.5 and C:\\\\Python2.5\\\\Scripts in your Path on Windows.\n\nOS Independent installation\n===========================\n\nModule installation\n-------------------\n\nEnter in a console::\n\n   easy_install aditam.server\n\nConfigure and install the database\n----------------------------------\n\nInstall the Python module for your database : http://www.sqlalchemy.org/docs/04/dbengine.html#dbengine_supported\n\nEnter in a console::\n\n   aditam-admin.py --create-db --config-db\n\nFollow the instructions.\n\nConfigure the server\n--------------------\nEnter in a console::\n\n   aditam-admin.py --server\n\nFollow the instructions.",
        "url": "http://pypi.python.org/pypi/aditam.server",
        "summary": "Automated and DIstributed TAsk Manager server part.",
        "command": "pip install 'aditam.server'"
      },
      "adi.ttw_styles": {
        "name": "adi.ttw_styles",
        "description": "Goal\n====\n\nGive people with CSS-skills the ability to apply styles through the \nweb (TTW), using a simple page as style-source and provide a preview-possibility.\n\nUsage\n=====\n\nFor live-developing the CSS and immediately see the changes, \nwhile to vistors the look will remain unchanged:\n\n- On top-level of your site add a page, name it 'ttw_live_styles', \n  insert yout CSS-rules in the bodytext-fieild, save page.\n\n- Add '/@@ttw_styles_view' to any URL of your site and see the changes.\n\n\nFor permanently adding the styles to your site and make them visible to everybody:\n\n- Create a local copy of your style-rules on your computer with a texteditor, \n  name it 'ttw_permanent_styles.css' and upload it as a file on top-level of your site.\n\nNote: Permanent changes require to remerge stylesheets for caching, \n\t  which you can achieve by putting ithe portal_css-debug-mode off,\n\t  (accessible via 'http://localhost:8080/yourPlonesiteId/portal_css/manage_cssForm').\n\t  You might need to ask your siteadministrator to do that for you.\n\n\nInstallation\n============\n\nAdd 'adi.ttw_styles' to the eggs-section of your instance-part in the buildout-cfg.\nRun buildout, restart instance, activate product in a Plonesite via\n'http://localhost:8080/yourPlonesiteId/prefs_install_products_form'.\n\nAuthor\n======\n\nIda Ebkes\n\n\nCredits\n=======\n\nLa communidas de Plone\n\nChangelog\n=========\n\n1.1 (2013-07-26)\n-------------------\n\n- Added MANIFEST.in\n\n\n1.0 (2013-07-26)\n-------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/adi.ttw_styles",
        "summary": "Apply your styles TTW.",
        "command": "pip install 'adi.ttw_styles'"
      },
      "adium-sh": {
        "name": "adium-sh",
        "description": "Adium Shell\n===========\n\n.. image:: https://pypip.in/v/adium-sh/badge.png\n        :target: https://pypi.python.org/pypi/adium-sh\n\nAdium Shell (adium-sh) is a command-line tool and Python wrapper for Adium.\n\nDescription\n-----------\nadium-sh provides shell utilities and Python wrapper based on `AppleScript support <https://trac.adium.im/wiki/AppleScript_Support_1.2>`_ of Adium.\n\nFeature\n-------\n\nThe current features are:\n\n* Set default service and account\n* Send messages using exact account name or alias\n* Receive and reply to messages using patterns or external API (SimSimi currently supported)\n* React to events\n\nInstallation\n------------\n::\n\n    $ pip install adium-sh\n\nUsage\n-----\nYou must specify the account and service to associate with the current use, either as command-line arguments or in the config file. When specifying them as arguments, you must put them before the sub-commands.\n\nSend messages\n~~~~~~~~~~~~~\nSend a message using account name:\n::\n\n    $ adiumsh -s GTalk -t yourname@gmail send -b buddy@gmail.com\n    Hello, there\n    <<EOF\n\nSend a message using alias:\n::\n\n    $ adiumsh -s GTalk -t yourname@gmail.com send -a 'John Smith'\n    Hello, there\n    <<EOF\n\nSet default configuration file at ``~/.adiumsh``:\n::\n\n    [default]\n    service = GTalk\n    account = yourname@gmail.com\n\nThen you can send messages without specifying ``-s/--service`` and ``-t/--account``:\n::\n\n    $ adiumsh send -a 'John Smith'\n\nYou can also pass as argument your message:\n::\n\n    $ adiumsh send -a 'John Smith' -m 'Hello, there'\n\nReceive messages\n~~~~~~~~~~~~~~~~\nYou must specify a chat method to receive messages. By default, adium-sh uses \"Simple Chat\", which basically replies to received messages according to the patterns you set. You must set the patterns in the config file, possibly like the following settings::\n\n    [default]\n    service = GTalk\n    account = yourname@gmail.com\n\n    [chat-default]\n    type = wildcard\n    patterns = \n        *hello*: hi\n        *what*: sorry\t\n        *: I'm not available now\n\nThen, you can invoke the \"receive\" sub-command with the ``-c/--chat`` arguments::\n\n    $ adiumsh receive -c default \n\nThe patterns is a list of string pairs where each pair is separated by a colon. The string to the left of the colon is the pattern against which the received text will be matched, and the right one is the corresponding reply text. There is also a \"type\" option in the chat section, which defaults to \"wildcard\" that uses globbing pattern matching; another value to it is \"regex\", which uses regular expression.\n\nYou can also use \"SimSimi Chat\" which hits the SimSimi API with the messages received. You have to set the API key in the config file and the key type (\"trial\", which is default, or \"paid\")::\n\n    [chat-simi]\n    simi-key = some-really-long-key\n    simi-key-type = trial\n\nThen, invoke \"receive\" with this chat from command line::\n\n    $ adiumsh receive -c simi\n\nSet the default chat in the default settings::\n\n    [default]\n    service = GTalk\n    account = yourname@gmail.com\n    chat = default\n\n    [chat-default]\n    patterns = \n        *hello*: hi\n        *what*: sorry\t\n        *: I'm not available now\n\n    [chat-another]\n    patterns =\n        *: not here\n\nNow you can also switch between chats from the command line other than the default::\n\n    $ adiumsh receive -c another\n\nTODO\n----\n* Complete Python wrapper API to AppleScript support\n* Exhaustive commands based on the wrapper",
        "url": "http://pypi.python.org/pypi/adium-sh",
        "summary": "Command-line wrapper of Adium",
        "command": "pip install 'adium-sh'"
      },
      "ADIVINA_EL_NUMERO": {
        "name": "adivina_el_numero",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ADIVINA_EL_NUMERO",
        "summary": "Ejemplo del funcionamiento de distutils",
        "command": "pip install 'ADIVINA_EL_NUMERO'"
      },
      "adi.workingcopyflag": {
        "name": "adi.workingcopyflag",
        "description": "------------\nIntroduction\n------------\n\nThis package extends all Archetypes of a Plonesite with a boolean field, that will be set to true if a workingcopy was created for an item via plone.app.iterate.\n\nThis way, it is possible to have this information availiable as a criterion in a collection (old-style collections, a.k.a. topics).\n\nIt's friendly name is 'Has workingcopy'.\n\nThe field is set to hidden, we don't want it in the UI of an item.\n\n\nChangelog\n=========\n\n1.3 (2012-11-19)\n----------------\n\n- Corrected namespace in MANIFEST.in [ida]\n\n\n1.3 (2012-11-19)\n----------------\n\n- Added MAINIFEST.in [ida]\n\n\n1.2 (2012-11-19)\n----------------\n\n- try again with different pypirc-config [ida]\n\n\n1.1 (2012-11-19)\n----------------\n\n- configure.zcml and profiles are missing in pypi-release for unknown reason,\n  let's try to make it work with this release [ida]\n\n- Better description [ida]\n\n\n1.0 (2012-11-01)\n----------------\n\n- Initial release [ida]",
        "url": "http://pypi.python.org/pypi/adi.workingcopyflag",
        "summary": "Adds a field iHas workingcopy to archetypes and makes it available to collections for sorting.",
        "command": "pip install 'adi.workingcopyflag'"
      },
      "adjacent": {
        "name": "adjacent",
        "description": "Centrifuge integration with Django framework",
        "url": "http://pypi.python.org/pypi/adjacent",
        "summary": "Centrifuge integration with Django framework",
        "command": "pip install 'adjacent'"
      },
      "Adjax": {
        "name": "adjax",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Adjax",
        "summary": "A framework for easing the development of Django sites with Ajax.",
        "command": "pip install 'Adjax'"
      },
      "Adjector": {
        "name": "adjector",
        "description": "A lightweight, fast, flexible, open-source ad server.  Serves plain text, HTML, and Javascript ads to your web application in several different ways, even from a separate machine.  Tracks views and clicks.  Designed to save you time and effort and stay out of your way.  Written in Pylons.",
        "url": "http://pypi.python.org/pypi/Adjector",
        "summary": "A lightweight, fast, flexible ad server.  Stays out of your way.",
        "command": "pip install 'Adjector'"
      },
      "AdjectorClient": {
        "name": "adjectorclient",
        "description": "This is the client-only package for Adjector.  This package should be used if you would like to render the ads directly from your application, instead of through the server.\n\n Adjector is a lightweight, fast, flexible, open-source ad server.  It serves plain text, HTML, and Javascript ads to your web application in several different ways, even from a separate machine.  It tracks views and clicks.  It is designed to save you time and effort and stay out of your way.  Written in Pylons.",
        "url": "http://pypi.python.org/pypi/AdjectorClient",
        "summary": "Client-only package for Adjector, a lightweight, fast, flexible ad server.",
        "command": "pip install 'AdjectorClient'"
      },
      "AdjectorTracPlugin": {
        "name": "adjectortracplugin",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AdjectorTracPlugin",
        "summary": "Integrate Adjector into your trac installation: render zones in trac templates.",
        "command": "pip install 'AdjectorTracPlugin'"
      },
      "adjointShapeOptimizationFlux": {
        "name": "adjointshapeoptimizationflux",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/adjointShapeOptimizationFlux",
        "summary": "Python front-end of the adjointShapeOptimizationFoam",
        "command": "pip install 'adjointShapeOptimizationFlux'"
      },
      "adjspecies": {
        "name": "adjspecies",
        "description": "=================\nadjective/species\n=================\n\nThe ``adjspecies`` Python module generates random names formed from\nan animal and a descriptor.\n\nInstallation\n============\n\n.. code:: bash\n\n    $ pip install -U adjspecies\n\nUsage\n=====\n\nFrom the command line\n---------------------\n\n.. code:: bash\n\n    $ adjspecies --help\n    usage: adjspecies.py [-h] [--maxlen MAXLEN] [--sep SEPARATOR] [--count COUNT]\n                         [--prevent-stutter]\n    \n    Print the name of a random adjective/species, more or less…\n    \n    optional arguments:\n      -h, --help         show this help message and exit\n      --maxlen MAXLEN    Maximum length for the name, excluding any separator.\n                         (default=8)\n      --sep SEPARATOR    Separator between the adjective and species words.\n                         (default='')\n      --count COUNT      Number of adjective/species combinations to print.\n      --prevent-stutter  Prevent the same letter from appearing on an\n                         adjective/species boundary. (default=True)\n\n    $ python adjspecies.py --count 4\n    sillyfox\n    redpig\n    pinkdoge\n    lynxpaw\n    \nIn Python code\n--------------\n\n.. code:: python\n\n    >>> import adjspecies\n    >>> help(adjspecies.random_adjspecies)\n    Help on function random_adjspecies in module adjspecies:\n    \n    random_adjspecies(sep='', maxlen=8, prevent_stutter=True)\n        Return a random adjective/species, separated by `sep`. The keyword\n        arguments `maxlen` and `prevent_stutter` are the same as for\n        `random_adjspecies_pair`, but note that the maximum length argument is\n        not affected by the separator.\n    \n    >>> adjspecies.random_adjspecies('.', 7)\n    'wolf.toy'\n\nAbout\n=====\n\nWhile writing a deployment system targetting DigitalOcean_ Droplets,\nthe author found the largest bottleneck was finding names for the transient\ntest servers.\n\nThe adjective/species contrivance comes from the furry culture in general\nand more directly from the site `[adjective][species]`_. It provides a\nwide namespace of easy-to-remember randomness.\n\nEverything up until the initial commit was an exercise in yak shaving and\nprocrastinating getting out of bed.\n\n.. _DigitalOcean: https://www.digitalocean.com/\n.. _[adjective][species]: http://adjectivespecies.com/\n\n\nCredits\n=======\n\nThe `adjspecies` module is written and maintained by `Adam Wright`_,\nwho plays a cheetah on Twitter under the guise of `@chipikat`_, a Python\ndeveloper called `@pypikat`_ and a human being named `@hipikat`_.\n\n.. _Adam Wright: http://hipikat.org/\n.. _@chipikat: https://twitter.com/chipikat\n.. _@pypikat: https://twitter.com/pypikat\n.. _@hipikat: https://twitter.com/hipikat",
        "url": "http://pypi.python.org/pypi/adjspecies",
        "summary": "Print the name of a random adjective/species, more or less…",
        "command": "pip install 'adjspecies'"
      },
      "adjutant": {
        "name": "adjutant",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/adjutant",
        "summary": "A Python library for parsing StarCraft II replays.",
        "command": "pip install 'adjutant'"
      },
      "adl3": {
        "name": "adl3",
        "description": "This package wraps the AMD Display Library 3.0 [1] using ctypes. You do *not* need to install the\nSDK to use this package, and no compilation is required.\n\nAlso included is a sample Python script using adl3 called _atitweak_. This script can list your\nadapters and optionally sets core and memory clock speed and voltage per performance level.\n\nFor example, to downlock your memory to 300MHz, you might use this command:\n\n$ atitweak -m 300  \nSetting performance level 0 on adapter 0: memory clock 300MHz  \nSetting performance level 1 on adapter 0: memory clock 300MHz  \nSetting performance level 2 on adapter 0: memory clock 300MHz  \n\nWARNING! This software can damage or destroy your graphics card if used incorrectly. \n\nIf this helps you squeeze out a few extra MHash/s, please consider throwing a few bitcoins my way:\n1Kh3DsAhiu65EC7DFFHDGoGowAp5usQrCG\n\n[1] http://developer.amd.com/sdks/adlsdk/pages/default.aspx\n    AMD Display Library 3.0\n",
        "url": "http://pypi.python.org/pypi/adl3",
        "summary": "ADL (AMD Display Library)",
        "command": "pip install 'adl3'"
      },
      "adm": {
        "name": "adm",
        "description": "-",
        "url": "http://pypi.python.org/pypi/adm",
        "summary": "Active Data Mapping, Pre-Alpha Release",
        "command": "pip install 'adm'"
      },
      "admesh": {
        "name": "admesh",
        "description": "ADMesh bindings for Python\n==========================\n\n.. image:: https://badge.fury.io/py/admesh.svg\n    :target: http://badge.fury.io/py/admesh\n\n.. image:: https://travis-ci.org/admesh/python-admesh.png?branch=master\n        :target: https://travis-ci.org/admesh/python-admesh\n\n.. image:: https://pypip.in/d/admesh/badge.png\n        :target: https://pypi.python.org/pypi/admesh\n\nThis module provides bindings for the `ADMesh <https://github.com/admesh/admesh>`_ library. It lets you manipulate 3D models in binary or ASCII STL format and partially repair them if necessary.\n\nInstallation\n------------\n\nFirst, you'll need to install the `ADMesh <https://github.com/admesh/admesh>`_ library. This release is designed for ADMesh 0.98.x. Follow the instructions there. Also, you'll need Cython. Then you can install this as usual with **one** of the following:\n\n.. code:: sh\n\n    ./setup.py install\n    python3 setup.py install # for Python 3\n    pip install admesh # install directly from PyPI\n\nIn case your ADMesh library is located in non-standard location, you'll have to tell the compiler and linker where to look:\n\n.. code:: sh\n\n    LDFLAGS='-L/path/to/library' CFLAGS='-I/path/to/header' ./setup.py install\n\nUsage\n-----\n\nUse the ``Stl`` class provided.\n\n.. code:: python\n\n    import admesh\n    \n    # load an STL file\n    stl = admesh.Stl('file.stl')\n    \n    # observe the available methods\n    help(stl)\n    \n    # read the stats\n    s.stats\n    \n    # see how many facets are there\n    len(stl)\n    \n    # walk the facets\n    for facet in stl:\n        # get the normal\n        facet['normal']\n        # walk the vertices\n        for vertex in facet['vertex']:\n            # read the coordinates\n            vertex['x']\n            vertex['y']\n            vertex['z']\n\nNote that all C ADMesh functions start with ``stl_`` prefix and the Python methods of this module do not. Also note that not all C ADMesh functions are provided, because some would require more complicated approach and are not considered worthy. In case you are missing some functions, create `new issue <https://github.com/admesh/python-admesh/issues/new>`_.",
        "url": "http://pypi.python.org/pypi/admesh",
        "summary": "Python bindings for ADMesh, STL maipulation library",
        "command": "pip install 'admesh'"
      },
      "adminapi": {
        "name": "adminapi",
        "description": "Eucalyptus Cloud Services and General System Administrative Utilities",
        "url": "http://pypi.python.org/pypi/adminapi",
        "summary": "Eucalyptus Cloud Services and General System Administrative Utilities",
        "command": "pip install 'adminapi'"
      },
      "admin_bootstrap": {
        "name": "admin_bootstrap",
        "description": "django-admin-twitter-bootstrap\n==============================\n\nDjango admin templates that are compatible with Twitter Bootstrap version 2.\n\n## Usage\n\n1. Clone the repository into your Django project.\n2. Add the path to 'admin_bootstrap/templates' to your `TEMPLATE_DIRS` setting.\n3. Add 'admin_bootstrap' to your `INSTALLED_APPS` setting.\n4. Run `python manage.py collectstatic`.\n\nAlternatively to #2, you can symlink the 'admin', 'admin_doc' and 'registration' folders in 'admin_bootstrap/templates' to your templates folder.\n\n_This has only been tested in Django 1.4._\n\n## TODO\n\n* Test more Django form field types and admin options.\n\n## LICENSE\n\nOffered under a [BSD 3 Clause License](https://github.com/dryan/django-admin-twitter-bootstrap/blob/master/LICENSE).",
        "url": "http://pypi.python.org/pypi/admin_bootstrap",
        "summary": "Django admin templates that are compatible with Twitter Bootstrap version 2.1.0",
        "command": "pip install 'admin_bootstrap'"
      },
      "admincsvimport": {
        "name": "admincsvimport",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/admincsvimport",
        "summary": "Add loaddata like csv support at Django Admin Site",
        "command": "pip install 'admincsvimport'"
      },
      "admin-extra-url": {
        "name": "admin-extra-url",
        "description": "admin-extra-urls\n================\n\nthis plugable django application that offer one single Mixin ``ExtraUrlMixin``\nto easily add new url (and related buttons on the screen) to any ModelAdmin.\n\nExample::\n\n    class MyModelModelAdmin(ExtraUrlMixin, admin.ModelAdmin):\n\n        @link() # /admin/myapp/mymodel/update_all/\n        def update_all(self, request):\n            ...\n            ...\n\n        @action() # /admin/myapp/mymodel/update/10/\n        def update(self, request):\n            ...\n            ...",
        "url": "http://pypi.python.org/pypi/admin-extra-url",
        "summary": "Django mixin to easily add urls to any ModelAdmin",
        "command": "pip install 'admin-extra-url'"
      },
      "admin-extra-urls": {
        "name": "admin-extra-urls",
        "description": "admin-extra-urls\n================\n\n\nplugable django application that offers one single Mixin ``ExtraUrlMixin``\nto easily add new url (and related buttons on the screen) to any ModelAdmin.\n\nIt provides two decorators ``link()`` and ``action()``.\n\n- ``link()`` is intended to be used for multiple records. It will produce a button in the change list view.\n\n- ``action()`` works on a single record. It will produce a button in the change form view.\n\n\n\nInstall\n-------\n\n.. code-block:: python\n\n    pip install admin-extra-urls\n\n\nAfter installation add it to ``INSTALLED_APPS``\n\n.. code-block:: python\n\n\n   INSTALLED_APPS = (\n       ...\n       'admin_extra_urls',\n   )\n\nHow to use it\n-------------\n\n.. code-block:: python\n\n    class MyModelModelAdmin(ExtraUrlMixin, admin.ModelAdmin):\n\n        @link() # /admin/myapp/mymodel/update_all/\n        def update_all(self, request):\n            ...\n            ...\n\n\n        @action() # /admin/myapp/mymodel/update/10/\n        def update(self, request, pk):\n            ...\n            ...\n\nYou don't need to return a HttpResponse, by default:\n\n    - with `link()` browser will be redirected to ``changelist_view``\n\n    - with `action()` browser will be redirected to ``change_view``\n\n\nMore options\n------------\n\n.. code-block:: python\n\n\n    @link(label='Update', icon=\"icon-refresh icon-white\", permission='model_change\", order=-1)\n    def update_all(self, request):\n            ....\n\n\n*Note*\n\n    The package contains a ``UploadMixin`` to manage custom file uploads\n    (simply set `upload_handler` to a function.\n    This can be checked to see how to create wizard with an intermediate form.\n\n\nLinks\n~~~~~\n\n+--------------------+----------------+--------------+------------------------+\n| Stable             | |master-build| | |master-cov| | |master-req|           |\n+--------------------+----------------+--------------+------------------------+\n| Development        | |dev-build|    | |dev-cov|    | |dev-req|              |\n+--------------------+----------------+--------------+-----------------------------+\n| Project home page: |https://github.com/saxix/django-admin-extra-urls             |\n+--------------------+---------------+---------------------------------------------+\n| Issue tracker:     |https://github.com/saxix/django-admin-extra-urls/issues?sort |\n+--------------------+---------------+---------------------------------------------+\n| Download:          |http://pypi.python.org/pypi/django-admin-extra-urls/         |\n+--------------------+---------------+---------------------------------------------+\n\n\n.. |master-build| image:: https://secure.travis-ci.org/saxix/django-admin-extra-urls.png?branch=master\n                    :target: http://travis-ci.org/saxix/django-admin-extra-urls/\n\n.. |master-cov| image:: https://coveralls.io/repos/saxix/django-admin-extra-urls/badge.png?branch=master\n                    :target: https://coveralls.io/r/saxix/django-admin-extra-urls\n\n.. |master-req| image:: https://requires.io/github/saxix/django-admin-extra-urls/requirements.png?branch=master\n                    :target: https://requires.io/github/saxix/django-admin-extra-urls/requirements/?branch=master\n                    :alt: Requirements Status\n\n\n.. |dev-build| image:: https://secure.travis-ci.org/saxix/django-admin-extra-urls.png?branch=develop\n                  :target: http://travis-ci.org/saxix/django-admin-extra-urls/\n\n.. |dev-cov| image:: https://coveralls.io/repos/saxix/django-admin-extra-urls/badge.png?branch=develop\n                :target: https://coveralls.io/r/saxix/django-admin-extra-urls\n\n.. |dev-req| image:: https://requires.io/github/saxix/django-admin-extra-urls/requirements.png?branch=develop\n                    :target: https://requires.io/github/saxix/django-admin-extra-urls/requirements/?branch=develop\n                    :alt: Requirements Status\n\n\n.. |python| image:: https://pypip.in/py_versions/django-admin-extra-urls/badge.svg\n    :target: https://pypi.python.org/pypi/django-admin-extra-urls/\n    :alt: Supported Python versions\n\n.. |pypi| image:: https://pypip.in/version/admin-extra-urls/badge.svg?text=version\n    :target: https://pypi.python.org/pypi/admin-extra-urls/\n    :alt: Latest Version\n\n.. |license| image:: https://pypip.in/license/admin-extra-urls/badge.svg\n    :target: https://pypi.python.org/pypi/admin-extra-urls/\n    :alt: License\n\n.. image:: https://pypip.in/wheel/django-admin-extra-urls/badge.svg\n    :target: https://pypi.python.org/pypi/django-admin-extra-urls/\n    :alt: Wheel Status\n\n.. |travis| image:: https://travis-ci.org/saxix/django-admin-extra-urls.svg?branch=develop\n    :target: https://travis-ci.org/saxix/django-admin-extra-urls\n\n.. |django| image:: https://img.shields.io/badge/Django-1.8-orange.svg\n    :target: http://djangoproject.com/\n    :alt: Django 1.7, 1.8",
        "url": "http://pypi.python.org/pypi/admin-extra-urls",
        "summary": "Django mixin to easily add urls to any ModelAdmin",
        "command": "pip install 'admin-extra-urls'"
      },
      "adminfuncs": {
        "name": "adminfuncs",
        "description": "Module to automatically build admin function runner",
        "url": "http://pypi.python.org/pypi/adminfuncs",
        "summary": "Admin Function Runner",
        "command": "pip install 'adminfuncs'"
      },
      "adminish": {
        "name": "adminish",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/adminish",
        "summary": "Auto web admin system for couchdb and restish",
        "command": "pip install 'adminish'"
      },
      "adminish-categories": {
        "name": "adminish-categories",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/adminish-categories",
        "summary": "support library for adminish",
        "command": "pip install 'adminish-categories'"
      },
      "AdminKit": {
        "name": "adminkit",
        "description": "AdminKit is a tool to manage the configuration of systems via a high\r\nlevel description using roles. The tool belongs to the same familly as\r\ncfengine, puppet or chef.",
        "url": "http://pypi.python.org/pypi/AdminKit",
        "summary": "Manage system configurations easily",
        "command": "pip install 'AdminKit'"
      },
      "adminlettuce": {
        "name": "adminlettuce",
        "description": "Admin documentation for lettuce-generated integration tests.\n-------------------------------------\n\nThis module integrates lettuce (http://www.lettuce.it) support for Django by\nprinting out the content of the features and scenarios to the Django admin\ninterface.\n\nThe goal is to make the final user aware of the specifications and requirements\nof the application without having to browse the source code.",
        "url": "http://pypi.python.org/pypi/adminlettuce",
        "summary": "Displays lettuce features as documentation in Django admin.",
        "command": "pip install 'adminlettuce'"
      },
      "admin_logs": {
        "name": "admin_logs",
        "description": "About\n=====\n\nThis small module for django allows you to store requests in your database(now supports only database) and then look at them in django admin.\nThis module was inspired by logs in Google Application Engine\n\n\nConfigure\n=========\n\nInclude this lines to your settings.py:\n\n\n::\n\n  INSTALLED_APPS += ('admin_logs', )\n  MIDDLEWARE_CLASSES = ('admin_logs.middleware.LogRequestMiddleware', ) + MIDDLEWARE_CLASSES  # place middleware as early as possible\n\n  ADMIN_LOGS_BACKEND = 'admin_logs.backends.database.DatabaseBackend'  # now supports only database\n\n  from admin_logs import setup_level\n  setup_level('INFO')  # set minumum log level that will be written to logs\n\n\nWorking\n=======\n\nAnywhere in the code you can run:\n\n::\n\n  import logging\n  logging.warning('Test')\n\n\nAnd this warning will be written to logs and you can check it later.",
        "url": "http://pypi.python.org/pypi/admin_logs",
        "summary": "Admin logs for django like in Google Application Engine",
        "command": "pip install 'admin_logs'"
      },
      "admin_scripts": {
        "name": "admin_scripts",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/admin_scripts",
        "summary": "Administration Scripts",
        "command": "pip install 'admin_scripts'"
      },
      "admin-timeline": {
        "name": "admin-timeline",
        "description": "Note\r\n======================\r\nDue to name change, this package is no longer updated! The new version could be found at https://pypi.python.org/pypi/django-admin-timeline\r\n\r\nPackage\r\n======================\r\ndjango-admin-timeline\r\n\r\nDescription\r\n======================\r\nA Facebook-like timeline app for Django admin. It's very similar to built-in feature \"Daily progress\", but then\r\nhas a nicer templates and infinite scroll implemented. Also, actions are broken up by day, then by action. Filtering\r\nby user is implemented too.\r\n\r\nInstallation\r\n======================\r\n1. Install in your virtual environemnt\r\n\r\n   Latest stable version from PyPI:\r\n\r\n    $ pip install admin_timeline\r\n\r\n   Latest stable version from bitbucket:\r\n\r\n    $ pip install -e hg+http://bitbucket.org/barseghyanartur/django_admin_timeline@stable#egg=django_admin_timeline\r\n\r\n   Latest development version from bitbucket:\r\n\r\n    $ pip install -e hg+http://bitbucket.org/barseghyanartur/django_admin_timeline#egg=django_admin_timeline\r\n\r\n3. Add `admin_timeline` to your `INSTALLED_APPS` in the global settings.py.\r\n\r\n    >>> INSTALLED_APPS = (\r\n    >>> # ...\r\n    >>> 'admin_timeline',\r\n    >>> # ...\r\n    >>> )\r\n\r\n4. Collect the static files by running (see the Troubleshooting section in case of problems):\r\n\r\n    $ ./manage.py collectstatic\r\n\r\n5. Override app settings in your global `settings` module (see the ``apps.admin_timeline.defaults`` for the list of\r\n   settings). As for now, most important of those is ``NUMBER_OF_ENTRIES_PER_PAGE`` - number of entries displayer per\r\n   page (for both non-AJAX and AJAX requests).\r\n\r\n6. Add the following lines to the global ``urls`` module:\r\n\r\n    >>> # Admin timeline URLs. Should be placed BEFORE the Django admin URLs.\r\n    >>> (r'^admin/timeline/', include('admin_timeline.urls')),\r\n    >>> url(r'^admin/', include(admin.site.urls)),\r\n\r\nTroubleshooting\r\n======================\r\nIf somehow static files are not collected properly (missing admin_timeline.js and admin_timeline.css files), install\r\nthe latest stable version from source.\r\n\r\n    $ pip install -e hg+http://bitbucket.org/barseghyanartur/django_admin_timeline@stable#egg=django_admin_timeline\r\n\r\nUsage\r\n======================\r\nAfter following all installation steps, you should  be able to access the admin-timeline by:\r\n\r\n    http://127.0.0.1:8000/admin/timeline/\r\n\r\nLicense\r\n===================================\r\nGPL 2.0/LGPL 2.1\r\n\r\nSupport\r\n===================================\r\nFor any issues contact me at the e-mail given in the `Author` section.\r\n\r\nAuthor\r\n===================================\r\nArtur Barseghyan <artur.barseghyan@gmail.com>",
        "url": "http://pypi.python.org/pypi/admin-timeline",
        "summary": "Facebook-like timeline for Django admin",
        "command": "pip install 'admin-timeline'"
      },
      "admin-tools-zinnia": {
        "name": "admin-tools-zinnia",
        "description": "==================\nAdmin-tools Zinnia\n==================\n\nAdmin-tools-zinnia is package providing new dashboard modules related to\nyour `Zinnia`_ application for `django-admin-tools`_.\n\n.. _Zinnia: http://django-blog-zinnia.com/\n.. _django-admin-tools: http://pypi.python.org/pypi/django-admin-tools/",
        "url": "http://pypi.python.org/pypi/admin-tools-zinnia",
        "summary": "Admin tools for django-blog-zinnia",
        "command": "pip install 'admin-tools-zinnia'"
      },
      "adnpy": {
        "name": "adnpy",
        "description": "ADNpy: App.net API for Python\n=============================\n\n.. image:: https://badge.fury.io/py/adnpy.png\n    :target: http://badge.fury.io/py/adnpy\n\n.. image:: https://travis-ci.org/appdotnet/ADNpy.png?branch=master\n    :target: https://travis-ci.org/appdotnet/ADNpy\n\n\nADNpy aims to be an easy-to-use Python library for interacting with the `App.net API <https://developers.app.net>`_.\n\nInstallation\n------------\n\nTo install Requests, simply:\n\n.. code-block:: bash\n\n    $ pip install adnpy\n\nDocumentation\n-------------\n\nDocumentation is available at http://adnpy.readthedocs.org/.\n\nQuick Start\n-----------\n\nIn order to use ADNpy, You'll to need an access token. If you don't already have one, first `create an app`_, and then generate an access token for your app.\n\n.. code-block:: python\n\n    import adnpy\n    adnpy.api.add_authorization_token(<Access Token Here>)\n\n    # Create a post\n    post, meta = adnpy.api.create_post(data={'text':'Hello App.net from adnpy!'})\n\n    # Take a look at recent checkins\n    posts, meta = adnpy.api.get_explore_stream('checkins')\n    for post in posts:\n      print post\n\n    # You can even paginate through checkins using the cursor method.\n    # Cursors will obey rate limits (by blocking until retries are\n    # permitted), and will allow you to page through the entire stream.\n    for post in adnpy.cursor(adnpy.api.get_explore_stream, 'checkins'):\n        print post\n\n.. _create an app: https://account.app.net/developer/apps/",
        "url": "http://pypi.python.org/pypi/adnpy",
        "summary": "App.net API library for python",
        "command": "pip install 'adnpy'"
      },
      "adns": {
        "name": "adns",
        "description": "adns-python is a Python module that interfaces to the adns asynchronous\nresolver library.\n\nhttp://www.gnu.org/software/adns/",
        "url": "http://pypi.python.org/pypi/adns",
        "summary": "An interface to GNU adns - python3 port",
        "command": "pip install 'adns'"
      },
      "adns-python": {
        "name": "adns-python",
        "description": "adns-python is a Python module that interfaces to the adns asynchronous\nresolver library.\n\nhttp://www.gnu.org/software/adns/",
        "url": "http://pypi.python.org/pypi/adns-python",
        "summary": "An interface to GNU adns",
        "command": "pip install 'adns-python'"
      },
      "ado": {
        "name": "ado",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ado",
        "summary": "UNKNOWN",
        "command": "pip install 'ado'"
      },
      "AdobeColor": {
        "name": "adobecolor",
        "description": "A module that provides access to .aco and .ase color files in a read-only manner.",
        "url": "http://pypi.python.org/pypi/AdobeColor",
        "summary": "A small module for reading .aco and .ase color files",
        "command": "pip install 'AdobeColor'"
      },
      "adodbapi": {
        "name": "adodbapi",
        "description": "Project\n-------\nadodbapi\n\nA Python DB-API 2.0 (PEP-249) module that makes it easy to use Microsoft ADO \nfor connecting with databases and other data sources\nusing either CPython or IronPython.\n\nHome page: <http://sourceforge.net/projects/adodbapi>\nDocumentation: <http://adodbapi.sourceforge.net/quick_reference.pdf>\n\nFeatures:\n* 100% DB-API 2.0 (PEP-249) compliant (including most extensions and recommendations).\n* Includes pyunit testcases that describe how to use the module.  \n* Fully implemented in Python. -- runs in Python 2.5+ Python 3.0+ and IronPython 2.6+\n* Licensed under the LGPL license, which means that it can be used freely even in commercial programs subject to certain restrictions. \n* Includes SERVER and REMOTE modules so that a Windows proxy can serve ADO databases to a Linux client using PyRO.\n* The user can choose between paramstyles: 'qmark' 'named' 'format' 'pyformat' 'dynamic'\n* Supports data retrieval by column name e.g.:\n  for row in myCurser.execute(\"select name,age from students\"):\n     print(\"Student\", row.name, \"is\", row.age, \"years old.\")\n* Supports user-definable system-to-Python data conversion functions (selected by ADO data type, or by column)\n\nPrerequisites:\n* C Python 2.5 or higher\n and pywin32 (Mark Hammond's python for windows extensions.)\nor\n Iron Python 2.6 or higher.  (works in IPy2.0 for all data types except BUFFER)\n\nInstallation:\n* (C-Python on Windows): Download pywin32 from http://sf.net/projects/pywin32 and install from .msi (adodbapi is included)\n* ((to use Windows as a server, also download and install Pyro4 (requires Python 2.6 or later))) https://pypi.python.org/pypi/Pyro4\n* (IronPython on Windows): Download adodbapi from http://sf.net/projects/adodbapi.  Unpack the zip.\n     Open a command window as an administrator. CD to the folder containing the unzipped files.\n     Run \"setup.py install\" using the IronPython of your choice.\n* (Linux, as a client): download and install from PyPi: \"pip install adodbapi Pyro4\"\n\nNOTE: ...........\nIf you do not like the new default operation of returning Numeric columns as decimal.Decimal,\nyou can select other options by the user defined conversion feature. \nTry:\n        adodbapi.apibase.variantConversions[adodbapi.ado_consts.adNumeric] = adodbapi.apibase.cvtString\nor:\n        adodbapi.apibase.variantConversions[adodbapi.ado_consts.adNumeric] = adodbapi.apibase.cvtFloat\nor:\n        adodbapi.apibase.variantConversions[adodbapi.ado_consts.adNumeric] = write_your_own_convertion_function\n\t\t............\nwhats new in version 2.6\n   A cursor.prepare() method and support for prepared SQL statements.\n   Lots of refactoring, especially of the Remote and Server modules (still to be treated as Beta code).\n   The quick start document 'quick_reference.odt' will export as a nice-looking pdf.\n   Added paramstyles 'pyformat' and 'dynamic'. If your 'paramstyle' is 'named' you _must_ pass a dictionary of\n      parameters to your .execute() method. If your 'paramstyle' is 'format' 'pyformat' or 'dynamic', you _may_\n      pass a dictionary of parameters -- provided your SQL operation string is formatted correctly.\n\nwhats new in version 2.5\n   Remote module: (works on Linux!) allows a Windows computer to serve ADO databases via PyRO\n   Server module: PyRO server for ADO.  Run using a command like= C:>python -m adodbapi.server\n   (server has simple connection string macros: is64bit, getuser, sql_provider, auto_security)\n   Brief documentation included.  See adodbapi/examples folder adodbapi.rtf\n   New connection method conn.get_table_names() --> list of names of tables in database\n\n   Vastly refactored. Data conversion things have been moved to the new adodbapi.apibase module.\n   Many former module-level attributes are now class attributes. (Should be more thread-safe)\n   Connection objects are now context managers for transactions and will commit or rollback.\n   Cursor objects are context managers and will automatically close themselves.\n   Autocommit can be switched on and off.\n   Keyword and positional arguments on the connect() method work as documented in PEP 249.\n   Keyword arguments from the connect call can be formatted into the connection string.\n   New keyword arguments defined, such as: autocommit, paramstyle, remote_proxy, remote_port.\n  *** Breaking change: variantConversion lookups are simplified: the following will raise KeyError:\n         oldconverter=adodbapi.variantConversions[adodbapi.adoStringTypes]\n      Refactor as: oldconverter=adodbapi.variantConversions[adodbapi.adoStringTypes[0]]\n\n(( More information like this in older_whatsnew.txt ))\n\t  \nLicense\n-------\nLGPL, see http://www.opensource.org/licenses/lgpl-license.php\n\nDocumentation\n-------------\nStart with:\n\nhttp://www.python.org/topics/database/DatabaseAPI-2.0.html\nread the examples in adodbapi/examples\nand look at the test cases in adodbapi/test directory. \n\nMailing lists\n-------------\nThe adodbapi mailing lists have been deactivated. Submit comments to the \npywin32 or IronPython mailing lists.\n  -- the bug tracker on sourceforge.net/projects/adodbapi will be checked, (infrequently).",
        "url": "http://pypi.python.org/pypi/adodbapi",
        "summary": "A pure Python package implementing PEP 249 DB-API using Microsoft ADO.",
        "command": "pip install 'adodbapi'"
      },
      "adol-Py": {
        "name": "adol-py",
        "description": "",
        "url": "http://pypi.python.org/pypi/adol-Py",
        "summary": "ADOL-Py is a python extension to the ADOL-C automatic differentiation library.",
        "command": "pip install 'adol-Py'"
      },
      "adpasswd": {
        "name": "adpasswd",
        "description": "adpasswd.py: Pure Python Command line interface to change Active Directory Passwords via LDAP.\r\n\r\nSETUP:\r\n\tyou need a config file.\r\n\tconfig files can either be in the Current Working Directory, or in ~/\r\n\tconfig files are always named .adpasswd.cfg and are INI style.\r\n\t\r\nExample:\r\n\t\r\n\t\t[ad]\r\n\thost: ad.blah.com\r\n\tport: 636\r\n\tbinddn: cn=Administrator,CN=Users,DC=ad,DC=blah,DC=com\r\n\tbindpw: changemequickly\t\r\n\tsearchdn: DC=ad,DC=blah,DC=com\r\n\r\nAll of the options above MUST exist, and be configured properly for this to work.\r\n\r\nOnce you have a config file setup, then it's EASY to use:\r\n\tadpasswd.py username [password]\r\n\r\n\r\nyou can call it with a password or not, if you don't you will be prompted for one.\r\n\r\nyou get NO OUTPUT (but successful return) if everything went well. (good for scripts!)\r\nIf things went wrong, you will be told about it.\r\n\r\n\r\nBug reports, etc please use launchpad: https://launchpad.net/adpasswd\r\n\r\nCREDITS:\r\n\tldaplib.py originally from scmgre@users.sourceforge.net\r\n\tURL: http://sourceforge.net/projects/ldaplibpy/\r\n\tBig thanks for doing all the hard work!\r\n\r\nFYI: I no longer use this code in production, nor really maintain it.  If you love/use or care about this code, feel free to adopt it or take over ownership.",
        "url": "http://pypi.python.org/pypi/adpasswd",
        "summary": "adpasswd.py Pure Python Command line interface to change Active Directory Passwords via LDAP.\tusage: adpasswd.py username [password]",
        "command": "pip install 'adpasswd'"
      },
      "adpil": {
        "name": "adpil",
        "description": "===================================\nadpil - Adessowiki to PIL interface\n===================================\n\nDescription\n-----------\n\nThis toolbox interfaces to PIL, used by ia636 and ia870 toolboxes. The main functions it provides are adshow,\nadread, adreadgray.\n\nRequirements\n------------\n\nThis toolbox requires PIL. To install PIL using pip use the following command:\n\npip install PIL  --allow-unverified PIL --allow-all-external",
        "url": "http://pypi.python.org/pypi/adpil",
        "summary": "Interface between Adessowiki and PIL.Used by ia636 and ia870 toolboxes.",
        "command": "pip install 'adpil'"
      },
      "ADPY": {
        "name": "adpy",
        "description": "ADPY\n====\n\n##Description\n\n\nADPY is a Python library for algorithmic differentiation (http://en.wikipedia.org/wiki/Automatic_differentiation).\nIt aims to provide an easy way to extract partial derivatives of vector valued function (Jacobian matrix). In addition it allows to created callable function for obtaining function values using computational graphs.  \n\nFeatures:\n\n* optimize numerical evaluation by using computational graph\n* create callable function from Sympy expressions (calls lambdify once and creates a computational graph) \n* extract partial derivatives using forward or reverse algorithmic differentiation\n* bonus: a small nonlinear solver using all advantages mentioned above\n\n\n\n##How to use\n\nDue the small amount of features the handling is quite easy.         \n        \nFor the easiest use you need a callable function which takes a list of float numbers and returns a list.\n\n        def f(x):\n        \treturn [x[0]**2,2*x[1]]\n\nYou need a valid values for x which cause no singularities while evaluating the function.\n\n\t\tx1 = [1.,2.]\n\nInitialize the ADFUN object.\n\n\t\tfrom ADPY import adfun\n\t\tadpy_test  = adfun(f,x1)\n\nNow you have a callable function with computational graph optimization.\n\n\t\t\ty1 = adpy_test(x1)\n\nIf you want to use derivatives just do\n\t\n\t\tadpy_test.init_reverse_jac()\n\nor\n\n\t\tadpy_test.init_forward_jac()\n\nNow you can evaluate them using\n\n\t\tJ_forward = adpy_test.jac_reverse(x1)\n\nor\n\n\t\tJ_forward = adpy_test.jac_forward(x1)\n\n\nFor more information see the attached examples.\n\n##Install\n\nclone git\n\n        git clone https://github.com/zwenson/ADPY\nand run setup.py\n\n        python setup.py install\n\nor use easy_install\n\n        easy_install ADPY\n\n##How it works\n\nWithout going in to detail. It uses an overloaded class \"adfloat\" to record a list of the mathematical operations required to obtain the result. This list is then translated in to python expressions and made executable. The list is also used to perform automatic differentiation.\n\n\n##To do\n* more testing\n* add more operations\n* maybe add Hessian matrix? \n* add Taylor arithmetic?",
        "url": "http://pypi.python.org/pypi/ADPY",
        "summary": "ADPY is a Python library for algorithmic differentiation",
        "command": "pip install 'ADPY'"
      },
      "adrest": {
        "name": "adrest",
        "description": "|logo| ADREST\n#############\n\nAdrest is Another Django REST. Django application for simple make HTTP REST API.\n\nDocumentation in `construction <http://adrest.readthedocs.org>`_.\n\n.. _badges:\n\n.. image:: http://img.shields.io/travis/klen/adrest.svg?style=flat-square\n    :target: http://travis-ci.org/klen/adrest\n    :alt: Build Status\n\n.. image:: http://img.shields.io/coveralls/klen/adrest.svg?style=flat-square\n    :target: https://coveralls.io/r/klen/adrest\n    :alt: Coverals\n\n.. image:: http://img.shields.io/pypi/v/adrest.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/adrest\n    :alt: Version\n\n.. image:: http://img.shields.io/pypi/dm/adrest.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/adrest\n    :alt: Downloads\n\n.. image:: http://img.shields.io/pypi/l/adrest.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/adrest\n    :alt: License\n\n.. image:: http://img.shields.io/gratipay/klen.svg?style=flat-square\n    :target: https://www.gratipay.com/klen/\n    :alt: Donate\n\n.. _requirements:\n    \nRequirements\n=============\n\n- Python 2.7\n- Django (1.5, 1.6, 1.7)\n\n.. _installation:\n\nInstallation\n=============\n\n**ADRest** should be installed using pip: ::\n\n    pip install adrest\n\n.. _quickstart:\n\nQuick start\n===========\n::\n\n    from adrest import Api, ResourceView\n\n    api = Api('v1')\n\n    @api.register\n    class BookResource(ResourceView):\n        class Meta:\n            allowed_methods = 'get', 'post'\n            model = 'app.book'\n\n    urlpatterns = api.urls\n\n\n.. _setup:\n\nSetup\n=====\n\nAdrest settings (default values): ::\n\n    # Enable logs\n    ADREST_ACCESS_LOG = False\n\n    # Auto create adrest access key for User\n    ADREST_AUTO_CREATE_ACCESSKEY = False\n\n    # Max resources per page in list views\n    ADREST_LIMIT_PER_PAGE = 50\n\n    # Display django standart technical 500 page\n    ADREST_DEBUG = False\n\n    # Limit request number per second from same identifier, null is not limited\n    ADREST_THROTTLE_AT = 120\n    ADREST_THROTTLE_TIMEFRAME = 60\n\n    # We do not restrict access for OPTIONS request\n    ADREST_AUTHENTICATE_OPTIONS_REQUEST = False\n\n.. note::\n    Add 'adrest' to INSTALLED_APPS\n\n\nUse adrest\n==========\n\nSee test/examples in ADREST sources.\n\n\n.. _bagtracker:\n\nBug tracker\n===========\n\nIf you have any suggestions, bug reports or\nannoyances please report them to the issue tracker\nat https://github.com/klen/adrest/issues\n\n\n.. _contributing:\n\nContributing\n============\n\nDevelopment of adrest happens at github: https://github.com/klen/adrest\n\n\n.. _contributors:\n\nContributors\n=============\n\n* klen_ (Kirill Klenov)\n\n\n.. _license:\n\nLicense\n=======\n\nLicensed under a `GNU lesser general public license`_.\n\n\n.. _links:\n\n.. _GNU lesser general public license: http://www.gnu.org/copyleft/lesser.html\n.. _klen: http://klen.github.com/\n.. _REST: http://en.wikipedia.org/wiki/Representational_state_transfer\n.. _RPC: http://en.wikipedia.org/wiki/JSON-RPC\n.. |logo| image:: https://raw.github.com/klen/adrest/develop/docs/_static/logo.png\n                  :width: 100",
        "url": "http://pypi.python.org/pypi/adrest",
        "summary": "Adrest - Another Django REST. Simple application for quick build REST API.",
        "command": "pip install 'adrest'"
      },
      "ads": {
        "name": "ads",
        "description": "**A Python Module to Interact with NASA's ADS that Doesn't Suck™**\n==================================================================\n\n[![Build Status](http://img.shields.io/travis/andycasey/ads.svg?branch-master)](https://travis-ci.org/andycasey/ads) [![PyPi download count image](http://img.shields.io/pypi/dm/ads.svg)](https://pypi.python.org/pypi/ads/)\n\nIf you're in research, then you pretty much _need_ NASA's ADS. It's tried, true, and people go crazy on the rare occasions when it goes down.\n\n**Getting Started**\n\n1. You'll need an API key from NASA ADS labs. Sign up for the newest version of ADS search at https://ui.adsabs.harvard.edu, visit account settings and generate a new API token. The official documentation is available at https://github.com/adsabs/adsabs-dev-api\n\n2. When you get your API key, save it to a file called ``~/.ads/dev_key`` or save it as an environment variable named ``ADS_DEV_KEY``\n\n3. From a terminal type ``pip install ads`` (or [if you must](https://stackoverflow.com/questions/3220404/why-use-pip-over-easy-install), use ``easy_install ads``)\n\nHappy Hacking!\n\n\n**Examples**\n\nYou can use this module to search for some popular supernova papers:\n````\n>>> import ads\n\n# Opps, I forgot to follow step 2 in \"Getting Started\"\n>>> ads.config.token = 'my token'\n\n>>> papers = ads.SearchQuery(q=\"supernova\", sort=\"citations\")\n\n>>> for paper in papers:\n>>>    print(paper.title)\n   ...:     \n[u'Maps of Dust Infrared Emission for Use in Estimation of Reddening and Cosmic Microwave Background Radiation Foregrounds']\n[u'Measurements of Omega and Lambda from 42 High-Redshift Supernovae']\n[u'Observational Evidence from Supernovae for an Accelerating Universe and a Cosmological Constant']\n[u'First-Year Wilkinson Microwave Anisotropy Probe (WMAP) Observations: Determination of Cosmological Parameters']\n[u'Abundances of the elements: Meteoritic and solar']\n````\n\nOr search for papers first-authored by someone:\n````\n>>> people = list(ads.SearchQuery(first_author=\"Reiss, A\"))\n\n>>> people[0].author\n[u'Reiss, A. W.']\n````\n\nOr papers where they are anywhere in the author list:\n````\n>>> papers = list(ads.SearchQuery(author=\"Reiss, A\"))\n\n>>> papers[0].author\n[u'Goodwin, F. E.', u'Henderson, D. M.', u'Reiss, A.', u'Wilkerson, John L.']\n````\n\nOr search by affiliation:\n````\n>>> papers = list(ads.SearchQuery(aff=\"*stromlo*\"))\n\n>>> papers[0].aff\n[u'University of California, Berkeley',\n u'University of Kansas',\n u'Royal Greenwich Observatory',\n u\"Queen's University\",\n u'Mt. Stromlo Observatory',\n u'University of Durham']\n````\n\nIn the above examples we `list()` the results from `ads.SearchQuery` because `ads.SearchQuery` is a generator, allowing us to return any number of articles. \nTo prevent deep pagination of results, a default of `max_pages=3` is set. \nFeel free to change this, but be aware that each new page fetched will count against your daily API limit. \nEach object returned is an ````ads.Article```` object, which has a number of *very* handy attributes and functions:\n\n````\n>>> first_paper = papers[0]\n\n>>> first_paper\n<ads.search.Article at 0x7ff1b913dd10>\n\n# Show some brief details about the paper\n>>> print first_paper\n<Zepf, S. et al. 1994, 1994AAS...185.7506Z>\n\n# You can access attributes of an object in IPython by using the 'tab' button:\n>>> first_paper.\nfirst_paper.abstract              first_paper.build_citation_tree   first_paper.first_author_norm     first_paper.keys                  first_paper.pubdate\nfirst_paper.aff                   first_paper.build_reference_tree  first_paper.id                    first_paper.keyword               first_paper.read_count\nfirst_paper.author                first_paper.citation              first_paper.identifier            first_paper.metrics               first_paper.reference\nfirst_paper.bibcode               first_paper.citation_count        first_paper.issue                 first_paper.page                  first_paper.title\nfirst_paper.bibstem               first_paper.database              first_paper.items                 first_paper.property              first_paper.volume\nfirst_paper.bibtex                first_paper.first_author          first_paper.iteritems             first_paper.pub                   first_paper.year\n````\n\nWhich allows you to easily build complicated queries. Feel free to fork this repository and add your own examples!\n\n**Authors**\n\nVladimir Sudilovsky & Andy Casey, Geert Barentsen, Dan Foreman-Mackey, Miguel de Val-Borro\n\n**License**\n\nCopyright 2014 the authors \n\nThis is open source software available under the MIT License. For details see the LICENSE file.",
        "url": "http://pypi.python.org/pypi/ads",
        "summary": "A Python module for NASA's ADS that doesn't suck.",
        "command": "pip install 'ads'"
      },
      "adsbibdesk": {
        "name": "adsbibdesk",
        "description": "ADS to BibDesk\n==============\n\nThis is the command line edition of ADS to BibDesk, a tool for retrieving the bibtex, abstract and PDF of an astronomical journal article published on `ADS <http://adsabs.harvard.edu>`_ or `arXiv.org <http://arxiv.org/archive/astro-ph>`_ and add it to your `BibDesk <http://bibdesk.sourceforge.net/>`_ database.\n\nADS to BibDesk is a tool for retrieving the bibtex, abstract and PDF of an astronomical journal article published on `ADS <http://adsabs.harvard.edu>`_ or `arXiv.org <http://arxiv.org/archive/astro-ph>`_ and adding it to your `BibDesk <http://bibdesk.sourceforge.net/>`_ database.\n\nADS to BibDesk comes in two flavours: an Automator Service that you can use to grab papers in any app (e.g., in Safari, or Mail), or a command line app.\n\n*Developers:* please read the `CONTRIBUTING <https://github.com/jonathansick/ads_bibdesk/blob/master/CONTRIBUTING.md>`_ document for details on how to build the ADS to BibDesk CLI/Service from source, make changes, and submit pull requests.\n\nCommand Line Quickstart\n-----------------------\n\nADS to BibDesk can also be run directly from the command line.\nThe command line script can be installed via::\n\n    python setup.py install\n\nYou may need to run the last command with `sudo`.\n\nOnce `adsbibdesk` is installed, you can call it with the same types of article tokens you can launch the Service with, e.g.,::\n\n    adsbibdesk 1998ApJ...500..525S\n\nA full summary of `adsbibdesk` commands is available via::\n\n    adsbibdesk --help\n\nSummary of article tokens\n-------------------------\n\n* The URL of an ADS or arXiv article page,\n* The ADS bibcode of an article (e.g. `1998ApJ...500..525S`),\n* The arXiv identifier of an article (e.g. `0911.4956`), or\n* An article DOI.\n\nOther Modes\n-----------\n\nBesides the primary mode (adding a single paper to BibDesk, ADS to BibDesk has three other modes: previewing papers, updated preprints, and ingesting PDF archives into BibDesk.\n\nPreviewing Papers\n~~~~~~~~~~~~~~~~~\n\nUse the `-o` switch to simply download and view the PDF of an article without adding it to BibDesk. E.g.,::\n\n    adsbibdesk -o 1998ApJ...500..525S\n\nUpdating Preprints\n~~~~~~~~~~~~~~~~~~\n\nRun ADS to BibDesk with the `-u` switch to find and update all astro-ph preprints in your BibDesk bibliography::\n\n    adsbibdesk -u\n\nTo restrict this update to a date range, you can use the `--from_date` (`-f`) and `--to_date` (`-t`) flags with dates in `MM/YY` format. For example, to update preprints published in 2012, run::\n\n    adsbibdesk -u --from_date=01/12 --to_date=12/12\n\nNote that this operation can take some time since we throttle requests to ADS to be a nicer robot.\n\nPDF Ingest Mode\n~~~~~~~~~~~~~~~\n\nWith the command-line ADS to BibDesk, you can ingest a folder of PDFs that originated from ADS into BibDesk.\nThis is great for users who have amassed a literature folder, but are just starting to use BibDesk.\nThis will get you started quickly.\n\nYou need the program `pdf2json <http://code.google.com/p/pdf2json/>`_ to use\nthis script. The easiest way to get pdf2json and its dependencies is through\n`Homebrew <http://mxcl.github.com/homebrew/>`_, the Mac package manager.\nOnce homebrew is setup, simply run `brew install pdf2json`.\n\nTo run this workflow,::\n\n    adsbibdesk -p my_pdf_dir/\n\nwhere `my_pdf_dir/` is a directory containing PDFs that you want to ingest.\n\nNote that this workflow relies on a DOI existing in the PDF.\nAs such, it will not identify astro-ph pre-prints, or published papers older than a few years.\nTypically the DOI is published on the first page of modern papers.\nThis method was inspired by a script by `Dr Lucy Lim <http://www.mit.edu/people/lucylim/BibDesk.html>`_.\n\nLicense\n-------\n\nCopyright 2014 Jonathan Sick, Rui Pereira and Dan-Foreman Mackey\n\nADS to BibDesk is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nADS to BibDesk is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with ADS to BibDesk.  If not, see <http://www.gnu.org/licenses/>.",
        "url": "http://pypi.python.org/pypi/adsbibdesk",
        "summary": "Add papers from arxiv.org or NASA/SAO ADS to your BibDesk bibliography.",
        "command": "pip install 'adsbibdesk'"
      },
      "ADSBibTeX": {
        "name": "adsbibtex",
        "description": "# ADSBibTeX\n[![Build Status](https://api.travis-ci.org/ryanvarley/adsbibtex.png?branch=master)](https://travis-ci.org/ryanvarley/adsbibtex)\n[![Coverage Status](https://coveralls.io/repos/ryanvarley/adsbibtex/badge.svg?branch=master&service=github)](https://coveralls.io/github/ryanvarley/adsbibtex?branch=master)\n\nBuilds a bibtex file for a LaTeX document using by querying a list of bibcodes with NASA ADS\n\n## Why?\n\nTwo main reasons\n\n1. If you cite a preprint paper, this will automatically update the entry to the published version, when it is published\n2. For really long bibtex files, its much easier to manage a list of bibcodes than bibtex entries, and you can divide\n them into sections with comments i.e.\n\n```bash\n# Transmission Spectroscopy\n2008Natur.452..329S  Swain2008  # The presence of methane in the atmosphere of an extrasolar planet\n2006AGUSM.A21A..06T  Tinetti2006\n\n# Detrending Techniques\n2013ApJ...766....7W  Waldmann2013\n```\n\nIt is also fast after the initial run, entries are cached so they are only fetched from ADS again after they are older than your ttl (time to live) setting in the config. This means you can integrate it into your latex compilation without worrying about it adding a significant overhead to your build.\n\n## Setup and installation\n\nYou'll need an ADS API key, the following is from the `ads` [module docs](https://github.com/andycasey/ads)\n\n1. You'll need an API key from NASA ADS labs. Sign up for the newest version of ADS search at https://ui.adsabs.harvard.edu, visit account settings and generate a new API token. The official documentation is available at https://github.com/adsabs/adsabs-dev-api\n2. When you get your API key, save it to a file called ``~/.ads/dev_key`` or save it as an environment variable named ``ADS_DEV_KEY``\n\nThen install this package\n\n```bash\npip install adsbibtex\n```\n\nor get the latest development version from here with\n\n```bash\ngit clone https://github.com/ryanvarley/adsbibtex.git\ncd adsabs-dev-api\npython setup.py install\n```\n\n\n## Usage\n\n```bash\nadsbibtex <config_file>\n```\n\nconfig_file defaults to `config.adsbib`, see the next section for an example file\n\n## Example config file\n\nThe config file consists of a top section of `yaml` where the config is stored and a list of bibcode citename entries\n(after `---`). Comments can be entered with `#`.\n\nAll entries must have a valid bibcode, if no citename is given then the bibcode will be the citename\n\n```bash\n# YAML front matter (config)\ncache_ttl:   24  # hours\ncache_file:  adsbibtex_cache\nbibtex_file: example.bib\n---\n#   Bibcode          Name          # Optional Comment\n2008Natur.452..329S  Swain2008\n2006AGUSM.A21A..06T                # no name needed\n\n# You can use comments to divide papers into sections\n2013ApJ...766....7W  Waldmann2013  # You could put the paper title or subject here\n```\n\nRunning `adsbibtex` on this file produces the following output\n\n```bibtex\n@ARTICLE{Swain2008,\n   author = {{Swain}, M.~R. and {Vasisht}, G. and {Tinetti}, G.},\n    title = \"{The presence of methane in the atmosphere of an extrasolar planet}\",\n  journal = {\\nat},\n     year = 2008,\n    month = mar,\n   volume = 452,\n    pages = {329-331},\n      doi = {10.1038/nature06823},\n   adsurl = {http://adsabs.harvard.edu/abs/2008Natur.452..329S},\n  adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}\n\n@ARTICLE{2006AGUSM.A21A..06T,\n   author = {{Tinetti}, G. and {Meadows}, V.~S. and {Crisp}, D. and {Kiang}, N. and \n\t{Fishbein}, E. and {Kahn}, B. and {Turnbull}, M.},\n    title = \"{Detectability of Surface and Atmospheric Signatures in the Disk-averaged Spectra of the Earth}\",\n  journal = {AGU Spring Meeting Abstracts},\n keywords = {5210 Planetary atmospheres, clouds, and hazes (0343), 5704 Atmospheres (0343, 1060), 0343 Planetary atmospheres (5210, 5405, 5704), 0406 Astrobiology and extraterrestrial materials},\n     year = 2006,\n    month = may,\n    pages = {A6},\n   adsurl = {http://adsabs.harvard.edu/abs/2006AGUSM.A21A..06T},\n  adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}\n\n@ARTICLE{Waldmann2013,\n   author = {{Waldmann}, I.~P. and {Tinetti}, G. and {Deroo}, P. and {Hollis}, M.~D.~J. and \n\t{Yurchenko}, S.~N. and {Tennyson}, J.},\n    title = \"{Blind Extraction of an Exoplanetary Spectrum through Independent Component Analysis}\",\n  journal = {\\apj},\narchivePrefix = \"arXiv\",\n   eprint = {1301.4041},\n primaryClass = \"astro-ph.EP\",\n keywords = {methods: data analysis, methods: observational, methods: statistical, planets and satellites: atmospheres, planets and satellites: individual: HD189733b, techniques: spectroscopic },\n     year = 2013,\n    month = mar,\n   volume = 766,\n      eid = {7},\n    pages = {7},\n      doi = {10.1088/0004-637X/766/1/7},\n   adsurl = {http://adsabs.harvard.edu/abs/2013ApJ...766....7W},\n  adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}\n```",
        "url": "http://pypi.python.org/pypi/ADSBibTeX",
        "summary": "ADSBibTeX",
        "command": "pip install 'ADSBibTeX'"
      },
      "adsense.portlet": {
        "name": "adsense.portlet",
        "description": "Introduction\r\n        ============\r\n        \r\n        \r\n        \r\n        Changelog\r\n        =========\r\n        \r\n        1.0 (xxxx-xx-xx)\r\n        ----------------\r\n        \r\n        * Initial release",
        "url": "http://pypi.python.org/pypi/adsense.portlet",
        "summary": "Display adsense zones from google",
        "command": "pip install 'adsense.portlet'"
      },
      "adsense_scraper": {
        "name": "adsense_scraper",
        "description": "adsense_scraper is a simple module that uses Twill and html5lib to scrape\nGoogle AdSense earnings data from your account.\n\nFor example, this is useful as a cron job or other sort of periodic task to \nstore a copy of your earnings in your own database so that you don't have\nto visit the AdSense site every day.",
        "url": "http://pypi.python.org/pypi/adsense_scraper",
        "summary": "Scrapes Google AdSense earnings data with Python using Twill",
        "command": "pip install 'adsense_scraper'"
      },
      "adshli": {
        "name": "adshli",
        "description": "ADSHLI implements a python client for the Beckhoff Twincat AMS/ADS protocol. The client is independent from any Beckhoff supplied libraries. Consequently, no Twincat installation is needed.\r\n\r\nIt provides two APIs:\r\n\r\n- A low level API allowing you to directly send ADS commands to the PLC \r\n- A high level API providing convenience functions making access to the PLC as easy as possible.\r\n\r\nFor documentation please see the readme file and sample_code.py available at:\r\nhttps://github.com/simonwaid/adshli",
        "url": "http://pypi.python.org/pypi/adshli",
        "summary": "Client for the Twincat AMS/ADS protocol",
        "command": "pip install 'adshli'"
      },
      "adsorb": {
        "name": "adsorb",
        "description": "Adsorption\r\n==========\r\n\r\nLightweight loose coupling library for Python. Add listeners to a named event\r\nand call them from anywhere to collect their responses.\r\n\r\nEvent listeners are called in an undefined sequence and all responses are\r\ncollected before execution resumes with the caller. Future versions may\r\nadd support to call listeners in parallel threads.\r\n\r\nInstallation\r\n------------\r\n\r\nRun ``easy_install adsorb`` or ``pip install adsorb`` to get from\r\n`PyPI <http://pypi.python.org/>`__ (not yet implemented).\r\n\r\nTo install from source, run ``python setup.py install``.\r\n\r\nTo run the tests, install ``nose`` and ``coverage`` and run\r\n``python setup.py nosetests``.\r\n\r\nUsage\r\n-----\r\n\r\nSee http://jace.github.com/adsorb/\r\n\n\n0.1\r\n---\r\n\r\n- Initial version",
        "url": "http://pypi.python.org/pypi/adsorb",
        "summary": "Lightweight loose coupling library for Python. Add listeners to a named event and call them from anywhere to collect their responses.",
        "command": "pip install 'adsorb'"
      },
      "adspy": {
        "name": "adspy",
        "description": "pyads is a simple way of interacting with a bibtex library built primarily from\nthe ADS (http://adsabs.harvard.edu/abstract_service.html). Your mileage may\nvary, but I've found it useful for quickly looking up cite info.  There are a \nlot of improvements that could be made.\n\nHere's a short script to start showing the functionality.  I'll try to get get\nsome more docs up here soon.\n\nlib = ADSLibrary('test')\nfor t in [\"2011ApJ...735...96S\", \"2008ApJ...689.1063S\"]:\n    lib.add_entry(t)\nlib.write_bib()\nlib.save()\nlib.find('Skillman')\nlib.find('Dinosaur')\nlib.find('2008ApJ...689.1063S')\nb = lib.find('Skillman2011')\nb.download() # Not fully tested\nb.open() # Also not fully tested.\n\n# You would import an exisiting bib library with:\n# lib.import_bib('library.bib')\n# lib.save()\n \nnn",
        "url": "http://pypi.python.org/pypi/adspy",
        "summary": "Simple bibtex tools for use with ADS.",
        "command": "pip install 'adspy'"
      },
      "adspygoogle": {
        "name": "adspygoogle",
        "description": "====================================\nNotice: This library is now sunset\n====================================\n\nAs of 1/5/15, this library is sunset and will no longer receive updates for new\nversions of supported APIs or bug fixes. Once all supported APIs are no longer\ncompatible with this library, it will be removed from GitHub and PyPI.\n\nA newer library named googleads is available that supports Python 2.7 and Python\n3.3+. You can read more about it here:\n\n* `The release announcement <http://googleadsdeveloper.blogspot.com/2014/03/the-ads-apis-python-client-library.html>`_.\n* `googleads github page <https://github.com/googleads/googleads-python-lib>`_.\n* `Migrating from adspygoogle to googleads <https://github.com/googleads/googleads-python-lib/wiki/Migrating-from-adspygoogle-to-googleads>`_.\n\n===========================================\nThe Google Ads APIs Python Client Libraries\n===========================================\n\nThe Google Ads APIs Python Client Libraries support the following products:\n\n* AdWords API Python Client Library v15.17.1\n* DoubleClick for Advertisers API Python Client Library v2.4.2\n* DFP API Python Client Library v9.12.0\n\nYou can find more information about the Google Ads Python Client Libraries\n`here <https://github.com/googleads/googleads-python-legacy-lib/>`_.\n\nInstallation\n============\n\nYou have two options for installing the Ads Python Client Libraries:\n\n* Install with a tool such as pip::\n\n  $ sudo pip install adspygoogle\n  $ --allow-external PyXML\n  $ --allow-unverified PyXML\n  $ --allow-external ElementTree\n  $ --allow-unverified ElementTree\n  $ --allow-external cElementTree\n  $ --allow-unverified cElementTree\n\n* Install manually after downloading and extracting the tarball::\n\n  $ sudo python setup.py install\n\nExamples and Configuration Scripts\n==================================\n\nThis package only provides the core components necessary to use the client\nlibraries. If you would like to obtain example code for any of the included\nclient libraries, you can find it on our\n`downloads page <https://github.com/googleads/googleads-python-legacy-lib/releases>`_.\n\nKnown Issues\n============\n\n* Due to changes to PyPI's installation process, using 'pip install' to install\n  the library currently requires a number of 'allow-external' and\n  'allow-unverified' flags for the external dependencies of PyXML, ElementTree,\n  and cElementTree. If you're using a version of Python greater than 2.5 and\n  would prefer not to install PyXML or cElementTree from external sources, then\n  follow the steps below to install via the tarball without those dependencies\n  (cElementTree is installed already as a default library in > Python 2.5).\n  Alternatively, if you would prefer to download these libraries to install\n  yourself, they can be downloaded at these locations:\n\n    - `ElementTree <https://pypi.python.org/pypi/elementtree/>`_\n    - `cElementTree <https://pypi.python.org/pypi/cElementTree>`_\n    - `PyXML <https://pypi.python.org/pypi/PyXML/0.8.4>`_\n\n* The installation of PyXML and cElementTree will fail on Ubuntu 13.04. If you\n  are trying to install adspygoogle on Ubuntu 13.04, you should avoid installing\n  these dependencies. If you need to use either of these dependencies, there is\n  a work-around that can be found in\n  `this bug <https://bugs.launchpad.net/ubuntu/+source/python2.7/+bug/1238244/>`_.\n  Another alternative is to install manually and exclude these dependencies. To\n  do so, first download and extract the tarball below. In the root directory,\n  run the following command::\n\n  $ sudo python setup.py install --no_PyXML --no_cElementTree\n\nContact Us\n==========\n\nDo you have an issue using the Ads Python Client Libraries? Or perhaps some\nfeedback for how we can improve them? Feel free to let us know on our\n`issue tracker <https://github.com/googleads/googleads-python-legacy-lib/issues>`_.",
        "url": "http://pypi.python.org/pypi/adspygoogle",
        "summary": "Google Ads Python Client Library",
        "command": "pip install 'adspygoogle'"
      },
      "adspygoogle.adwords": {
        "name": "adspygoogle.adwords",
        "description": "For additional information, please see http://code.google.com/p/google-api-ads-python",
        "url": "http://pypi.python.org/pypi/adspygoogle.adwords",
        "summary": "AdWords API Python Client Library",
        "command": "pip install 'adspygoogle.adwords'"
      },
      "adspygoogle.dfp": {
        "name": "adspygoogle.dfp",
        "description": "WARNING: PyPI release is unofficial. For official information, please see http://code.google.com/p/google-api-ads-python",
        "url": "http://pypi.python.org/pypi/adspygoogle.dfp",
        "summary": "DFP API Python Client Library",
        "command": "pip install 'adspygoogle.dfp'"
      },
      "adsy-autotest": {
        "name": "adsy-autotest",
        "description": "Minimalistic Continuous Integration for git\n\nOn failure it sends a notification to all users who have contributed to the\nbranch since the last sucessful test.",
        "url": "http://pypi.python.org/pypi/adsy-autotest",
        "summary": "Autotest tool - Minimalistic Continuous Integration",
        "command": "pip install 'adsy-autotest'"
      },
      "adsy-helper": {
        "name": "adsy-helper",
        "description": "Installs/Updates configuration of Adfinis-SyGroup Packages",
        "url": "http://pypi.python.org/pypi/adsy-helper",
        "summary": "Adfinis SyGroup Packaging Helper",
        "command": "pip install 'adsy-helper'"
      },
      "ADTM": {
        "name": "adtm",
        "description": "Adaptive Data Tabulation Markup\n===============================\n\nA Replacement for the nonuniform CSV, DSV, TSV type file formats for storing data tables based on JSON and YAML.\n\nThis format has been desgined to support complex data types and provide methods of presentation for elexclent text base readablity.\n\n\nSpecification\n=============\n\nsee `spec.md <https://github.com/alphaomega-technology/ADTM/blob/master/spec.md>`_",
        "url": "http://pypi.python.org/pypi/ADTM",
        "summary": "Adaptive Data Tabulation Markup",
        "command": "pip install 'ADTM'"
      },
      "aduana": {
        "name": "aduana",
        "description": null,
        "url": "http://pypi.python.org/pypi/aduana",
        "summary": "Bindings for Aduana library",
        "command": "pip install 'aduana'"
      },
      "advanced-config-manager": {
        "name": "advanced-config-manager",
        "description": "# advanced_config_manager\r\nA configuration manager for python that handles multiple config sources and sections.\r\n\r\nDocumentation for this can be found at: http://advanced-config-manager.readthedocs.org/en/latest/\r\n",
        "url": "http://pypi.python.org/pypi/advanced-config-manager",
        "summary": "Advanced Configuration Manager",
        "command": "pip install 'advanced-config-manager'"
      },
      "AdvancedHTMLParser": {
        "name": "advancedhtmlparser",
        "description": "AdvancedHTMLParser\n==================\n\nAdvancedHTMLParser is an Advanced HTML Parser (with optional indexing), writer, and formatter, and html->xhtml formtter written in python, and compatible and tested in Python 2.7 and Python 3.4.\n\nThere are many potential applications, not limited to:\n * Webpage Scraping / Data Extraction\n * Testing and Validation\n * HTML Modification/Insertion\n * Debugging\n * HTML Document generation\n * Web Crawling\n * Formatting HTML documents or web pages\n\n\nFull API\n--------\n\nCan be found  `Here <http://htmlpreview.github.io/?https://github.com/kata198/AdvancedHTMLParser/blob/master/doc/AdvancedHTMLParser.html>`_ .\n\nVarious examples  can be found in the \"tests\" directory, check github.\n\nShort Doc\n---------\n\nThe AdvancedHTMLParser can read in a file (or string) of HTML, and will create a modifiable DOM tree from it. It can also be constructed manually from AdvancedHTMLParser.AdvancedTag objects.\n\nThe parser then exposes many \"standard\" functions as you'd find on the web for accessing the data:\n\n    getElementsByTagName   - Returns a list of all elements matching a tag name\n\n    getElementsByName      - Returns a list of all elements with a given name attribute\n\n    getElementById         - Returns a single AdvancedTag (or None) if found an element matching the provided ID\n\n    getElementsByClassName - Returns a list of all elements containing a class name\n\n    getElementsByAttr       - Returns a list of all elements matching a paticular attribute/value pair.\n\n    getElementsWithAttrValues - Returns a list of all elements with a specific attribute name containing one of a list of values\n\n    getElementsCustomFilter - Provide a function/lambda that takes a tag argument, and returns True to \"match\" it. Returns all matched objects\n\n    getHTML                 - Returns string of HTML representing this DOM\n\n    getRootNodes            - Get a list of nodes at root level (0)\n\n    getFormattedHTML        - Returns a formatted string (using AdvancedHTMLFormatter; see below) of the HTML. Takes as argument an indent (defaults to two spaces)\n\n\nThe results of all of these getElement\\* functions are TagCollection objects. These objects can be modified, and will be reflected in the parent DOM.\n\n**Style Attribute**\n\nStyle attributes can be manipulated just like in javascript, so element.style.position = 'relative' for setting, or element.style.position for access. There are also helper methods, getStyle(name) and setStyle(name, value) which will set the  correct values.\n\n**TagCollection**\n\nA TagCollection can be used like a list. It also exposes the various get\\* functions which operate on the elements within the list (and their children). To operate just on items in the list, you can use filterCollection which takes a lambda/function and returns True to retain that tag in the return.\n\n**AdvancedTag**\n\nthe AdvancedTag represents a single tag and its inner text. It exposes many of the functions and properties you would expect to be present if using javascript.\neach AdvancedTag also supports the same getElementsBy\\* functions as the parser. It adds several additional that are not found in javascript, such as peers and arbitrary attribute searching.\n\nsome of these include:\n\n    appendText              -  Append text to this element\n\n    appendChild             -  Append a child to this element\n\n    insertBefore            -  Inserts a child before an existing child\n\n    insertAfter             - Inserts a child after an existing child\n\n    removeChild             -  Removes a child\n\n    getChildren             - Returns the children as a list\n\n    getStartTag             - Start Tag, with attributes\n\n    getEndTag               - End Tag\n\n    getPeersByName          - Gets \"peers\" (elements with same parent, at same level in tree) with a given name\n\n    getPeersByAttr          - Gets peers by an arbitrary attribute/value combination\n\n    getPeersWithAttrValues  - Gets peers by an arbitrary attribute/values combination. \n\n    getPeersByClassName   - Gets peers that contain a given class name\n\n    getElement\\*            - Same as above, but act on the children of this element.\n\n    nextSibling            - Get next sibling, be it text  or  an element\n\n    nextSiblingElement     - Get next sibling, that is an element\n\n    previousSibling            - Get previous sibling, be it text  or  an element\n\n    previousSiblingElement     - Get previous sibling, that is an element\n\n    {get,set,has}Attribute  - get/set/test for an attribute\n\n    {add,remove}Class       - Add/remove a class from the list of classes\n\n    getUid                  - Get a unique ID for this tag (internal)\n\n    __str__                 - str(tag) will show start tag with attributes, inner text, and end tag\n\n    __getitem__             - Can be indexed like tag[2] to access second child.\n\n\nAnd some properties:\n\n    children/childNodes     - The children as a list\n\n    innerHTML               - The innerHTML including the html of all children\n\n    outerHTML               - innerHTML wrapped in this tag\n\n    classNames/classList    - a list of the classes\n\n    parentNode/parentElement - The parent tag\n\n    tagName                - The tag name\n\n\nIndexedAdvancedHTMLParser\n-------------------------\n\nIndexedAdvancedHTMLParser provides the ability to use indexing for faster search. If you are just parsing and not modifying, this is your best bet. If you are modifying the DOM tree, make sure you call IndexedAdvancedHTMLParser.reindex() before relying on them. Each of the get* functions above takes an additional \"useIndex\" function, which can also be set to False to skip index. See constructor for more information, and \"Performance and Indexing\" section below.\n\nAdvancedHTMLFormatter and formatHTML\n------------------------------------\n\nThe AdvancedHTMLFormatter formats HTML into a pretty layout. It can handle elements like pre, core, script, style, etc to keep their contents preserved, but does not understand CSS rules.\n\nThe methods are:\n\n   parseStr               - Parse a string of contents\n   parseFile              - Parse a filename or file object\n\n   getHTML                - Get the formatted html\n\n\nA script, formatHTML comes with this package and will perform formatting on an input file, and output to a file or stdout:\n\n    Usage: formatHTML (optional: /path/to/in.html) (optional: [/path/to/output.html])\n\n      Formats HTML on input and writes to output file, or stdout if output file is omitted.\n\n\n    If output filename is not specified or is empty string, output will be to stdout.\n\n    If input filename is not specified or is empty string, input will be from stdin\n\n\nNotes\n-----\n\n* Each tag has a generated unique ID which is assigned at create time. The search functions use these to prevent duplicates in search results. There is a global function in the module, AdvancedHTMLParser.uniqueTags, which will filter a list of tags and remove any duplicates. TagCollections will only allow one instance of a tag (no duplicates)\n* In general, for tag names and attribute names, you should use lowercase values. During parsing, the parser will lowercase attribute names (like NAME=\"Abc\" becomes name=\"Abc\"). During searching, however, for performance reasons, it is assumed you are passing in already-lowercased strings. If you can't trust the input to be lowercase, then it is your responsibility to call .lower() before calling .getElementsBy\\*\n* If you are using this to construct HTML and not search, I recommend either setting the index params to False in the constructor, or calling  AdvancedHTMLParser.disableIndexing()\n* There are additional functions and usages not documented here, check the file for more information.\n\nPerformance and Indexing\n------------------------\n\nPerformance is very good using this class. The performance can be further enhanced via several indexing tunables:\n\nFirstly, in the constructor of IndexedAdvancedHTMLParser and in the reindex method is a boolean to be set which determines if each field is indexed (e.x. indexIDs will make getElementByID use an index).\n\nIf an index is used, parsing time slightly goes up, but searches become O(1) (from root node, slightly less efficent from other nodes) instead of O(n) [n=num elements].\n\nBy default, IDs, Names, Tag Names, Class Names are indexed.\n\nYou can add an index for any arbitrary field (used in getElementByAttr) via IndexedAdvancedHTMLParser.addIndexOnAttribute('src'), for example, to index the 'src' attribute. This index can be removed via removeIndexOnAttribute.\n\nExample Usage\n-------------\n\nSee `This Example <https://raw.githubusercontent.com/kata198/AdvancedHTMLParser/master/example.py>`_ for an example of parsing store data using this class.\n\nChanges\n-------\nSee: https://raw.githubusercontent.com/kata198/AdvancedHTMLParser/master/ChangeLog\n\n\nContact Me / Support\n--------------------\n\nI am available by email to provide support, answer questions, or otherwise  provide assistance in using this software. Use my email kata198 at gmail.com with \"AdvancedArgumentParser\" in the subject line.\n\nUnit Tests\n----------\n\nSee \"tests\" directory available in github. Use \"runTests.py\" within that directory. Tests use my `GoodTests <https://github.com/kata198/GoodTests>`_ framework. It will download it to the current directory if not found in path, so you don't need to worry that it's a dependency.",
        "url": "http://pypi.python.org/pypi/AdvancedHTMLParser",
        "summary": "A Powerful HTML Parser/Scraper/Validator/Formatter that constructs a modifiable, searchable DOM tree, and includes many standard JS DOM functions (getElementsBy*, appendChild, etc) and additional methods",
        "command": "pip install 'AdvancedHTMLParser'"
      },
      "AdvancedHTTPServer": {
        "name": "advancedhttpserver",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AdvancedHTTPServer",
        "summary": "Standalone web server built on Python's BaseHTTPServer",
        "command": "pip install 'AdvancedHTTPServer'"
      },
      "advanced_jabberclient": {
        "name": "advanced_jabberclient",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/advanced_jabberclient",
        "summary": "Advanced jabber client with ping timeouts",
        "command": "pip install 'advanced_jabberclient'"
      },
      "AdvancedLangConv": {
        "name": "advancedlangconv",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AdvancedLangConv",
        "summary": "Advanced Language Converter",
        "command": "pip install 'AdvancedLangConv'"
      },
      "AdvancedSearchDiscovery": {
        "name": "advancedsearchdiscovery",
        "description": "CLI Search and Discovery\n########################\n:date: 2014-04-21 09:51\n:tags: openstack, linux, administration\n:category: \\*nix\n\nAdvanced search and discovery tool\n==================================\n\nThis tool was built to allow you to query the worlds largest database. The\nquery strings will be rendered in your local web browser as standard HTML\ncontent. If this tool is running on a headless system the tool willl provide\nyou a link to the content that you are looking for.\n\n\nWhy\n---\n\nSometimes you just need information and sometimes you want this information at\nyour fingertips without the bottleneck of a mouse.\n\nIf these things have ever been true for you this tool is for you.\n\nExample Usage\n-------------\n\n.. code-block:: bash\n\n    asd linux --query how does it work\n\n\nFollow this project at \"https://github.com/cloudnull/AdvancedSearchDiscovery\"",
        "url": "http://pypi.python.org/pypi/AdvancedSearchDiscovery",
        "summary": "Search and Discover information on a variety of subjects",
        "command": "pip install 'AdvancedSearchDiscovery'"
      },
      "advanced-ssh-config": {
        "name": "advanced-ssh-config",
        "description": "Advanced SSH config\n===================\n\n|Travis| |PyPI version| |PyPI downloads| |License| |Requires.io|\n|Gitter|\n\n|ASSH logo - Advanced SSH Config logo|\n\nEnhances ``ssh_config`` file capabilities\n\n**NOTE**: This program is called by\n`ProxyCommand <http://en.wikibooks.org/wiki/OpenSSH/Cookbook/Proxies_and_Jump_Hosts#ProxyCommand_with_Netcat>`__\nfrom `lib-ssh <https://www.libssh.org>`__.\n\n--------------\n\nIt works *transparently* with :\n\n-  ssh\n-  scp\n-  rsync\n-  git\n-  and even desktop applications depending on ``lib-ssh`` (for instance\n   `Tower <http://www.git-tower.com>`__, `Atom.io <https://atom.io>`__,\n   `SSH Tunnel Manager <http://projects.tynsoe.org/fr/stm/>`__)\n\n--------------\n\nThe ``.ssh/config`` file is automatically generated, you need to update\n``.ssh/config.advanced`` file instead; With new features and a better\nregex engine for the hostnames.\n\nUsage\n-----\n\n.. code:: console\n\n    $ assh --help\n    Usage: assh [OPTIONS] COMMAND [arg...]\n\n    Commands:\n      build                 Build .ssh/config based on .ssh/config.advanced\n      connect <host>        Open a connection to <host>\n      info <host>           Print connection informations\n      init                  Build a .ssh/config.advanced file based on .ssh/config\n      generate-etc-hosts    Print a /etc/hosts file of .ssh/config.advanced\n      stats                 Print statistics\n\n    Options:\n      --version             show program's version number and exit\n      -h, --help            show this help message and exit\n      -p PORT, --port=PORT  SSH port\n      -c CONFIG_FILE, --config=CONFIG_FILE\n                            ssh_config file\n      -f, --force\n      -v, --verbose\n      -l LOG_LEVEL, --log_level=LOG_LEVEL\n      --dry-run\n\nCommmand line features\n----------------------\n\n**Gateway chaining**\n\n.. code:: bash\n\n    ssh foo.com/bar.com\n\nConnect to ``bar.com`` using ssh and create a proxy on ``bar.com`` to\n``foo.com``. Then connect to ``foo.com`` using the created proxy on\n``bar.com``.\n\n.. code:: bash\n\n    ssh foo.com/bar.com/baz.com\n\nConnect to ``foo.com`` using ``bar.com/baz.com`` which itself uses\n``baz.com``.\n\nConfiguration features\n----------------------\n\n-  **regex for hostnames**: ``gw.school-.*.domain.net``\n-  **aliases**: ``gate`` -> ``gate.domain.tld``\n-  **gateways**: transparent ssh connections chaining\n-  **includes**: split configuration into multiple files, support\n   globbing\n-  **local command execution**: finally a way to execute a command\n   locally on connection\n-  **inheritance**: ``inherits = gate.domain.tld``\n-  **variable expansion**: ``User = $USER`` (take $USER from\n   environment)\n-  **smart proxycommand**: connect using ``netcat``, ``socat`` or custom\n   handler\n\nConfig example\n--------------\n\n``~/.ssh/config.advanced``\n\n.. code:: ini\n\n    # Simple example\n    [foo.com]\n    user = pacman\n    port = 2222\n\n    [bar]\n    hostname = 1.2.3.4\n    gateways = foo.com   # `ssh bar` will use `foo.com` as gateway\n\n    [^vm-[0-9]*\\.joe\\.com$]\n    gateways = bar       # `ssh vm-42.joe.com will use `bar` as gateway which\n                         # itself will use `foo.com` as gateway\n\n    [default]\n    ProxyCommand = assh --port=%p connect %h\n\n--------------\n\n.. code:: ini\n\n    # Complete example\n    [foo]\n    user = pacman\n    port = 2222\n    hostname = foo.com\n\n    [bar]\n    hostname = 1.2.3.4\n    gateways = foo\n    # By running `ssh bar`, you will ssh to `bar` through a `ssh foo`\n\n    [^vm-[0-9]*\\.joe\\.com$]\n    IdentityFile = ~/.ssh/root-joe\n\n    gateways = direct joe.com joe.com/bar\n    # Will try to ssh without proxy, then fallback to joe.com proxy, then\n    # fallback to joe.com through bar\n\n    DynamicForward = 43217\n    LocalForward = 1723 localhost:1723\n    ForwardX11 = yes\n\n    [default]\n    Includes = ~/.ssh/config.advanced2 ~/.ssh/config.advanced3 ~/.ssh/configs/*/host.config\n    # The `Includes` directive must be in the `[default]` section\n\n    Port = 22\n    User = root\n    IdentityFile = ~/.ssh/id_rsa\n    ProxyCommand = assh connect %h --port=%p\n    Gateways = direct\n    PubkeyAuthentication = yes\n    VisualHostKey = yes\n    ControlMaster = auto\n    ControlPath = ~/.ssh/controlmaster/%h-%p-%r.sock\n    EscapeChar = ~\n\nInstallation\n------------\n\nDownload the latest build\n\n.. code:: console\n\n    $ curl -L https://github.com/moul/advanced-ssh-config/releases/download/v1.1.0/assh-`uname -s`-`uname -m` > /usr/local/bin/assh\n    $ chmod +x /usr/local/bin/assh\n\nUsing Pypi\n\n.. code:: console\n\n    $ pip install advanced-ssh-config\n\nOr by cloning\n\n.. code:: console\n\n    $ git clone https://github.com/moul/advanced-ssh-config\n    $ cd advanced-ssh-config\n    $ make install\n\nFirst run\n---------\n\nAutomatically generate a new ``.ssh/config.advanced`` based on your\ncurrent ``.ssh/config`` file:\n\n.. code:: console\n\n    $ assh init > ~/.ssh/config.advanced\n    $ assh build -f\n\nTests\n-----\n\n.. code:: console\n\n    $ make test\n\nDocker\n------\n\nBuild\n\n.. code:: console\n\n    $ docker build -t moul/advanced-ssh-config .\n\nRun\n\n.. code:: console\n\n    $ docker run -rm -i -t moul/advanced-ssh-config\n    or\n    $ docker run -rm -i -t -v $(pwd)/:/advanced_ssh_config moul/advanced-ssh-config\n    or\n    $ docker run -rm -i -t -v moul/advanced-ssh-config python setup.py test\n\nContributors\n------------\n\n-  `Christo DeLange <https://github.com/dldinternet>`__\n\n--\n\n© 2009-2015 Manfred Touron - `MIT\nLicense <https://github.com/moul/advanced-ssh-config/blob/master/License.txt>`__.\n\n.. |Travis| image:: https://img.shields.io/travis/moul/advanced-ssh-config.svg\n   :target: https://travis-ci.org/moul/advanced-ssh-config\n.. |PyPI version| image:: https://img.shields.io/pypi/v/advanced-ssh-config.svg\n   :target: https://pypi.python.org/pypi/advanced-ssh-config/\n.. |PyPI downloads| image:: https://img.shields.io/pypi/dm/advanced-ssh-config.svg\n   :target: \n.. |License| image:: https://img.shields.io/pypi/l/advanced-ssh-config.svg?style=flat\n   :target: https://github.com/moul/advanced-ssh-config/blob/develop/LICENSE.md\n.. |Requires.io| image:: https://img.shields.io/requires/github/moul/advanced-ssh-config.svg\n   :target: https://requires.io/github/moul/advanced-ssh-config/requirements/\n.. |Gitter| image:: https://img.shields.io/badge/chat-gitter-ff69b4.svg\n   :target: https://gitter.im/moul/advanced-ssh-config\n.. |ASSH logo - Advanced SSH Config logo| image:: https://raw.githubusercontent.com/moul/advanced-ssh-config/develop/assets/assh.jpg\n   :target: https://github.com/moul/advanced-ssh-config",
        "url": "http://pypi.python.org/pypi/advanced-ssh-config",
        "summary": "Add some magic to SSH and .ssh/config",
        "command": "pip install 'advanced-ssh-config'"
      },
      "AdvaS-Advanced-Search": {
        "name": "advas-advanced-search",
        "description": "AdvaS is a python library that provides methods and algorithms for high-level\r\nsearch and information retrieval as used in a search engine or a database optimizer.",
        "url": "http://pypi.python.org/pypi/AdvaS-Advanced-Search",
        "summary": "Library for advanced search",
        "command": "pip install 'AdvaS-Advanced-Search'"
      },
      "advene": {
        "name": "advene",
        "description": "Annotate DVds, Exchange on the NEt\n\n The Advene (Annotate DVd, Exchange on the NEt) project is aimed\n towards communities exchanging discourses (analysis, studies) about\n audiovisual documents (e.g. movies) in DVD format. This requires that\n audiovisual content and hypertext facilities be integrated, thanks to\n annotations providing explicit structures on  audiovisual streams, upon\n which hypervideo documents can be engineered.\n .\n The cross-platform Advene application allows users to easily\n create comments and analyses of video comments, through the\n definition of time-aligned annotations and their mobilisation\n into automatically-generated or user-written comment views (HTML\n documents). Annotations can also be used to modify the rendition\n of the audiovisual document, thus providing virtual montage,\n captioning, navigation... capabilities. Users can exchange their\n comments/analyses in the form of Advene packages, independently from\n the video itself.\n .\n The Advene framework provides models and tools allowing to design and reuse\n annotations schemas; annotate video streams according to these schemas;\n generate and create Stream-Time Based (mainly video-centred) or User-Time\n Based (mainly text-centred) visualisations of the annotations. Schemas\n (annotation- and relation-types), annotations and relations, queries and\n views can be clustered and shared in units called packages. Hypervideo\n documents are generated when needed, both from packages (for annotation and\n view description) and DVDs (audiovisual streams).",
        "url": "http://pypi.python.org/pypi/advene",
        "summary": "Annotate DVds, Exchange on the NEt",
        "command": "pip install 'advene'"
      },
      "adventure": {
        "name": "adventure",
        "description": "This is a faithful port of the “Adventure” game to Python 3 from the\noriginal 1977 FORTRAN code by Crowther and Woods (it is driven by the\nsame ``advent.dat`` file!) that lets you explore Colossal Cave, where\nothers have found fortunes in treasure and gold, though it is rumored\nthat some who enter are never seen again.  To encourage the use of\nPython 3, the game is designed to be played right at the Python prompt.\nSingle-word commands can be typed by themselves, but two-word commands\nshould be written as a function call (since a two-word command would not\nbe valid Python)::\n\n    >>> import adventure\n    >>> adventure.play()\n    WELCOME TO ADVENTURE!!  WOULD YOU LIKE INSTRUCTIONS?\n\n    >>> no\n    YOU ARE STANDING AT THE END OF A ROAD BEFORE A SMALL BRICK BUILDING.\n    AROUND YOU IS A FOREST.  A SMALL STREAM FLOWS OUT OF THE BUILDING AND\n    DOWN A GULLY.\n\n    >>> east\n    YOU ARE INSIDE A BUILDING, A WELL HOUSE FOR A LARGE SPRING.\n    THERE ARE SOME KEYS ON THE GROUND HERE.\n    THERE IS A SHINY BRASS LAMP NEARBY.\n    THERE IS FOOD HERE.\n    THERE IS A BOTTLE OF WATER HERE.\n\n    >>> get(lamp)\n    OK\n\n    >>> leave\n    YOU'RE AT END OF ROAD AGAIN.\n\n    >>> south\n    YOU ARE IN A VALLEY IN THE FOREST BESIDE A STREAM TUMBLING ALONG A\n    ROCKY BED.\n\nThe original Adventure paid attention to only the first five letters of\neach command, so a long command like ``inventory`` could simply be typed\nas ``inven``.  This package defines a symbol for both versions of every\nlong word, so you can type the long or short version as you please.\n\nYou can save your game at any time by calling the ``save()`` command\nwith a filename, and then can resume it later::\n\n    >>> save('advent.save')\n    GAME SAVED\n\n    >>> adventure.resume('advent.save')\n    GAME RESTORED\n    >>> look\n    SORRY, BUT I AM NOT ALLOWED TO GIVE MORE DETAIL.  I WILL REPEAT THE\n    LONG DESCRIPTION OF YOUR LOCATION.\n    YOU ARE IN A VALLEY IN THE FOREST BESIDE A STREAM TUMBLING ALONG A\n    ROCKY BED.\n\nYou can find two complete, working walkthroughs of the game in its\n``tests`` directory, which you can run using the ``discover`` module that\ncomes built-in with Python 3.2::\n\n    $ python3.2 -m unittest discover adventure\n\nI wrote most of this package over Christmas vacation 2010, to learn more\nabout the workings of the game that so enthralled me as a child; the\nproject also gave me practice writing Python 3.  I still forget the\nparentheses when writing ``print()`` if I am not paying attention.\n\nTraditional Mode\n================\n\nYou can also use this package to play Adventure at a traditional prompt\nthat does not require its input to be valid Python.  Use your operating\nsystem command line to run the package::\n\n    $ python3 -m adventure\n    WELCOME TO ADVENTURE!!  WOULD YOU LIKE INSTRUCTIONS?\n\n    >\n\nAt the prompt that will appear, two-word commands can simply be\nseparated by a space::\n\n    > get lamp\n    OK\n\nFor extra authenticity, the output of the Adventure game in this mode is\ntyped to your screen at 1200 baud.  You will note that although this\nprints the text faster than you can read it anyway, your experience of\nthe game will improve considerably, especially when a move results in a\nsurprise.\n\nWhy is the game better at 1200 baud?  When a paragraph of text is\nallowed to appear on the screen all at once, your eyes scan the entire\nparagraph for important information, often ruining any surprises before\nyou can then settle down and read it from the beginning.  But at 1200\nbaud, you wind up reading the text in order as it appears, which unfolds\nthe narrative sequentially as the author of Adventure intended.\n\nIf you created a file with the in-game ``save`` command, you can restore\nit later by naming it on the command line::\n\n    > save mygame\n    GAME SAVED\n    > quit\n    DO YOU REALLY WANT TO QUIT NOW?\n    > y\n    OK\n\n    $ python3 -m adventure mygame\n    GAME RESTORED\n    >\n\nNotes\n=====\n\n* Several Adventure commands conflict with standard Python built-in\n  functions.  If you want to run the normal Python function ``exit()``,\n  ``open()``, ``quit()``, or ``help()``, then import the ``builtin``\n  module and run the copy of the function stored there.\n\n* The word “break” is a Python keyword, so there was no possibility of\n  using it in the game.  Instead, use one of the two synonyms defined by\n  the PDP version of Adventure: “shatter” or “smash.”\n\nChangelog\n=========\n\n| 1.3 — 2012 April 27 — installs on Windows; fixed undefined commands\n| 1.2 — 2012 April 5 — restoring saves from command line; 5-letter commands\n| 1.1 — 2011 March 12 — traditional mode; more flexible Python syntax\n| 1.0 — 2011 February 15 — 100% test coverage, feature-complete\n| 0.3 — 2011 January 31 — first public release",
        "url": "http://pypi.python.org/pypi/adventure",
        "summary": "Colossal Cave adventure game at the Python prompt",
        "command": "pip install 'adventure'"
      },
      "adver_mng": {
        "name": "adver_mng",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/adver_mng",
        "summary": "forbid spiders",
        "command": "pip install 'adver_mng'"
      },
      "AdvOptParse": {
        "name": "advoptparse",
        "description": "A python module that provides an enhanced command line argument parser that can handle fields, values and command chaining of different sub-commands and fields.",
        "url": "http://pypi.python.org/pypi/AdvOptParse",
        "summary": "A more advanced options parser for python, allowing for multi command chaining and parameter parsing",
        "command": "pip install 'AdvOptParse'"
      },
      "advpy": {
        "name": "advpy",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/advpy",
        "summary": "Collection of small Python modules for WEBand Database",
        "command": "pip install 'advpy'"
      },
      "Adytum-NetCIDR": {
        "name": "adytum-netcidr",
        "description": "This package is deprecated; please use NetCIDR instead (http://cheeseshop.python.org/pypi/NetCIDR).\r\n\r\nThere are five major chunks of functionality to this library:\r\n\r\n    * create CIDR addresses for hosts and net blocks\r\n    * get node counts for any given netblock\r\n    * get ranges of addresses for net blocks\r\n    * create collections of networks (list subclass)\r\n    * determine if a CIDR address is in a given network or set of networks\r\n(__contains__ override)",
        "url": "http://pypi.python.org/pypi/Adytum-NetCIDR",
        "summary": "Object representations, operations and logic for hosts, networks, and collections of networks.",
        "command": "pip install 'Adytum-NetCIDR'"
      },
      "Adytum-PyMonitor": {
        "name": "adytum-pymonitor",
        "description": "Supporting python modules for the pymon monitoring tool",
        "url": "http://pypi.python.org/pypi/Adytum-PyMonitor",
        "summary": "Supporting python modules for the pymon monitoring tool",
        "command": "pip install 'Adytum-PyMonitor'"
      },
      "ae": {
        "name": "ae",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ae",
        "summary": "Python accoustic emission tools",
        "command": "pip install 'ae'"
      },
      "aead": {
        "name": "aead",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aead",
        "summary": "An authenticated encryption implementation.",
        "command": "pip install 'aead'"
      },
      "AEI": {
        "name": "aei",
        "description": "==========\nAEI Readme\n==========\n\nThis package provides a specification for the Arimaa Engine Interface (AEI).\nIt also includes some tools for using engines that implement AEI. Including an\ninterface to the arimaa.com gameroom. A full description of AEI can be found in\nthe file ``aei-protocol.txt``.\n\nThe scripts included for working with an AEI engine are:\n\n``analyze``\n  A simple script that runs an engine and has it search a given position or\n  move sequence.\n``gameroom``\n  AEI controller that connects to the arimaa.com gameroom and plays a game.\n``postal_controller``\n  Keeps a bot making moves as needed in any postal games it is a participant\n  in.\n``roundrobin``\n  Plays engines against each other in a round robin tournament.\n``simple_engine``\n  Very basic AEI engine, just plays random step moves.\n\nBasic examples of using the scripts can be found in the file ``usage.rst``.\n\nThe pyrimaa package also includes modules implementing the controller side of\nthe AEI protocol (``aei.py``), the Arimaa position representation (as bitboards\nin ``board.py`` and x88 in ``x88board.py``), and a few utility functions for\nhandling Arimaa timecontrols (``util.py``).\n\nIf you have python2 and pip on your machine you can install the latest\nrelease with::\n\n    pip install aei\n\nOn an operating system with a system supplied python you probably want to keep\nthe aei install separate from your system installed packages. To accomplish\nthat you can use either a virtualenv or user install.  A user install is done\nsimply by adding the ``--user`` option::\n\n    pip install --user aei",
        "url": "http://pypi.python.org/pypi/AEI",
        "summary": "Arimaa Engine Interface tools",
        "command": "pip install 'AEI'"
      },
      "aeltei": {
        "name": "aeltei",
        "description": "======\naeltei\n======\n\naeltei is a virtual multi instrument environment using soundfonts. It allows\none to use a keyboard to enter and play musical notes in a curses interface,\ni.e. on the command line. Current limitations include only support for one\nchannel, no pitch bending, and no saving recordings as MIDI files.\n\naeltei only works on Python 2.x where x >= 5. Python 3 support would require\nPython 3 support in the modules used by this program.\n\n\nLicense\n=======\n\naeltei is free software under the terms of the GNU Affero General Public\nLicense version 3 (or any later version). The author of aeltei is Niels Serup,\ncontactable at ns@metanohi.org (for now, just use this address for bug\nreports). This is version 0.1.0 of the program.\n\n\nInstallation\n============\n\nTo install aeltei the easy way, run::\n\n  easy_install aeltei\n\n(You must be a superuser and have python-setuptools installed to do this.)\n\nAlternatively, you can download aeltei either from\nhttp://metanohi.org/projects/aeltei/ or from http://pypi.python.org/pypi/aeltei\nand then install it from the downloaded file. This way you'll also get useful\nexample files. To install aeltei this way, run::\n\n  python setup.py install\n\nDependencies\n------------\n\naeltei depends on ``fluidsynth``, ``mingus``, ``pyFluidSynth``, and the\navailability of a soundfont (free soundfonts come with ``fluidsynth``).\n\n\nUse\n===\n\nRun ``aeltei --help``.\n\n\nDevelopment\n===========\n\naeltei uses Git for code management. To get the latest branch, download it from\ngitorious.org::\n\n  $ git clone git://gitorious.org/aeltei/aeltei.git\n\n\n\nThis document\n=============\nCopyright (C) 2011  Niels Serup\n\nCopying and distribution of this file, with or without modification, are\npermitted in any medium without royalty provided the copyright notice and this\nnotice are preserved.  This file is offered as-is, without any warranty.",
        "url": "http://pypi.python.org/pypi/aeltei",
        "summary": "UNKNOWN",
        "command": "pip install 'aeltei'"
      },
      "aem-cmd": {
        "name": "aem-cmd",
        "description": "AEM command line management.\n===============================\n\nA set of tools to administrate an Adobe AEM content management installation\nfrom the command line. Features include:\n\n* Unix philosophy enables pipe and script based composition of common tasks\n* Bash completion script included\n* Content search, modification, deletion\n* User and group management\n* Package management\n* Simple instance management for running a command against all your installations\n* Common ops tools like repo optimization, activation and cache clearing\n\nFull documentation at <https://github.com/bjorns/aem-cmd/blob/master/README.md>",
        "url": "http://pypi.python.org/pypi/aem-cmd",
        "summary": "AEM Command line tools",
        "command": "pip install 'aem-cmd'"
      },
      "Aeon": {
        "name": "aeon",
        "description": "Aeon\n====\n\nMeasures how often designated functions, methods, or pieces of code are\nexecuted and what their runtime is. Optionally prints a nice report to\nthe screen, although the raw data is available for further processing as\nwell.\n\nOutline\n-------\n\n1. Mark parts of the code that should be monitored with the provided\n   context manager or decorators.\n2. Tell your program to output the report or provide you the data when\n   it's done.\n3. Run your program.\n4. \\?\\?\\?\\?\\?\n5. Profit.\n\nBasic Usage\n-----------\n\nHow to designate code that should be monitored.\n\nA free-standing piece of code.\n\n.. code:: python\n\n    from aeon import timer\n\n    with timer('my measurement'):\n        # do stuff here...\n\n    # to assign the measurement to a specific group\n    with timer('my measurement', 'general frobnication'):\n        # do stuff here\n\nA function.\n\n.. code:: python\n\n    from aeon import timer\n\n    @timer\n    def my_function():\n        pass\n\nA method.\n\n.. code:: python\n\n    from aeon import timer\n\n    class Foo(object):\n        @timer.method\n        def bar(self):\n            pass\n\nHow to see the report.\n\n.. code:: python\n\n    from aeon import timer\n\n    print timer.report() \n    print timer  # equivalent\n\nFurther features\n----------------\n\nYou can instantiate your own timer if you want to, in case you want to\nuse several in parallel.\n\n.. code:: python\n\n    from aeon import Timer\n\n    my_timer= Timer()\n\n    with my_timer('my_measurement'):\n        pass\n\n    # or\n    with my_timer('my_measurement', 'my_group'):\n        pass\n\n    @my_timer\n    def foo():\n        pass\n\n    class Foo(object):\n        @my_timer.method\n        def bar(self):\n            pass\n\nThe timer object can be queried for specific measurements or the data\nwith which it generates the report.\n\nAlso, nothing prevents you from using the Measurement class on its own:\n\n.. code:: python\n\n    from aeon import Measurement\n\n    m = Measurement()\n    for i in xrange(100):\n        m.start()\n        # stuff happens here\n        m.stop()\n\n    assert m.calls == 100\n    print m.total_runtime, m.time_per_call\n\nInstallation\n------------\n\nInstallation is easy as:\n\n.. code:: bash\n\n    $ sudo pip install aeon\n\nRationale\n---------\n\nThe code has originally been used in a computational physics project\nwhere the typical runtime distribution is very dependent on the problem\nat hand. It has proven itself useful for giving a feel for where time is\nspent during computation and quickly showing when parts of code went on\na riot. In fact, in that project, it is enabled in production since the\noverhead is low.\n\nWhat sets it apart is the possibility to monitor only specific parts of\nthe code and optionally have these parts logically grouped (by default,\nit will use the class or module names).\n\nThere are better alternatives for proper benchmarking, like cProfile.",
        "url": "http://pypi.python.org/pypi/Aeon",
        "summary": "Runtime and number of calls for designated functions, methods, or pieces of code. Optionally output nice report.",
        "command": "pip install 'Aeon'"
      },
      "aero": {
        "name": "aero",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aero",
        "summary": "aero adds django-like apps support to tornado and automates common actions",
        "command": "pip install 'aero'"
      },
      "AeroCalc": {
        "name": "aerocalc",
        "description": "AeroCalc is a pure python package that performs various aeronautical \r\nengineering calculations.  Currently it provides airspeed conversions, \r\nstatic source error correction calculations, standard atmosphere \r\ncalculations and unit conversions.",
        "url": "http://pypi.python.org/pypi/AeroCalc",
        "summary": "Aeronautical Engineering Calculations",
        "command": "pip install 'AeroCalc'"
      },
      "aerofiles": {
        "name": "aerofiles",
        "description": "|aerofiles|\n===========\n\n**waypoint, task, tracklog readers and writers for aviation**\n\n.. image:: https://travis-ci.org/Turbo87/aerofiles.png?branch=master\n   :target: https://travis-ci.org/Turbo87/aerofiles\n   :alt: Build Status\n\nFeatures\n--------\n\n-  `Flarm <http://flarm.com/>`_ configuration file writer\n   (``aerofiles.flarmcfg``)\n-  `IGC <http://www.fai.org/gliding>`_ file writer (``aerofiles.igc``)\n-  `OpenAir <http://www.winpilot.com/UsersGuide/UserAirspace.asp>`_ file\n   reader (``aerofiles.openair``)\n-  `SeeYou <http://www.naviter.com/products/seeyou/>`_ CUP file reader and\n   writer (``aerofiles.seeyou``)\n-  `WELT2000 <http://www.segelflug.de/vereine/welt2000/>`_ file reader\n   (``aerofiles.welt2000``)\n-  `XCSoar <http://www.xcsoar.org>`_ task file writer (``aerofiles.xcsoar``)\n\nDevelopment Environment\n-----------------------\n\nIf you want to work on aerofiles you should install the necessary dependencies\nusing::\n\n    $ pip install -r requirements-dev.txt\n\nYou can run the testsuite with::\n\n    $ tox\n\nLicense\n-------\n\nThis code is published under the MIT license. See the\n`LICENSE <https://github.com/Turbo87/aerofiles/blob/master/LICENSE>`__ file\nfor the full text.\n\n\n.. |aerofiles| image:: https://github.com/Turbo87/aerofiles/raw/master/img/logo.png\n    :alt: aerofiles",
        "url": "http://pypi.python.org/pypi/aerofiles",
        "summary": "waypoint, task, tracklog readers and writers for aviation",
        "command": "pip install 'aerofiles'"
      },
      "aerofs": {
        "name": "aerofs",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aerofs",
        "summary": "aerofs",
        "command": "pip install 'aerofs'"
      },
      "aerolito": {
        "name": "aerolito",
        "description": "Aerolito is an AIML alternative based on YAML. Aerolito provides features \nfor natural language processing simulation. Example of usage::\n\n    from aerolito import Kernel\n    kernel = Kernel('config.yml')\n\n    print kernel.respond(u'Hello')",
        "url": "http://pypi.python.org/pypi/aerolito",
        "summary": "Python library for natural language processing simulation",
        "command": "pip install 'aerolito'"
      },
      "aeromancer": {
        "name": "aeromancer",
        "description": "",
        "url": "http://pypi.python.org/pypi/aeromancer",
        "summary": "",
        "command": "pip install 'aeromancer'"
      },
      "aeronaut": {
        "name": "aeronaut",
        "description": "Aeronaut: A client library for DiData Cloud\n===========================================\n\nIt's alpha, it may have bugs, and it's free!\n\nSee http://pythonhosted.org//aeronaut/ for usage.\n\nSee LICENSE.txt for licensing information.\n",
        "url": "http://pypi.python.org/pypi/aeronaut",
        "summary": "Aeronaut: A client library for DiData Cloud",
        "command": "pip install 'aeronaut'"
      },
      "aerospike": {
        "name": "aerospike",
        "description": "Aerospike Python Client\n=======================\n|Build| |Release| |Wheel| |Downloads| |License|\n\n.. |Build| image:: https://travis-ci.org/aerospike/aerospike-client-python.svg?branch=master\n.. |Release| image:: https://img.shields.io/pypi/v/aerospike.svg\n.. |Wheel| image:: https://img.shields.io/pypi/wheel/aerospike.svg\n.. |Downloads| image:: https://img.shields.io/pypi/dm/aerospike.svg\n.. |License| image:: https://img.shields.io/pypi/l/aerospike.svg\n\nDependencies\n------------\n\nThe Python Client for Aerospike works on Python 2.6, 2.7 running on\n**64-bit** OS X 10.9+ and Linux.\n\nThe client depends on:\n\n-  Python devel Package\n-  The Aerospike C client\n\nRedHat 6+ and CentOS 6+\n~~~~~~~~~~~~~~~~~~~~~~~\n\nThe following are dependencies for:\n\n-  RedHat Enterprise (RHEL) 6 or newer\n-  CentOS 6 or newer\n-  and related distributions using ``yum`` package manager.\n\n::\n\n    sudo yum install python-devel\n    sudo yum install openssl-devel\n\nDebian 6+ and Ubuntu 12.04+\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe following are dependencies for:\n\n-  Debian 6 or newer\n-  Ubuntu 12.04 or newer\n-  and related distributions using ``apt-get`` package manager.\n\n::\n\n    sudo apt-get install python-dev\n    sudo apt-get install libssl-dev\n\nOS X\n~~~~~~~~\n\nBy default OS X will be missing command line tools. On Mavericks (OS X 10.9)\nand higher those `can be installed without Xcode <http://osxdaily.com/2014/02/12/install-command-line-tools-mac-os-x/>`__.\n\n::\n\n    xcode-select --install # install the command line tools, if missing\n\nThe dependencies can be installed through the OS X package manager `Homebrew <http://brew.sh/>`__.\n\n::\n\n    brew install openssl\n\nInstall\n-------\n\nAerospike Python Client can be installed using `pip`:\n\n::\n\n    pip install aerospike\n\n    # with pip versions >= 6.0 you can\n\n    pip install --no-cache-dir aerospike\n\nBuild\n-----\n\nInstructions for building Aerospike Python Client, please refer to the \n``BUILD.md`` file for details.\n\nDocumentation\n-------------\n\nDocumentation is hosted at `pythonhosted.org/aerospike <https://pythonhosted.org/aerospike/>`__\nand at `aerospike.com/apidocs/python <http://www.aerospike.com/apidocs/python/>`.\n\nExamples\n--------\n\nExample applications are provided in the `examples directory of the GitHub repository <https://github.com/aerospike/aerospike-client-python/tree/master/examples/client>`__\n\nFor examples, to run the ``kvs.py``:\n\n::\n\n    python examples/client/kvs.py\n\n\nBecnhmarks\n----------\n\nTo run the benchmarks the python modules 'guppy' and 'tabulate' need to be installed.\nBenchmark applications are provided in the `benchmarks directory of the GitHub repository <https://github.com/aerospike/aerospike-client-python/tree/master/benchmarks>`__\n\nLicense\n-------\n\nThe Aerospike Python Client is made availabled under the terms of the\nApache License, Version 2, as stated in the file ``LICENSE``.\n\nIndividual files may be made available under their own specific license,\nall compatible with Apache License, Version 2. Please see individual\nfiles for details.",
        "url": "http://pypi.python.org/pypi/aerospike",
        "summary": "Aerospike Client Library for Python",
        "command": "pip install 'aerospike'"
      },
      "AerospikeClientMock": {
        "name": "aerospikeclientmock",
        "description": "Aerospike client mock based on dict used for unit testing",
        "url": "http://pypi.python.org/pypi/AerospikeClientMock",
        "summary": "Aerospike client mock",
        "command": "pip install 'AerospikeClientMock'"
      },
      "aescalante_nester": {
        "name": "aescalante_nester",
        "command": "pip install 'aescalante_nester'"
      },
      "aesculaap": {
        "name": "aesculaap",
        "description": "reppa\n=====\n\n    a general purpose bot to suit your purpose ..\n\n\n    in memoriam:\n\n    Boedha: \"there is suffering\"\n    Me: \"there is ignored suffering\"\n    Them: \"there is no ignored suffering\"\n    Us: \"who makes the need for denial of ignored suffering?\"\n    We: \"lets remove the need for suffering by removing the denial of ignored suffering\" \n    Rest: \"wait .. lets do that ourselves, cause all you do is talk and let your words be\" \n    World: \"there is no more ignored suffering\"\n    More Rest: \"what has been denied is no more deniable\"\n    Void and Peace: \"sure been waiting for this for a looooong time\"\n    Nobody: \"still suffering\"\n    Nomore: \"end of book.\"\n    Bartholomeus: \"i thought we we're talking multiple books\"\n\n    Sat Aug  3 13:27:51 CEST 2013\n\napplications provided are:\n\n[x] reppa - the bot in consideration \n\nlicense is MMIT (Modified MIT)\n",
        "url": "http://pypi.python.org/pypi/aesculaap",
        "summary": "aesculaap - general purpose bot.",
        "command": "pip install 'aesculaap'"
      },
      "Aesthete": {
        "name": "aesthete",
        "description": "========\r\nAesthete\r\n========\r\n\r\nAesthete is an integrated mathematics environment, incorporating\r\n\r\n* Glypher: WYSIWYG computer algebra package over Sympy\r\n* Glancer: matplotlib GUI\r\n* Source: underlying discrete/continuous mapping manager (inc CSV, functions, etc.)\r\n\r\n-------\r\nWebsite\r\n-------\r\n\r\nPlease see http://launchpad.net/aesthete for further details\r\n\r\n------------\r\nDependencies\r\n------------\r\n\r\n* numpy (>=1.4.1)\r\n* scipy (>=0.7.2)\r\n* sympy (>=0.7.1)\r\n* pycairo (>=1.8.8)\r\n* pygobject (>=2.21.5)\r\n* pygtk (>=2.17.0)\r\n* PIL (>=1.1.7)\r\n* matplotlib (>=1.0.1)\r\n* IPython (>=0.10)\r\n* rsvg (>=2.30.0)\r\n* argparse (>=1.1)\r\n* lxml (>=2.3)\r\n\r\nPackages for Sympy 0.7.x series should in turn depend on mpmath but, if not, you may need to install python-mpmath separately",
        "url": "http://pypi.python.org/pypi/Aesthete",
        "summary": "Integrated mathematics environment",
        "command": "pip install 'Aesthete'"
      },
      "aexpect": {
        "name": "aexpect",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aexpect",
        "summary": "Aexpect",
        "command": "pip install 'aexpect'"
      },
      "afapi": {
        "name": "afapi",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/afapi",
        "summary": "A Python wrapper for interacting with AppFirst's APIs (v5)\n\nSee https://github.com/appfirst/afapi for more info.",
        "command": "pip install 'afapi'"
      },
      "afei": {
        "name": "afei",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/afei",
        "summary": "这是一个简单的例子",
        "command": "pip install 'afei'"
      },
      "affinegap": {
        "name": "affinegap",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/affinegap",
        "summary": "A Cython implementation of the affine gap string distance",
        "command": "pip install 'affinegap'"
      },
      "affinitic.docpyflakes": {
        "name": "affinitic.docpyflakes",
        "description": "Introduction\n============\n\nCheck your doctest for various errors. Depends on pyflakes (http://pypi.python.org/pypi/pyflakes).\n\nUsage example::\n\n    docpyflakes yourdoctext.txt\n\nThis package has an entry point for buildout to create a script via::\n\n    [buildout]\n    parts = ...\n            scripts\n\n    [scripts]\n    recipe = zc.recipe.egg:scripts\n    eggs = affinitic.docpyflakes\n\nVIM\n===\n\nMy vim configuration integration to run docpyflakes while I am working on my doctest and handle errors quickly::\n\n    fun! PyflakesForDocTest()\n        let tmpfile = tempname()\n        execute \"w\" tmpfile\n        execute \"set makeprg=(docpyflakes\\\\ \" . tmpfile . \"\\\\\\\\\\\\|sed\\\\ s@\" . tmpfile .\"@%@)\"\n        make\n        cw\n        redraw!\n    endfun\n\n    autocmd BufWrite *.{txt} :call PyflakesForDocTest()\n\nEMACS\n=====\n\nLearn VIM\n\nChangelog\n=========\n\n0.1 (2010-02-19)\n----------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/affinitic.docpyflakes",
        "summary": "Pyflakes your doctest",
        "command": "pip install 'affinitic.docpyflakes'"
      },
      "affinitic.recipe.fakezope2eggs": {
        "name": "affinitic.recipe.fakezope2eggs",
        "description": "Fake Zope 2 Eggs\n================\n\nZope 2 isn't eggified yet, Zope 3 does. That can become a problem if you want to\ninstall some egg with depedencies related to Zope 3 eggs (such as zope.interface,\nzope.component, ...)\n\nThis buildout recipe will simply add some fake egg link to zope libraries (installed\ninside zope/lib/python/zope/...) so that setuptools can see that the dependencies are\nalready satisfied and it won't fetch them anymore.\n\nJust add it to your buildout config like this::\n\n    [buildout]\n\n    parts =\n        ... your other parts ...\n        fakezope2eggs\n\n    [fakezope2eggs]\n    recipe = affinitic.recipe.fakezope2eggs\n\nBe careful to run this recipe after the plone.recipe.zope2install recipe.\n\nYou might also want to add other fake eggs to your buildout, to do so use the\nadditional-fake-eggs option, for example::\n\n\n    [buildout]\n\n    parts =\n        ... your other parts ...\n        fakezope2eggs\n\n    [fakezope2eggs]\n    recipe = affinitic.recipe.fakezope2eggs\n    additional-fake-eggs = ZODB3",
        "url": "http://pypi.python.org/pypi/affinitic.recipe.fakezope2eggs",
        "summary": "ZC Buildout recipe to fake zope 2 packages as eggs.",
        "command": "pip install 'affinitic.recipe.fakezope2eggs'"
      },
      "affinitic.simplecookiecuttr": {
        "name": "affinitic.simplecookiecuttr",
        "description": "affinitic.simplecookiecuttr\n===========================\n\nBasic integration of `jquery.cookiecuttr.js <http://cookiecuttr.com>`_ for\nPlone 3.\n\nIf you want jquery.cookiecuttr.js integration for Plone 4, please consider\n`collective.cookiecuttr <https://github.com/fourdigits/collective.cookiecuttr>`_.\n\n\nOptions\n-------\n\nOptions are stored in ``portal_properties`` / ``affinitic_simplecookiecuttr``\nsheet. You can enable / disable the warning and add any language there.\n\nFrench is supported by default.\n\n\nCredits\n-------\n\nThis package was developed by `Affinitic team <https://github/affinitic>`_.\n\n.. image:: http://www.affinitic.be/affinitic_logo.png\n   :alt: Affinitic website\n   :target: http://www.affinitic.be\n\n``affinitic.simplecookiecuttr`` is licensed under GNU General Public License, version 2.\n\nChangelog\n=========\n\n0.1 (2015-03-25)\n----------------\n\n* Initial release",
        "url": "http://pypi.python.org/pypi/affinitic.simplecookiecuttr",
        "summary": "Basic integration of jquery.cookiecuttr.js for Plone 3",
        "command": "pip install 'affinitic.simplecookiecuttr'"
      },
      "affinitic.verifyinterface": {
        "name": "affinitic.verifyinterface",
        "description": "Introduction\n============\n\nWhat's the use to declare an interface if your class doesn't implement correctly the interface ?\n\nOf course you should verify that in a test but if you don't want to write a test to check that all your code really implements the promised interfaces use this package.\n\nIt's a simple patch that calls ``zope.interface.verify.verifyClass`` once you declare implementing an\ninterface and print the BrokenImplementation or BrokenMethodImplementation as a warning (if any).\n\nSimple example in testrunner:\n-----------------------------\n\nBy default the egg enable interface contract verification for ``zope.interface.implements`` and\n``zope.interface.classImplements`` that are present in all your packages::\n\n    >>> write('buildout.cfg',\n    ... \"\"\"\n    ... [buildout]\n    ... parts =\n    ...     test\n    ...\n    ... [test]\n    ... recipe = zc.recipe.testrunner\n    ... eggs = affinitic.verifyinterface\n    ...        zope.exceptions\n    ... defaults = ['-m', 'module']\n    ... \"\"\")\n\n    >>> print system(buildout)\n    Installing test.\n    ...\n\n    >>> from os.path import join\n    >>> print system(join('bin', 'test')),\n    <class 'affinitic.verifyinterface.tests.test_module1.Foo'> failed implementing <InterfaceClass affinitic.verifyinterface.tests.test_module1.IFoo>: An object has failed to implement interface <InterfaceClass affinitic.verifyinterface.tests.test_module1.IFoo>\n    <BLANKLINE>\n            The bla attribute was not provided.\n    <BLANKLINE>\n    <class 'affinitic.verifyinterface.tests.test_module2.Bar'> failed implementing <InterfaceClass affinitic.verifyinterface.tests.test_module2.IBar>: An object has failed to implement interface <InterfaceClass affinitic.verifyinterface.tests.test_module2.IBar>\n    <BLANKLINE>\n            The bla attribute was not provided.\n    <BLANKLINE>\n    Running zope.testing.testrunner.layer.UnitTests tests:\n      Set up zope.testing.testrunner.layer.UnitTests in 0.000 seconds.\n      Ran 2 tests with 0 failures and 0 errors in 0.000 seconds.\n    Tearing down left over layers:\n      Tear down zope.testing.testrunner.layer.UnitTests in 0.000 seconds.\n\n\nLimit verifications\n-------------------\n\nBut you can limit the package where this verification needs to be done (sometimes you don't care that\na package you depend on didn't implement correctly an interface).\n\nThis is done by adding an environment variable ``verifyinterface`` where you specify what packages/modules (separated by \\n as usual) you accept to verify interfaces.\n\nHere is a simple example where I only want to have warning for bad implementation of interfaces used by module1::\n\n    >>> write('buildout.cfg',\n    ... \"\"\"\n    ... [buildout]\n    ... parts =\n    ...     test\n    ...\n    ... [test]\n    ... recipe = zc.recipe.testrunner\n    ... eggs = affinitic.verifyinterface\n    ...        zope.exceptions\n    ... defaults = ['-m', 'module']\n    ... environment = testenv\n    ...\n    ... [testenv]\n    ... verifyinterface = affinitic.verifyinterface.tests.test_module1\n    ... \"\"\")\n\n    >>> print system(buildout)\n    Uninstalling test.\n    Installing test.\n    ...\n\n    >>> from os.path import join\n    >>> print system(join('bin', 'test'))\n    <class 'affinitic.verifyinterface.tests.test_module1.Foo'> failed implementing <InterfaceClass affinitic.verifyinterface.tests.test_module1.IFoo>: An object has failed to implement interface <InterfaceClass affinitic.verifyinterface.tests.test_module1.IFoo>\n    <BLANKLINE>\n            The bla attribute was not provided.\n    <BLANKLINE>\n    Running zope.testing.testrunner.layer.UnitTests tests:\n      Set up zope.testing.testrunner.layer.UnitTests in 0.000 seconds.\n      Ran 2 tests with 0 failures and 0 errors in 0.000 seconds.\n    Tearing down left over layers:\n      Tear down zope.testing.testrunner.layer.UnitTests in 0.000 seconds.\n\nChangelog\n=========\n\n0.1 (2009-12-18)\n----------------\n\n* Initial release",
        "url": "http://pypi.python.org/pypi/affinitic.verifyinterface",
        "summary": "Verify interface contract for all implements/classImplements declaration",
        "command": "pip install 'affinitic.verifyinterface'"
      },
      "affinitic.zamqp": {
        "name": "affinitic.zamqp",
        "description": "This package defines basic components of a Messaging Gateway integrated inside Zope using AMQP.\n\nZope Component Architecture (ZCA) is about loosely coupled design in an Application.\nAMQP is about loosely coupled communication between Applications. This package tries to join the two.\n\n  * Documentation: http://docs.affinitic.be/affinitic.zamqp\n  * Code Repository: http://bitbucket.org/jfroche/affinitic.zamqp\n  * Buildbot: http://buildbot.affinitic.be/builders/affinitic.zamqp%20linux_debian/\n  * Test Coverage: http://coverage.affinitic.be/affinitic.zamqp/affinitic.zamqp.html\n\nChangelog\n=========\n\n0.6 (2011-06-14)\n----------------\n\n- Nothing changed yet.\n\n\n0.5 (2011-06-09)\n----------------\n\n- Also compatible with Zope 2.10/2.11\n\n\n0.4 (2011-06-09)\n----------------\n\n- Change transactionmanager order to be the very last one\n\n\n0.3 (2011-02-22)\n----------------\n\n- Fix for Zope 2.13\n\n\n0.2 (2010-10-19)\n----------------\n\n- Abort transaction correctly on error - send error to utility if available\n\n- Add multithreaded consumer (default to 1)\n\n\n0.1 (2010-03-20)\n----------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/affinitic.zamqp",
        "summary": "AMQP Consumer and publisher integration with Zope",
        "command": "pip install 'affinitic.zamqp'"
      },
      "affinity": {
        "name": "affinity",
        "description": "'affinity' provides a simple api for setting the processor affinity by\nwrapping the specific underlying function calls of each\nplatform. works on windows (requires pywin32) and linux (kernel 2.6 or\npatched 2.4).",
        "url": "http://pypi.python.org/pypi/affinity",
        "summary": "affinity - control processor affinity on windows and linux",
        "command": "pip install 'affinity'"
      },
      "affix": {
        "name": "affix",
        "description": "",
        "url": "http://pypi.python.org/pypi/affix",
        "summary": "",
        "command": "pip install 'affix'"
      },
      "affurl": {
        "name": "affurl",
        "description": "===============================\naffurl\n===============================\n\n.. image:: https://badge.fury.io/py/affurl.png\n    :target: http://badge.fury.io/py/affurl\n\n.. image:: https://travis-ci.org/yaph/affurl.png?branch=master\n        :target: https://travis-ci.org/yaph/affurl\n\n.. image:: https://pypip.in/d/affurl/badge.png\n        :target: https://pypi.python.org/pypi/affurl\n\nQuickstart\n----------\n\nTurn URLs into affiliate URLs based on provided domain parameter mapping. This package currently works provided you only need to add or change query parameters of the URL, an example are links to different Amazon domains. See the code and the result below.\n\nUsage\n~~~~~\n\n::\n\n    from affurl import affurl\n\n    mapping = {\n        'amazon.com': {'tag': ['affurl-20']},\n        'amazon.co.uk': {'tag': ['afflink-21']}\n    }\n    urls = [\n        'http://www.amazon.com/', # no existing URL params\n        'http://www.amazon.com/dp/1906966141?ie=UTF8',# with URL params\n        'http://www.amazon.com/dp/1906966141?tag=XXX',# replace existing tag\n        'http://www.amazon.co.uk/Best-Sellers-Welcome/zgbs/' # different domain and tag\n    ]\n    for url in urls:\n        print(affurl.convert(url, mapping))\n\nOutput\n~~~~~~\n\n| http://www.amazon.com/?tag=affurl-20\n| http://www.amazon.com/dp/1906966141?tag=affurl-20&ie=UTF8\n| http://www.amazon.com/dp/1906966141?tag=affurl-20\n| http://www.amazon.co.uk/Best-Sellers-Welcome/zgbs/?tag=afflink-21\n\nAbout\n-----\n\n* Free software: MIT license\n* Documentation: https://pythonhosted.org/affurl/\n\nTODO\n----\n\n* Install Python 3.3 to test affurl\n* Cleanup setup.py once there is a domain_parser release that supports Python 3\n* Make it possible to replace the host part\n\n\n\nHistory\n-------\n\n0.1.0 (2014-09-29)\n---------------------\n\n* First release on PyPI.",
        "url": "http://pypi.python.org/pypi/affurl",
        "summary": "Turn URLs into affiliate URLs based on provided domain parameter mapping",
        "command": "pip install 'affurl'"
      },
      "afn": {
        "name": "afn",
        "description": "**AFN** is Alexander Boyd's \"labs\" project. It contains a collection of useful\ntools and libraries that aren't big enough or popular enough to merit their own\nprojects.",
        "url": "http://pypi.python.org/pypi/afn",
        "summary": "A collection of useful tools and libraries",
        "command": "pip install 'afn'"
      },
      "afnumpy": {
        "name": "afnumpy",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/afnumpy",
        "summary": "A GPU-ready drop-in replacement for numpy",
        "command": "pip install 'afnumpy'"
      },
      "afp-cli": {
        "name": "afp-cli",
        "description": "=======\nAFP CLI\n=======\n\n.. image:: https://travis-ci.org/ImmobilienScout24/afp-cli.png?branch=master\n   :alt: Travis build status image\n   :target: https://travis-ci.org/ImmobilienScout24/afp-cli\n\n.. image:: https://img.shields.io/pypi/v/afp-cli.svg\n   :alt: Version\n   :target: https://pypi.python.org/pypi/afp-cli\n\nOverview\n========\n\nThe AFP CLI is the command line interface to access the\nAWS Federation Proxy (AFP).\n\nIts main use case is starting a new shell where your temporary\nAWS credentials have been exported into the environment.\n\nConfiguration\n=============\n\nThe **afp** command can be configured through yaml files in\nthe following direcories:\n\n* ``/etc/afp-cli/*.yaml`` (global configuration)\n* ``$HOME/.afp-cli/*.yaml`` (per-user configuration)\n\nThe yaml files are read in lexical order and merged via\n`yamlreader <https://github.com/ImmobilienScout24/yamlreader>`_.\nThe following configuration options are supported:\n\n* ``api_url: <api-url>``\n  Defaults to lookup a FQDN of a host named **afp** via DNS and construct\n  the server url from it: ``https://{FQDN}/afp-api/latest``\n* ``user: <username>``\n  Defaults to the currently logged in username\n\nExample:\n\n.. code-block:: yaml\n\n    api_url: https://afp-server.my.domain/afp-api/latest\n    user: myuser\n\nCLI Tool\n========\n\nGet help text\n-------------\n\n.. code-block:: console\n\n    $ afp [-h | --help]\n\nList available account names and roles\n--------------------------------------\n\nFor the currently logged-in user:\n\n.. code-block:: console\n\n    $ afp\n\nThe same for another user:\n\n.. code-block:: console\n\n    $ afp --user=username\n\nOutput format:\n\n::\n\n    <accountname>    <role1>,<role2>,...,<roleN>\n\nExample output:\n\n::\n\n    abc_account    some_role_in_abc_account\n    xyz_account    some_role_in_yxz_account,another_role_in_xyz\n\nUse AWS credentials\n-------------------\n\nThis starts a subshell in which the credentials have been exported into the\nenvironment. Use the **exit** command or press **CTRL+D** to terminate the subshell.\n\nUse credentials for currently logged in user and specified account and role:\n\n.. code-block:: console\n\n    $ afp accountname rolename\n\nUse credentials for the currently logged in user for the *first* role:\n\n.. code-block:: console\n\n    $ afp accountname\n\nAs above, but specifying a different user:\n\n.. code-block:: console\n\n    $ afp --user=username accountname rolename\n\nSpecify the URL of the AFP server, overriding any config file:\n\n.. code-block:: console\n\n    $ afp --api-url=https://yourhost/some/path\n\nShow and Export\n---------------\n\nIn case you don't want to start a subshell or are using something other than\nbash, you can use ``--show`` or ``--export`` to display the credentials. You\ncan use the usual UNIX tools to add/remove them from your environment.\n``--show`` will just show them and ``--export`` will show them in format\nsuitable for an export into your environment, i.e. prefixed with ``export`` for\nUNIX and ``set`` for Windows.\n\n\n.. code-block:: console\n\n   $ afp --show <myaccount> [<myrole>]\n   Password for myuser:\n   AWS_VALID_SECONDS='600'\n   AWS_SESSION_TOKEN='XXX'\n   AWS_SECURITY_TOKEN='XXX'\n   AWS_SECRET_ACCESS_KEY='XXX'\n   AWS_EXPIRATION_DATE='1970-01-01T01:00:00Z'\n   AWS_ACCESS_KEY_ID='XXX'\n\n.. code-block:: console\n\n   $ afp --export <myaccount> [<myrole>]\n   Password for myuser:\n   export AWS_VALID_SECONDS='600'\n   export AWS_SESSION_TOKEN='XXX'\n   export AWS_SECURITY_TOKEN='XXX'\n   export AWS_SECRET_ACCESS_KEY='XXX'\n   export AWS_EXPIRATION_DATE='1970-01-01T01:00:00Z'\n   export AWS_ACCESS_KEY_ID='XXX'\n\n\nThe following examples work in zsh, to add and remove them from your\nenvironment:\n\nAdding credentials:\n\n.. code-block:: console\n\n   $ eval $(afp --export <accountname>)\n\nRemoving them again:\n\n.. code-block:: console\n\n    $ env | grep AWS | cut -f 1 -d'=' | while read line ; do ; unset $line ; done ;",
        "url": "http://pypi.python.org/pypi/afp-cli",
        "summary": "Command line client for AWS federation proxy api",
        "command": "pip install 'afp-cli'"
      },
      "afpproxy": {
        "name": "afpproxy",
        "description": "=========\nAFPproxy\n=========\n\nAFPproxy is an MIT licensed proxy for an AppleShare file server. You can use it to help debug client/server connections on Mac OS X, but I wrote it to explore the Twisted networking framework.\n\nWhen running, the proxy prints details of the client/server communication to stderr.\n\n\nInstallation\n=============\n\nRequires Python 2.5 or later and Twisted. AFPproxy does not run on Python 3. Mac OS X 10.5 and later include Python and Twisted by default.\n\nYou can download and install the source directly::\n\n    tar -xf afpproxy-0.1.tar.gz\n    cd afpproxy-0.1\n    python setup.py install\n\nOr install it from PyPI::\n\n    pip install afpproxy\n\nIf you don't have Twisted installed, install it. For Python 2.5 install it with::\n\n    pip install 'Twisted<12.2' 'zope.interface<4'\n\n\nUsage\n======\n\nOnce installed, start the proxy with the ``afpproxy`` command.\n\nBy default this proxies your real AFP server on localhost port 548, and accepts connections on port 5548. You then connect to the running afpproxy and will see a description of the commands sent between client and server.\n\nTo proxy to a different server give its name or IP address::\n\n    afpproxy --host example.com\n\nOr to proxy to a server running on a non-standard port::\n\n    afpproxy --host example.com --port 1234\n\nTo start a proxy listening for connections on port 1548::\n\n    afpproxy --listen 1548\n\n\nDevelopment\n===========\n\nThe source for afpproxy is hosted on GitHub: https://github.com/davidwtbuxton/afpproxy",
        "url": "http://pypi.python.org/pypi/afpproxy",
        "summary": "proxy for the AFP (AppleShare) protocol",
        "command": "pip install 'afpproxy'"
      },
      "afpy.ldap": {
        "name": "afpy.ldap",
        "description": "afpy.ldap\n=========\n\nThis module is actively used on http://www.afpy.org to manage the french python comunity members.\n\nThe following examples show all features of the package. If you just want to\ngive it a try in a quickest way read `Installation and configuration\n<http://hg.afpy.org/gawel/afpy.ldap/install.html>`_ from the Sphinx\ndocumentation.\n\n\nGet a connection (this custom afpy connection get is configuration from a\n`~/.ldap.ini` file. See `Installation and configuration\n<http://hg.afpy.org/gawel/afpy.ldap/install.html>`_)::\n\n    >>> from afpy.ldap import custom as ldap\n    >>> conn = ldap.get_conn()\n\nGet a node via is dn::\n\n    >>> dn = 'uid=gawel,ou=members,dc=afpy,dc=org'\n    >>> node = conn.get_node(dn)\n    >>> node\n    <Node at uid=gawel,ou=members,dc=afpy,dc=org>\n\n    >>> print node.birthDate\n    19750410000000Z\n\nYou can also define your own node class with a schema::\n\n    >>> from afpy.ldap.node import Node\n    >>> from afpy.ldap import schema\n    >>> class User(Node):\n    ...     uid=schema.StringProperty('uid')\n    ...     birthDate = schema.DateProperty('birthDate', title='Date de naissance')\n    >>> node = conn.get_node(dn, node_class=User)\n    >>> node\n    <User at uid=gawel,ou=members,dc=afpy,dc=org>\n\nThen data is converted to a python object::\n\n    >>> node.birthDate\n    datetime.date(1975, 4, 10)\n\nThis also allow to generate forms with FormAlchemy_::\n\n    >>> from afpy.ldap import forms\n    >>> fs = forms.FieldSet(User)\n    >>> user = User()\n    >>> fs.rebind(user)\n    >>> print fs.render().strip() # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n    <div>\n      <label class=\"field_opt\" for=\"User--uid\">Uid</label>\n      <input id=\"User--uid\" name=\"User--uid\" type=\"text\" />\n    </div>\n    ...\n    <div>\n      <label class=\"field_opt\" for=\"User--birthDate\">Date de naissance</label>\n    ...\n\n.. _FormAlchemy: http://docs.formalchemy.org\n\nThe source code can be find on the `AFPy repository`_\n\n.. _AFPy repository: http://hg.afpy.org/gawel/afpy.ldap/summary\n\nGot a bug, feature request ? Want to send beer because you love it ? Send an\nemail at gawel@afpy.org or join us on the #afpy channel on freenode.\n\n\n\nNews\n=====\n\n0.8.2\n------\n\n- Add ListOfGroups and ListOfPerms attributes. Allow to set user.groups = []\n\n0.8.1\n-----\n\n- fix authentification failure when uid does not exist\n\n0.8\n---\n\n- small fixes\n\n- add GroupOfUniqueNames\n\n0.7\n---\n\n- Add repoze.what plugins\n\n- Allow to set node classes via config file\n\n- fix compat with latest python-ldap\n\n0.5\n-----\n\n- require dataflake.ldapconnection>=1.0b1, python-ldap>=2.3.10\n\n0.1\n-----\n\n- initial version",
        "url": "http://pypi.python.org/pypi/afpy.ldap",
        "summary": "This module provide an easy way to deal with ldap stuff in python.",
        "command": "pip install 'afpy.ldap'"
      },
      "afpy.xap": {
        "name": "afpy.xap",
        "description": "===\nxap\n===\n\n<tarek@ziade.org>\nwebsite: http://programmation-python.org\n\nHelpers to work with Xapian. see doc/\n\n\nYou need xapian-core and xapian-bindings: http://www.xapian.org/download.php\n\n\n\n\nHistory\n=======\n\n0.1 (2008-09-27)\n::::::::::::::::\n\n- refactoring of 'xap' from Tarek Ziadé\n- initial version created by IngeniSkel",
        "url": "http://pypi.python.org/pypi/afpy.xap",
        "summary": "afpy xapian indexer package",
        "command": "pip install 'afpy.xap'"
      },
      "afraid": {
        "name": "afraid",
        "description": "afraid\n------\n\nThis is a simple & extensible command-line client for the dynamic DNS service\noffered by `afraid.org <http://freedns.afraid.org/>`_. It will retrieve the set\nof hostnames associated with a particular account and update their records at\na user-specifiable regular interval.\n\nThe development version is available at `GitHub\n<https://github.com/atdt/afraid>`_. Issues should be documented\nthere.",
        "url": "http://pypi.python.org/pypi/afraid",
        "summary": "A simple client for the afraid.org dynamic DNS service",
        "command": "pip install 'afraid'"
      },
      "afro": {
        "name": "afro",
        "description": "======\nREADME\n======\n\nDescription\n-----------\n\n**AFRO** is **A**\\ nother **F**\\ ree **R**\\ ipping **O**\\ rchestra\n\nDocumentation\n-------------\n\nYou can `read the doumentation online <http://pythonhosted.org/afro>`_.",
        "url": "http://pypi.python.org/pypi/afro",
        "summary": "Another Free Ripping Orchestra",
        "command": "pip install 'afro'"
      },
      "afsk": {
        "name": "afsk",
        "description": "AFSK and ``aprs``\n=================\n\nLibrary to generate Bell 202 AFSK audio samples and \nAFSK encoded APRS/AX.25 packets. \n\nThe ``aprs`` command line program encodes APRS packets \nas AFSK audio data. \n\ne.g.::\n\n    $ aprs -c <your callsign> \":EMAIL    :test@example.com Test email\"\n\nInstallation\n------------\n\nInstall with ``pip``::\n\n    $ pip install afsk\n    $ pip install --allow-external PyAudio --allow-unverified PyAudio PyAudio\n\nPyAudio is optional, so must be installed separately. \n\nIf you want to use the CLI program to play APRS packets via your\nsoundcard, install PyAudio. Otherwise, if you just want to generate\nWave files of AFSK data, you can skip it. \n\nNote that installing PyAudio will require a C compiler and PyAudio's various\nC dependencies, in addition to the ``--allow-external`` and ``--allow-unverified``\n``pip`` flags. \n\nFor development, change to the afsk directory and install with::\n\n    $ pip install -r requirements.txt\n    $ python setup.py develop\n\nRequires Python 2.6 or 2.7.\n\nCommand Line Interface\n----------------------\n\nGenerate APRS messages with the ``aprs`` CLI program::\n\n    $ aprs --callsign <your callsign> \":EMAIL    :test@example.com Test email\"\n\nSpecify your message body with INFO command line argument. Be sure to wrap the message in \nquotes so it's passed as one argument, spaces includd. \n\nAt the moment, no message formats are implemented in the ``aprs`` program; you must \nconstruct the body string yourself. For instance, in the example above, the string \npassed as an argument to ``aprs`` follows the email messsage format specified for APRS. \n\nYou *must* specify your amateur radio callsign with the ``--callsign`` or ``-c`` flags.\n\nUse the ``--output`` option to write audio to a Wave file (use '-' for STDOUT) rather \nthan play over the soundcard. \n\nGet a listing of other options with ``aprs --help``.\n\nExamples\n--------\n\nPlayback with PyAudio and short options::\n\n    $ aprs --callsign <your callsign> \":EMAIL    :test@example.com Test email\"\n\nPlayback with ``sox``::\n\n    $ aprs --callsign <your callsign> --output - \":EMAIL    :test@example.com Test email\" |\\\n          play -t wav -\n\nSave to a wave file with using short options::\n\n    $ aprs -c <your callsign> -o packet.wav \":EMAIL    :test@example.com Test email\"\n\nVersion History\n---------------\n\n- 0.0.3 – Pin dependency versions, fix bug with STDOUT playback, verbosity CLI option.",
        "url": "http://pypi.python.org/pypi/afsk",
        "summary": "Bell 202 Audio Frequency Shift Keying encoder and APRS packet audio tools",
        "command": "pip install 'afsk'"
      },
      "AFStatsd": {
        "name": "afstatsd",
        "description": "StatsD was popularized by Etsy, and we refer to their implementation as \"Etsy-standard\" (https://github.com/etsy/statsd/).\nIt's a light-weight method of gathering statistics from your applications.  As an application developer, all you need\nto do is include a small library, and sprinkle one-liners like this throughout your code:\n\n    Statsd.increment(\"my.important.event\")\n    Statsd.gauge(\"my.important.value\", important_value)\n    Statsd.timing(\"my.important.process\", important_process_time)\n\nIn the Etsy version, this will cause a UDP packet to be sent to a designated server that is running their\ncollection and visualization packages. The AppFirst client API looks the same to the application developer,\nbut sends data via POSIX message queue or Windows Mailslot to the collector and takes advantage of AppFirst collection\nand visualization technologies.\n\nIf you are already running an AppFirst collector on your server, then all you need to do is use an\nAppFirst StatsD library instead of an Etsy-only library.  This library will aggregate your metrics, and then\nuse a message queue to pass them to the AppFirst collector, which will pass them up to our Big Data store, where\nthey will be visible on your AppFirst dashboards and Correlate charts.  This is more efficient than the UDP method\nand you don't need to set up the Etsy collection and visualization environment.\n\nIf you are already using Etsy StatsD, you can make a gradual transition.  Our libraries can be used in\nEtsy mode, so you can configure them to send UDP to your existing Etsy monitoring apparatus.  Our collector also\naccepts StatsD UDP messages, so you can just point your existing Etsy-only StatsD library to localhost:8125,\nuntil you are ready to transition to an AppFirst StatsD library. For more information on enabling UDP StatsD\non the collector click here: http://support.appfirst.com/appfirst-statsd-beta/#other_clients",
        "url": "http://pypi.python.org/pypi/AFStatsd",
        "summary": "Statsd Library for use with the AppFirst collector (http://www.appfirst.com)",
        "command": "pip install 'AFStatsd'"
      },
      "afterflight": {
        "name": "afterflight",
        "description": "afterflight\n===========\n\n An application for analysis of UAV log and video.\n\n Introductory video with quickstart is at http://youtu.be/wdeeGyvHJ9c .\n\nInstalling the release version\n**********************************\n\nInstalling the development version\n**********************************\n\n#. make sure you have scipy installed on your system. On ubuntu, that means doing: ``sudo apt-get install scipy``. Once scipy 0.13 is released, this step will no longer be necessary because setup.py will be able to install it properly.\n\n#. Clone the afterflight repository to with ``git clone https://github.com/foobarbecue/afterflight.git``\n\n#. In the directory that is created (called afterflight unless you specified otherwise), run ``pip -r requirements.txt``. This will install the remaining dependancies.\n\n#. Create ``settings_local.py`` based on the example ``settings_local_example.py``. Usually you can just run ``cp settings_local_example.py settings_local.py``, but if you want to use a database other than sqlite (such as postgres) this is where your database access information will go.\n\n#. Create your database tables by running ``python afterflight/manage.py syncdb``. This will also add a default site for the django sites framework, which is required for the authentication system.\n\n#. Run a local development server: ``python afterflight/manage.py runserver``. By default this will run at http://localhost:8000 , so you can point your browser there to get started.\n\n#. If you want to run this on a public server, follow https://docs.djangoproject.com/en/1.5/howto/deployment/ .",
        "url": "http://pypi.python.org/pypi/afterflight",
        "summary": "An application for analysis of UAV log and video.",
        "command": "pip install 'afterflight'"
      },
      "after_hours": {
        "name": "after_hours",
        "description": "********************************\nRead me for after_hours module\n********************************\n\nPython module after_hours can retrieve pre-market prices and after-hours trading prices from Nasdaq for a given stock symbol\n\n-Created by Jason Lewris\n\n-License: The MIT License\n\n-Developer Home Page: 'https://github.com/datawrestler'.\n\n----\n\n\nRequirements\n--------------\nPython 2.7/3.4+\n\nMethod Overview\n----------------\n\n                                    +--------------------------------------+--------------------------------------+\n                                    |       Method Name                    |          Description                 |\n                                    +======================================+======================================+\n                                    |       pre_latest                     | Returns latest pre market price      |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       pre_high                       | Returns high pre market price        |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       pre_low                        | Returns low pre market price         |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       pre_volume                     | Returns volume pre market price      |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       pre_market_avg                 | Returns avg pre market prices        |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       pre_market_sse                 | pre market standard sqaure error     |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       pre_market_sd                  | pre market standard deviation        |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       ah_latest                      | Returns latest after hours price     |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       ah_high                        | Returns high after hours price       |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       ah_low                         | Returns low after hours price        |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       ah_volume                      | Returns after hours volume           |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       ah_all                         | Returns all after hours prices       |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       ah_avg                         | Returns after hours average price    |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       ah_sse                         | After hours standard sqaure error    |\n                                    +--------------------------------------+--------------------------------------+\n                                    |       ah_sd                          | After hours standard deviation       |\n                                    +--------------------------------------+--------------------------------------+\n\nInstallation\n**************\n\nInstallation is done using pip install:\n\n    .. code-block::\n\n        pip install after_hours\n\nAlternative installation can be done by downloading the source files directly from github, navigating to the directory through terminal and running the following:\n\n    .. code-block::\n\n        python setup.py install\n\n    .. note:: The source file can be downloaded here: https://github.com/datawrestler/after-hours/tarball/0.1\n\n\nAfter installation, the package is ready for use. Simply import it into your python script with the following:\n\n    .. code-block::\n\n        import after_hours\n\n\nExamples\n---------\n\n    .. code-block::\n\n        >>> import after_hours\n        >>> print(after_hours.ah_latest('aapl'))\n            ('aapl', 102.18)\n\n        >>> print(after_hours.ah_high('aapl'))\n            ('aapl', 109.055, '16:09:59 PM')\n\n        >>> print(after_hours.ah_low('aapl'))\n            ('aapl', 102.1, '19:58:46 PM')\n\n        >>> print(after_hours.ah_volume('aapl'))\n            ('aapl', '2,140,117')\n\n        >>> print(after_hours.ah_all('aapl'))\n            ('aapl', ['19:59', '19:57', '19:53'], [102.18, 102.16, 102.11], ['100', '10', '10']\n\n        >>> print(after_hours.ah_avg('aapl'))\n            ('aapl', 102.22793048\n\n        >>> print(after_hours.ah_sse('aapl'))\n            ('aapl', 0.572312)\n\n        >>> print(after_hours.ah_sd('aapl'))\n            ('aapl', 0.0835429)",
        "url": "http://pypi.python.org/pypi/after_hours",
        "summary": "retrieve after hours stock information from Nasdaq",
        "command": "pip install 'after_hours'"
      },
      "aftership": {
        "name": "aftership",
        "description": "About aftership-python\n======================\n\naftership-python is Python SDK (module) for `AfterShip API <https://www.aftership.com/docs/api/4>`_.\nModule provides clean and elegant way to access API endpoints.\n\nInstallation\n============\n\nVia pip\n-------\n\nRun the following:\n\n.. code-block:: bash\n\n    $ pip install aftership\n\nVia source code\n---------------\n\nDownload the code archive, unzip it, create/activate `virtualenv <http://virtualenv.readthedocs.org/en/latest/virtualenv.html>`_, go to the source root directory, then run:\n\n.. code-block:: bash\n\n    $ python setup.py install\n\nUsage\n=====\n\nQuick Start\n-----------\n\nThe following code gets list of supported couriers\n\n.. code-block:: python\n\n    import aftership\n    api = aftership.APIv4('AFTERSHIP_API_KEY')\n    couriers = api.couriers.all.get()\n\nGet API object\n--------------\n\nImport aftership module and obtain APIv4 object. Valid API key must be provided.\n\n.. code-block:: python\n\n    import aftership\n    api = aftership.APIv4('AFTERSHIP_API_KEY')\n\nAPIv4 object\n------------\n\nAPIv4 object is used to make API calls. Object constructor:\n\n.. code-block:: python\n\n    class aftership.APIv4(key, max_calls_per_sec=10, datetime_convert=True)\n\n#. **key** is AfterShip API key\n#. **max_calls_per_sec** represents maximum number of calls provided for each second (10 is a limit for single client, but you might want to set less if you have multiple parallel API objects)\n#. **datetime_convert** provides timestamp strings conversion to datetime in API output\n\nMake API calls\n--------------\n\nThe module provides direct bindings to API calls: https://www.aftership.com/docs/api/4\n\nEach call consists of three parts:\n\n#. **Positional arguments** (goes after api.aftership.com/v4/, separated by slash \"/\")\n#. **Named arguments** (listed in Request —> Parameters section)\n#. **HTTP Method** (GET, POST, PUT or DELETE)\n\nThe following convention is used to construct a call:\n\n.. code-block:: python\n\n    <APIv4 object>.positional.arguments.<HTTP method>(*more_positional_arguments, **named_arguments)\n\nThe code above makes a call to /positional/arguments/... endpoint with named arguments passed in request body as JSON or HTTP query (depending on HTTP method).\n\nAPI calls examples\n------------------\n\nThe following code creates, modifies and deletes tracking:\n\n.. code-block:: pycon\n\n    >>> import aftership\n    >>> api = aftership.APIv4(API_KEY)\n    >>> slug = 'russian-post'\n    >>> number = '65600077151512'\n\n    # create tracking\n    # https://www.aftership.com/docs/api/4/trackings/post-trackings\n    >>> api.trackings.post(tracking=dict(slug=slug, tracking_number=number, title=\"Title\"))\n    {u'tracking': { ... }}\n\n    # get tracking by slug and number, return 'title' and 'created_at' field\n    # https://www.aftership.com/docs/api/4/trackings/get-trackings-slug-tracking_number\n    >>> api.trackings.get(slug, number, fields=['title', 'created_at'])\n    {u'tracking': { ... }}\n\n    # change tracking title\n    # https://www.aftership.com/docs/api/4/trackings/put-trackings-slug-tracking_number\n    >>> api.trackings.put(slug, number, tracking=dict(title=\"Title (changed)\"))\n    {u'tracking': { ... }}\n\n    # delete tracking\n    # https://www.aftership.com/docs/api/4/trackings/delete-trackings\n    >>> api.trackings.delete(slug, number)\n    {u'tracking': { ... }}\n\nPositional arguments\n--------------------\n\nPositional arguments passed in the following forms:\n\n#. APIv4 object attributes\n#. APIv4 object keys\n#. HTTP Method arguments\n\nAPIv4 object attributes used to represent constant parts of the endpoint, while HTTP Method arguments are used for variable parts, e.g.:\n\n.. code-block:: python\n\n    api.trackings.get('russian-post', '65600077151512')\n\nPositional arguments passed as keys are useful if they are stored in variables and followed by constant value, e.g.:\n\n.. code-block:: python\n\n    api.trackings['russian-post']['65600077151512'].retrack.post()\n\nNamed arguments\n---------------\n\nNamed arguments passed as keyword arguments of HTTP Methods calls.\nComma-separated values strings could be passed as [lists], timestamp strings could be passed as regular datetime objects, e.g.:\n\n.. code-block:: python\n\n    import datetime\n    ...\n    api.trackings.get(created_at_min=datetime.datetime(2014, 9, 1), fields=['title', 'order_id'])\n\nHTTP Method arguments\n---------------------\n\nThe following HTTP methods are supported:\n\n#. get()\n#. post()\n#. put()\n#. delete()\n\nEach method return either JSON of 'data' field or throws an aftership.APIv4RequestException.\naftership-python relies on Requests library and ones should expect `Requests exceptions <http://docs.python-requests.org/en/latest/user/quickstart/#errors-and-exceptions>`_.\n\nAPIv4RequestException\n---------------------\n\nAn exception is throwed on errors. The following methods are provided to get error details:\n\n#. code()\n#. type()\n#. message()\n\nEach functions returns appropriate value from 'meta' field. Check `errors documentation <https://www.aftership.com/docs/api/4/errors>`_ for more details.\nCode example:\n\n.. code-block:: python\n\n    try:\n        api = aftership.APIv4('FAKE_API_KEY')\n        api.couriers.get()\n    except aftership.APIv4RequestException as error:\n        # FAKE_API_KEY will result in Unauthorized (401) error\n        print 'Error:', error.code(), error.type(), error.message()",
        "url": "http://pypi.python.org/pypi/aftership",
        "summary": "Python SDK of AfterShip API",
        "command": "pip install 'aftership'"
      },
      "afthermal": {
        "name": "afthermal",
        "description": "afthermal\n=========\n\n.. note:: afthermal is currently in alpha status. This is a snapshot release of\n          the development branch. While it is used productively, some features\n          may be unfinished or undocumented.\n\n``afthermal`` is a driver/library for the popular `Adafruit\n<https://www.adafruit.com/products/597>`_ (originally Cashino\nA2) thermal printer [1]_.\n\nPartially, it is inspired by previous efforts:\n\n* https://github.com/adafruit/Adafruit-Thermal-Printer-Library\n* https://github.com/adafruit/Python-Thermal-Printer/\n* https://github.com/luopio/py-thermal-printer/\n\n``afthermal`` try to be more pythonic and efficient than previous efforts,\nwhich have mostly been 1:1 ports from other languages.\nAdditionally it is not focused on education but rather on being a\nreliable library for handling this kind of hardware.\n\nFeatures include:\n\n* Comfortable handling of text formatting\n* Adapters to print images from PIL_ / Pillow_ as well as OpenCV_\n* A fast Floyd-Steinberg_ implementation to dither OpenCV_ images.\n* Command-line utilities for calibrating the printer for optimum speed and\n  quality, as well as other capabilities\n* Support for printing QR codes via PyQRCode_ without having to render them\n  into images first\n\n.. [1] Specification is available at http://www.adafruit.com/datasheets/CSN-A2%20User%20Manual.pdf\n\n.. _PyQRCode: https://pypi.python.org/pypi/PyQRCode\n.. _OpenCV: https://opencv-python-tutroals.readthedocs.org\n.. _Pillow: http://pillow.readthedocs.org\n.. _PIL: http://www.pythonware.com/products/pil/\n.. _Floyd-Steinberg: https://en.wikipedia.org/wiki/Floyd%E2%80%93Steinberg_dithering\n\n\nInstallation\n------------\n\n``afthermal`` is installable from ``pip``. It supports an extra feature named\n``tools``, installing it will include cli tools for calibrating the\nprinter, printing test images or other tasks:\n\n.. code-block:: sh\n\n   $ pip install 'afthermal[tools]'\n\nIt includes a C extension for Floyd-Steinberg_ dithering, since OpenCV_ does\nnot ship with a dithering function. For this reason C-modules must be\ncompileable when installing ``afthermal``.\n\n\nFull docs\n---------\n\nThe complete documentation is housed at http://pythonhosted.org/afthermal.",
        "url": "http://pypi.python.org/pypi/afthermal",
        "summary": "UNKNOWN",
        "command": "pip install 'afthermal'"
      },
      "again": {
        "name": "again",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/again",
        "summary": "Python decorators for type and value checking at runtime. Also, some boilerplate code for making classes that support event registration and firing.",
        "command": "pip install 'again'"
      },
      "agalma": {
        "name": "agalma",
        "description": "Agalma is an automated tool that constructs matrices for\n        phylogenomic analyses, allowing complex phylogenomic analyses to be\n        implemented and described unambiguously as a series of high-level\n        commands.  The user provides raw Illumina transcriptome data, and\n        Agalma produces annotated assemblies, aligned gene sequence matrices,\n        a preliminary phylogeny, and detailed diagnostics that allow the\n        investigator to make extensive assessments of intermediate analysis\n        steps and the final results.  Sequences from other sources, such as\n        externally assembled genomes and transcriptomes, can also be\n        incorporated in the analyses. Agalma is built on the BioLite\n        bioinformatics framework, which tracks provenance, profiles processor\n        and memory use, records diagnostics, manages metadata, installs\n        dependencies, logs version numbers and calls to external programs, and\n        enables rich HTML reports for all stages of the analysis. Agalma\n        includes a small test data set and a built-in test analysis of these\n        data.",
        "url": "http://pypi.python.org/pypi/agalma",
        "summary": "An automated phylogenomics pipeline.",
        "command": "pip install 'agalma'"
      },
      "agamemnon": {
        "name": "agamemnon",
        "description": "==============\nAgamemnon\n==============\n\nAgamemnon is a thin library built on top of pycassa.  \nIt allows you to use the Cassandra database (<http://cassandra.apache.org>) as a graph database. \nUsing cassandra provides an extremely high level of reliability and scalability that is not available in other\ngraph databases.  Cassandra provides integrated support for both data partitioning as well as replication via configuration.\n\nMuch of the api was inspired by the excellent neo4j.py project (<http://components.neo4j.org/neo4j.py/snapshot/>),\nhowever the support in this package has diverged from that project.\n\nAgamemnon also has integrated RDF support through RDFLib (http://www.rdflib.net/)\n\n==========================\nUsage\n==========================\n\nThe following is an example of how to use Agamemnon in your own code\n\n\n>>> from agamemnon.factory import load_from_settings\n\nFirst, we can decide which kind of data store we are creating.  In this case we're creating an InMemory data store\n\n>>> config = {'backend': 'agamemnon.memory.InMemoryDataStore'}\n>>> graph_db = load_from_settings(config)\n\nIn honor of The Simpsons Movie, we'll create a node called spiderpig\n\n>>> spiderpig = graph_db.create_node('test_type', 'spiderpig', {'sound':'oink'})\n\nNow we will retrieve the spiderpig from the graph and check that the attributes were correct.\n\n>>> spiderpig = graph_db.get_node('test_type', 'spiderpig')\n>>> spiderpig['sound']\n'oink'\n\n\nNow we will create a friend for the spiderpig (who also happens to be his alter ego).  Again, let's check to\nconfirm that the node and it's attributes were created correctly.\n\n>>> harry_plopper = graph_db.create_node('test_type', 'Harry Plopper', {'sound':'plop'})\n>>> harry_plopper = graph_db.get_node('test_type','Harry Plopper')\n>>> harry_plopper['sound']\n'plop'\n\nNodes can have different types as well.  Here we create a node of type simpson, with name Homer.  This node has\ndifferent attributes than the previous nodes.\n\n>>> homer = graph_db.create_node('simpson', 'Homer', {'sound':'Doh', 'job':'Safety Inspector'})\n>>> homer = graph_db.get_node('simpson', 'Homer')\n>>> homer['sound']\n'Doh'\n>>> homer['job']\n'Safety Inspector'\n\nNodes by themselves are not very useful.  Let's create a relationship between spiderpig and Harry Plopper.\n\n>>> rel = spiderpig.friend(harry_plopper, key='spiderpig_harry_plopper_alliance', alter_ego=True, best=False)\n\nThis creates a relationship of type friend.  The key has been specified in this case, although it is not necessary.\nIf no key is supplied a uuid will be generated for the relationship.\n\nEvery node type has a \"reference node\".  This is a metanode for the type and functions as an index for all nodes of a\ngiven type.\n\n>>> reference_node = graph_db.get_reference_node('test_type')\n\nGetting the instances from the test_type reference node should return the Harry Plopper node and the spiderpig node.\n\n>>> sorted([rel.target_node.key for rel in reference_node.instance.outgoing])\n['Harry Plopper', 'spiderpig']\n\nThe spiderpig should only have one friend at this point, and it should be Harry Plopper\n\n>>> friends = [rel for rel in spiderpig.friend]\n\n>>> len(friends)\n1\n\n>>> friends[0].target_node.key\n'Harry Plopper'\n\nNow let's confirm that Harry Plopper is friends with spider pig as well:\n\n>>> 'spiderpig' in harry_plopper.friend\nTrue\n\nAnd, once more, make sure that spider pig is Harry Plopper's only friend:\n\n>>> friends = [rel for rel in harry_plopper.friend]\n\n>>> len(friends)\n1\n\n>>> friends[0].source_node.key\n'spiderpig'\n\nThey should not be best friends.  Let's confirm this:\n\n>>> friends[0]['best']\nFalse\n\nHomer is spiderpig's best friend:\n\n>>> rel = homer.friend(spiderpig, best=True, alter_ego=False, type='love', strength=100)\n\nHere we added additional attributes to the relationship.\n\nNow spiderpig should have 2 friends.\n\n>>> friends = [rel for rel in spiderpig.friend]\n>>> len(friends)\n2\n\nYou can get a list of all of the relationships of a particular type between a node and other nodes with a particular key\n\n>>> homer_spiderpig_love = spiderpig.friend.relationships_with('Homer')\n>>> len(homer_spiderpig_love)\n1\n\n>>> homer_spiderpig_love = spiderpig.friend.relationships_with('Homer')\n>>> print homer_spiderpig_love[0]['strength']\n100\n\n\n\nThanks To\n=============\nThis project is an extension of the globusonline.org project and is being used to power the upcoming version of globusonline.org.  I'd like to thank Ian Foster and Steve Tuecke for leading that project, and all of the members of the cloud services team for participating in this effort, especially: Vijay Anand, Kyle Chard, Martin Feller and Mike Russell for helping with design and testing.  I'd also like to thank Bryce Allen for his help with some of the python learning curve.\n\n\n0.3.1.0\n==============\n\n* Added many tests and fixed bugs with certain operations\n\n* Added RDF support through RDFlib\n\n0.2.1.3\n==============\n\n* fixed bug with in memory column comparisons\n\n0.2.1.2\n==============\n\n* fixing bug with root reference node, adding support for unicode serialization and bumping version num\n\n\n0.2.1.1\n==============\n\n* adding method to get all relationships regardless of type\n\n* removing generated doc files and updating index.rst\n\n* adding doctest to usage documentation and setup.cfg\n\n* updating setup files with requirements\n\n* multiple fixes for issues discovered by globusonline\n\n\n0.2.1.0\n==============\n\n* added support for contains operator (with relationships_with(other_node_key) function) and added type conversion for pr\n\n* merging relationship code from globusonline\n\n\n0.0.1.3\n==============\n\n* Updating datastore.save_node so that it no longer uses batch storage",
        "url": "http://pypi.python.org/pypi/agamemnon",
        "summary": "A graph database built on top of cassandra",
        "command": "pip install 'agamemnon'"
      },
      "agamotto": {
        "name": "agamotto",
        "description": "Agamotto\n========\n\nAgamotto is a helper module to make it easier to test a running system\nwith Python.\n\nWhy not use serverspec? I work in a Python shop and want our devs to be\nable to easily write their own tests. Making the test suite use the same\nlanguage they use daily removes a potential friction point.\n\nInstallation\n============\n\n.. code:: bash\n\n    pip install agamotto\n\nUsage\n=====\n\n.. code:: python\n\n\n    import agamotto\n    import unittest2 as unittest\n\n    class TestKnownSecurityIssues(unittest.TestCase):\n\n      def testBashHasCVE_2014_6271Fix(self):\n        \"\"\"Confirm that fix has been installed for CVE-2014-6271 Bash Code\n        Injection Vulnerability via Specially Crafted Environment Variables\n        \"\"\"\n        self.assertFalse(agamotto.process.stdoutContains(\"(env x='() { :;}; echo vulnerable'  bash -c \\\"echo this is a test\\\") 2>&1\",\n                         'vulnerable'), 'Bash is vulnerable to CVE-2014-6271')\n\n\n      def testBashHasCVE_2014_7169Fix(self):\n        \"\"\"Confirm that fix has been installed for CVE-2014-7169 Bash Code\n        Injection Vulnerability via Specially Crafted Environment Variables\n        \"\"\"\n        self.assertFalse(agamotto.process.stdoutContains(\"env X='() { (a)=>\\' bash -c \\\"echo echo vuln\\\"; [[ \\\"$(cat echo)\\\" == \\\"vuln\\\" ]] && echo \\\"still vulnerable :(\\\" 2>&1\",\n                         'still vulnerable'), 'Bash is vulnerable to CVE-2014-7169')\n\n\n      def testNoAccountsHaveEmptyPasswords(self):\n        \"\"\"/etc/shadow has : separated fields. Check the password field ($2) and\n           make sure no accounts have a blank password.\n        \"\"\"\n        self.assertEquals(agamotto.process.execute(\n          'sudo awk -F: \\'($2 == \"\") {print}\\' /etc/shadow | wc -l').strip(), '0',\n          \"found accounts with blank password\")\n\n\n      def testRootIsTheOnlyUidZeroAccount(self):\n        \"\"\"/etc/passwd stores the UID in field 3. Make sure only one account entry\n        has uid 0.\n        \"\"\"\n        self.assertEquals(agamotto.process.execute(\n                          'awk -F: \\'($3 == \"0\") {print}\\' /etc/passwd').strip(),\n                          'root:x:0:0:root:/root:/bin/bash')\n\n\n\n    if __name__ == '__main__':\n      unittest.main()\n\nThen run py.test.\n\nCaveats\n=======\n\nWe're a CentOS shop. This hasn't even been tested on stock RHEL, let\nalone Debian or Ubuntu. Pull requests adding that functionality are\nwelcome, of course.",
        "url": "http://pypi.python.org/pypi/agamotto",
        "summary": "Agamotto is a module that provides helper functions for testing the configuration of a running server",
        "command": "pip install 'agamotto'"
      },
      "agar": {
        "name": "agar",
        "description": "agar\n====\n\nAgar is a set of utilities for `Google App Engine python`_, , created as part of the `Substrate Project`_.\n\nResources\n---------\n\n* `Documentation`_\n* `PyPI Package`_\n* `Source Code Repository`_\n\nRequirements\n------------\n\nAgar requires the Google App Engine SDK, `webapp2`_, `webapp2_extras`_,\n`pytz`_, `restler`_, and `basin`_. Versions of these (except the Google App\nEngine SDK) are located in the ``lib`` directory.\n\nInstallation\n------------\n\nTo install Agar, download the source and add the ``agar`` directory to\nyour Google App Engine project. It must be on your path.\n\nTests\n-----\n\nAgar comes with a set of tests. Running Agar's tests requires\n`unittest2`_ and `WebTest`_ (included in the ``lib`` directory). To run them,\nexecute::\n\n     $ ./run_tests.py\n\nTesting\n-------\n\nGoogle App Engine now includes testbed to make local unit testing\neasier. This obsoletes the now-unsupported GAE TestBed\nlibrary. However, it had several useful helper functions, many of\nwhich have been re-implemented in Agar. To use them, you must use\n`unittest2`_ and inherit from `agar.tests.BaseTest`_ or `agar.tests.WebTest`_.\n\nLicense\n-------\n\nAgar is licensed under the MIT License. See ``LICENSE.txt`` for details.\n\nContributing\n------------\n\nTo contribute to the Agar project, fork the repository, make your\nchanges, and submit a pull request.\n\n.. Links\n\n.. _Substrate Project: http://pypi.python.org/pypi/substrate\n\n.. _Documentation: http://packages.python.org/agar\n.. _PyPI Package: http://pypi.python.org/pypi/agar\n.. _Source Code Repository: http://bitbucket.org/gumptioncom/agar\n\n.. _Google App Engine python: http://code.google.com/appengine/docs/python/overview.html\n.. _webapp2: http://code.google.com/p/webapp-improved/\n.. _webapp2_extras: http://webapp-improved.appspot.com/#api-reference-webapp2-extras\n.. _pytz: http://pytz.sourceforge.net/\n.. _basin: http://pypi.python.org/pypi/basin\n.. _unittest2: http://pypi.python.org/pypi/unittest2\n.. _WebTest: http://webtest.pythonpaste.org/\n.. _restler: http://packages.python.org/substrate/restler.html\n\n.. _agar.tests.BaseTest: http://packages.python.org/agar/agar.html#agar.test.BaseTest\n.. _agar.tests.WebTest: http://packages.python.org/agar/agar.html#agar.test.WebTest",
        "url": "http://pypi.python.org/pypi/agar",
        "summary": "A collection of libraries for making Google App Engine development easier.",
        "command": "pip install 'agar'"
      },
      "agarclient": {
        "name": "agarclient",
        "description": "",
        "url": "http://pypi.python.org/pypi/agarclient",
        "summary": "agar.io client and connection toolkit",
        "command": "pip install 'agarclient'"
      },
      "agarnet": {
        "name": "agarnet",
        "description": null,
        "url": "http://pypi.python.org/pypi/agarnet",
        "summary": "agar.io client and connection toolkit",
        "command": "pip install 'agarnet'"
      },
      "agaro": {
        "name": "agaro",
        "description": "===============================\nagaro\n===============================\n\n.. image:: https://img.shields.io/travis/eddiejessup/agaro.svg\n        :target: https://travis-ci.org/eddiejessup/agaro\n\n.. image:: https://img.shields.io/pypi/v/agaro.svg\n        :target: https://pypi.python.org/pypi/agaro\n\n\nFramework to run models\n\n* Free software: BSD license\n* Documentation: https://agaro.readthedocs.org.\n\nFeatures\n--------\n\n* TODO\n\n\n\n\nHistory\n-------\n\n0.1.0 (2015-01-11)\n---------------------\n\n* First release on PyPI.",
        "url": "http://pypi.python.org/pypi/agaro",
        "summary": "Framework to run models",
        "command": "pip install 'agaro'"
      },
      "agate": {
        "name": "agate",
        "description": "agate is a Python data analysis library designed for humans working in the real world. It is an alternative to numpy and pandas that is optimized for making humans faster at working with normal-sized datasets.\n\nagate was previously known as journalism.\n\nImportant links:\n\n* Documentation:    http://agate.rtfd.org\n* Repository:       https://github.com/onyxfish/agate\n* Issues:           https://github.com/onyxfish/agate/issues",
        "url": "http://pypi.python.org/pypi/agate",
        "summary": "A Python data analysis library designed for humans working in the real world.",
        "command": "pip install 'agate'"
      },
      "agate-charts": {
        "name": "agate-charts",
        "description": "agate-charts adds exploratory charting support to agate.\n\nImportant links:\n\n* agate:            http://agate.rtfd.org\n* Documentation:    http://agate-charts.rtfd.org\n* Repository:       https://github.com/onyxfish/agate-charts\n* Issues:           https://github.com/onyxfish/agate-charts/issues",
        "url": "http://pypi.python.org/pypi/agate-charts",
        "summary": "agate-charts adds exploratory charting support to agate.",
        "command": "pip install 'agate-charts'"
      },
      "agate-sql": {
        "name": "agate-sql",
        "description": "agate-sql adds SQL read/write support to agate.\n\nImportant links:\n\n* agate             http://agate.rtfd.org\n* Documentation:    http://agate-sql.rtfd.org\n* Repository:       https://github.com/onyxfish/agate-sql\n* Issues:           https://github.com/onyxfish/agate-sql/issues",
        "url": "http://pypi.python.org/pypi/agate-sql",
        "summary": "agate-sql adds SQL read/write support to agate.",
        "command": "pip install 'agate-sql'"
      },
      "Agatsuma": {
        "name": "agatsuma",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Agatsuma",
        "summary": "Flexible modular metaframework, mostly intended for web but not only",
        "command": "pip install 'Agatsuma'"
      },
      "agavepy": {
        "name": "agavepy",
        "description": "=======\nAgavePy\n=======\n\nA simple Python binding for the `Agave API`_.\n\n\nInstallation\n============\n\nInstall from PyPI_::\n\n    pip install agavepy\n\n\nUsing agavepy in Docker\n========================\n\nThis repository includes a ``Dockerfile`` and a ``docker-compose.yml``\nfile, which allows a zero installation version of ``agavepy``.\n\nThe only requirement is Docker_ and `docker-compose`_, most likely\nalready installed in your system.\n\nThen, clone this repository and execute ``docker-compose`` as follows:\n\n.. code-block:: bash\n\n   $ git clone https://bitbucket.org/taccaci/agavepy.git\n   $ cd agavepy\n   $ docker-compose build\n   $ docker-compose up\n\n(a bug in ``docker-compose`` is preventing to run just ``up``. The steps ``build`` and ``up`` have to be done separately.)\nNavigate to http://localhost:8888 and access the Jupyter_ notebook\nwith password ``agavepy``.  The notebook ``Example.ipynb`` contains a\nfull example of use.\n\n\nQuickstart\n==========\n\nThe first step is to create an ``agave`` Python object pointing to\nyour tenant:\n\n.. code-block:: pycon\n\n   >>> from agavepy.agave import Agave\n   >>> my_agave = Agave(api_server='https://agave.iplantc.org',\n   ...                  username='myusername', password='mypassword')\n\nOnce the object is instantiated, interact with it according to the\nmethods in the API documentation.\n\nFor example, create a new client with:\n\n.. code-block:: pycon\n\n   >>> my_agave.clients.create(body={'clientName': 'my_client'})\n\nAccess any endpoint with:\n\n.. code-block:: pycon\n\n   >>> my_agave.systems.list()\n   >>> my_agave.jobs.manage(...)\n\nOnce a client is created, it is used by default to access the API.\n\nTo make use of an existing client, pass the client's credentials into the Agave constructor:\n\n.. code-block:: pycon\n\n   >>> from agavepy.agave import Agave\n   >>> my_agave = Agave(api_server='https://agave.iplantc.org',\n   ...                  username='myusername', password='mypassword', client_name='my_client', api_key='123', api_secret='abc')\n\nAlternatively, the SDK will attempt to recover the client credentials from the client name if they are stored\nin the user's ``.agavepy`` file, in which case just passing the ``client_name`` will suffice:\n\n.. code-block:: pycon\n\n   >>> from agavepy.agave import Agave\n   >>> my_agave = Agave(api_server='https://agave.iplantc.org',\n   ...                  username='myusername', password='mypassword', client_name='my_client')\n\n\n\n.. _Agave API: http://agaveapi.co/\n.. _PyPI: https://pypi.python.org/pypi\n\n\nLicense\n=======\n\nAgavepy is licensed under the MIT license.\n\nSwagger.py is copyright of Digium, Inc., and licensed under BSD 3-Clause License.\n\n.. _Docker: https://docs.docker.com/installation/#installation\n.. _docker-compose: https://docs.docker.com/compose/install/\n.. _Jupyter: http://ipython.org/",
        "url": "http://pypi.python.org/pypi/agavepy",
        "summary": "SDK for Agave",
        "command": "pip install 'agavepy'"
      },
      "age": {
        "name": "age",
        "description": "Analog Genetic Encoding (AGE) implemented in Python",
        "url": "http://pypi.python.org/pypi/age",
        "summary": "Analog Genetic Encoding",
        "command": "pip install 'age'"
      },
      "agecalc": {
        "name": "agecalc",
        "description": "AgeCalc\r\n=======\r\n\r\n\r\nSynopsis\r\n--------\r\n\r\nCalculates birth information based on a specified Date of Birth.\r\n\r\n\r\nInstallation\r\n------------\r\n\r\npip install agecalc\r\n\r\n\r\n\r\nWhat's Inside\r\n-------------\r\n\r\nClasses\r\n~~~~~~~\r\n\r\nAgeCalc\r\n^^^^^^^\r\n\r\nThis stores the DOB data into a class. You can then use the methods\r\nbelow to get data from this.\r\n\r\nFunctions\r\n~~~~~~~~~\r\n\r\nage\r\n^^^\r\n\r\nDisplays a DOB's age in years.\r\n\r\nage\\_days\r\n^^^^^^^^^\r\n\r\nDisplays a DOB's age in days.\r\n\r\nage\\_hours\r\n^^^^^^^^^^\r\n\r\nDisplays a DOB's age in hours.\r\n\r\nage\\_months\r\n^^^^^^^^^^^\r\n\r\nDisplays a DOB's age in months.\r\n\r\nage\\_weeks\r\n^^^^^^^^^^\r\n\r\nDisplays a DOB's age in weeks.\r\n\r\nage\\_weeks\\_days\r\n^^^^^^^^^^^^^^^^\r\n\r\nDisplays a DOB's age in weeks/days. Will return a dictionary with the\r\n'weeks' and 'days' keys, and their values.\r\n\r\nage\\_years\\_months\r\n^^^^^^^^^^^^^^^^^^\r\n\r\nDisplays a DOB�s age in years/months. Will return a dictionary with the\r\n'years' and 'months' keys, and their values.\r\n\r\ndating\\_ages\r\n^^^^^^^^^^^^\r\n\r\nDisplays the socially acceptable dating ages for a person. Will return a \r\ndictionary with the \"max\", \"min\" and \"original\" keys, with their values.\r\n\r\nday\\_of\\_birth\r\n^^^^^^^^^^^^^^\r\n\r\nDisplays the DAY of birth of a DOB.\r\n\r\nlast\\_birthday\r\n^^^^^^^^^^^^^^\r\n\r\nDisplays the days since a DOB's last birthday\r\n\r\nnext\\_birthday\r\n^^^^^^^^^^^^^^\r\n\r\nDisplays the days until a DOB's next birthday\r\n\r\n\r\nExample (age function)\r\n----------------------\r\n\r\nWith AgeCalc class\r\n~~~~~~~~~~~~~~~~~~\r\n\r\n.. code:: python\r\n\r\n    import agecalc\r\n    dob = agecalc.AgeCalc(1, 1, 2000) \r\n    print dob.age\r\n\r\nWith Functions\r\n~~~~~~~~~~~~~~\r\n\r\n.. code:: python\r\n\r\n    import agecalc\r\n    print agecalc.age(1, 1, 2000)\r\n\r\n\r\nNotes\r\n-----\r\n\r\nAll functions/classes take only these three arguments:\r\n\r\ndd: Day\r\n\r\nmm: Month\r\n\r\nyy: Year\r\n\r\nDates should be passed as if they were integers. If the Date/Month\r\ncontains a '0' before the integer, the '0' should be ommitted.\r\n\r\nE.G. DOB '01/01/2000' should be passed as:\r\n\r\ndd: 1\r\n\r\nmm: 1\r\n\r\nyy: 2000\r\n\r\n\r\nSubmitting an Issue\r\n-------------------\r\n\r\nIf you wish to submit an issue with this module, or suggest any changes,\r\nyou can either use the `GitHub Issue Tracker`_, or email me at\r\nalir6716@gmail.com\r\n\r\n\r\nCopyright/License\r\n-----------------\r\n\r\nCopyright (C) 2015, Ali Raja\r\n\r\nThis program is free software: you can redistribute it and/or modify it\r\nunder the terms of the GNU General Public License as published by the\r\nFree Software Foundation, either version 3 of the License, or (at your\r\noption) any later version.\r\n\r\nThis program is distributed in the hope that it will be useful, but\r\nWITHOUT ANY WARRANTY; without even the implied warranty of\r\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General\r\nPublic License for more details.\r\n\r\nYou should have received a copy of the GNU General Public License along\r\nwith this program. If not, see http://www.gnu.org/licenses/.\r\n\r\n.. _GitHub Issue Tracker: https://github.com/alir6716/agecalc/issues",
        "url": "http://pypi.python.org/pypi/agecalc",
        "summary": "Calculates birth information based on a specified Date of Birth.",
        "command": "pip install 'agecalc'"
      },
      "ageliaco.p10userdata": {
        "name": "ageliaco.p10userdata",
        "description": "Introduction\n============\n\nThis product adds some properties to the user data to exploit to its best the values\nthere are in the p10 ldap.\n\nThis product is dependant on **plone.app.ldap**, because it does set the basic properties.\n\n\nInstallation\n============\n  * Go to admin > Site Setup > Add-ons\n  * Activate plone.app.ldap\n  * Activate ageliaco.p10userdata\n  * Go to ZMI > acl_users > ldap-plugin > acl_users\n    ** reset LDAP Server\n    ** reset \"Configure\" to fit your needs (filter and groups)\n\nThere is a bug concerning plone.app.ldap => when the ldap server is set \nit doesn't set properly the port number, and the ldap filter is not set either.\n\nThis product may contain traces of nuts.\n\n\nAuthors\n=======\n  \"AGELIACO\", Serge Renfer mailto:serge.renfer@gmail dot com\n\nChangelog\n=========\n\n1.0dev (unreleased)\n-------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/ageliaco.p10userdata",
        "summary": "Member Data for p10 EEEL project (Geneva)",
        "command": "pip install 'ageliaco.p10userdata'"
      },
      "ageliaco.rd": {
        "name": "ageliaco.rd",
        "description": "Introduction\n============\n\nThis product is intended for a service management in Geneva School Departement (DIP).\nThis service is \"Ressources & Développement\" and it brings a support for educational projects\nin the upper secondary schools (colleges).\n\nThis product is dependant on **ageliaco.p10userdata**, because it does set the basic properties\nin user data conforming to our ldap settings.\n\n\nInstallation\n============\n  * Go to admin > Site Setup > Add-ons\n  * Activate plone.app.ldap\n  * Activate ageliaco.p10userdata\n  * Go to ZMI > acl_users > ldap-plugin > acl_users\n    ** reset LDAP Server\n    ** reset \"Configure\" to fit your needs (filter and groups)\n  * Activate ageliaco.rd\n\nThere is a bug concerning plone.app.ldap => when the ldap server is set \nit doesn't set properly the port number, and the ldap filter is not set either.\n\nThis product may contain traces of nuts.\n\n\nAuthors\n=======\n  \"AGELIACO\", Serge Renfer mailto:serge.renfer@gmail dot com\n\n\n\nChangelog\n=========\n\n0.1dev (unreleased)\n-------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/ageliaco.rd",
        "summary": "UNKNOWN",
        "command": "pip install 'ageliaco.rd'"
      },
      "ageliaco.rd2": {
        "name": "ageliaco.rd2",
        "description": "Introduction\n============\n\n\n\nThis product helps managing a service in the post-obligatory schools of Geneva.\n\"Ressource & Developpement\" is a service that manages resources (hours of teaching used\nto produce a pedagogic project) to help teachers bring new teaching resources.\n\nThis is an experimental project, to see how far I can push this dexterity/Plone matter ;-)\n\nChangelog\n=========\n\n0.1dev (unreleased)\n-------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/ageliaco.rd2",
        "summary": "Product to manage project with annual cycles",
        "command": "pip install 'ageliaco.rd2'"
      },
      "ageliaco.recipe.csvconfig": {
        "name": "ageliaco.recipe.csvconfig",
        "description": "- Code repository:https://github.com/renfers/ageliaco.recipe.csvconfig\n- Questions and comments to serge.renfer at gmail dot com\n\n=========================\nageliaco.recipe.csvconfig\n=========================\n\nThe idea behind this recipe is to have only one source of information for your buildout\nvariable settings.\n\nWhen one is confronted with several deployments which are very similar, then you gather\nthe variable elements into a csv file (just like a flat representation of several columns).\n\nFor instance, let's say you need to generate several Plone instances and you want to gather\nthem in a same buildout, because you will add a supervisor and a cache with varnish, plus\na config for the nginx that runs on your server.\n\nYour CSV file, main.csv::\n\n    instance,port,domain,subdomain,plone,emailadmin\n    albertcair,15004,albertcair.ch,base.albertcair.ch,/,albert.cair@gmail.com\n    albertcair,15004,albertcair.ch,albertcair.ch,/alberto,albert.cair@gmail.com\n    albertcair,15004,albertcair.ch,www.albertcair.ch,/alberto,albert.cair@gmail.com\n    albertcair,15004,albertcair.ch,histoire.albertcair.ch,/bestie,albert.cair@gmail.com\n    albertcair,15004,albertcair.ch,images.albertcair.ch,/images,albert.cair@gmail.com\n    albertcair,15004,albertcair.ch,italiano.albertcair.ch,/italiano,albert.cair@gmail.com\n    bopip,15005,bopip.ch,base.bopip.ch,/,jm.del@gmail.com\n    bopip,15005,bopip.ch,bopip.ch,/bopip,jm.del@gmail.com\n    bopip,15005,bopip.ch,www.bopip.ch,/bopip,jm.del@gmail.com\n    bopip,15005,bopip.ch,jaun.bopip.ch,/jaun,jm.del@gmail.com\n    bopip,15005,bopip.ch,java.bopip.ch,/java,jm.del@gmail.com\n    bopip,15005,bopip.ch,math.bopip.ch,/math,jm.del@gmail.com\n    bopip,15005,bopip.ch,ecole-en-sauvygnon.ch,/ensauvygnon,jm.del@gmail.com\n    bopip,15005,bopip.ch,www.ecole-en-sauvygnon.ch,/ensauvygnon,jm.del@gmail.com\n\nIn your buildout you will be able to spread those information at different levels, \nthat means on different templates.\nLet's make a *templates* directory in our buildout and we put our first template\n\ninstances.cfg.in::\n\n    [$${subdomain}-parameters]\n    port = $${port}\n    host = 127.0.0.1\n    plone = $${plone}\n    name = $${instance}\n\nand a second one\n\nvarsetting.cfg.in::\n\n    [var-settings]\n    vh-targets =\n        $${subdomain}:$${subdomain}-parameters\n    \n    instances-targets =\n        $${instance}:$${instance}-parameters\n    \n    backup-targets =\n        backup-$${instance}:$${instance}-parameters\n    \n    cron-targets =\n        cron-$${instance}:$${instance}-parameters\n    \n    supervisor =\n        20 $${instance} ${buildout:directory}/bin/$${instance} [console] true ${users:zope}\n    \n    eventlistener =\n        $${instance}-HttpOk TICK_60 ${buildout:bin-directory}/httpok [-m $${emailadmin} -p $${instance} http://localhost:11011]\n\n\nNotice that our variables have the ``$${var}`` format.\n\nIn a buildout file you will have a part that has the following form:\n\nmain.cfg::\n\n    [buildout]\n    parts = main\n    \n    eggs = ageliaco.recipe.csvconfig\n    \n    \n    [main]\n    recipe = ageliaco.recipe.csvconfig:default\n    csvfile = main.csv\n    templates = templates/varsetting.cfg.in\n        templates/instances.cfg.in\n\nRunning the following commands::\n\n    ../Python-2.7/bin/python bootstrap.py -c main.cfg\n    bin/buildout -c main.cfg\n    \nIt will generate 2 files in your buildout directory, \n\nvarsetting.cfg::\n\n    [var-settings]\n    vh-targets = \n        base.albertcair.ch:base.albertcair.ch-parameters \n        albertcair.ch:albertcair.ch-parameters \n        www.albertcair.ch:www.albertcair.ch-parameters \n        histoire.albertcair.ch:histoire.albertcair.ch-parameters \n        images.albertcair.ch:images.albertcair.ch-parameters \n        italiano.albertcair.ch:italiano.albertcair.ch-parameters \n        base.bopip.ch:base.bopip.ch-parameters \n        bopip.ch:bopip.ch-parameters \n        www.bopip.ch:www.bopip.ch-parameters \n        jaun.bopip.ch:jaun.bopip.ch-parameters \n        java.bopip.ch:java.bopip.ch-parameters \n        math.bopip.ch:math.bopip.ch-parameters \n        ecole-en-sauvygnon.ch:ecole-en-sauvygnon.ch-parameters \n        www.ecole-en-sauvygnon.ch:www.ecole-en-sauvygnon.ch-parameters\n    instances-targets = \n        albertcair:albertcair-parameters \n        bopip:bopip-parameters\n    backup-targets = \n        backup-albertcair:albertcair-parameters \n        backup-bopip:bopip-parameters\n    cron-targets = \n        cron-albertcair:albertcair-parameters \n        cron-bopip:bopip-parameters\n    supervisor = \n        20 albertcair ${buildout:directory}/bin/albertcair [console] true ${users:zope} \n        20 bopip ${buildout:directory}/bin/bopip [console] true ${users:zope}\n    eventlistener = \n        albertcair-HttpOk TICK_60 ${buildout:bin-directory}/httpok [-m albert.cair@gmail.com -p albertcair http://localhost:11011] \n        bopip-HttpOk TICK_60 ${buildout:bin-directory}/httpok [-m jm.del@gmail.com -p bopip http://localhost:11011]\n\nand \n\ninstances.cfg::\n\n    [base.albertcair.ch-parameters]\n    port = 15004\n    host = 127.0.0.1\n    plone = /\n    name = albertcair\n    \n    [albertcair.ch-parameters]\n    port = 15004\n    host = 127.0.0.1\n    plone = /alberto\n    name = albertcair\n    \n    [www.albertcair.ch-parameters]\n    port = 15004\n    host = 127.0.0.1\n    plone = /alberto\n    name = albertcair\n    \n    [histoire.albertcair.ch-parameters]\n    port = 15004\n    host = 127.0.0.1\n    plone = /bestie\n    name = albertcair\n    \n    [images.albertcair.ch-parameters]\n    port = 15004\n    host = 127.0.0.1\n    plone = /images\n    name = albertcair\n    \n    [italiano.albertcair.ch-parameters]\n    port = 15004\n    host = 127.0.0.1\n    plone = /italiano\n    name = albertcair\n    \n    [base.bopip.ch-parameters]\n    port = 15005\n    host = 127.0.0.1\n    plone = /\n    name = bopip\n    \n    [bopip.ch-parameters]\n    port = 15005\n    host = 127.0.0.1\n    plone = /bopip\n    name = bopip\n    \n    [www.bopip.ch-parameters]\n    port = 15005\n    host = 127.0.0.1\n    plone = /bopip\n    name = bopip\n    \n    [jaun.bopip.ch-parameters]\n    port = 15005\n    host = 127.0.0.1\n    plone = /jaun\n    name = bopip\n    \n    [java.bopip.ch-parameters]\n    port = 15005\n    host = 127.0.0.1\n    plone = /java\n    name = bopip\n    \n    [math.bopip.ch-parameters]\n    port = 15005\n    host = 127.0.0.1\n    plone = /math\n    name = bopip\n    \n    [ecole-en-sauvygnon.ch-parameters]\n    port = 15005\n    host = 127.0.0.1\n    plone = /ensauvygnon\n    name = bopip\n    \n    [www.ecole-en-sauvygnon.ch-parameters]\n    port = 15005\n    host = 127.0.0.1\n    plone = /ensauvygnon\n    name = bopip\n    \nvarsetting.cfg.in exposes one kind of variable substitution, when a variable is present in\nan option value => the option value is repeated based on the number of different result we \nhave in the csv file configuration, for instance the \"instance\" column in my csv file has \n2 different values then, based on that the \"eventlistner\" option expands in a 2 lines value.\n\ninstances.cfg.in exposes another kind of variable substitution, where the variable is present\nin the section identifier => the section with the \"subdomain\" variable will epxand in as\nmany sections as there are different values for this variable in the csv file.\n\nCSV as flat database :\n----------------------\nLet's see another example to show you that the csv file can be just a flat representation \nof a relational database.\n\nThe csv file, testmultikey.csv::\n\n    prenom, nom, naissance, profession\n    bob,wut,1961,doc\n    marie,wut,1962,maitresse\n    serge,ren,1960,prof\n    coco,ren,1961,maitresse\n    \nThe template, templates/contact.cfg.in::\n\n    [contact]\n    $${prenom}-$${nom}-$${naissance} = $${profession}\n    \n    [famille-$${nom}]\n    $${prenom}-naissance = $${naissance}\n    $${prenom}-profession = $${profession}\n    \n    [annee-de-naissance-$${naissance}]\n    $${prenom}-$${nom} = $${profession}\n    \n    [$${profession}]\n    nom = $${prenom}-$${nom}-$${naissance}\n\nand now the buildout, buildout.cfg::\n\n    [buildout]\n    \n    parts = main\n    \n    develop = src/ageliaco.recipe.csvconfig\n    eggs =\n        ageliaco.recipe.csvconfig\n        \n    [main]\n    recipe = ageliaco.recipe.csvconfig\n    templates = templates/contact.cfg.in\n    csvfile = testmultikey.csv\n\nand the result of `bin/buildout`, contact.cfg::\n\n    [contact]\n    bob-wut-1961 = doc\n    coco-ren-1961 = maitresse\n    marie-wut-1962 = maitresse\n    serge-ren-1960 = prof\n    \n    [famille-ren]\n    coco-naissance = 1961\n    serge-naissance = 1960\n    coco-profession = maitresse\n    serge-profession = prof\n    \n    [famille-wut]\n    bob-naissance = 1961\n    marie-naissance = 1962\n    bob-profession = doc\n    marie-profession = maitresse\n    \n    [annee-de-naissance-1961]\n    bob-wut = doc\n    coco-ren = maitresse\n    \n    [annee-de-naissance-1962]\n    marie-wut = maitresse\n    \n    [annee-de-naissance-1960]\n    serge-ren = prof\n    \n    [maitresse]\n    nom = marie-wut-1962\n            coco-ren-1961\n    \n    [doc]\n    nom = bob-wut-1961\n    \n    [prof]\n    nom = serge-ren-1960\n\n\nDetailed Documentation\n**********************\n\nSupported options\n=================\n\nThe recipe supports the following options:\n\n.. Note to recipe author!\n   ----------------------\n   For each option the recipe uses you should include a description\n   about the purpose of the option, the format and semantics of the\n   values it accepts, whether it is mandatory or optional and what the\n   default value is if it is omitted.\n\ncsvfile\n    this is a path (relative or absolute) to csv file that will be used by the recipe\n\ntemplates\n    one (or more) path to a template file => by default, it is expected a name with \".in\" \n    suffix and a file with the same name without the suffix \".in\" will be generate in the\n    buildout directory. If you want to use another suffix or naming convention you will have\n    to use an alternative format with a \":\" to separate the template path to the target path,\n    \n    This alternate format with \":\" is also interesting if you want to generate a file in\n    a different directory than the buildout-directory!\n    \nfor instance::\n\n    templates = templates/instances.cfg.in\n    \nthat will generate a ./instances.cfg file (in the buildout directory) or\n\n    templates = templates/init-cache.cfg:production/cache.cfg\n    \nthat will generate a production/cache.cfg file (notice that in this example it is a relative path, \nbut it can also be a full path)\n     \n\n\n\n\nContributors\n************\n\n\"renfers\", Author\n\n\nChange history\n**************\n\n0.7 (2013-01-10)\n----------------\n\n- changed from ConfigParser to configparser\n- added \"+=\" and \"-=\" to the delimiters, but could not recreate the same operator on options\n  it passes automatically to \"=\" (=> still a feature to implement)\n  [\"renfers\"]\n  \n0.6 (2013-01-07)\n----------------\n\n- change variable call from ${} to $${} to easily substitute variables embedded in buildout variables\n- added \"+\" to the generated file mode (\"wb+\" instead of \"wb\")\n  [\"renfers\"]\n\n0.5 (2012-12-28)\n----------------\n\n- Documentation updated\n  [\"renfers\"]\n\n\n0.4 (2012-12-26)\n----------------\n\n- rewrite to be sure to take into account multiple value keys. For instance, if you have\none or several variables on a part name, you can consider this set becomes a key and if there are\nvariables in the options we only consider values that for which key values match those of\nthe part. The same can apply when the left part of an option has one or several variables\nthen variables on the right part can only apply to values that have the same key values\n(the ones from the left part).\n  [\"renfers\"]\n\n\n\n0.3 (2012-12-19)\n----------------\n\n- Documentation updated\n  [\"renfers\"]\n\n0.2 (2012-12-19)\n----------------\n\n- Changed \"update\" to redo the install on update\n  [\"renfers\"]\n\n0.1 (2012-12-18)\n----------------\n\n- Created recipe with ZopeSkel\n  [\"renfers\"]\n\n\nDownload\n********",
        "url": "http://pypi.python.org/pypi/ageliaco.recipe.csvconfig",
        "summary": "Use a CSV file to populate buildout templates",
        "command": "pip install 'ageliaco.recipe.csvconfig'"
      },
      "ageliaco.tracker": {
        "name": "ageliaco.tracker",
        "description": "Introduction\n============\n\nGeneric Issue Tracker\n\nThis product may contain traces of nuts.\n\nChangelog\n=========\n\n0.1dev (unreleased)\n-------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/ageliaco.tracker",
        "summary": "Issue tracker",
        "command": "pip install 'ageliaco.tracker'"
      },
      "agenda2pdf": {
        "name": "agenda2pdf",
        "description": "agenda2pdf is a script which generates a book agenda file in PDF format, ready\r\nto be printed or to be loaded on a ebook reader\r\n\r\nYou can choose among different sections. Each section have pdf links to other\r\nparts of the agenda.\r\n\r\nI've created it for using with my iLiad eBook reader.",
        "url": "http://pypi.python.org/pypi/agenda2pdf",
        "summary": "Simple script which generates a book agenda file in PDF format, ready to be printed or to be loaded on a ebook reader",
        "command": "pip install 'agenda2pdf'"
      },
      "agent.http": {
        "name": "agent.http",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/agent.http",
        "summary": "Rackspace Monitoring agent.plugin HTTP check",
        "command": "pip install 'agent.http'"
      },
      "AgentML": {
        "name": "agentml",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AgentML",
        "summary": "An XML dialect for creating natural language software agents",
        "command": "pip install 'AgentML'"
      },
      "agent.pgep": {
        "name": "agent.pgep",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/agent.pgep",
        "summary": "Rackspace Cloud Monitoring plugin for PostgreSQL       endpoints as an agent.plugin type of check.",
        "command": "pip install 'agent.pgep'"
      },
      "agentsdk": {
        "name": "agentsdk",
        "description": "AgentSDK-Python\n===============\n\nPure-Python client library for the AgentSDK-RPCd server, providing access to\nthe NewRelic AgentSDK via a local RPC daemon.",
        "url": "http://pypi.python.org/pypi/agentsdk",
        "summary": "Pure-Python client library for AgentSDK-RPCd",
        "command": "pip install 'agentsdk'"
      },
      "agentx": {
        "name": "agentx",
        "description": "This is a Python 2.x and 3.x module that enables SNMP AgentX functionality",
        "url": "http://pypi.python.org/pypi/agentx",
        "summary": "Python 2.x and 3.x module for SNMP AgentX functionality",
        "command": "pip install 'agentx'"
      },
      "agg2567": {
        "name": "agg2567",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/agg2567",
        "summary": "first packet of python",
        "command": "pip install 'agg2567'"
      },
      "aggdraw": {
        "name": "aggdraw",
        "description": "The aggdraw module implements the basic WCK 2D Drawing Interface on\ntop of the AGG library. This library provides high-quality drawing,\nwith anti-aliasing and alpha compositing, while being fully compatible\nwith the WCK renderer.",
        "url": "http://pypi.python.org/pypi/aggdraw",
        "summary": "High quality drawing interface for PIL.",
        "command": "pip install 'aggdraw'"
      },
      "AgglomCluster": {
        "name": "agglomcluster",
        "description": "agglom\\_cluster\r\n===============\r\n\r\nAgglomerative clustering tool for network-x graphs\r\n\r\nClustering\r\n----------\r\n\r\nImplements the algorithm described by: \"Fast algorithm for detecting\r\ncommunity structure in networks\" M. E. J. Newman. 2004\r\nhttp://arxiv.org/pdf/cond-mat/0309508v1.pdf This is a greedy\r\nagglomerative hierarchical clustering algorithm. The alogorithm\r\nefficiently clusters large number of nodes (this is one of the best\r\nscaling clustering algorithms) while producing a suggested number of\r\nclusters. See papers on scaling and accuracy questions regarding greedy\r\nNewman.\r\n\r\nThis implementation uses a heap to select the best pair to cluster at\r\neach iteration - A naive implementation considers all \"n\" edges in the\r\ngraph (O(n)) - A heap reduces this search dramatically (O(log(n))\r\n\r\nDependencies\r\n------------\r\n\r\nallset -- for automatic module importing networkx -- supported graphing\r\nlibrary\r\n\r\nProblems\r\n--------\r\n\r\n-  The actual Modularity score does not exactly match the Modularity\r\n   score of the example on the wikipedia page\r\n-  http://en.wikipedia.org/wiki/Modularity\\_(networks)\r\n-  Does not work for directed graphs (TODO operate on the undirected\r\n   graph)\r\n-  Does not work for negative graphs (TODO add this capability)\r\n-  Does not handle disconnected components (unless than are components\r\n   of size 1)\r\n-  Clustering needs to move to a function call rather than an object\r\n   holder (return dendrogram object)\r\n-  Node relabeling is messy\r\n-  Dendrogram crawling is used for two separate purposes which aren't\r\n   clearly defined/called\r\n\r\nAttributes\r\n----------\r\n\r\nNewmanGreedy objects store the following attributes \\* Supergraph -\r\nDuplicate of the original graph. Gets manipulated during the clustering:\r\nedges and nodes are condensed and reweighted - Cluster degree stored in\r\nnode attribute - Number of connections between clusters stored in edge\r\nattribute (weighted edge) - Implicitly keeps track of the existing nodes\r\nwhich is required for the heap \\* Dendrogram - Stores the clustering\r\nhistory in a tree \\* Heap - Stores the modularity quality difference for\r\ncombining each pair of existing nodes - Popping returns the node pair\r\nwith the largest modulairty/quality difference, then smallest id1, then\r\nsmallest id2 \\* Stored as a tuple (value, id1, id2) where the\r\nmodularity/value is negated, and id1 is the smaller of the two \\*\r\nProcessing the smaller IDs first means that smaller clusters will be\r\nchosen first during modularity tie breaking - Non-existing nodes are not\r\nactively removed from the heap, so pairs with non-existing nodes are\r\nignored when popping \\* Quality History - Charts the Modularity score\r\nfor each number of clustering\r\n\r\nAuthor\r\n------\r\n\r\nAuthor(s): Ethan Lozano & Matthew Seal\r\n\r\nCollaborator(s): Zubin Jelveh",
        "url": "http://pypi.python.org/pypi/AgglomCluster",
        "summary": "Performs greedy agglomerative clustering on network-x graphs",
        "command": "pip install 'AgglomCluster'"
      },
      "aggregate6": {
        "name": "aggregate6",
        "description": "aggregate6\n==========\n\naggregate6 will compress an unsorted list of IPv6 prefixes.\n\nDESCRIPTION\n-----------\n\nTakes a list of IPv6 prefixes in conventional format on stdin, and performs two\noptimisations to attempt to reduce the length of the prefix list. The first\noptimisation is to remove any supplied prefixes which are superfluous because\nthey are already included in another supplied prefix. For example,\n```2001:67c:208c:10::/64``` would be removed if ```2001:67c:208c::/48``` was\nalso supplied.\n\nThe second optimisation identifies adjacent prefixes that can be combined under\na single, shorter-length prefix. For example, ```2001:67c:208c::/48``` and\n```2001:67c:208d::/48``` can be combined into the single prefix\n2001:67c:208c::/47.\n\nINSTALLATION\n------------\n\n```\n    $ sudo apt-get install python-dev\n    $ sudo pip install aggregate6\n```\n\nUSAGE\n-----\n\nEither provide the list of IPv6 prefixes on STDIN, or give filenames containing\nlists of IPv6 prefixes as arguments.\n\n```\n    $ cat prefix_list | aggregate6\n       ... output ...\n\n    $ aggregate6 prefix_list [ ... optional_other_prefix_lists ]\n       ... output ...\n\n    $ echo -e \"2001:67c:208c::/48\\n2000::/3\" | aggregate6\n    2000::/3\n```\n\nSee ```aggregate6 -h``` for a full list of options.\n\nBUGS\n----\n\nPlease report bugs at: https://github.com/job/aggregate6\n\nCopyright and License\n---------------------\n\nCopyright (c) 2014, Job Snijders <job@instituut.net>. All rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\nlist of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\nthis list of conditions and the following disclaimer in the documentation\nand/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/aggregate6",
        "summary": "IPv6 prefix list compressor",
        "command": "pip install 'aggregate6'"
      },
      "agha": {
        "name": "agha",
        "description": "Agha: Another GitHub API\n========================\n\nYes, Agha is another GitHub API library for Python 2.x development.\n\nSupport basic CRUD operations throw the\nofficial REST API v3: http://developer.github.com/v3/\n\nExample:\n\n.. code:: python\n\n    from agha import GitHubApi\n    api = GitHubApi(\"myuser\", \"mypass\")\n\n    # Create a repository\n    api.create_repo({'name': 'mytestrepo1', 'description': 'Github Test 1', 'auto_init': True}\n\n    # Edit the repo description\n    api.edit_myrepo(\"mytestrepo1\", {'description': 'Another description for my repo'})\n\n    # List my repositories\n    for repo in api.get_myrepos():\n        print \"NAME: %(name)s, DESCRIPTION: %(description)s, URL: %(html_url)s\" % repo\n\n    # Delete the repo\n    api.delete_myrepo(\"mytestrepo1\")\n\n   # Show my profile information\n   print \"USER: %(login)s, NAME: %(name)s, EMAIL: %(email)s\" % api.get_myprofile()\n\n\nRequirements\n------------\n\n* Python 2.6+\n* Requests library\n\n\nAbout\n-----\n\nThis source code is available in https://github.com/mrsarm/python-agha\n\nDeveloped by Mariano Ruiz <mrsarm@gmail.com>\n\nLicense: LGPL-3 (C) 2014\n",
        "url": "http://pypi.python.org/pypi/agha",
        "summary": "Agha, Another GitHub API",
        "command": "pip install 'agha'"
      },
      "agic": {
        "name": "agic",
        "description": "",
        "url": "http://pypi.python.org/pypi/agic",
        "summary": "",
        "command": "pip install 'agic'"
      },
      "agile": {
        "name": "agile",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/agile",
        "summary": "A meta-package containing a full toolset for agile development with TDD",
        "command": "pip install 'agile'"
      },
      "agilearning": {
        "name": "agilearning",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/agilearning",
        "summary": "UNKNOWN",
        "command": "pip install 'agilearning'"
      },
      "AgileCLU": {
        "name": "agileclu",
        "description": "# AgileCLU #\n\nAgileCLU is a command line implementation of Limelight Networks Agile Storage cloud platform.  It is also a Python library to simplify integrating Python applications with cloud object storage.\n\nThe tools and library leverage Agile's JSON-RPC APIs and HTTP ingest and egress capabilities in an easy to use way.  To use these tools, you must have:\n\n* An account on Limelight Network's Agile Storage cloud platform. (http://www.limelightnetworks.com)\n\n## Agile Storage Locations ##\n\nAs of October 2012, the Agile Storage Cloud has storage capacity in 34 geographies around the world.\n\n![Agile Storage Locations](https://raw.github.com/wylieswanson/AgileCLU/master/agile_locations_oct_2012.jpg)\n\n## Communication ##\n\nFeel free to send any questions, comments, or patches using the AgileCLU Development at Github page (you'll need to join to send a message): \n\n* [AgileCLU Release Documentation](http:/wylieswanson.github.com/AgileCLU)\n\n* [AgileCLU Development at GitHub](https://github.com/wylieswanson/AgileCLU)\n\n* [AgileCLU at Python Package Index](http://pypi.python.org/pypi/AgileCLU)\n\n# Basic Installation #\nIf you already have Python and [Python Package Index](http://pypi.python.org/pypi/setuptools) (PyPI) installed on your machine, the installation of AgileCLU is simple and straightfoward.  Simply execute one of the following commands (sudo is usually required on Linux):\n\n\teasy_install AgileCLU\n\nor,\n\n\tpip install AgileCLU\n\nIf the above method worked for you, you can skip the operating system-specific installation sections and move to Configuration, as you have now completed the installation of AgileCLU.  If not, consult the relevant operating system-specific sections in the Advanced Configuration sections.\n\n# Upgrading #\n\nIf you are upgrading from a release prior to 0.3.1, you may need to manually delete the files from your Python installation (egg and easy-install.pth) prior to invoking easy_install or pip.  For future upgrades, can force to latest version with:\n\n\teasy_install -U AgileCLU\n\n# Configuration #\n\nSince AgileCLU 0.4.0 the configuration of profiles has been greatly simplified.  Configuration profiles are stored in ~/.agileclu (off of active user accounts home directory).  After installing AgileCLU, use 'agileprofile create' to configure a default account.  You can create as many configuration profiles as you like, with 'agileprofile create profilename'.  To use different profiles from the command line tools, specify the -l option for any given command.  If you are using Windows, you need to include the .py extension, substituting agileprofile with agileprofile.py.\n\n\tagileprofile create\n\nExample output:\n\n\tagileprofile.py (AgileCLU 0.4.0)\n\n\tCREATE PROFILE: test\n\t                                          Username : testcompany\n\t                                          Password : \n\t                                 Re-enter password : \n\t                            Egress protocol [http] : \n\t             Egress hostname [global.mt.lldns.net] : \n\t                                  Egress base path : /testcompany\n\t                           Ingest protocol [https] : \n\t                                   Ingest hostname : test-company.api.agile.lldns.net\n\t\n\tProfile (test) has been saved.  Exiting.\n\n# AgileCLU from Command Line #\n\nThe commands that are currently available are:\n\n*agileprofile* - Generate a profile based on account credentials and ingest/egress information\n\n*agilefetch* - Automatically download a file from any URL and place it in your storage in a specified directory\n\n*agilemkdir* - Make a directory\n\n*agilerm* - Remove a file\n\n*agilels* - List a directory\n\n*agilepost* - Upload a file\n\nNOTE: For Windows, add a \".py\" extension to the above commands.\n\n\n# Advanced Installation #\n\nThe advanced installation covers installing prerequisites, like Python and Python Setuptools.  Specific Python libraries will be installed automaticaly when you run easy_install.  If you already have Python and Easysetup installed, you do not need to use the following directions.\n\n\n## Installation:Linux ##\n\nOn most Linux distributions, Python is already installed, you only need to install PyPI.  For Debian, Ubuntu and other distributions using APT, install PyPI with the following:\n\n\tsudo apt-get install python-pip\n\nIf you are running another distribution, consult the [Python setuptools](http://pypi.python.org/pypi/setuptools) documentation.  After you complete this step, complete Basic Installation and move on to Configuration.\n\n\n## Installation:Mac OSX ##\n\nPython is already installed by default on modern OS X.\n\n## Installation:Windows 32-bit and 64-bit ##\n\nThe Windows 32-bit and 64-bit Installation section covers Windows environment variables, along with Python and Python Setuptools.\n\n### Windows Python ###\n\nPython must be installed on the machine.  You can download from http://www.python.org/getit/ or, specifically, for Windows 32 and 64-bit:\n\n* Python 2.7.3 Windows Installer (Windows binary - does not include source)\n\t* http://www.python.org/ftp/python/2.7.3/python-2.7.3.msi\n\n* Python 2.7.3 Windows X86-64 Installer (Windows AMD64 / Intel 64 / X86-64 bainry - does not include source)\n\t* http://www.python.org/ftp/python/2.7.3/python-2.7.3.amd64.msi\n\n### Windows Environment Variables ###\n\nOnce Python has been installed, you will want to add setuptools, the mainstream package manager for Python, also known as PyPI.\n\nNext, set the system's PATH variable to include directories that include Python components and packages we'll add later.  To do this:\n\n* Click the bottom left Windows icon\n* In the search field, type 'system'\n* In the Control Panel section of the search results, select \"Edit system environment variables\"\n* Select \"Environment Variables\"\n* In the \"System variables\" section, scroll down to Path and click \"Edit...\", and then append the below text to the \"Variable Value\" field, then select OK.\n\n> ;C:\\Python27;C:\\Python27\\Lib\\site-packages;C:\\Python27\\Scripts;\n\n\n### Windows Python Setuptools ###\n\n* For 32-bit Windows\n\t* Install setuptools using the provided .exe installer.\n\t\t* http://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11.win32-py2.7.exe\n\n* For 64-bit Windows\n\t* Download ez_setup.py and run it; it will download the appropriate .egg file and install it for you. (Currently, the provided .exe installer does not support 64-bit versions of Python for Windows, due to a distutils installer compatibility issue.\n\t\t* http://peak.telecommunity.com/dist/ez_setup.py\n\t\t* Run \"ez_setup.py\"\n\nAt this point, you can return to the basic installation method (easy_install) at the top of this document.  Note that you will need to place the output of agileprofile in C:\\etc\\agile\\agile.conf, or alternate profiles C:\\etc\\agile\\profileconf (to be used by the -l command line option).\n\n\n# Libraries used by AgileCLU #\n\nThis package leverages the following Python libraries:\n\n* poster by Chris AtLee - used for streaming ingest (http://atlee.ca/software/poster/)\n* progressbar by Nilton Volpato - used for console ingest progress bar (http://code.google.com/p/python-progressbar/)\n* pydes by Todd Whiteman - used as part of the password encryption scheme for config files (http://twhiteman.netfirms.com/des.html)\n* jsonrpclib by John Marshall - an implementation of the JSON-RPC specification (https://github.com/joshmarshall/jsonrpclib)",
        "url": "http://pypi.python.org/pypi/AgileCLU",
        "summary": "Agile Command Line Utilities",
        "command": "pip install 'AgileCLU'"
      },
      "agile_conf": {
        "name": "agile_conf",
        "description": "## Agile Conf Document (WIP)\n\n[agile_conf](https://github.com/tly1980/agile_conf) - A config files (in [YAML](http://yaml.org) format) and template engine ([Jinja2](http://jinja.pocoo.org)) based configuration compile / management tool to make DevOp tasks (or maybe 1,000 other things) easier.\n\n### Motivation\n\nA lot of work of DevOps is about configs / deployment script generation and management.\n\nOne can easily implement script using [\"sed\"](http://en.wikipedia.org/wiki/Sed) to generate the configs / deployment scripts.\nHowever, [\"sed\"](http://en.wikipedia.org/wiki/Sed) is far away from a perfect tool when you want to do some slightly complicated find / replace.\nFrom my expierence, modern [Templating processor](http://en.wikipedia.org/wiki/Template_processor) does a much better job in:\n\n**translating the variables into any forms of text-based outputs** (HTML, XML, JSON, YAML, INI, ..., etc.).\n\nPowered by ([Jinja2](http://jinja.pocoo.org)), [agile_conf](https://github.com/tly1980/agile_conf) supports all the features that is built-in with ([Jinja2](http://jinja.pocoo.org)) templating, such as:\ntemplate inhertitance, include, .etc.\n\nOn top of that, [agile_conf](https://github.com/tly1980/agile_conf) comes with some useful filters for DevOps purpose:\n\n1. jsonify\n2. aws_userdata     \n(it can translate [AWS userdata](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html) into [cloudformation stack template](http://aws.amazon.com/cloudformation/aws-cloudformation-templates/))\n3. yamlify\n\nOther than that, I believe that we should be serious about config / deployment scripts. Rather than doing the scripts / config generation with the execution altogether at run time, I prefer that we can have the compiled scripts / configuration by hands **before** executing it. \n\nSo that we can review the deployment scripts / config before running them, to gain clear idea on what is going to happen and avoid the surpise you don't want.\n\nI also believe we should manage those compiled deployment scripts / configurations in [git](http://git-scm.com) or any other SCM, so that we can treat them seriously just like we usually does with our code.\nAnd because they're managed by SCM, we will have full history, diff between changes, and permissions control.\n\n\n### Basic workfolw\n\n0. Create a project, and use [git](http://git-scm.com) or other SCM to manage it.\n1. Define your variable and templates. \n2. Compile artifacts: any text-based config / scripts.\n3. Commit your changes (variable, templates and the compiled scripts and configs) to the [git](http://git-scm.com) or other SCM repository.\n4. Use Bamboo or Jenkins to check out the compiled scripts and configs and execute them.\nOr, you can always run the scripts locally as long as you have the permissions.\n5. Retired your compiled scripts and configs if you don't need them (You should destroy the resources accordingly, using the pre-compiled destroy scripts.)\n\n### Install\n\nUse [PIP](https://pip.pypa.io/en/latest/quickstart.html) to install it.\n\n```\npip install agile-conf\n```\nIf you don't have [PIP](https://pip.pypa.io/en/latest/quickstart.html), please [install](https://pip.pypa.io/en/latest/installing.html) it first.\n\nAfter the installation, you can run ```agc --help``` to verify.\n\n### Getting started\n```agc``` is the main commandline tool of [agile_conf](https://github.com/tly1980/agile_conf).\n\n0. Clone the boilplate locally.\n```\ngit clone https://github.com/tly1980/agile_conf_boilplate.git ~/workspace/agile_conf_boilplate\n```\n\nYou don't have to use this boilplate repository, you can create your own boilplate repository by using same directory structure.\n\n\n#### 1. Create a new project by using the boilplate. \n\n```\n$ agc create single_ec2 my_ec2 --bo_repo=~/workspace/agile_conf_boilplate/\ncreating project: my_ec2\nusing boilerplate: /Users/minddriven/workspace/agile_conf_boilplate/single_ec2\n```\n\nNotes: You can specify the boilplate_repo with ```--bo_repo```, or set it in enviornment variable: ```AGC_BOIL```.\n\n#### 2. Walk thorugh the project.\n\n```my_ec2``` project (build from single_ec2 boilplate) comes with following structure.\n\nPlease read through the comments.\n\n```\nmy_ec2\n\t/_script\n\t/cfn\n\t\tmodule.yaml  # the variables specifically for cfn module\n\t\tec2.josn.tpl # template of cloudformation script\n\t\t0_userdata.sh.tpl # template of the userdata. \n\t\t\t\t\t\t  # Rendering happended alphabatically\n\t\t\t\t\t\t  # '0_' prefix makes it the first one to be render.\n\tconf_perf.yaml   # config for 'perf' performance test builds.\n\tconf_prod.yaml   # config for 'prod' production builds.\n\tconf_uat.yaml    # config for 'uat' user user acceptance builds.\n\tMakefile\n\tproject.yaml    # the common variables \n\t                # that can use across \n\t                # diffeent modules\n\tREADME.md\n```\n\nIn project folder, any sub-folders do **NOT** has \"_\" prefix is a module. Each module can have its own templates. \nInside the module, any file that has \".tpl\" postfix in the name would be rendered.\n\nThe order of rendering is alphabetical. This is a simple way to avoid circulating dependencies.\n\nCommon template variables are defined in ```project.yaml```, ```conf.yaml```.\n\nModule specific variables are defined in ```module.yaml```.\n\n\nVariables defined in ```conf.yaml```, can be referenced in ```projects.yaml``` and ```module.yaml``` and templates.\n\nIn the single_ec2 projects, it has mupltiple conf.yaml for different enviornments.\n```conf_uat.yaml```, ```conf_prod.yaml``` and ```conf_prod.yaml```. When you run the command, you should run it with ```--conf``` options.\n\n\nWith a ```conf_uat.yaml```\n```yaml\nname: uat\nnetenv: uat   # will deploy to uat subnets\nnumber: 1\n```\n\nFollowing is a line in ```project.yaml```\n```yaml\nproduct_fullname: hello-ec2-{{ conf.name }}-{{ conf.number }}\n```\n\nwould be rendered into\n\n```yaml\nproduct_fullname: hello-ec2-uat-1\n```\n\nVariables defined in ```conf.yaml``` and ```project.yaml``` can be use in ```${MODULE}/module.yaml``` and templates.\n\nIf you want to see the exact value used in the templates:\nUSE ```inspect``` command.\n\n```\n$ agc inspect --conf conf_uat.yaml\n```\n\nOutput would be:\n```\nwith [conf=conf_uat.yaml]\n[conf]\nname: uat\nnetenv: uat\nnumber: 1\n\n\n[project]\ninstance_type:\n  perf: m3.large\n  prod: m3.medium\n  uat: t2.micro\nproduct_fullname: hello-ec2-uat-1\n\n\n[cfn]\nimage_id: ami-d50773ef\ninstance_type: t2.micro\nkey_name: my-key\nnetenv: uat\nsubnet_id:\n  prod: subnet-prodsubnet\n  uat: subnet-uatsubnet\nsubnet_security_groups:\n  prod:\n  - sg-prod1\n  - sg-prod2\n  uat:\n  - sg-uat1\n  - sg-uat2\nsubnet_sg_group: front\ntags:\n- Key: Name\n  Value: hello-ec2-uat-1\n- Key: Environment\n  Value: uat\n```\n\n### 3. Create a config build.\n\nRun follow command will generate a build. \nYou must provide the conf file with ```--conf```, so that command tool knows which conf file to use.\n\n```\nagc build --conf conf_uat.yaml\n```\n\nIt will generate a new folder in ```_builds/{conf.name}/{conf.number}```.\n\nIf the content inside ```conf_uat.yaml``` is following:\n\n```yaml\nname: uat\nnetenv: uat   # will deploy to uat subnets\nnumber: 1\n```\n\nYou would have a folder ```_builds/uat/1``` with following layout:\n\n```\ncfn/             # all are from cfn/*.tpl\n\t0_userdata.sh\n\tec2.json\n\tmodule.yaml\ncreate_stack.sh  # compiled from _script/create_stack.sh.tpl\nkill_stack.sh    # compiled from _script/kill_stack.sh.tpl\n```\n\n### 4. filters\n\n[agile_conf](https://github.com/tly1980/agile_conf) built-in jinja2 filters.\n\n\nHere is the example of ```aws_userdata``` filter from the ```single_ec2``` boilplate project.\n\n```bash\necho \"hello world\"\necho \"This is [{{conf.name}}-{{conf.number}}] for project: {{project.product_fullname}}\"\n```\n\nIt would be rendered into:\n```bash\necho \"hello world\"\necho \"This is [uat-1] for project: hello-ec2-uat-1\"\n```\n\nIn ```ec2.json.tpl``` we have a following code. \n\n```\n\"UserData\": {{ [_BUILD_DST_FOLDER, \"0_userdata.sh\"] |aws_userdata }},\n```\n\nIt is using a ```aws_userdata``` filter to turn ```0_userdata.sh``` into following code.\n\n```_BUILD_DST_FOLDER``` is the output destination folder of the module, exactly where the ```0_userdata.sh``` located.\n\nAnd you can see the shell script is rendred into cloudformation json structure:\n\n```\n\"UserData\": {\n    \"Fn::Base64\": {\n        \"Fn::Join\": [\n            \"\",\n            [\n                \"echo \\\"hello world\\\"\\n\",\n                \"echo \\\"This is [uat-1] for project: hello-ec2-uat-1\\\"\\n\"\n            ]\n        ]\n    }\n},\n```\n\nAnother filter is ```jsonify```.\n\nIn ```cfn/module.yaml```, tags are defined in following value:\n\n```yaml\ntags:\n  - Key: Name\n    Value: {{ project.product_fullname }}\n  - Key: Environment\n    Value: {{ conf.netenv }}\n```\n\nIn ```cfn/ec2.json.tpl```, it is how ```tags``` being used:\n\n```\n\"Tags\": {{ tags|jsonify }}\n```\n\nIt would be rendered into following:\n\n```\n\"Tags\": [\n\t\t{\"Key\": \"Name\", \"Value\": \"hello-ec2-uat-1\"},\n\t\t{\"Key\": \"Environment\", \"Value\": \"uat\"}\n\t]\n```\n\n### Commands\n\n**Command: build**\n\nCompile the variables into \n\n\n```\nagc build --conf conf_xxx.yaml\n```\n\n**Command: inspect**\n\nPrint out all the variables, would be very useful for debugging\n\n```\nagc inspect --conf conf_xxx.yaml\n```\n\n**Command: inspect**\n\n\n```\nagc inspect --conf conf_xxx.yaml\n```\n\n**Shortcut: using**\n\nIf you put following shell script in your BASH rc file,  \n\n```bash\nusing() {\n    envcmd=\"env AGC_CONF=conf_$1.yaml\"\n    shift\n    actual_cmd=\"$@\"\n    $envcmd $actual_cmd\n}\n```\n\nyou will have a very convinient short cut to switch different conf_xxx.yaml.\n\n\n```\nusing uat agc inspect\n```\n\n```\nusing uat agc build\n```\n\nIt is particular useful to do it with Makefile.\n\nSupposed you have following a Makefile.\n\n```Makefile\nbuild_uat:\n\tagc build --conf conf_uat.yaml\n\nbuild_prod:\n\tagc build --conf conf_prod.yaml\n\nbuild_perf:\n\tagc build --conf conf_prod.yaml\n\n```\n\nWith shortcut ```using```, you could have a Makefile like following:\n\n```Makefile\nbuild_uat:\n\tagc build\n```\n\nSo you can switch between different conf_xxx.yaml by:\n\n\n1. ```using uat make build```\n2. ```using prod make build```\n3. ```using perf make build```\n\n**PS**: ```using``` can work with all the command with ```--conf``` options.\n\n**Command: create**\n\nTo create a project from boilerplate repository.\n\n```\nagc create ${bo_name} ${project}\n```\n\nBefore you run this command, you should set enviornment variable ```AGC_BOIL```,  \nor use it with ```--bo_repo``` with it.\n\n> --bo_repo or AGC_BOIL can only be set to point to a local path. \n> You cannot put it GIT/HTTP URL to it, yet ... :)\n\n\n**Command: id**\n\n```agc id --conf conf_uat.yaml``` or ```using uat agc id```\n\nWill output:\n\n```{conf_name}/{conf_number}```\n\n**Command: where**\n```agc id --conf conf_uat.yaml``` or ```using uat agc where```\n\nWill output the exact location where the build is gonna to be.\n\ne.g.:\n```\n$ using uat agc where\n/Users/minddriven/workspace/play_agile_conf/my_ec2/_builds/uat/1\n```",
        "url": "http://pypi.python.org/pypi/agile_conf",
        "summary": "A config files (in [YAML](http://yaml.org) format) and template engine ([Jinja2](http://jinja.pocoo.org)) based configuration compile / management tool to make DevOp tasks",
        "command": "pip install 'agile_conf'"
      },
      "agilegeo": {
        "name": "agilegeo",
        "description": "===========\nagilegeo\n===========\n\n.. image:: https://travis-ci.org/agile-geoscience/agilegeo.png?branch=master\n    :target: https://travis-ci.org/agile-geoscience/agilegeo\n    :alt: Build\n\n.. image:: https://www.codacy.com/project/badge/f445542bc50e48c18a0d0e15a2768eb7\n    :target: https://www.codacy.com/public/matt/agilegeo\n    :alt: Codacy\n\n.. image:: https://img.shields.io/badge/license-Apache-blue.svg\n    :target: https://github.com/agile-geoscience/modelr/blob/develop/LICENSE.md\n    :alt: Apache 2 license\n\n.. image:: http://img.shields.io/pypi/dw/agilegeo.svg\n    :target: http://pypi.python.org/pypi/agilegeo/\n    :alt: PyPI downloads\n    \n.. image:: https://img.shields.io/pypi/v/agilegeo.svg\n    :target: http://pypi.python.org/pypi/agilegeo/\n    :alt: PyPI version\n    \n.. image:: http://img.shields.io/github/issues/badges/agilegeo.svg\n    :target: https://github.com/agile-geoscience/agilegeo\n    :alt: GitHub issues\n\n.. line-block::\n   The agilegeo module contains several common geophysics functions \n   used for modelling and post-processing seismic reflection data.\n\nPrerequisites\n++++++++++++++++\nRequires scipy and numpy.\n\nContributors\n++++++++++++\n* Evan Bianco\n* Ben Bougher\n* Matt Hall\n* Wes Hamlyn, and Sean Ross-Ross\n\nLinks\n+++++++\n* `Agile Geoscience <http://www.agilegeoscience.com>`_\n* `Homepage <http://agile-geoscience.github.com/agilegeo/>`_\n* `Issue Tracker <https://github.com/agile-geoscience/agilegeo/issues/>`_\n* `PyPi <http://pypi.python.org/pypi/agilegeo/>`_\n* `Github <https://github.com/agile-geoscience/agilegeo>`_",
        "url": "http://pypi.python.org/pypi/agilegeo",
        "summary": "Useful geophysics functions",
        "command": "pip install 'agilegeo'"
      },
      "agileid": {
        "name": "agileid",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/agileid",
        "summary": "Generate and manage AgileID identifiers",
        "command": "pip install 'agileid'"
      },
      "aglar": {
        "name": "aglar",
        "description": "",
        "url": "http://pypi.python.org/pypi/aglar",
        "summary": "Standalone graphical agar.io Python client using OpenGL",
        "command": "pip install 'aglar'"
      },
      "Aglyph": {
        "name": "aglyph",
        "description": "Aglyph is a Dependency Injection framework for Python 2.7+, supporting\r\ntype 2 (setter) and type 3 (constructor) injection.\r\n\r\nAglyph runs on CPython (http://www.python.org/) 2.7 and 3.1 - 3.4, and on\r\nrecent versions of the PyPy (http://pypy.org/>),\r\nJython (http://www.jython.org/), IronPython (http://ironpython.net/),\r\nand Stackless Python (http://www.stackless.com/) variants.\r\n\r\nAglyph can assemble \"prototype\" components (a new instance is created\r\nevery time), \"singleton\" components (the same instance is returned every\r\ntime), \"borg\" components (a new instance is created every time, but all\r\ninstances of the same class share the same internal state), and \"weakref\"\r\ncomponents (the same instance is returned as long as there is at least one\r\n\"live\" reference to the instance in the running application).\r\n\r\nAglyph can be configured using a declarative XML syntax, or\r\nprogrammatically in pure Python.",
        "url": "http://pypi.python.org/pypi/Aglyph",
        "summary": "Aglyph is a Dependency Injection framework for Python 2.7+, supporting type 2 (setter) and type 3 (constructor) injection.",
        "command": "pip install 'Aglyph'"
      },
      "agms": {
        "name": "agms",
        "description": "Agms Python Library for Payment Gateway",
        "url": "http://pypi.python.org/pypi/agms",
        "summary": "Agms Python Library",
        "command": "pip install 'agms'"
      },
      "Agner": {
        "name": "agner",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Agner",
        "summary": "simple data-only queueing system backed by Redis",
        "command": "pip install 'Agner'"
      },
      "agnos": {
        "name": "agnos",
        "description": "Agnos - The Agnostic RPC Framework\n==================================\n\n*Agnos* is a **cross-language**, **cross-platform**, lightweight RPC framework\nwith support for passing objects *by-value* or *by-reference*. Agnos is meant\nto allow programs written in different languages to easily interoperate,\nby providing the needed bindings (glue-code) and hiding all the details from\nthe programmer. The project essentially servers the same purpose as existing\ntechnologies like ``SOAP``, ``WSDL``, ``CORBA``, and others, but takes a\n**minimalist approach** to the issue at hand.",
        "url": "http://pypi.python.org/pypi/agnos",
        "summary": "Agnos Python Libraries",
        "command": "pip install 'agnos'"
      },
      "agnos_compiler": {
        "name": "agnos_compiler",
        "description": "Agnos - The Agnostic RPC Framework\n==================================\n\n*Agnos* is a **cross-language**, **cross-platform**, lightweight RPC framework\nwith support for passing objects *by-value* or *by-reference*. Agnos is meant\nto allow programs written in different languages to easily interoperate,\nby providing the needed bindings (glue-code) and hiding all the details from\nthe programmer. The project essentially servers the same purpose as existing\ntechnologies like ``SOAP``, ``WSDL``, ``CORBA``, and others, but takes a\n**minimalist approach** to the issue at hand.",
        "url": "http://pypi.python.org/pypi/agnos_compiler",
        "summary": "Agnos Compiler Toolchain",
        "command": "pip install 'agnos_compiler'"
      },
      "agnostic": {
        "name": "agnostic",
        "description": "Agnostic Database Migrations\n============================\n\nOverview\n--------\n\nAgnostic is a light-weight, easy-to-learn, and flexible database migration tool\nin which migration scripts are written in pure SQL. It is agnostic towards\ndatabase, programming language, and object relational mapper (ORM).\n\nSuper Quick Start\n-----------------\n\nHere is an absurdly brief introduction to Agnostic:\n\n.. code:: bash\n\n    ~/myapp $ pip3 install agnostic # Notice: python3 only!\n    <snip>\n\n    ~/myapp $ mkdir migrations\n\n    ~/myapp $ agnostic -t postgres -u myuser -s myapp bootstrap\n    Migration table created.\n\n    ~/myapp $ cat > migrations/add_cell_phone.sql\n    ALTER TABLE customer ADD cell_phone VARCHAR(255);\n    ^D\n\n    ~/myapp $ cat > migrations/add_nickname.sql\n    ALTER TABLE customer ADD nickname VARCHAR(255);\n    ^D\n\n    ~/myapp $ agnostic -t postgres -u myuser -s myapp migrate\n    Backing up schema \"myapp\" to \"/tmp/tmpm8glpgaa\".\n    About to run 2 migrations in schema \"myapp\":\n     * Running migration add_cell_phone (1/2)\n     * Running migration add_nickname (2/2)\n    Migrations completed successfully.\n    Removing backup \"/tmp/tmpm8glpgaa\".\n\nFor a not-quite-as-quick-but-still-pretty-quick start, please refer to the\n`full documentation <http://agnostic.readthedocs.org/en/latest/index.html>`_.\n",
        "url": "http://pypi.python.org/pypi/agnostic",
        "summary": "Agnostic Database Migrations",
        "command": "pip install 'agnostic'"
      },
      "agn_periodics": {
        "name": "agn_periodics",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/agn_periodics",
        "summary": "Some statistical functions for searchin periods in time rows",
        "command": "pip install 'agn_periodics'"
      },
      "ago": {
        "name": "ago",
        "description": "What are human readable timedeltas? \n===============================================\n\nago.py makes customizable human readable timedeltas, for example:\n\nTesting past tense::\n\n Russell commented 1 year, 127 days, 16 hours ago\n You replied 1 year, 127 days ago\n\nTesting future tense::\n\n Program will shutdown in 2 days, 3 hours, 27 minutes\n Job will run 2 days, 3 hours from now\n\n\nHow to install\n===================\n\nThere are a number of ways to install this package::\n\n easy_install ago\n\n pip install ago\n\nor specify *ago* under the *setup_requires* list within your\n*setuptools*-compatible project's *setup.py* file.\n\n\nHow to use\n==================\n\nThe ago module comes with two functions: \n\n#. human\n#. delta2dict\n\nYou really only need to worry about *human*.\n\nHere are all the available arguments and defaults::\n\n human(dt, precision=2, past_tense='{} ago', future_tense='in {}'):\n\ndt\n either a datetime or timedelta object to become human readable, required\n\nprecision\n control how verbose the output should look, optional\n\npast_tense\n format string used when dt is a past datetime, optional\n\nfuture_tense\n format string used when dt is a future datetime, optional\n\n\nHere is an example on how to use *human*::\n\n from ago import human\n from ago import delta2dict\n \n from datetime import datetime\n from datetime import timedelta\n\n # pretend this was stored in database\n db_date = datetime( \n   year = 2010, \n   month=5, \n   day=4, \n   hour=6, \n   minute=54, \n   second=33, \n   microsecond=4000\n  )\n\n # to find out how long ago, use the human function\n print 'Created ' + human( db_date )\n \n # optionally pass a precision\n print 'Created ' + human( db_date, 3 )\n print 'Created ' + human( db_date, 6 )\n\nWe also support future dates and times::\n\n PRESENT = datetime.now()\n PAST = PRESENT - timedelta( 492, 58711, 45 ) # days, secs, ms\n FUTURE = PRESENT + timedelta( 2, 12447, 963 ) # days, secs, ms\n\n print human( FUTURE )\n\nExample past_tense and future_tense keyword arguments::\n\n output1 = human( PAST,\n   past_tense = 'titanic sunk {0} ago',\n   future_tense = 'titanic will sink in {0} from now'\n )\n\n output2 = human( FUTURE,\n   past_tense = 'titanic sunk {0} ago',\n   future_tense = 'titanic will sink in {0} from now'\n )\n\n print output1\n # titanic sunk 1 year, 127 days ago\n print output2\n # titanic will sink in 2 days, 3 hours from now\n\nNow we will document how to use delta2dict::\n\n # subtract two datetime objects for a timedelta object\n delta = PRESENT - db_date\n\n # create a dictionary of units out of the timedelta\n print delta2dict( delta )\n\n\nNeed more examples?\n==========================\n\nYou should look at test_ago.py\n\n\nHow do I thank you?\n==========================\n\nYou should follow me on twitter http://twitter.com/russellbal\n\n\nLicense\n=========================\n\nPublic Domain\n\n\nPublic Revision Control\n==============================\n\nhttps://bitbucket.org/russellballestrini/ago",
        "url": "http://pypi.python.org/pypi/ago",
        "summary": "ago: Human readable timedeltas",
        "command": "pip install 'ago'"
      },
      "agon": {
        "name": "agon",
        "description": "===========\nagon README\n===========\n\nagon provides the ability to track points on arbitrary objects in your system.\nThe common case being ``User`` instances. It can additionally keep track of\npositions for these objects to produce leaderboards.\n\nThis code has mostly been pulled out of `typewar`_ and made slightly more\ngeneric to work well.\n\n.. _typewar: http://typewar.com/\n\n\nRequirements\n============\n\nThis app requires the use of Django 1.1+.",
        "url": "http://pypi.python.org/pypi/agon",
        "summary": "a reusable Django points, positions and levels application",
        "command": "pip install 'agon'"
      },
      "agon-ratings": {
        "name": "agon-ratings",
        "description": "agon-ratings\n============\n\nProvides user ratings of objects.\n\n\nDocumentation\n-------------\n\nDocumentation can be found online at http://agon-ratings.readthedocs.org/.",
        "url": "http://pypi.python.org/pypi/agon-ratings",
        "summary": "a user ratings app",
        "command": "pip install 'agon-ratings'"
      },
      "agora": {
        "name": "agora",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/agora",
        "summary": "A portfolio and risk management system based on onyx.",
        "command": "pip install 'agora'"
      },
      "agora.bloomberg": {
        "name": "agora.bloomberg",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/agora.bloomberg",
        "summary": "Bloomberg datafeed library for agora",
        "command": "pip install 'agora.bloomberg'"
      },
      "Agora-Client": {
        "name": "agora-client",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Agora-Client",
        "summary": "An Agora client for Python that requests and executes search plans for graph patterns",
        "command": "pip install 'Agora-Client'"
      },
      "Agora-Fountain": {
        "name": "agora-fountain",
        "description": "Agora-Fountain\n==============\n\nThe Agora core service for ontology paths discovery and seed management.\n\nAgora-Fountain is distributed under the Apache License, version 2.0.\n\n## Build Status\n\n[![Build Status](https://travis-ci.org/SmartDeveloperHub/agora-fountain.svg?branch=master)](https://travis-ci.org/SmartDeveloperHub/agora-fountain)\n[![Coverage Status](https://coveralls.io/repos/SmartDeveloperHub/agora-fountain/badge.svg?branch=master&service=github)](https://coveralls.io/github/SmartDeveloperHub/agora-fountain?branch=master)",
        "url": "http://pypi.python.org/pypi/Agora-Fountain",
        "summary": "The Agora core service for ontology paths discovery and seed management",
        "command": "pip install 'Agora-Fountain'"
      },
      "Agora-Fragment": {
        "name": "agora-fragment",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Agora-Fragment",
        "summary": "An Agora service that collects fragments for graph patterns",
        "command": "pip install 'Agora-Fragment'"
      },
      "Agora-Planner": {
        "name": "agora-planner",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Agora-Planner",
        "summary": "The Agora core service that provides search plans for graph patterns.",
        "command": "pip install 'Agora-Planner'"
      },
      "agoraplex.themes.sphinx": {
        "name": "agoraplex.themes.sphinx",
        "description": "==================================================================\n `Agoraplex Sphinx Theme <https://github.com/agoraplex/themes>`__\n==================================================================\n\nAbout\n=====\n\nThis repository contains `Sphinx`_ themes for `Agoraplex`_ projects,\nbased on the `Pylons Sphinx Themes`_, and some helper roles. The\nfollowing themes exist:\n\n- **agoraplex** - the generic `Agoraplex`_ documentation theme\n\n.. _Sphinx: http://sphinx-doc.org/\n.. _Agoraplex: http://agoraplex.github.com/\n.. _Pylons Sphinx Themes: https://github.com/Pylons/pylons_sphinx_theme\n\n\nRequirements\n------------\n\n- `Sphinx`_ 1.1 or newer\n\nTo rebuild the graphics from the SVG originals (which requires cloning\nthe `github repository <https://github.com/agoraplex/themes>`__):\n\n- ``rsvg-convert`` from `librsvg`_\n\n- ``pngtopam``, ``pnmremap``, ``pnmcolormap``, and ``pnmtopng`` from\n  `Netpbm`_\n\n- ``icotool`` from `icoutils`_\n\n.. _librsvg: http://live.gnome.org/LibRsvg\n.. _Netpbm: http://netpbm.sourceforge.net/\n.. _icoutils: http://www.nongnu.org/icoutils/\n\n\nInstallation\n------------\n\nTo use a theme in your Sphinx documentation, follow this guide:\n\n1. Install the package::\n\n    $ pip install agoraplex.themes.sphinx\n\n2. Edit your ``conf.py`` doc configuration file to point to the\n   `agoraplex` theme::\n\n       import agoraplex.themes.sphinx\n\n       # ...\n\n       html_theme = 'agoraplex'\n       html_theme_path = agoraplex.themes.sphinx.get_html_theme_path()\n\n\nHelpers\n-------\n\nThis package adds several Sphinx helper roles (in ``roles.py``). To\nuse these, add ``agoraplex.themes.sphinx.roles`` to the ``extensions``\nlist in your ``conf.py``.\n\nThe roles are:\n\n- ``github``: link to a github_ project::\n\n    :github:`agoraplex/themes`\n\n  The ``github_url`` configuration directive defaults to\n  ``https://github.com/``.\n\n- ``pypi``: link to a project record at `PyPi, the Python Package\n  Index <http://pypi.python.org/>`__::\n\n    :pypi:`agoraplex.themes.sphinx`\n\n  The ``pypi_url`` configuration directive defaults to\n  ``http://pypi.python.org/pypi/``\n\n- ``wikipedia``: link to a `Wikipedia`_ article::\n\n    :wikipedia:`Ancient Agora of Athens`\n\n  The ``wikipedia_url`` and ``wikipedia_lang`` configuration\n  directives default to ``http://%s.wikipedia.org/wiki/`` and\n  ``en``, respectively. Note that the ``wikipedia_url`` directive\n  **must** contain a ``%s``, where the role will insert the\n  ``wikipedia_lang`` value.\n\n  The ``wikipedia`` role will (mostly) canonicalize an article\n  name by replacing spaces with underscores (``_``), uppercasing\n  the first letter of the name, and lowercasing the\n  rest. Wikipedia's own URL rewriting is tolerant of case\n  mismatch, so these simplistic rules work well enough.\n\n.. _github: https://github.com/\n.. _Wikipedia: http://wikipedia.org/\n\n\nConfiguration\n-------------\n\nIn addition to the role-related configuration directives, this theme\nadds the following directives to the set defined by the original\nPylons theme:\n\n- ``fontsets``: a space-separated list of directory names, relative to\n  the `font directory`_ (``_static/fonts``), from which to load a\n  ``stylesheet.css`` file containing ``@font-face`` directives.\n\n- ``font_body``, ``font_header``: the 'base' names of the fonts to use\n  for body and header text, respectively.\n\n.. note::\n\n   The stylesheets assume that the font family is actually named\n   ``<fontname>Regular``. So, to use `NeutonRegular` as the header\n   font (which is the default), ``theme.conf`` would specify\n   ``font_header=Neuton``.\n\n.. _font directory: https://github.com/agoraplex/themes/blob/master/sphinx/agoraplex/static/fonts",
        "url": "http://pypi.python.org/pypi/agoraplex.themes.sphinx",
        "summary": "A Sphinx theme for Agoraplex projects, based on the Pylons Sphinx theme",
        "command": "pip install 'agoraplex.themes.sphinx'"
      },
      "Agora-Service-Provider": {
        "name": "agora-service-provider",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Agora-Service-Provider",
        "summary": "A library for making web services built on the Agora",
        "command": "pip install 'Agora-Service-Provider'"
      },
      "agpy": {
        "name": "agpy",
        "description": "A collection of astronomy-related tools.  Please see the `package documentation <http://packages.python.org/agpy>`_.\n\n\nCHANGES\n*******\n\nRelease 0.1.3\n~~~~~~~~~~~~~\n    Version, manifest fixes.\n\nRelease 0.1.2\n~~~~~~~~~~~~~\n    Bugfix.  Imports should now work\n\nRelease 0.1.1\n~~~~~~~~~~~~~\n    First pypi release.  Made mpfit an agpy subpackage",
        "url": "http://pypi.python.org/pypi/agpy",
        "summary": "agpy, Adam Ginsburg's Python Code (in 0.1 for perpetuity - it won't bump up until I release something)",
        "command": "pip install 'agpy'"
      },
      "Agree": {
        "name": "agree",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Agree",
        "summary": "Simple argument resolution.",
        "command": "pip install 'Agree'"
      },
      "agrimpy": {
        "name": "agrimpy",
        "description": "=======\nagrimpy\n=======\n\n**agrimpy** utiliza pyproj para hacer algunas opreaciones con coordenadas geodésicas.\n\nInstalación\n===========\n\nEjecutar en la terminal::\n\n    $ sudo pip install agrimpy\n\nUso\n====\n\nVer archivo ``test.py`` con ejemplos.\n\nTo do\n=====\n\n- ...\n- ayudame con un pull-request en https://github.com/quijot/agrimpy-package\n\nAutor\n=====\n\n* Santiago Pestarini <santiagonob@gmail.com>\n\nLicencia\n========\n\n**agrimpy** is licensed under the *MIT License*. See the LICENSE file.",
        "url": "http://pypi.python.org/pypi/agrimpy",
        "summary": "Algunas operaciones con coordenadas geodésicas.",
        "command": "pip install 'agrimpy'"
      },
      "agsci.blognewsletter": {
        "name": "agsci.blognewsletter",
        "description": "Description\n\nA Blog/Newsletter product which is distilled from multiple PSU AgSci \nproducts.\n\nChangelog\n=========\n\n0.1 (Unreleased)\n----------------\nInitial version\n\n\n0.4 (PSE2012)\n-------------\n\n * Added tests\n * Fixed JavaScript in IE",
        "url": "http://pypi.python.org/pypi/agsci.blognewsletter",
        "summary": "Plone blog/newsletter package based on the PSU AgSci products.",
        "command": "pip install 'agsci.blognewsletter'"
      },
      "agssearch": {
        "name": "agssearch",
        "description": "agssearch\n=========\n\nPython client for the official German directory of cities by DeStatis,\ncalled \"`Gemeindeverzeichnis <https://www.destatis.de/gv/>`_\\ \". Allows\nyou to look up the official city key (\"Amtlicher Gemeindeschluessel\", in\nbrief: AGS) for a city name and vice versa.\n\nNote that the AGS is still in common use, but to be replaced by the\n\"Regionalschluessel\" (RS). Read more in the German Wikipedia page\n`Amtlicher\nGemeindeschluessel <http://de.wikipedia.org/wiki/Amtlicher_Gemeindeschl%C3%BCssel>`_.\n\nInstall\n-------\n\n::\n\n    pip install agssearch\n\nUse in your code\n----------------\n\nFinding the AGS for a city:\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    >>> import agssearch.agssearch as ags\n    >>> result = ags.search(\"Bonn\")\n    >>> for r in result:\n    >>>     print r['ags'], r['name']\n\n    05314000 Stadt Bonn\n    08337022 VVG der Stadt Bonndorf im Schwarzwald\n    08337022 Stadt Bonndorf im Schwarzwald\n\nLook up an AGS:\n~~~~~~~~~~~~~~~\n\n::\n\n    >>> import agssearch.agssearch as ags\n    >>> result = ags.lookup(\"05314000\")\n    >>> if result is not None:\n    >>>     print result['ags'], result['name']\n\n    05314000 Stadt Bonn\n\nUse as command line client\n--------------------------\n\n::\n\n    $ agssearch Bonn\n    [05314000] Stadt Bonn, Bonn, Stadt, Nordrhein-Westfalen\n    [08337022] VVG der Stadt Bonndorf im Schwarzwald, Waldshut, Baden-Wuerttemberg\n    [08337022] Stadt Bonndorf im Schwarzwald, Waldshut, Baden-Wuerttemberg\n\n    $ agssearch 05314000\n    [05314000] Stadt Bonn, Bonn, Stadt, Nordrhein-Westfalen\n\nLike agssearch?\n---------------\n\nFeel free to `tip me <https://www.gittip.com/marians/>`_!",
        "url": "http://pypi.python.org/pypi/agssearch",
        "summary": "Python client for the German Destatis Gemeindeverzeichnis",
        "command": "pip install 'agssearch'"
      },
      "ags_tool_deploy": {
        "name": "ags_tool_deploy",
        "description": "Overview\r\n--------\r\n\r\nThis tool provides a command-line interface for packaging and publishing\r\npython toolboxes to ArcGIS Server (10.2.x).\r\n\r\nInstallation\r\n------------\r\n\r\nTo install the latest stable version:\r\n\r\n::\r\n\r\n    pip install python-ags\r\n\r\nLatest changes:\r\n\r\n::\r\n\r\n    pip install https://bitbucket.org/databasin/ags_tool_deploy/get/develop.zip#egg=ags_tool_deploy\r\n\r\n*Installing manually:*\r\n\r\nDownload the latest changes from the `develop\r\nbranch <https://bitbucket.org/databasin/ags_tool_deploy/get/develop.zip>`__,\r\nextract, and execute\r\n\r\n::\r\n\r\n    python setup.py install\r\n\r\nThis will install the script to your local python packages folder as\r\n\r\n::\r\n\r\n    ags_tool_deploy/deploy.py\r\n\r\nConsider adding this folder to your PATH.\r\n\r\nUsage\r\n-----\r\n\r\nThis tool is intended to be run from within a console.\r\n\r\nFor information on usage, simply run\r\n\r\n::\r\n\r\n    python deploy.py --help\r\n\r\nThe commands below allow you to include Mercurial repository\r\ninformation. This does not bundle the full repository, but instead\r\nincludes the link to the source repository and current branch, so that\r\nyou can run\r\n\r\n::\r\n\r\n    hg pull --update\r\n\r\non the server to pull down the full repository.\r\n\r\nPackaging\r\n~~~~~~~~~\r\n\r\nUse the ``package`` command to bundle your python toolbox into a service\r\ndefinition (\\*.sd) file.\r\n\r\n::\r\n\r\n    Usage: deploy.py package [OPTIONS] <toolbox_path> <service_name> <outfile_name>\r\n\r\n    Package a python toolbox into a service definition file (*.sd). Local\r\n    python modules this toolbox references are included automatically.\r\n    Requires 7Zip to be installed and on the system PATH.\r\n\r\n    WARNING: this will overwrite the file <outfile_name> if it already exists.\r\n\r\n      Aguments:\r\n      <toolbox_path>:         Filename of python toolbox (*.pyt) to deploy\r\n      <service_name>:         Name of service, including folder(s).  Example: SomeFolder/MyTool\r\n      <outfile>:              Name of the service definition file to create\r\n\r\n    Options:\r\n      --files <files>                 Wildcard patterns of additional files to\r\n                                      include (relative to toolbox).  Example:\r\n                                      *.csv,some_data.*\r\n      --hg                            Include Mercurial (hg) repository \r\n                                      information?                                  \r\n      --sync                          Execute tool synchronously instead of\r\n                                      asynchronously (default)\r\n      --messages [None|Info|Error|Warning]\r\n                                      Level of messaging for service\r\n      --help                          Show this message and exit.\r\n\r\nPublishing\r\n~~~~~~~~~~\r\n\r\nUse the ``publish`` command to deploy your python toolbox to an ArcGIS\r\nserver.\r\n\r\n::\r\n\r\n    Usage: deploy.py publish [OPTIONS] <toolbox_path> <service_name> <server:port> <user>\r\n\r\n    Publish a python toolbox to an ArcGIS server. Local python modules this\r\n    toolbox references are included automatically. Requires 7Zip to be\r\n    installed and on the system PATH.\r\n\r\n      Aguments:\r\n      <toolbox_path>:         Filename of python toolbox (*.pyt) to deploy\r\n      <service_name>:         Name of service, including folder(s).  Example: SomeFolder/MyTool\r\n      <server:port>:               Hostname and port number of ArcGIS server\r\n      <user>:                 ArcGIS server administrator user name\r\n\r\n    Options:\r\n      --password <password>           ArcGIS administrator password.  You will be\r\n                                      prompted for this if you do not provide it\r\n      --files <files>                 Wildcard patterns of additional files to\r\n                                      include (relative to toolbox).  Example:\r\n                                      *.csv,some_data.*\r\n      --hg                            Include Mercurial (hg) repository \r\n                                      information?                                  \r\n      --sync                          Execute tool synchronously instead of\r\n                                      asynchronously (default)\r\n      --messages [None|Info|Error|Warning]\r\n                                      Level of messaging for service\r\n      --overwrite                     Delete and replace the service, if it\r\n                                      already exists?\r\n      --help                          Show this message and exit.\r\n\r\nRequirements:\r\n-------------\r\n\r\n-  lxml\r\n-  click\r\n-  ags (from: https://bitbucket.org/databasin/python-ags)\r\n-  7Zip: must be installed manually from `7Zip\r\n   website <http://www.7-zip.org/>`__\r\n\r\nAssumptions\r\n-----------\r\n\r\n-  only Python 2.7 is supported\r\n-  only tested on Windows\r\n-  only ArcGIS 10.2.x is supported\r\n\r\nLicense\r\n-------\r\n\r\nSee LICENSE file.",
        "url": "http://pypi.python.org/pypi/ags_tool_deploy",
        "summary": "Provides packaging and publishing tools for ArcGIS python toolboxes",
        "command": "pip install 'ags_tool_deploy'"
      },
      "agtl": {
        "name": "agtl",
        "description": "AGTL, the all-in-one solution for on- and offline geocaching, makes geocaching paperless! \nIt downloads geocaches including their description, hints, difficulty levels and images. No premium account needed. Searching for caches in your local db is a matter of seconds.\n.\n- Map view - supporting Open Street Maps and Open Cycle Maps by default, configurable for other map types, including google maps.\n- GPS view - shows the distance and direction to the selected geocache.\n- Cache details - all necessary details are available even in offline mode.\n- Paperless geocaching features - take notes for a geocache on the go, see the hints and spoiler images, check the latest logs.\n- Multicache calculation help - Let your phone do the math for you. Working for the most multi-stage geocaches, AGTL finds the coordinate calculations and let you enter the missing variables. (N900 only)\n- Fieldnotes support - Ever came home after a long tour and asked yourself which geocaches you found? Never again: Log your find in the field and upload notes and log text when you're at home. Review them on the geocaching website and post the logs.\n- Text-to-Speech-Feature! - Select a target, activate TTS and put your headphones on to enjoy completely stealth geocaching. (N900 only)\n- Download map tiles for selected zoom levels - for offline use.\n- Advanced waypoint handling - AGTL finds waypoints in the geocache descriptions, in the list of waypoints and even in your notes. For your convenience, they're displayed on the map as well - see where you have to go next.\n- Search for places - in the geonames.org database to navigate quickly. (N900 only)\n- Sun compass - Compensates the lack of a magnetic compass. (N900 only)\n- Instant update feature - Follow web site updates as soon as possible.\n.\nAGTL is Open source and in active development.",
        "url": "http://pypi.python.org/pypi/agtl",
        "summary": "Towards paperless geocaching",
        "command": "pip install 'agtl'"
      },
      "agvc_nester": {
        "name": "agvc_nester",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/agvc_nester",
        "summary": "A simple printer of nested lists",
        "command": "pip install 'agvc_nester'"
      },
      "agx.core": {
        "name": "agx.core",
        "description": "This Package is part of **AGX**. See `<http://agx.me>`_ for Details.\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a2\r\n-----\r\n\r\n- Fix version output of generator listing in ``IConfLoader.generators``.\r\n  [rnix, 2013-02-23]\r\n\r\n\r\n1.0a1\r\n-----\r\n\r\n- initial release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.core",
        "summary": "AGX tree transformation chain processor",
        "command": "pip install 'agx.core'"
      },
      "agx.dev": {
        "name": "agx.dev",
        "description": "=======\r\nagx.dev\r\n=======\r\n\r\nThis is the installation and development buildout for AGX.\r\n\r\nThis packages includes buildout configurations to use AGX for development, and\r\nto develop AGX itself.\r\n\r\nFull documentation is available `here <http://agx.me>`_.\r\n\r\n\r\nInstall for using AGX\r\n---------------------\r\n\r\nRun bootstrap.py::\r\n\r\n    python bootstrap.py --version 1.7\r\n\r\nAnd buildout::\r\n\r\n    ./bin/buildout\r\n\r\n\r\nInstall for developing AGX\r\n--------------------------\r\n\r\nRun bootstrap.py::\r\n\r\n    python bootstrap.py --version 1.7 -c dev.cfg\r\n\r\nAnd buildout::\r\n\r\n    ./bin/buildout -c dev.cfg\r\n\r\n\r\nRun Tests\r\n---------\r\n\r\nYou can run tests for a single package, e.g.::\r\n\r\n    bin/test agx.generator.pyegg\r\n\r\nOr test them all::\r\n\r\n   ./test.sh\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a1\r\n-----\r\n\r\n- Initial Release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.dev",
        "summary": "AGX development bundle",
        "command": "pip install 'agx.dev'"
      },
      "agx.generator.buildout": {
        "name": "agx.generator.buildout",
        "description": "This Package is part of **AGX**. See `<http://agx.me>`_ for Details.\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a1\r\n-----\r\n\r\n- initial release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.generator.buildout",
        "summary": "AGX generator for buildout",
        "command": "pip install 'agx.generator.buildout'"
      },
      "agx.generator.dexterity": {
        "name": "agx.generator.dexterity",
        "description": "This Package is part of **AGX**. See `<http://agx.me>`_ for Details.\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a1\r\n-----\r\n\r\n- initial release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.generator.dexterity",
        "summary": "AGX generator for dexterity",
        "command": "pip install 'agx.generator.dexterity'"
      },
      "agx.generator.generator": {
        "name": "agx.generator.generator",
        "description": "This Package is part of **AGX**. See `<http://agx.me>`_ for Details.\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a1\r\n-----\r\n\r\n- initial release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.generator.generator",
        "summary": "AGX generator for generators",
        "command": "pip install 'agx.generator.generator'"
      },
      "agx.generator.plone": {
        "name": "agx.generator.plone",
        "description": "This Package is part of **AGX**. See `<http://agx.me>`_ for Details.\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a1\r\n-----\r\n\r\n- initial release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.generator.plone",
        "summary": "AGX generator for plone products",
        "command": "pip install 'agx.generator.plone'"
      },
      "agx.generator.pyegg": {
        "name": "agx.generator.pyegg",
        "description": "This Package is part of **AGX**. See `<http://agx.me>`_ for Details.\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a1\r\n-----\r\n\r\n- initial release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.generator.pyegg",
        "summary": "AGX generator for python and python eggs",
        "command": "pip install 'agx.generator.pyegg'"
      },
      "agx.generator.sql": {
        "name": "agx.generator.sql",
        "description": "This Package is part of **AGX**. See `<http://agx.me>`_ for Details.\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a1\r\n-----\r\n\r\n- initial release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.generator.sql",
        "summary": "AGX generator for sqlalchemy",
        "command": "pip install 'agx.generator.sql'"
      },
      "agx.generator.uml": {
        "name": "agx.generator.uml",
        "description": "This Package is part of **AGX**. See `<http://agx.me>`_ for Details.\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a1\r\n-----\r\n\r\n- initial release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.generator.uml",
        "summary": "AGX generator for UML nodes",
        "command": "pip install 'agx.generator.uml'"
      },
      "agx.generator.zca": {
        "name": "agx.generator.zca",
        "description": "This Package is part of **AGX**. See `<http://agx.me>`_ for Details.\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a1\r\n-----\r\n\r\n- initial release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.generator.zca",
        "summary": "AGX generator for zope component architecture",
        "command": "pip install 'agx.generator.zca'"
      },
      "agx.transform.uml2fs": {
        "name": "agx.transform.uml2fs",
        "description": "This Package is part of **AGX**. See `<http://agx.me>`_ for Details.\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a1\r\n-----\r\n\r\n- initial release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.transform.uml2fs",
        "summary": "AGX UML to Filesystem Transform",
        "command": "pip install 'agx.transform.uml2fs'"
      },
      "agx.transform.xmi2uml": {
        "name": "agx.transform.xmi2uml",
        "description": "This Package is part of **AGX**. See `<http://agx.me>`_ for Details.\r\n\r\n\r\nIssues and Feedback\r\n-------------------\r\n\r\nFor reporting issues, please use tracker at\r\n``https://github.com/bluedynamics/agx.core/issues``.\r\n\r\nFor direct feedback or questions send an email to ``dev@agx.me``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n1.0a1\r\n-----\r\n\r\n- initial release\r\n\r\nLicense\r\n=======\r\n\r\nCopyright (c) 2010-2013, BlueDynamics Alliance, Austria\r\nAll rights reserved.\r\n\r\nRedistribution and use in source and binary forms, with or without\r\nmodification, are permitted provided that the following conditions are met:\r\n\r\n* Redistributions of source code must retain the above copyright notice, this \r\n  list of conditions and the following disclaimer.\r\n* Redistributions in binary form must reproduce the above copyright notice, this \r\n  list of conditions and the following disclaimer in the documentation and/or \r\n  other materials provided with the distribution.\r\n* Neither the name of the BlueDynamics Alliance nor the names of its \r\n  contributors may be used to endorse or promote products derived from this \r\n  software without specific prior written permission.\r\n      \r\nTHIS SOFTWARE IS PROVIDED BY BlueDynamics Alliance ``AS IS`` AND ANY\r\nEXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\nDISCLAIMED. IN NO EVENT SHALL BlueDynamics Alliance BE LIABLE FOR ANY\r\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/agx.transform.xmi2uml",
        "summary": "AGX XMI to UML Transform",
        "command": "pip install 'agx.transform.xmi2uml'"
      },
      "aha": {
        "name": "aha",
        "description": "Aha\n==================\nAha is a framework made specially for Google App Engine. Here are some quick instruction getting started with it. For more details, visit our website :-).\n\n  http://coreblog.org/aha\n\nOr you can get source code from the repository.\n\n  http://code.google.com/p/aha-gae/\n\nWhat is aha\n-----------------------\nAha is a web application framework. It has been developed hoping it will be the best way to propagate your 'aha!' into the cloud :-).\n\nAha has following features.\n\n- rails like routing\n- class base controller\n- mako template ( for speed ;-) )\n- db / query cache\n- form, field generation\n- plugins\n- development with buildout\n- easy to make admin/crud interface\n- interactive debug interface using werkzeug\n- appstats integration\n- decorator based authentication mechanizm\n- plagable authentication mecanizm\n- i18n\n- DRY\n\n\nQuickstart\n-----------------------\nTo start playing with aha, download bootstrap from url bellow.\n\n  http://aha-gae.googlecode.com/files/project.zip\n\nAfter extracting the archive, move to the folder you'll get and just type\n\n  python bootstrap.py\n\nNext step is to launch buildout command. Make sure that you have internet connection, because it will download libraries via the internet.\n\n  bin/buildout\n\nThen, launch app in local development environment. All the stuff required to run application are under app directory. So you may give 'app' argument to the command.\n\n  bin/dev_appserver app\n\nNow it's time to visit your fiest aha application's screen :-). Type http://127.0.0.1:8080/ to see initial page of aha's default application.",
        "url": "http://pypi.python.org/pypi/aha",
        "summary": "aha is a web application framework specialized for Google App Engine.",
        "command": "pip install 'aha'"
      },
      "aha.application.coreblog3": {
        "name": "aha.application.coreblog3",
        "description": "A blog application works on Google App Engine.",
        "url": "http://pypi.python.org/pypi/aha.application.coreblog3",
        "summary": "A blog application workins on Google App Engine",
        "command": "pip install 'aha.application.coreblog3'"
      },
      "aha.application.default": {
        "name": "aha.application.default",
        "description": "A default appliction for aha framework. It has only simple controller and say 'aha :-)' .",
        "url": "http://pypi.python.org/pypi/aha.application.default",
        "summary": "An default application for aha framework.",
        "command": "pip install 'aha.application.default'"
      },
      "aha.application.microneimageboard": {
        "name": "aha.application.microneimageboard",
        "description": "A image bbs application that needs authenticate via twitter build on the top of microne.' .",
        "url": "http://pypi.python.org/pypi/aha.application.microneimageboard",
        "summary": "An image bbs application with twitter authentication.",
        "command": "pip install 'aha.application.microneimageboard'"
      },
      "ahab": {
        "name": "ahab",
        "description": "",
        "url": "http://pypi.python.org/pypi/ahab",
        "summary": "",
        "command": "pip install 'ahab'"
      },
      "aha.plugin.microne": {
        "name": "aha.plugin.microne",
        "description": "A plugin that makes aha framework work as microframework.",
        "url": "http://pypi.python.org/pypi/aha.plugin.microne",
        "summary": "Yet another microframework on the top of the full stack framework aha",
        "command": "pip install 'aha.plugin.microne'"
      },
      "aha.plugin.twitteroauth": {
        "name": "aha.plugin.twitteroauth",
        "description": "A plugin that ssupplies authentication support of twitter oauth.",
        "url": "http://pypi.python.org/pypi/aha.plugin.twitteroauth",
        "summary": "A twitter auth plugin for aha",
        "command": "pip install 'aha.plugin.twitteroauth'"
      },
      "aha.recipe.gae": {
        "name": "aha.recipe.gae",
        "description": "a buildout recipe for web application framework aha",
        "url": "http://pypi.python.org/pypi/aha.recipe.gae",
        "summary": "a buildout recipe for web application framework aha",
        "command": "pip install 'aha.recipe.gae'"
      },
      "ahc": {
        "name": "ahc",
        "description": "--------------------------------------------------------------\n                            ABOUT\n--------------------------------------------------------------\nPackage for control apache/nginx virtual hosts, mysql/ftp\nusers, bind zones, apache clients certificates on\ndeveloper/production web-hosts. Tested on\nUbuntu/Debian Linux.\nPublished under GNU GPL v.2.\n--------------------------------------------------------------\n\n##############################################################\n\n--------------------------------------------------------------\n                        INSTALLATION\n--------------------------------------------------------------\nApache Host Control:\n--------------------------------------------------------------\n    $ sudo -i\n    # apt-get update && apt-get upgrade -y\n    # apt-get install -y python-pip python-mysqldb python-flup git-core make python-pycurl\n    # cd /usr/src/ && git clone https://github.com/gotlium/ahc.git\n    # cd ahc/ && pip install -r requirements.txt && make install\n\nOR using pip:\n\n    # sudo pip install ahc\n\nAfter installation, you can install system packages and firewall:\n    # ahc -m install -s lamp\n    # ahc -m install -s firewall\n--------------------------------------------------------------\n\n##############################################################\n\n--------------------------------------------------------------\n                            USAGE\n--------------------------------------------------------------\nApache hosts:\n--------------------------------------------------------------\n# ahc -m install -s apache2_ssl\n# ahc -m test -s apache\n# ahc -m apache -t php -a example.com\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nNginx hosts:\n--------------------------------------------------------------\n# ahc -m install -s nginx_ssl\n# ahc -m test -s nginx\n# ahc -m nginx -t php -a example.com\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nFTP accounts:\n--------------------------------------------------------------\n# ahc -m install -s ftp\n# ahc -m test -s ftp\n# ahc -m ftp -a example.com -u User -p Password\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nMySQL accounts:\n--------------------------------------------------------------\n# ahc -m install -s mysql\n# ahc -m test -s mysql\n# ahc -m mysql -a example.com -u User -p Password\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nBind zone:\n--------------------------------------------------------------\n# ahc -m install -s bind\n# ahc -m test -s bind\n# ahc -m bind -a example.com -i 127.0.0.1\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nGit deployment:\n--------------------------------------------------------------\n# ahc -m test -s git\n# ahc -m git -a example.com\n# ahc -m git -d example.com\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nGit jail:\n--------------------------------------------------------------\nahc -m test -s git_jail\nahc -m git_jail -a mail@example.com -p 'TYPE KEY-STRING COMMENT'\nahc -m git_jail -d mail@example.com\nahc -m git_jail -l\nahc -m git_jail -i example.com -e templates -u mail@example.com\nahc -m git_jail -i example.com -f templates -u mail@example.com\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nProject Protection\n--------------------------------------------------------------\n# ahc -m test -s crypt\n# ahc -m crypt -a mount\n# ahc -m crypt -a umount\n--------------------------------------------------------------\n\n--------------------------------------------------------------\niRedMail\n--------------------------------------------------------------\n# ahc -m install -s mail\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nFirewall:\n--------------------------------------------------------------\n# ahc -m install -s firewall\n# iptables -L -n\n    or\n# cat /etc/init.d/rc.fw\n--------------------------------------------------------------\n\n##############################################################\n\n--------------------------------------------------------------\n                         EXAMPLES\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nApache2\n--------------------------------------------------------------\n# ahc -m apache -t php -a hostname -o -x\n# ahc -m apache -t php -d hostname\n# ahc -m apache -t php -e hostname\n# ahc -m apache -t php -f hostname\n# ahc -m apache -t php -l\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nNginx\n--------------------------------------------------------------\n# ahc -m nginx -t php -a hostname\n# ahc -m nginx -t php -d hostname\n# ahc -m nginx -t php -e hostname\n# ahc -m nginx -t php -f hostname\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nFTP\n--------------------------------------------------------------\n# ahc -m ftp -a hostname -u user -p password\n# ahc -m ftp -a hostname -u user -p random\n# ahc -m ftp -a hostname -u user -p password -f folder\n# ahc -m ftp -a hostname\n# ahc -m ftp -d hostname\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nMySQL\n--------------------------------------------------------------\n# ahc -m mysql -a hostname -u user -p password\n# ahc -m mysql -a hostname -u user -p random\n# ahc -m mysql -a hostname\n# ahc -m mysql -d hostname -u user\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nBind9\n--------------------------------------------------------------\n# ahc -m bind -a hostname -i ip-address\n# ahc -m bind -d hostname\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nBackups\n--------------------------------------------------------------\n# ahc -m backup -b mysql\n# ahc -m backup -b site\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nTests\n--------------------------------------------------------------\n# ahc -m test -s apache\n# ahc -m test -s nginx\n# ahc -m test -s ftp\n# ahc -m test -s mysql\n# ahc -m test -s bind\n# ahc -m test -s crypt\n# ahc -m test -s git\n# ahc -m test -s git_jail\n# ahc -m test -s sendmail\n# ahc -m test -s all\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nCertificates\n--------------------------------------------------------------\n# ahc -m certs -i example.com -a email-address\n# ahc -m certs -i example.com -d email-address\n# ahc -m certs -i example.com -l\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nOpenVPN\n--------------------------------------------------------------\n# ahc -m vpn -a client1\n# ahc -m vpn -d client1\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nProjects protection\n--------------------------------------------------------------\n# ahc -m crypt -a encrypt\n# ahc -m crypt -a mount\n# ahc -m crypt -a umount\n# ahc -m crypt -a decrypt\n    OR\n# ahc -m crypt -a e\n# ahc -m crypt -a m\n# ahc -m crypt -a u\n# ahc -m crypt -a d\n--------------------------------------------------------------\n\n--------------------------------------------------------------\nService Installing\n--------------------------------------------------------------\n# ahc -m install -s apache2_ssl\n# ahc -m install -s nginx_ssl\n# ahc -m install -s ftp\n# ahc -m install -s bind\n# ahc -m install -s mysql\n# ahc -m install -s firewall\n# ahc -m install -s nginx_proxy\n# ahc -m install -s certs -i example.com\n# ahc -m install -s lighttpd\n# ahc -m install -s sendmail\n# ahc -m install -s mail\n# ahc -m install -s shell\n# ahc -m install -s jira\n# ahc -m install -s confluence\n# ahc -m install -s web\n# ahc -m install -s vpn\n# ahc -m install -s dropbox\n# ahc -m install -s all\n--------------------------------------------------------------\n\nAhc flags:\n    --version - current version\n    -h or --help - help section\n\nBind flags:\n    -a = add zone\n    -d = remove zone\n    -i = ip-address for a specified zone\n\n\nCerts flags:\n    -a = add user\n    -d = remove user\n    -l = List of users\n\n\nMySQL flags:\n    -a = add [database] or [hostname]\n    -d = remove database\n    -u = username(optional)\n    -p = password(optional)\n\n\nFTP flags:\n    -a = add ftp account for hostname\n    -d = remove ftp account(still working, when hostname is removed)\n    -u = username (optional)\n    -p = password (optional)\n    -f = manual specified folder (optional)\n\n    Note:\n        Default \"username\" & \"password\" is equal to hostname\n\n\nGit jail flags:\n    -a - add user\n    -p - ssh public key\n    -d - delete user\n    -l - user list\n    -i - project name (domain name)\n    -e - add access for directory in project\n    -u - email address\n    -f - remove access for directory\n\n\nApache/Nginx flags:\n    -t = type [php,python,django,ruby,ror]\n    -a = add host\n    -d = remove host\n    -e = enable host\n    -f = disable host\n    -o = static optimization(optional)\n    -x = enable host protection(optional)\n    -l = list available websites\n    -w = wsgi config for python OR django (nginx/uwsgi)\n    -b = basic auth. params=user:password\n    -v = VirtualEnv (available for python & django)",
        "url": "http://pypi.python.org/pypi/ahc",
        "summary": "Package with extensions for Developers on Python(+Django), Ruby(+RoR) and PHP.",
        "command": "pip install 'ahc'"
      },
      "ahcm": {
        "name": "ahcm",
        "description": "ahcm apply mypatch /prj/foo\nahcm apply blah.txt foo.txt /prj/foo\n\n- Copy all files under directory mypatch over corresponding files in \n/prj/foo. Do the same for blah.txt and foo.txt \nIf file doesn't exist under target dir, it's NOT created.\n\nAlso other simple but handy \"dirty\" CM operations are supported for those unmanaged situations. ;-)",
        "url": "http://pypi.python.org/pypi/ahcm",
        "summary": "ahcm - ad hoc configuration management tool",
        "command": "pip install 'ahcm'"
      },
      "ahc-tools": {
        "name": "ahc-tools",
        "description": "Tools for RDO-Manager automatic health checks\n=============================================\n\nThese are tools to perform advanced reporting and role matching based on the\nintrospection results from `OpenStack Ironic`_ prior to doing an\n**RDO-Manager** deployment. This is based on the `AHC`_ concept from the\n**enovance edeploy** install method.\n\n.. _OpenStack Ironic: https://wiki.openstack.org/wiki/Ironic\n.. _AHC: https://github.com/enovance/edeploy/blob/master/docs/AHC.rst\n\nUsage\n-----\n\nUsage documentation is currently provided as part of the\n`RDO-Manager documentation`_\n\n.. _RDO-Manager documentation: https://repos.fedorapeople.org/repos/openstack-m/instack-undercloud/html/index.html",
        "url": "http://pypi.python.org/pypi/ahc-tools",
        "summary": "Tools for RDO-manager automatic health checks",
        "command": "pip install 'ahc-tools'"
      },
      "Ahem": {
        "name": "ahem",
        "description": "Ahem\n====\n\nAhem is a notifications framework for Django projects, it uses\ndeclarative style just like Django models.\n\nInstalation\n===========\n\n::\n\n    pip install Ahem\n\nAdd it to the list of installed apps in your settings file:\n\n.. code:: python\n\n    # settings.py\n\n    INSTALLED_APPS = (\n        'ahem',\n    )\n\nIf you are using ``Celery``, configure the celery beat schedule variable\nso periodic tasks can run:\n\n.. code:: python\n\n    # settings.py\n\n    from ahem.loader import get_celery_beat_schedule\n    CELERYBEAT_SCHEDULE = get_celery_beat_schedule()\n\n    # you may add more periodic tasks after this:\n    CELERYBEAT_SCHEDULE.update({\n        'other-task': {\n            'task': 'mytasks.the_taks',\n            'schedule': crontab(...),\n        }\n    })\n\nDocumentation\n=============\n\n| Ahem can be runned both with or without\n`celery <http://celery.readthedocs.org/>`__. If the celery lib can be\nimported, it will try sending notifications asynchronously, else it will\nsend then in the same thread it was called.\n| Periodic notifications will not work without celery.\n\n| **Attention**\n| Sending notifications without celery may slow down your system, please\nbe careful.\n\nNotifications\n-------------\n\nTo define notifications, create a ``notifications.py`` file in any of\nthe installed apps of your project and create a class that extends ahem\n``Notification`` class.\n\n.. code:: python\n\n    # my_django_app/notifications.py\n\n    from datetime import timedelta\n    from ahem.notification import Notification\n    from ahem.scopes import QuerySetScope\n    from ahem.triggers import DelayedTrigger\n\n    class MyProjectNotification(Notification):\n        name = 'my_project'\n\n        scope = QuerySetScope()\n        trigger = DelayedTrigger(timedelta(days=1))\n\n        backends = ['email']\n        templates = {\n            'default': 'path/to/template.html'}\n\n-  ``name`` will be used as the id of your notification, it should be\n   unique in your project.\n-  ``scope`` defines which users will receive the notification.\n-  ``trigger`` defines how and when the notification will be triggered.\n-  ``backends`` is a list of available backend names for the\n   notification.\n-  ``templates`` dictionary with templates to be used for each backend.\n\nContext\n-------\n\nget\\_context\\_data(self, user, backend\\_name, \\*\\*kwargs):\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nYou can override ``get_context_data`` to add more variables to the\ncontext. ``User`` is added to context by default, remember to call\n``super`` if overriding.\n\n.. code:: python\n\n    class TheNotification(Notification):\n        ...\n        def get_context_data(self, user, backend_name, **kwargs):\n            kwargs = super(TheNotification, self).get_context_data(\n                user, backend_name, **kwargs)\n            kwargs['extra_context'] = 'This will be shown in the notification'\n            return kwargs\n\nBackends\n--------\n\nCurrently, ``EmailBackend`` is the only backend available. Developers\nare encouraged to build new ones and merge then to this repository via\nPull Request.\n\nRegistering users in a backend\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nBefore sending a notification to a user using a specific backend, you\nneed to register it.\n\n.. code:: python\n\n    from ahem.utils import register_user\n\n    register_user('backend_name', user,\n        setting1='username', setting2='secure_key')\n\nEmailBackend\n~~~~~~~~~~~~\n\n-  name: ``email``\n-  settings: no settings required. The ``User`` email will be used.\n\nContext data\n''''''''''''\n\n-  ``subject`` will be used as the email subject.\n-  ``from_email`` the email the message will be sent from, default is\n   DEFAULT\\_FROM\\_EMAIL.\n-  ``use_html`` if true, the email will be sent with html content type.\n\nScheduling a notification\n-------------------------\n\nUse the ``schedule`` method to trigger a notification. Use the\n``context`` kwarg to pass a context dictionary to the notification.\n\n.. code:: python\n\n    # this will trigger the notification according to it's `trigger`\n    # for the MyProjectNotification, it will wait 1 day before sending\n    # the notification.\n    MyProjectNotification.schedule(context={'some_param': 'value'})\n\nOverriding backends\n~~~~~~~~~~~~~~~~~~~\n\nYou can also limit the backends that will be used by passing a list to\nthe ``backends`` kwarg.\n\n**Since the EmailBackend is currently the only one available, this\nfeature is currently useless**\n\n.. code:: python\n\n    MyProjectNotification.schedule(backends=['email'])\n\nOverriding trigger\n~~~~~~~~~~~~~~~~~~\n\nYou can also explicitly tell when the notification should be sent by\npassing ``delay_timedelta`` or ``eta``.\n\n.. code:: python\n\n    # Notification will be sent at 23:45\n    from celery.schedules import crontab\n    MyProjectNotification.schedule(eta=crontab(crontab(hour=23, minute=45)))\n\n    # Notification will be send 20 minutes after it was scheduled\n    from datetime import timedelta\n    MyProjectNotification.schedule(delay_timedelta=timedelta(minutes=20))\n\nScopes\n------\n\nScopes are a declarative way to select which users will receive the\nnotification when it's executed. Ahem comes with 2 scopes by default,\nbut if you are feeling adventurous you can build your onw one.\n\nQuerySetScope\n~~~~~~~~~~~~~\n\n``QuerySetScope`` will return all users if no argument is passed but you\ncan pass a queryset to filter only the ones you desire.\n\n.. code:: python\n\n    from ahem.scopes import QuerySetScope\n\n    class TheNotification(Notification):\n        ...\n        scope = QuerySetScope(User.objects.filter(is_staff=True))\n        ...\n\nThis will scope the notification only to staff users.\n\nContextFilterScope\n~~~~~~~~~~~~~~~~~~\n\n``ContextFilterScope`` filters the ``User`` model according to a param\nspecified in the context passed to the notification when it's scheduled.\n\n.. code:: python\n\n    from ahem.scopes import ContextFilterScope\n    class TheNotification(Notification):\n        ...\n        scope = ContextFilterScope(\n            context_key='user_is_admin', lookup_field='is_admin')\n        ...\n\n    # This will send the notification only to non admin users\n    TheNotification.schedule(context={'user_is_admin': False})\n\nfilter\\_scope(self, queryset, context)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nExtra filters can be performed in the ``Notification`` ``scope`` by\nadding a ``filter_scope`` method to your notification. This method\nshould return a list of ``User``\\ s\n\n.. code:: python\n\n    # This will restrict the notification to users with `first_name` \"Camila\"\n    class TheNotification(Notification):\n        ...\n        scope = QuerySetScope(User.objects.filter(is_staff=True))\n\n        def filter_scope(self, queryset, context):\n            return queryset.filter(first_name='Camila').all()\n\nTriggers\n--------\n\nTriggers define when notifications will be send. Currently the two types\nof triggers available are: ``DelayedTrigger`` and ``CalendarTrigger``,\nbut you can also write custom ones by extending ``NotificationTrigger``.\n\nDelayedTrigger\n~~~~~~~~~~~~~~\n\n``DelayedTrigger``\\ s should receive a timedelta as their first param.\nThis will specify how long should be waited before sending the\nnotification. If a timedelta is not specified, the notification will be\nimediately sent. You can optitionaly pass ``at_hour`` and/or\n``at_minute`` kwargs. By doing this, after timedelta is added to the\ncurrent time, the hour and minute will be overwriten to the ones you\nspecified.\n\n.. code:: python\n\n    from datetime import timedelta\n    from ahem.triggers import DelayedTrigger\n\n    # Will send 2 days after scheduled at 18:00.\n    class TheNotification(Notification):\n        ...\n        trigger = DelayedTrigger(timedelta(days=2), at_hour=18, at_minute=0)\n        ...\n\nCalendarTrigger\n~~~~~~~~~~~~~~~\n\n``CalendarTrigger`` are periodic notifications, use ``Celery``\n``crontab`` to define it's periodicity. See ``Celery`` documentation for\nmore info:\nhttp://celery.readthedocs.org/en/latest/userguide/periodic-tasks.html#crontab-schedules\n\n.. code:: python\n\n    from celery.schedules import crontab\n    from ahem.triggers import CalendarTrigger\n\n    # Will send notifications everyday at midnight\n    class TheNotification(Notification):\n        ...\n        trigger = CalendarTrigger(crontab(hour=0, minute=0))\n        ...\n\nTemplates\n---------\n\n``templates`` specify which template should be used to render\nnotification content. There should be at least a ``default`` template,\nbut you can specify a different one for each backend. When rendering the\ntemplate, all context variables will be available.\n\n.. code:: python\n\n    class TheNotification(Notification):\n        ...\n        templates = {\n            'default': 'path/to/your/template.html',\n            'email': 'path/to/email/template.html'}\n\nTests\n-----\n\nUse ``tox`` to run tests.\n",
        "url": "http://pypi.python.org/pypi/Ahem",
        "summary": "Simple, but rich, declarative notification framework for Django",
        "command": "pip install 'Ahem'"
      },
      "aheui": {
        "name": "aheui",
        "description": "* English: [README.en.md](https://github.com/aheui/rpaheui/blob/master/README.en.md)\n* 한국어: [README.ko.md](https://github.com/aheui/rpaheui/blob/master/README.ko.md)\n\n* Working log: [LOG.md](https://github.com/aheui/rpaheui/blob/master/LOG.md)",
        "url": "http://pypi.python.org/pypi/aheui",
        "summary": "Aheui compiler & assembler toolkit.",
        "command": "pip install 'aheui'"
      },
      "ahkab": {
        "name": "ahkab",
        "description": "ahkab\n=====\n\n**a SPICE-like electronic circuit simulator written in Python**\n\nThe code should be easy to read and modify, the main language is Python\n-- 2 or 3 -- and it is platform-independent.\n\nNews!\n-----\n\n-  Ahkab v0.18 was released on July 18 2015, including new features,\n   bugfixes and improved documentation. It is recommended to upgrade.\n   Check out `the release\n   notes <https://github.com/ahkab/ahkab/releases/tag/v0.18>`__ for\n   more!\n-  The whole codebase has been going through a (yet incomplete)\n   refactoring and documenting effort. The `new documentation is\n   available on RTD <http://ahkab.readthedocs.org/en/latest/>`__.\n\nMy resources are limited these days, so the much-needed work is\nproceeding slowly, albeit hopefully steadily. If you are interested and\nyou would like to contribute to refactoring or documenting a particular\nfeature, it would be very welcome.\n\n|Build Status| |Coverage Status| |PyPi version| |GPLv2 license| |DOI|\n\nSupported simulations:\n----------------------\n\n-  Numeric:\n\n   -  **Operating point**, with guess computation to speed up the\n      solution. See example: `Downscaling current\n      mirror <https://ahkab.readthedocs.org/en/latest/examples/OP_simulation.html>`__\n   -  **DC sweep**\n   -  **Transient analysis**, available differentiation formulas:\n      implicit Euler, trapezoidal, gear orders from 2 to 5. See for\n      example the `simulation of a Colpitts\n      Oscillator <https://ahkab.readthedocs.org/en/latest/examples/Transient-Example.html>`__.\n   -  **AC analysis**\n   -  **PZ** analysis\n   -  **Periodic steady state analysis** of non-autonomous circuits,\n      *time* *domain* shooting and brute-force algorithms.\n\n-  Symbolic:\n\n   -  **Small signal analysis**, AC or DC, with extraction of transfer\n      functions, DC gain, poles and zeros. Various `symbolic analysis\n      examples on this\n      page <https://ahkab.readthedocs.org/en/latest/examples/Symbolic-simulation.html>`__.\n\nThe results are saved to disk, plotted or printed to stdout and can be\nread/processed by the most common tools (eg.\n`Octave <http://www.gnu.org/software/octave/>`__,\n`gnuplot <http://www.gnuplot.info/>`__,\n`Matlab <http://www.mathworks.com/products/matlab/>`__,\n`gwave <http://www.telltronics.org/software/gwave/>`__ and others)\n\nInstall\n-------\n\nThe program requires:\n\n-  the Python interpreter version 2 or 3 (at least v.2.6 for Python2,\n   v.3.3 for Python3),\n-  numpy>=1.7.0, scipy>=0.14.0, sympy>=0.7.6 and tabulate>=0.7.3.\n\nMatplotlib is strongly recommended and no plotting will work without.\n\nIf you need more information about the dependencies, check the `Install\nnotes <https://ahkab.readthedocs.org/en/latest/help/Install-Notes.html>`__.\n\nUsage\n-----\n\n1. ``ahkab`` can be run as a Python library\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. code:: python\n\n    from ahkab import new_ac, run\n    from ahkab.circuit import Circuit\n    from ahkab.plotting import plot_results # calls matplotlib for you\n    import numpy as np\n\n    # Define the circuit\n    cir = Circuit('Butterworth 1kHz band-pass filter')\n    cir.add_vsource('V1', 'n1', cir.gnd, dc_value=0., ac_value=1.)\n    cir.add_resistor('R1', 'n1', 'n2', 50.)\n    cir.add_inductor('L1', 'n2', 'n3', 0.245894)\n    cir.add_capacitor('C1', 'n3', 'n4', 1.03013e-07)\n    cir.add_inductor('L2', 'n4', cir.gnd, 9.83652e-05)\n    cir.add_capacitor('C2', 'n4', cir.gnd, 0.000257513)\n    cir.add_inductor('L3', 'n4', 'n5', 0.795775)\n    cir.add_capacitor('C3', 'n5', 'n6', 3.1831e-08)\n    cir.add_inductor('L4', 'n6', cir.gnd, 9.83652e-05)\n    cir.add_capacitor('C4', 'n6', cir.gnd, 0.000257513)\n    cir.add_capacitor('C5', 'n7', 'n8', 1.03013e-07)\n    cir.add_inductor('L5', 'n6', 'n7', 0.245894)\n    cir.add_resistor('R2', 'n8', cir.gnd, 50.)\n\n    # Define the analysis\n    ac1 = new_ac(2.*np.pi*.97e3, 2.*np.pi*1.03e3, 1e2, x0=None)\n\n    # run it\n    res = run(cir, ac1)\n\n    # plot the results\n    plot_results('5th order 1kHz Butterworth filter', [('|Vn8|',\"\")], res['ac'],\n                 outfilename='bpf_transfer_fn.png')\n\n2. ``ahkab`` can be run from the command line with a netlist file\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nThe syntax is:\n\n::\n\n    `$ python ahkab -o graph.dat <netlist file>`\n\nSee ``ahkab --help`` for command line switches, `also online on the\ndocumentation\npages. <http://ahkab.readthedocs.org/en/latest/help/Command-Line-Help.html>`__\n\nDocumentation\n~~~~~~~~~~~~~\n\nThe `documentation is available on\nRTD <http://ahkab.readthedocs.org/en/latest/>`__.\n\nThere, you can find a\n`documentation <http://ahkab.readthedocs.org/en/latest/ahkab.html>`__\nand\n`examples <http://ahkab.readthedocs.org/en/latest/examples/Python_API.html>`__\nregarding how to simulate from a Python script.\n\nRefer to the `netlist syntax\npage <http://ahkab.readthedocs.org/en/latest/help/Netlist-Syntax.html>`__\nif you prefer to write netlist files that describe the circuit.\n\nExperience with running SPICE or related commercial simulators can be\nvery useful: this is not for the faint of heart.\n\nDevelopment model\n~~~~~~~~~~~~~~~~~\n\n-  The development happens on the `github\n   repository <https://github.com/ahkab/ahkab>`__,\n-  Mostly on the master branch, with feature branch being created only\n   for special purposes or non-trivial features.\n-  Snapshots are released on a (hopefully) regular basis and are\n   available on the `Releases pages, complete with\n   changelog <https://github.com/ahkab/ahkab/releases>`__ and on\n   `PYPI <https://pypi.python.org/pypi/ahkab/>`__\n\nPatches and pull requests are welcome!\n\nHow this project was born\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThis project was born when I was an enthusistic undergrad, apparently\nwith plenty of free time, attending \"Simulazione Circuitale\" (*Circuit\nSimulation*) taught by `Prof. A.\nBrambilla <http://brambilla.dei.polimi.it/>`__ back in Italy at the\nPolytechnic University of Milan.\n\nI am grateful to prof. Brambilla for teaching one of the most\ninteresting courses of my university years. -GV\n\nBugs and patches\n~~~~~~~~~~~~~~~~\n\nDoes it work? Bugs? Do you have patches? Did you run some noteworthy\nsimulation? Let me know! Feedback is very welcome, my `email\naddress <http://tinymailto.com/5310>`__ is available after a captcha.\n\nSupport the development with a donation\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIf you wish to support the development of ``ahkab``, ***please donate to\ncancer research:***\n\n-  `Association for International Cancer Research\n   (eng) <http://www.aicr.org.uk/donate.aspx>`__,\n\nor\n\n-  `Fond. IRCCS Istituto Nazionale dei Tumori\n   (it) <http://www.istitutotumori.mi.it/modules.php?name=Content&pa=showpage&pid=24>`__.\n\nCredits\n~~~~~~~\n\n**Authors:** `Giuseppe Venturini <https://github.com/ggventurini>`__,\nwith contributions from `Ian Daniher <https://github.com/itdaniher>`__\nand `Rob Crowther <https://github.com/weilawei>`__.\n\n**Code:** the module ``py3compat.py`` is (c) 2013 - the Jinja team.\n\n**Dependencies:** many thanks to the authors of ``numpy``, ``scipy``,\n``sympy``, ``matplotlib`` and ``tabulate``!\n\n.. |Build Status| image:: https://travis-ci.org/ahkab/ahkab.png?branch=master\n   :target: https://travis-ci.org/ahkab/ahkab\n.. |Coverage Status| image:: https://coveralls.io/repos/ahkab/ahkab/badge.png?branch=master\n   :target: https://coveralls.io/r/ahkab/ahkab?branch=master\n.. |PyPi version| image:: http://img.shields.io/badge/version-0.18-brightgreen.png\n   :target: https://pypi.python.org/pypi/ahkab/\n.. |GPLv2 license| image:: http://img.shields.io/badge/license-GPL%20v2-brightgreen.png\n   :target: https://raw.githubusercontent.com/ahkab/ahkab/master/LICENSE\n.. |DOI| image:: https://zenodo.org/badge/doi/10.5281/zenodo.17696.svg\n   :target: http://dx.doi.org/10.5281/zenodo.17696",
        "url": "http://pypi.python.org/pypi/ahkab",
        "summary": "a SPICE-like electronic circuit simulator",
        "command": "pip install 'ahkab'"
      },
      "ahocorasick": {
        "name": "ahocorasick",
        "description": "The Aho-Corasick automaton is a data structure that can quickly do a multiple-keyword search across text. It's described in the classic paper 'Efficient string matching: an aid to bibliographic search': http://portal.acm.org/citation.cfm?id=360855&dl=ACM&coll=GUIDE. The majority of the code here is adapted from source code from the Fairly Fast Packet Filter (FFPF) project: http://ffpf.sourceforge.net/general/overview.php.",
        "url": "http://pypi.python.org/pypi/ahocorasick",
        "summary": "Aho-Corasick automaton implementation",
        "command": "pip install 'ahocorasick'"
      },
      "ahonya-sika": {
        "name": "ahonya-sika",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ahonya-sika",
        "summary": "Sika API library client for python",
        "command": "pip install 'ahonya-sika'"
      },
      "ahoy": {
        "name": "ahoy",
        "description": "===============================\nahoy\n===============================\n\n.. image:: https://img.shields.io/travis/eddiejessup/ahoy.svg\n        :target: https://travis-ci.org/eddiejessup/ahoy\n\n.. image:: https://img.shields.io/pypi/v/ahoy.svg\n        :target: https://pypi.python.org/pypi/ahoy\n\n\nAgent-based simulations of active particles\n\n* Free software: BSD license\n* Documentation: https://ahoy.readthedocs.org.\n\nFeatures\n--------\n\n* TODO\n\n\n\n\nHistory\n-------\n\n0.1.0 (2015-01-11)\n---------------------\n\n* First release on PyPI.",
        "url": "http://pypi.python.org/pypi/ahoy",
        "summary": "Agent-based simulations of active particles",
        "command": "pip install 'ahoy'"
      },
      "ahsay": {
        "name": "ahsay",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ahsay",
        "summary": "A simple requests wrapper for the Ahsay API",
        "command": "pip install 'ahsay'"
      },
      "aiclib": {
        "name": "aiclib",
        "description": "======\naiclib\n======\n\nA declarative system to consume the NVP api.\n\nCurrent Build Status\n====================\n.. image:: https://api.travis-ci.org/rackerlabs/aiclib.png\n    :target: https://travis-ci.org/rackerlabs/aiclib\n\n\nUse of AIC wrapper lib\n======================\n\nThe AIC wrapper command, or sentence, consists of two\nparts:\n- An object and its parameters\n- A verb that acts on that object\n\nTypical use looks as follows:\nlibrary.[possible parameters].object.[params].verb\n\nIt is possible for the object to be a collection of the\nsame type of object. The AIC wrapper lib will perform a\nbulk operation on all of the objects.\n\nIf an object is not given it is assumed that the user\nwishes to create an object (this is finalized through the\nCREATE verb).\n\nObject's parameters are completely optional if they are\nset through a 'dot' function. Parameters that are required\nare set during the declaration of the object.\n\nA verb works on the object and is always the last portion\nof a normal command.\n\n\nQuerying using the wrapper lib\n==============================\n\nThe exception to the normal command pattern is when a user\nwishes to query. A query works much like the typical use\nbut acts works as a modifer to the verb (an adverb).\n\nTypical query use is as follows:\nlibrary.[params].object.query.[params].verb\n\nThe object stated in the command is what query is looking\nfor. Parameters may be passed to the query to make the\nsearch more precise.\n\nExtending the wrapper lib\n=========================\n\nThe creation of a custom entity requires that the entity,\nsomewhere in its inheritance chain, inherit from\ncore.Entity. For it to properly return responses from the\nserver it also needs to overload unroll.",
        "url": "http://pypi.python.org/pypi/aiclib",
        "summary": "A declarative system to consume the NVP api.",
        "command": "pip install 'aiclib'"
      },
      "aidan": {
        "name": "aidan",
        "description": "=====\naidan\n=====\n\nThis is a living package that I'll update with information about me, helper functions, and other fun stuff.\n\nAt the moment this is my \"hello world\" of a pypi package so my apologies for how barren it is.",
        "url": "http://pypi.python.org/pypi/aidan",
        "summary": "UNKNOWN",
        "command": "pip install 'aidan'"
      },
      "aidsinfo": {
        "name": "aidsinfo",
        "description": "AIDSinfo Python API Wrapper\n===========================\n\nA Python wrapper for the AIDSinfo drug information API.\n\nAIDSinfo Documentation:  http://www.aidsinfo.nih.gov/Other/rss.aspx\n\n\nUsage\n-----\n\n    >>> from aidsinfo import DrugInfo\n    >>> info = DrugInfo()\n    >>> info.search('abacavir')\n    {'abacavir': {'data': 'here'}}\n\n    >>> info.search('combivir')\n    {'combivir': {'data': 'here'}}\n\n    >>> # You can also get back just the XML data.\n    ... xml_data = info.search('combivir', output_format=None)\n\n\nCopyright\n---------\n\nCopyright (c) 2011 Code for America Laboratories.\n\nSee LICENSE for details.",
        "url": "http://pypi.python.org/pypi/aidsinfo",
        "summary": "A Python wrapper for the AIDSinfo drug information API.",
        "command": "pip install 'aidsinfo'"
      },
      "AIGO": {
        "name": "aigo",
        "description": "===========\n   AIGO\n===========\n\nAIGO is a python library for the Analysis and \nthe Inter-comparison of Gene Ontology functional annotations.\nsee (http://code.google.com/p/aigo).\n\nCreated by Michael Defoin-Platel on 21/02/2010.\nCopyright (c) 2010. All rights reserved.\n\nTypical usage could look like this::\n\n    #!/usr/bin/env python\n\n    from AIGO import logger\n\n    from AIGO.ReferenceSet import RefSet\n    from AIGO.FunctionalAnnotation import FuncAnnot\n    from AIGO.go.OBO import readGOoboXML\n\n    from AIGO.Analyse import AnalyseFA\n    from AIGO.Report import ReportFA\n\n    from AIGO.utils.Execute import batchExecute\n\n    refSet = RefSet(organism=\"platypus\", fileName=\"platypus.refSet\", refType=\"Text\")\n    G = readGOoboXML(\"go_daily-termdb.obo-xml\")\n    FA = FuncAnnot(\"platypusProject\", refSet, G, organism=\"platypus\")\n    FA.read(\"platypus.gaf\", \"GAF\") \n\n    analyseFA = AnalyseFA()\n\n    analyseFA.largestSet([FA])\n    logger.info(\"Largest sets of annotations:\")\n    logger.info(\"\\t%d for %s\" % (FA['largestSet']['All_aspects_of_GO'], FA.name))\n\n    batchList=[\"coverage\",  \"richness\", \"numberAnnot\", \"redundancy\", \"specificity\", \"informationContent\"]\n    batchExecute(batchList, analyseFA, [FA])\n\n    reportFA = ReportFA(outDir=None, name=\"platypusProject\", organism=\"platypus\")\n    reportFA.printStatistics([FA] ,batchList)\n\nTests\n=====\n\nRun testAIGO.py in the tests directory\n\n\nRequirements\n==============\n\nRunning AIGO on windows\n-------------------------\n* The 2.6.5 Python interpreter for Windows page http://www.python.org/download.\n* GTK+ runtime (recommend bundle), PyGTK, PyCairo? and PyGObject http://www.pygtk.org/downloads.html\n* BioPython? http://biopython.org/wiki/Download\n* NumPy? http://sourceforge.net/projects/numpy/files/NumPy\n* matplotlib http://sourceforge.net/projects/matplotlib/files/matplotlib/matplotlib-1.0\n* xlwt http://pypi.python.org/pypi/xlwt \n\nOptional :\n* wxPython http://www.wxpython.org/download.php#binaries\n* psyco http://sourceforge.net/projects/psyco/files\n* RPy http://sourceforge.net/projects/rpy/files\n\n\nContributors\n============\n* Michael Defoin-Platel\n* Matthew Hindle",
        "url": "http://pypi.python.org/pypi/AIGO",
        "summary": "Analysis and Inter-comparison of Gene Ontology functional annotations",
        "command": "pip install 'AIGO'"
      },
      "AIKIF": {
        "name": "aikif",
        "description": "AIKIF - Artificial Intelligence Knowledge Information Framework\n\nThis is an information classification framework that maps structured or freeform data to \na standard knowledge store.\n\nManages a dataset of your applications, the source data, parameters, runs and results and then uses your business rules to convert and store the information in a machine usable format.\n\nYour AI software can link to AIKIF by setting up logging watch-points to define success / \nfailure along with the range of input parameters. Goals and plans are defined by breaking \nthem down to smaller tasks until the task can be run by a tool in the Toolbox.\n\nA tool is any python wrapped function or application and is easily extensible.\n\n\nQuick Start\n===========\n\n>> pip install aikif\n\nor get latest info from  https://github.com/acutesoftware/AIKIF",
        "url": "http://pypi.python.org/pypi/AIKIF",
        "summary": "Artificial Intelligence Knowledge Information Framework",
        "command": "pip install 'AIKIF'"
      },
      "ail": {
        "name": "ail",
        "description": "ail is a generalized framework for interacting with...    well, stuff. It is sometimes better to ail than fail.",
        "url": "http://pypi.python.org/pypi/ail",
        "summary": "abstract interaction layer",
        "command": "pip install 'ail'"
      },
      "ailove-django-fias": {
        "name": "ailove-django-fias",
        "description": "Приложение для работы с базой данных ФИАС в Django\n\nОсновные возможности\n====================\n\n* Импорт базы ФИАС из скачанного архива XML или напрямую с сайта http://fias.nalog.ru\n* Возможность хранить данные в отдельной БД\n* Поле модели AddressField, предоставляющее в админке Django ajax-поиск адреса\n* Поддержка полнотекстового поиска для поля AddressField (`демо <http://youtu.be/ZVVrxg9-o_4>`_)\n* Связанное поле модели для выбора района внутри выбранного в AddressField города (районы никак не привязаны к улицам, соответственно, их нужно выбирать отдельно, если это требуется)\n* Несколько абстрактных моделей, немного упрощающих жизнь\n\nУстановка\n============\n\n1. Установите `django-fias`::\n\n        pip install django-fias\n\n2. Добавьте `fias` и `django_select2` в ваш список `INSTALLED_APPS`.\n3. Добавьте `url(r'^fias/', include('fias.urls', namespace='fias')),` в ваш urlpatterns\n4. Любым доступным способом подключите к админке приложения, в котором будете использовать поле FiasAddress свежую версию jQuery::\n\n    # например так:\n    class ItemAdmin(admin.ModelAdmin):\n        class Media:\n            js = ['//ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.js']\n    admin.site.register(Item, ItemAdmin)\n\n5. Если вы желаете использовать отдельную БД под данные ФИАС, выполните следующее\n\n* Создайте БД и подключите её к Джанго обычным способом\n* Добавьте в ваш `settings.py` параметр::\n\n        FIAS_DATABASE_ALIAS = 'fias'\n\nгде `fias` - имя БД\n\n* Добавьте в список `DATABASE_ROUTERS`::\n\n        fias.routers.FIASRouter\n\n* Выполните::\n\n        # для South\n        python manage.py migrate --database=fias\n        # без South\n        python manage.py syncdb --database=fias\nгде `fias` - имя БД ФИАС\n\n5. Выполните::\n\n        # для South\n        python manage.py migrate\n        # без South\n        python manage.py syncdb\n\n6. Выполните::\n\n        python manage.py collectstatic\n\nОбновление до версии 0.3\n========================\n\nОбязательно наличие South.\nВыполните::\n\n        # Если данные ФИАС хранятся в основной БД\n        python manage.py migrate\n        # Если данные ФИАС хранятся в другой БД\n        python manage.py migrate --database=fias\nгде `fias` - имя БД ФИАС\n\n\nОбновление до версии 0.4\n========================\n\nОбязательно наличие South.\n\nЕсли данные ФИАС хранятся в MySQL, выполните::\n\n        # Если данные ФИАС хранятся в основной БД\n        python manage.py migrate fias 0004 --fake\n        python manage.py migrate fias\n        # Если данные ФИАС хранятся в другой БД\n        python manage.py migrate fias 0004 --fake --database=fias\n        python manage.py migrate fias --database=fias\n\nИначе выполните::\n\n        # Если данные ФИАС хранятся в основной БД\n        python manage.py migrate\n        # Если данные ФИАС хранятся в другой БД\n        python manage.py migrate --database=fias\n        \nЗатем следует сгенерировать новый конфиг для Sphinx, как описано ниже, и переиндексировать базу.\n\nНастройка полнотекстового поиска\n================================\nAddressField поддерживает 2 метода поиска адреса: последовательный (sequence) и полнотекстовый (sphinx).\n\n**NOTE**: поддерживаются только 2 СУБД: PostgreSQL и MySQL.\n**NOTE2**: для индексации базы в MySQL может потребоваться до 2-2.5ГБ свободного места во временном каталоге MySQL.\n**NOTE3**: нет необходимости слишком часто пересоздавать поисковый индекс базы ФИАС. Это требуется делать только после обновления базы.\n\nПо-умолчанию используется последовательный метод, т. к. не требует дополнительных настроек.\nДля активации полнотекстового поиска необходимо выполнить несколько дополнительных шагов:\n\n1. Добавьте в ваш `settings.py` параметр::\n\n    FIAS_SEARCH_ENGINE='sphinx'\n\n2. Установите:\n\n* `sphinxit <https://github.com/semirook/sphinxit>`_\n* `Sphinx Search Engine <http://sphinxsearch.com>`_ Для Debian, Ubuntu, RHEL, Windows есть `пакеты <http://sphinxsearch.com/downloads/release/>`_\n\n\n3. Сгенерируйте конфигурацию `sphinx`:\n\nЕсли у вы уже используете `sphinx` в проекте, то вам нужен только конфиг индекса. Выполните::\n\n    python manage.py fias_sphinx --path=PATH > sphinx.conf\n\nгде `PATH` - путь до каталога с индексами sphinx.\n\nИначе выполните::\n\n    python manage.py fias_sphinx --path=PATH --full > sphinx.conf\n\nчтобы получить полный конфиг sphinx.\n\nЗамените конфиг sphinx полученными настройками (для **Gentoo** это файл `/etc/sphinx/sphinx.conf`, для **Ubuntu**: `/etc/sphinxsearch/sphinx.conf`)\n\n4. Псоле того, как данные **импортированы** и обновлены выполните::\n\n    indexer -c /etc/sphinx/sphinx.conf --all\n\n*NOTE*: для повторной переиндексации при запущенном Sphinx следует выполнять::\n\n    indexer -c /etc/sphinx/sphinx.conf --all --rotate\n\n5. Запустите sphinx::\n\n    # для Gentoo\n    /etc/init.d/searchd start\n    # для Ubuntu\n    /etc/init.d/sphinxsearch start\n\n**NOTE** Если Sphinx работает на другом хосте или на другом порту, добавьте в `settings.py` словарь соответствующими параметрами::\n\n    FIAS_SEARCHD_CONNECTION = {\n        'host': '127.0.0.1',\n        'port': 9306,\n    }\n\nНастройка весов\n===============\nИз-за особенностей организации БД ФИАС, сортировка результатов поиска происходит не так, как хотелось бы.\nПоэтому, начиная с версии 0.4 добавлена возможность настроить веса типов адресных объектов по своему усмотрению.\nДля этого в `settings.py` добавьте словарь `FIAS_SB_WEIGHTS` вида::\n\n        FIAS_SB_WEIGHTS = {\n            # СОКРАЩЕНИЕ: ВЕС\n            'г': 128,\n            'с': 100,\n        }\n        \nгде \n * СОКРАЩЕНИЕ - сокращённое наименование вида объекта из таблицы SocrBase\n * ВЕС - число от 0 до 128\n \n*NOTE*: по-умолчанию вес всех типов равен 64\n*NOTE*: пример заполнения можно посмотреть в weights.py - там перечислены предустановленные веса.\n\nЧтобы применить свои изменения, выполните::\n\n        python manage.py fias --fill-weights\n        \nКроме того изменить веса можно в панели администрирования Django.\nНо помните, что эти изменения будут **перезаписаны** при следующем вызове упомянутой команды!\nПосле внесения изменений обязательно нужно переиндексировать базу.\n    \nВыбор импортируемых таблиц\n==========================\n\nТаблицы NORMDOC, SOCRBASE и ADDROBJ импортируются всегда. Таблицы LANDMARK, HOUSEINT и HOUSE можно не импортировать.\n\nДобавьте в ваш `settings.py` список названий таблиц, которые вы хотели бы импортировать::\n\n    FIAS_TABLES = ('landmark', 'houseint', 'house')\n\n\nИмпорт данных\n==============\n\nПервоначальная загрузка данных\n------------------------------\nСуществует несколько способов импортировать данные в БД ФИАС\n\nПолностью автоматический импорт с сайта ФИАС::\n\n        python manage.py fias --remote-file\n\nТакой способ не всегда целесообразен по разным причинам, поэтому лучше самостоятельно скачать полный архив и импортировать уже его::\n\n        python manage.py fias --file /path/to/fias_xml.rar\n\n**Но!**\nВ случае, если в БД уже есть какие-то данные, скрипт выдаст соответствующее сообщение и прекратит работу.\nТакое поведение связано с тем, что при импорте из файла, если версия файла не совпадает с версией данных в какой-то таблице в БД ФИАС,\nданные в этой таблице будут удалены полностью и заменены новыми, при этом\nORM Django при наличии связанных таблиц удалит данные так же и оттуда.\nЕсли вы уверены в том, что делаете, добавьте к предыдущей команде флаг *--really-replace*::\n\n        python manage.py fias --file /path/to/fias_xml.rar --really-replace\n        # or\n        python manage.py fias --remote-file --really-replace\n\nЕсли по какой-то причине нужно импортировать всю БД ФИАС заново, добавьте флаг *--force-replace*::\n\n        python manage.py fias --file /path/to/fias_xml.rar --force-replace --really-replace\n        # or\n        python manage.py fias --remote-file --force-replace --really-replace\n\nЕсли скачанный файл не актуален, можно добавить к указанной выше команде флаг *--update* - скрипт сразу после импорта обновит БД до актуальной версии.::\n\n        python manage.py fias --file /path/to/fias_xml.rar --update\n        # or\n        python manage.py fias --remote-file --update\n        \n**NOTE**\nИмпортируются только актуальные записи. Если данные об объекте менялись, будет загружена самая последняя версия записи об этом объекте.\nЗаписи из будущего не импортируются.\n\nОбновление существующей БД\n--------------------------\nДля обновления БД выполните::\n\n        python manage.py fias --update\n\nОбновление выполняется только с сайта ФИАС. Обновить базу из файла нельзя.\n\n**NOTE**\nКак это ни печально, но мы живём в России. Тут всякое бывает. Вот и сервис ФИАС время от времени подсовывает битые дельта-архивы.\nЧтобы оные пропускать автоматически и обновляться следующими по порядку, используйте флаг *--skip* совместно с *--update*\n\nИспользование\n==============\n\nВы можете самостоятельно ссылаться на таблицы БД фиас.\n\nВы так же можете добавить в свои модели поле `fias.fields.address.AddressField`, которое предоставит вам удобный\nпоиск адреса по базе и прявязку Один-ко-Многим вашей модели к таблице `AddrObj` базы ФИАС. (см. модель `Item` в тестовом приложении)\n\nЛибо вы можете унаследоваться от любой модели из `fias.models.address`, которые добавят несколько дополнительных\nполей к вашим моделям и выполнят за вас кое-какую рутину:\n\n**FIASAddress** (см. модель `CachedAddress` в тестовом приложении)\n\nПомимо поля `address` добавляет еще два: `full_address` и `short_address`. В первом хранится полная запись адреса (но без индекса), во втором - укороченная.\n\n**FIASAddressWithArea** (см. модель `CachedAddressWithArea` в тестовом приложении)\n\nНаследуется от предыдущей модели и добавляет еще поле `area` - позволяет указывать район города, выбранного в поле `address` (если, конечно, таковые имеются в БД ФИАС для данного города)\n\n**FIASHouse** (см. модель `CachedAddressWithHouse` в тестовом приложении)\n\nМиксин, добавляющий 3 поля `house`, `corps` и `apartment` - соответственно номер дома, корпус и квартира.\n\n**FIASFullAddress**\n\nКомбинация моделей  `FIASAddress` и `FIASHouse`.\n\n**FIASFullAddressWithArea**\n\nКомбинация моделей `FIASAddressWithArea` и `FIASHouse`\n\n*NOTE*: в моделях `FIASFullAddress` и `FIASFullAddressWithArea` реализованы методы `_get_full_address` и `_get_short_address`, возвращающие соответственно полную и сокращённую строку адреса, включая номер дома/корпуса/квартиры.\n\n\nTODO\n==============\n\n* Проверять списки удалённых объектов и все связанные с AddrObj модели мигрировать на правильные записи\n\nИзвестные проблемы\n====================\n* Если используется отдельная БД под данные ФИАС, в админке в список `list_display` нельзя добавлять поля типа `ForeignKey`\n* South не умеет работать с несколькими БД\n\nБлагодарности\n====================\n\n`Коммит от EagerBeager <https://github.com/EagerBeager/django-fias/commit/ed375c2e1cafdc04f0c9612091eb040ef8f9f4fe>`_\nБлагодаря этому коммиту до меня наконец дошло, почему импорт отжирал память.",
        "url": "http://pypi.python.org/pypi/ailove-django-fias",
        "summary": "FIAS Django integration (fork Ailove)",
        "command": "pip install 'ailove-django-fias'"
      },
      "aima": {
        "name": "aima",
        "description": "Introduction\n============\n\nThis file gives an overview of the Python code for the algorithms in the\ntextbook Artificial Intelligence: A Modern Approach, also known as AIMA.\nThe code is offered free for your use under the MIT License. As you may\nknow, the textbook presents algorithms in pseudo-code format; as a\nsupplement we provide this code. The intent is to implement all the\nalgorithms in the book, but we are not done yet.\n\nPrerequisites\n=============\n\nThe code is meant for Python 2.5 through 2.7.\n\nHow to Browse the Code\n======================\n\nYou can get some use out of the code here just by browsing, starting at\nthe root of the source tree or by clicking on the links in the index on\nthe project home page. The source code is in the .py files; the .txt\nfiles give examples of how to use the code.\n\nHow to Install the Code\n=======================\n\nIf you like what you see, install the code using either one of these\nmethods:\n\nFrom a command shell on your computer, execute the svn checkout command\ngiven on the source tab of the project. This assumes you have previously\ninstalled the version control system Subversion (svn). Download and\nunzip the zip file listed as a \"Featured download\"on the right hand side\nof the project home page. This is currently (Oct 2011) long out of date;\nwe mean to make a new .zip when the svn checkout settles down.\n\nYou'll also need to install the data files from the aima-data project.\nThese are text files that are used by the tests in the aima-python\nproject, and may be useful for yout own work.\n\nYou can put the code anywhere you want on your computer, but it should\nbe in one directory (you might call it aima but you are free to use\nwhatever name you want) with aima-python as a subdirectory that contains\nall the files from this project, and data as a parallel subdirectory\nthat contains all the files from the aima-data project.\n\nHow to Test the Code\n====================\n\nFirst, you need to install Python (version 2.5 through 2.7; parts of the\ncode may work in other versions, but don't expect it to). Python comes\npreinstalled on most versions of Linux and Mac OS. Versions are also\navailable for Windows, Solaris, and other operating systems. If your\nsystem does not have Python installed, you can download and install it\nfor free.\n\nIn the aima-python directory, execute the command\n\n::\n\n    python doctests.py -v *.py\n\nThe \"-v\" is optional; it means \"verbose\". Various output is printed, but\nif all goes well there should be no instances of the word \"Failure\", nor\nof a long line of \"\". If you do use the \"-v\" option, the last line\nprinted should be \"Test passed.\"\n\nHow to Run the Code\n===================\n\nYou're on your own -- experiment! Create a new python file, import the\nmodules you need, and call the functions you want.\n\nAcknowledgements\n================\n\nMany thanks for the bug reports, corrected code, and other support from\nPhil Ruggera, Peng Shao, Amit Patil, Ted Nienstedt, Jim Martin, Ben\nCatanzariti, and others.",
        "url": "http://pypi.python.org/pypi/aima",
        "summary": "aima -- Artificial Intelligence, A Modern Approach, by Stuart Russell and Peter Norvig",
        "command": "pip install 'aima'"
      },
      "aimes.bundle": {
        "name": "aimes.bundle",
        "description": "``Bundle``\n=========\n\n'bundle_manager' is the major module provided by 'bundle'\n\n'bundle' depends on the following third party library to run:\n  paramiko  (A Python SSHv2 protocal library)\n  Pyro4*    (Python Remote Objects, needed only when using Bundle as a remote object)\n\nUsage example:\n**************\nBefore using bundle_manager, user needs to create a configuration file.\n  src/bundle/example/bundle_credentials.txt is a template configuration file\n\nThere are two ways to use bundle_manager.\nThe first way is to directly import bundle_manager as a library.\n  src/bundle/example/bundle_cml.py shows an example of using bundle_manager in\n  this way.\nThe second way is to launch bundle_manager as a deamon, register it with Pyro4 \nas a remote object. User program should query Pyro4 with bundle_manager's uri\nto get a reference to the remote object and call thie remote object's functions\n  src/bundle/example/bundle_cmlPyro.py shows an example of using bundle_manager\n  in this way.\n\nA screen copy of results on india.futuregrid.org (using aboved mentioned first way)\n**************\nfengl@exa (/home/grad03/fengl/DOEProj) % ls bundle_cml.py bundle\nbundle_cml.py*\n\nbundle:\napi/  bundle_credentials.txt  db/  impl/  __init__.py  __init__.pyc  tools/\nfengl@exa (/home/grad03/fengl/DOEProj) % cat bundle/bundle_credentials.txt \n#bundle cluster credential file\n#each line contains credential of a cluster, used for launching a remote connection to the cluster\n#accepted credential fields include: hostname, port, username, password, key_filename\nfinished_job_trace=/home/grad03/fengl/DOEProj/bundle/db\ncluster_type=moab hostname=india.futuregrid.org username=liux2102 key_filename=/home/grad03/fengl/.ssh/id_rsa h_flag=True\n#cluster_type=moab hostname=xray.futuregrid.org username=liux2102 key_filename=/home/grad03/fengl/.ssh/id_rsa\n#cluster_type=moab hostname=hotel.futuregrid.org username=liux2102 key_filename=/home/grad03/fengl/.ssh/id_rsa\n#cluster_type=moab hostname=sierra.futuregrid.org username=liux2102 key_filename=/home/grad03/fengl/.ssh/id_rsa\n#cluster_type=moab hostname=alamo.futuregrid.org username=liux2102 key_filename=/home/grad03/fengl/.ssh/id_rsa\nfengl@exa (/home/grad03/fengl/DOEProj) % ~/virtualenv/bin/python bundle_cml.py\nEnter command: loadc bundle/bundle_credentials.txt\n2013-10-29 17:11:39,251 india.futuregrid.org india.futuregrid.org INFO     __init__:112  Connected to india.futuregrid.org\nEnter command: list\n['india.futuregrid.org']\nEnter command: showc india.futuregrid.org\n{'state': 'Up', 'num_procs': 248, 'pool': {'compute': {'np': 8, 'num_procs': 168, 'num_nodes': 21}, 'b534': {'np': 8, 'num_procs': 8, 'num_nodes': 1}, 'delta': {'np': 12, 'num_procs': 72, 'num_nodes': 6}}, 'queue_info': {'bravo': {'started': 'True', 'queue_name': 'bravo', 'enabled': 'True', 'pool': 'bravo', 'max_walltime': 86400}, 'batch': {'started': 'True', 'queue_name': 'batch', 'enabled': 'True', 'pool': 'compute', 'max_walltime': 86400}, 'long': {'started': 'True', 'queue_name': 'long', 'enabled': 'True', 'pool': 'compute', 'max_walltime': 604800}, 'delta-long': {'started': 'True', 'queue_name': 'delta-long', 'enabled': 'True', 'pool': 'delta', 'max_walltime': 604800}, 'delta': {'started': 'True', 'queue_name': 'delta', 'enabled': 'True', 'pool': 'delta', 'max_walltime': 86400}, 'b534': {'started': 'True', 'queue_name': 'b534', 'enabled': 'True', 'pool': 'b534', 'max_walltime': 604800}, 'ib': {'started': 'True', 'queue_name': 'ib', 'enabled': 'True', 'pool': 'compute', 'max_walltime': 86400}, 'interactive': {'started': 'True', 'queue_name': 'interactive', 'enabled': 'True', 'pool': 'compute', 'max_walltime': 86400}}, 'num_nodes': 28}\nEnter command: showw india.futuregrid.org\n{'free_procs': 208, 'per_pool_workload': {'compute': {'free_procs': 128, 'free_nodes': 16, 'alive_nodes': 21, 'busy_nodes': 5, 'np': 8, 'busy_procs': 40, 'alive_procs': 168}, 'b534': {'free_procs': 8, 'free_nodes': 1, 'alive_nodes': 1, 'busy_nodes': 0, 'np': 8, 'busy_procs': 0, 'alive_procs': 8}, 'delta': {'free_procs': 72, 'free_nodes': 6, 'alive_nodes': 6, 'busy_nodes': 0, 'np': 12, 'busy_procs': 0, 'alive_procs': 72}}, 'free_nodes': 23, 'alive_nodes': 28, 'busy_nodes': 5, 'busy_procs': 40, 'alive_procs': 248}\nEnter command: quit\n2013-10-29 17:12:17,222 india.futuregrid.org india.futuregrid.org DEBUG    close:1003 close\n2013-10-29 17:12:17,222 india.futuregrid.org india.futuregrid.org DEBUG    run:607  received \"close\" command\ncmd_line_loop finish\n\nA screen copy of results on india.futuregrid.org (using aboved mentioned second way)\n**************\nfengl@exa (/home/grad03/fengl) % ~/virtualenv/bin/python -m Pyro4.naming\n/home/grad03/fengl/virtualenv/local/lib/python2.7/site-packages/Pyro4/core.py:167: UserWarning: HMAC_KEY not set, protocol data may not be secure\n  warnings.warn(\"HMAC_KEY not set, protocol data may not be secure\")\nNot starting broadcast server for localhost.\nNS running on localhost:9090 (127.0.0.1)\nURI = PYRO:Pyro.NameServer@localhost:9090\n\n\n\n#Open another terminal\nfengl@exa (/home/grad03/fengl/DOEProj) % ~/virtualenv/bin/python bundle/impl/bundle_manager.py -D -c bundle/bundle_credentials.txt \ndaemon mode\n2013-10-29 16:05:12,393 india.futuregrid.org india.futuregrid.org INFO     __init__:112  Connected to india.futuregrid.org\n2013-10-29 16:05:12,393 INFO:india.futuregrid.org:bundle_agent.py:112:Connected to india.futuregrid.org\n/home/grad03/fengl/virtualenv/local/lib/python2.7/site-packages/Pyro4/core.py:167: UserWarning: HMAC_KEY not set, protocol data may not be secure\n  warnings.warn(\"HMAC_KEY not set, protocol data may not be secure\")\nObject <__main__.BundleManager object at 0x1c59f90>:\n    uri = PYRO:obj_9262a45a566a46f39c4fad5288fbf9ae@localhost:41540\n    name = BundleManager\nPyro daemon running.\n\n\n\n#Check bundle_manager has successfully registered itself as a remote object to Pyro4\nfengl@exa (/home/grad03/fengl) % ~/virtualenv/bin/python -m Pyro4.nsc list\n/home/grad03/fengl/virtualenv/local/lib/python2.7/site-packages/Pyro4/core.py:167: UserWarning: HMAC_KEY not set, protocol data may not be secure\n  warnings.warn(\"HMAC_KEY not set, protocol data may not be secure\")\n--------START LIST \nBundleManager --> PYRO:obj_9262a45a566a46f39c4fad5288fbf9ae@localhost:41540\nPyro.NameServer --> PYRO:Pyro.NameServer@localhost:9090\n--------END LIST\n\n\n``AIMES``\n=========\n\nAIMES is a DOE ASCR funded collaborative project between the RADICAL\ngroup at Rutgers, University of Minnesota, and the Computation Institute\nat the University of Chicago, that will explore the role of abstractions\nand integrated middleware to support science at extreme scales. AIMES\nwill co-design middleware from an application and infrastructure\nperspective. AIMES will provide abstractions for compute, data and\nnetwork, integrated across multiple levels to provide an interoperable,\nextensible and scalable middleware stack to support extreme-scale\nscience.\n\nAIMES is funded by DOE ASCR under grant numbers: DE-FG02-12ER26115,\nDE-SC0008617, and DE-SC0008651\n\n\nChangelog for ``aimes``\n================================\n\n0.1.0 (2013-06-12)\n------------------\n\n- Created the python module for the bundle project.",
        "url": "http://pypi.python.org/pypi/aimes.bundle",
        "summary": "Bundle based Information System for AIMES",
        "command": "pip install 'aimes.bundle'"
      },
      "aimes.skeleton": {
        "name": "aimes.skeleton",
        "description": "<a href=\"http://dx.doi.org/10.5281/zenodo.13750\"><img src=\"https://zenodo.org/badge/doi/10.5281/zenodo.13750.svg\" alt=\"10.5281/zenodo.13750\"></a>\n\n\nSkeleton\n========\n\nApplication Skeleton is a tool to generate skeleton applications --- easy-to-program, easy-to-run applications --- that mimic a real applications' parallel or distributed performance at a task (but not process) level.\n\nApplication classes that can be represented include: bag of tasks, map reduce, multi-stage workflow, and variations of these with a fixed number of iterations.\n\nApplications are described as one or more stages.\n\nStages are described as one more more tasks.  Stages can also be iterative.\n\nTasks can be serial or parallel, and have compute and I/O (read and write) elements.\n\n=======\n\nDocumentation about Skeletons can be found in the report directory\n\n=======\n\nContributors are welcome!\n\n=======\n\nA paper about the first version of Application Skeletons is:\nZ. Zhang and D. S. Katz, \"Application Skeletons: Encapsulating MTC Application Task Computation and I/O,\" Proceedings of 6th Workshop on Many-Task Computing on Grids and Supercomputers (MTAGS), (in conjunction with SC13), 2013. http://dx.doi.org/10.1145/2503210.2503222\n\nA paper about the current version is:\nZ. Zhang and D. S. Katz, \"Using Application Skeletons to Improve eScience Infrastructure,\" Proceedings of 10th IEEE International Conference on eScience, 2014.\nhttp://dx.doi.org/10.1109/eScience.2014.9 (paper).\nhttp://www.slideshare.net/danielskatz/using-application-skeletons-to-improve-escience-infrastructure (slides).",
        "url": "http://pypi.python.org/pypi/aimes.skeleton",
        "summary": "A Skeleton Generator",
        "command": "pip install 'aimes.skeleton'"
      },
      "aimhii": {
        "name": "aimhii",
        "description": "AIMHII\n=======================\n\nThis package provides software for identifying the genome insertion points random mutants generated by insertional mutagenesis, which have been sequenced as a pool.\n\nThe package will install two executables: aimhii and extract_chimeras.\n\naimhii will run a full analysis starting from sequence data (a FASTQ file), genome sequence, and insert sequence.  extract_chimeras just runs the last step of this analysis, assuming you already have a BAM file and a concatenated genome-insert sequence.\n\nFor details see the project website http://granek.bitbucket.org/projects/aimhii/\n\n\n\nChanges in v0.5.4: Added --plot option to aimhii and shifted a few remaining \"prints\" to logging\n\nChanges in v0.5.3: Shifted debugging prints to logging and added scripts for generating synthetic sequences\n\nChanges in v0.5.2: Lowered pysam version requirement to allow installation using apt-get in Debian v8.\n\nChanges in v0.5.1: Fixed problem with missing DESCRIPTION.rst.",
        "url": "http://pypi.python.org/pypi/aimhii",
        "summary": "A pipeline for mapping insertion mutants from whole genome shotgun data",
        "command": "pip install 'aimhii'"
      },
      "aiml": {
        "name": "aiml",
        "description": "PyAIML implements an interpreter for AIML, the Artificial Intelligence\nMarkup Language developed by Dr. Richard Wallace of the A.L.I.C.E. Foundation.\nIt can be used to implement a conversational AI program.",
        "url": "http://pypi.python.org/pypi/aiml",
        "summary": "An interpreter package for AIML, the Artificial Intelligence Markup Language",
        "command": "pip install 'aiml'"
      },
      "aino-convert": {
        "name": "aino-convert",
        "description": "aino-convert\r\n============\r\n\r\naino-convert is a basically wrapper for `ImageMagick convert`_ with caching.\r\nThe main purpose is to help generate quality thumbnails simply and\r\nefficiently. During the development of sorl-thumbnail I learned some and\r\neventually I took the plunge to write something using ImageMagick convert\r\ninstead of PIL.\r\n\r\nPros\r\n----\r\n- Simple thumbnail tag generating high quality output\r\n- Remote files handling on the fly\r\n- Usage of convert commandline syntax for infinate flexibility\r\n- Caching mechanism\r\n- Cleanup of unused images or conversions of images can be made\r\n- Storage is local file storage only\r\n\r\nCons\r\n----\r\n- Requirements: convert, pyexiv2 is nice to have\r\n- Storage is local file storage only\r\n- Security (protecting the developer from himself)\r\n\r\nDemo\r\n====\r\nThere is a demo in the `demo` directory.\r\nTo run the demo it just cd in to it and type: `./run`\r\n\r\n\r\n.. _ImageMagic convert: http://www.imagemagick.org/",
        "url": "http://pypi.python.org/pypi/aino-convert",
        "summary": "Magick for Django",
        "command": "pip install 'aino-convert'"
      },
      "aino-jstools": {
        "name": "aino-jstools",
        "description": "============\naino-jstools\n============\n\naino-jstools is a set of tools for working with JavaScript and Django.\nPrimarily it compiles javascripts.\n\n\nDesign background\n-----------------\nWe wanted to make a tool that made including a bunch of JavaScripts in a\ntemplate easy and clean and compiling all those JavaScripts into packed pieces\nin production for optimal performance. The other goal we wanted to achive was\nto expose urls defined in ``urls.py``, ``MEDIA_URL``, ``DEBUG`` settings to\nJavaScript code. Our future includes making a cleaner implementation for i18n\nin JavaScript than the one provided by Django.\n\n\nRequirements\n------------\n- Django 1.x\n- Python 2.5+\n- Java (for compiling JavaScripts)\n\n\nInstall\n-------\nInclude ``jstools`` in ``INSTALLED_APPS`` in your project settings.\nOptionally include the jstools/urls.py in your ``urls.py``::\n\n   (r'^jstools/', include('jstools.urls'))\n\n\nTemplate usage\n--------------\nFirst define your scripts in a template as follows::\n\n    {% scripts \"js/mysite-min.js\" %}\n        http://yui.yahooapis.com/3.1.0/build/yui/yui-min.js\n        js/a.js\n        js/b.js\n        {% url jshelper %}\n    {% endscripts %}\n\nWhen ``settings.DEBUG`` is ``True`` this will translate to::\n\n    <script src=\"http://yui.yahooapis.com/3.1.0/build/yui/yui-min.js\"></script>\n    <script src=\"{{ MEDIA_URL }}js/a.js\"></script>\n    <script src=\"{{ MEDIA_URL }}js/b.js\"></script>\n    <script src=\"{% url jshelper %}\"></script>\n\nWhen ``settings.DEBUG`` is ``False`` this will translate to::\n\n    <script src=\"{{ MEDIA_URL }}js/mysite-min.js?TIMESTAMP\"></script>\n\nwhere ``TIMESTAMP`` is based on modification date of\n``{{ MEDIA_ROOT }}js/myste-min.js``\n\n\nCompiling\n---------\nCompiling all defined scripts is as simple as running::\n\n    python manage.py buildjs\n\nIf you are using the default ``filesystem`` and/or\n``app_directories`` this management command will find all templates with\n``{% scripts %}`` tags and compile its contents into the first argument of the\ntag.\n\n\njshelper view\n-------------\nThis view will output named urls, ``settings.MEDIA_URL``, ``settings.DEBUG``\n(I suggest you override this in your template unless you want to recompile the\nscript when you change your ``DEBUG`` setting) for use in your JavaScript code. You\nwill have access to a JavaScript object named ``JSTOOLS`` by default, you can\nchange the name by setting ``JSTOOLS_NAMESPACE``.\n\n``JSTOOLS.settings.MEDIA_URL``\n    ``settings.MEDIA_URL``\n\n``JSTOOLS.settings.DEBUG``\n    ``settings.DEBUG``\n\n``JSTOOLS.get_url``\n    This function will get named urls defined in your ``urls.py``. First argument is\n    the name of the named url, subsequent arguments are arguments passed to that\n    pattern. Examples::\n\n        JSTOOLS.get_url('jshelper');\n        JSTOOLS.get_url('blog_entry', 2010, 04, 25, 'aino-jstools');",
        "url": "http://pypi.python.org/pypi/aino-jstools",
        "summary": "JavaScript tools for Django",
        "command": "pip install 'aino-jstools'"
      },
      "aino-mutations": {
        "name": "aino-mutations",
        "description": "==============\naino-mutations\n==============\n\naino-mutations is a tool to call mutation scripts at a certain revision\nof a mercurial repository. Mutation scripts are typically scripts that perform\ndatabase refactoring of some sort. aino-convert is not intelligent:\n\n- Does not offer introspection\n\n- Mutation scripts are intended to use raw sql for schema migration\n  which means you will be locked to a particular database engine, that of\n  your own choice of course.\n\n\nWhy?\n----\naino-mutations solves the problem of running a mutation in the correct\nenvironment. Often when you do mutations you want to perform some logic\nto insert or remove data. To perform this logic we need the environment\nin which the mutation was written for. aino-convert automatically updates\na mercurial repository to the revision where the mutation was added and\nexecutes the mutation script.\n\n\nRequirements\n------------\n\n- Django with Multi DB support, v1.2+, or trunk until released.\n\n- Mercurial, only tested with v1.5\n\n- Django project managed by a mercurial repository\n\n\nInstallation\n------------\n\n1. Add ``mutations`` to your pythonpath\n\n2. Add ``mutations`` to ``INSTALLED_APPS``\n\n\nConfiguration\n-------------\nMutation scripts are by default looked for in a ``mutations`` subdirectory of\nyour mercurial repository root, you can change this by setting ``MUTATIONS_ROOT``\nin your settings file. Note that ``MUTATIONS_ROOT`` should be a relative\ndirectory path to your repository root.\n\n\nUsage\n-----\naino-mutations seperates mutations for different databases and therefore\nyou need to specify what database you are affecting with your mutation.\nTo add a mutation:\n\n1. Add the python file (mutation) to ``MUTATIONS_ROOT/alias/``\n   where ``alias`` is the alias used in your settings file\n   (the default is called ``default``).\n\n2. Add the file to the repository: ``hg add path/to/mutation``\n\n3. Commit: ``hg ci -m\"my first mutation\"``\n\n4. Now run the mutation: ``python manage.py mutate``\n\n\nMutations\n---------\nMutations are just normal python files that do whatever you like.\nFor convenience there are some local variables passed to the mutation scripts:\n\n- ``cursor``: a cursor instance for the current database\n\n- ``commit_unless_managed`` is just a shortcut for\n  ``django.db.transaction.commit_unless_managed``\n\n- ``dry``: this will be True if ``mutate`` is run with the ``--dry`` option\n  which can be usefull for displaying some info to the user.\n\n\nFAQ\n---\n\n- *I created a mutation that was wrong, what do I do?*\n- All you need to do is to remove it from the repository:\n  ``hg rm path/to/mutation; hg ci -m\"no more bad code\"``\n\n\n- *I want to try a mutation before commiting, how can i do that?*\n- run: ``python manage.py runmutation path/to/mutation``\n\n\n- *I have my django project in a deployment environment, can I still use\n  aino-mutations?*\n- The best way to solve this since aino-mutations may update project\n  files to a certain revision while performing the mutations it is best to\n  clone the repository to another location while accessing the same databases.",
        "url": "http://pypi.python.org/pypi/aino-mutations",
        "summary": "Mutating for evolution using Django and Mercurial",
        "command": "pip install 'aino-mutations'"
      },
      "aino-utkik": {
        "name": "aino-utkik",
        "description": "aino-utkik\n==========\n\naino-utkik provides minimalistic class based views for Django focusing on\ncommon usage, readability and convienience.\n\nFor Django 1.3 or earlier use 0.7.8\nFor Django 1.7 or later use 0.8.0 or later\n\nExample::\n\n    # urls.py\n    from utkik.dispatch import *\n\n    urlpatterns = patterns('',\n        (r'^(?P<slug>[-\\w]+)/$', 'news.NewsDetailView'),\n        (r'^$', 'news.NewsListView'),\n    )\n\n    # news/views.py\n    from django.shortcuts import get_object_or_404\n    from news.models import News\n    from utkik import View\n\n    class NewsDetailView(View):\n        template_name = 'news/news_detail.html'\n\n        def get(self, slug):\n            self.c.news = get_object_or_404(News.objects, slug=slug)\n\n\n    class NewsListView(View):\n        template_name = 'news/news_list.html'\n\n        def get(self):\n            self.c.news_list = News.objects.all()",
        "url": "http://pypi.python.org/pypi/aino-utkik",
        "summary": "Small, clean code with a lazy view dispatcher and class based views for Django.",
        "command": "pip install 'aino-utkik'"
      },
      "aio": {
        "name": "aio",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aio",
        "summary": "A CPython extension module wrapping the POSIX aio_* syscalls",
        "command": "pip install 'aio'"
      },
      "aio2gis": {
        "name": "aio2gis",
        "description": "python-aio2gis\n============\n\nA Python library for accessing the 2gis API via asyncio interface",
        "url": "http://pypi.python.org/pypi/aio2gis",
        "summary": "asyncio-powered 2gis library for Python",
        "command": "pip install 'aio2gis'"
      },
      "aio2py": {
        "name": "aio2py",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aio2py",
        "summary": "Simple web Frame",
        "command": "pip install 'aio2py'"
      },
      "aioamqp": {
        "name": "aioamqp",
        "description": "aioamqp\n=======\n\n.. image:: https://badge.fury.io/py/aioamqp.svg\n    :target: http://badge.fury.io/py/aioamqp\n.. image:: https://travis-ci.org/Polyconseil/aioamqp.svg?branch=master\n    :target: https://travis-ci.org/Polyconseil/aioamqp\n\n\n``aioamqp`` library is a pure-Python implementation of the `AMQP 0.9.1 protocol`_.\n\nBuilt on top on Python's asynchronous I/O support introduced in `PEP 3156`_, it provides an API based on coroutines, making it easy to write highly concurrent applications.\n\nBug reports, patches and suggestions welcome! Just open an issue_ or send a `pull request`_.\n\n\n.. _AMQP 0.9.1 protocol: https://www.rabbitmq.com/amqp-0-9-1-quickref.html\n.. _PEP 3156: http://www.python.org/dev/peps/pep-3156/\n.. _issue: https://github.com/Polyconseil/aioamqp/issues/new\n.. _pull request: https://github.com/Polyconseil/aioamqp/compare/",
        "url": "http://pypi.python.org/pypi/aioamqp",
        "summary": "AMQP implementation using asyncio",
        "command": "pip install 'aioamqp'"
      },
      "aio.app": {
        "name": "aio.app",
        "description": "Detailed documentation\n**********************\n\naio.app\n=======\n\nApplication runner for the aio_ asyncio framework\n\n.. _aio: https://github.com/phlax/aio\n\n\nBuild status\n------------\n\n.. image:: https://travis-ci.org/phlax/aio.app.svg?branch=master\n\t       :target: https://travis-ci.org/phlax/aio.app\n\n\nInstallation\n------------\n\nRequires python >= 3.4\n\nInstall with:\n\n.. code:: bash\n\n\t  pip install aio.app\n\n\nQuick start - hello world scheduler\n-----------------------------------\n\nSave the following into a file \"hello.conf\"\n\n.. code:: ini\n\t  \n\t  [schedule/EXAMPLE]\n\t  every = 2\n\t  func = my_example.schedule_handler\n\nAnd save the following into a file named \"my_example.py\"\t  \n\t  \n.. code:: python\n\n\t  import asyncio\n\t  \n\t  def schedule_handler(event):\n\t      yield from asyncio.sleep(1)\n\t      print (\"Received scheduled: %s\" % event.name)\n\nRun with the aio run command\n\n.. code:: bash\n\n\t  aio run -c hello.conf\n\t  \n\n\nThe *aio config* command\n------------------------\n\nWhen saving or reading configuration options, configuration files are searched for in order from the following locations\n\n- aio.conf\n- etc/aio.conf\n- /etc/aio/aio.conf\n\nTo dump the system configuration you can run\n\n.. code:: bash\n\n\t  aio config\n\nTo dump a configuration section you can use -g or --get with the section name\n\n.. code:: bash\n\n\t  aio config -g aio\n\n\t  aio config --get aio/commands\n\nTo get a configuration option, you can use -g with the section name and option\n\n.. code:: bash\n\n\t  aio config -g aio:log_level\n\n\t  aio config --get listen/example:example-signal\n\nYou can set a configuration option with -s or --set\n\nOptions containing interpolation should be enclosed in single quotes\n\nMulti-line options should be enclosed in \" and separated with \"\\\\n\"\n\n.. code:: bash\n\n\t  aio config --set aio:log_level DEBUG\n\n\t  aio config -s aio/otherapp:log_level '${aio:log_level}'\n\t  \n\t  aio config -s listen/example:example-signal \"my.listener\\nmy.listener2\"\n\nIf no configuration files are present in the standard locations, aio will attempt to save in \"aio.conf\" in the current working directory\n\nTo get or set an option in a particular file you can use the -f flag\n\n.. code:: bash\n\n\t  aio config -g aio:modules -f custom.conf\n\n\t  aio config -s aio:log_level DEBUG -f custom.conf\n\nWhen getting config values with the -f flag, ExtendedInterpolation_ is not used, and you therefore see the raw values\n\n\n\nthe *aio run* command\n---------------------\n\nYou can run an aio app as follows:\n\n.. code:: bash\n\n\t  aio run\n\nOr with a custom configuration file\n\t  \n.. code:: bash\n\n\t  aio -c custom.conf run\n\n\nOn startup aio run sets up the following\n\n- Configuration - system-wide configuration\n- Modules - initialization and configuration of modules\n- Logging - system logging policies  \n- Schedulers - functions called at set times\n- Servers - listening on tcp/udp or other type of socket\n- Signals - functions called in response to events\n\n\nConfiguration\n~~~~~~~~~~~~~\n\nConfiguration is in ini syntax\n\n.. code:: ini\n\n\t  [aio]\n\t  foo = eggs\n\t       spam\n\nWhile the app is running the system configuration is importable from aio.app\n\n.. code:: python\n\n\t  from aio.app import config\n\nConfiguration is parsed using ExtendedInterpolation_ as follows\n\n- aio.app defaults read\n- user configuration read to initialize modules\n- \"aio.conf\" read from initialized modules where present\n- user configuration read again\n\n\nLogging\n~~~~~~~\n\nLogging policies can be placed in the configuration file, following pythons fileConfig_ format\n\n.. _fileConfig: https://docs.python.org/3/library/logging.config.html#logging-config-fileformat\n\nAs the configuration is parsed with ExtendedInterpolation_ you can use options from other sections\n\n.. code:: ini\n\n\t  [logger_root]\n\t  level=${aio:log_level}\n\t  handlers=consoleHandler\n\t  qualname=aio\n\nThe default aio:log_level is INFO\n\nAny sections that begin with handler, logger, or formatter will automattically be added to the relevant logging section\n\nSo by adding a section such as\n\n.. code:: ini\n\n\t  [logger_custom]\n\t  level=${aio:log_level}\n\t  handlers=consoleHandler\n\t  qualname=custom\n\n\"logger_custom\" will automatically be added to the logger keys:\n\n.. code:: ini\n\n\t  [loggers]\n\t  keys=root,custom\n\n\nModules\n~~~~~~~\n\nYou can list any modules that should be imported at runtime in the configuration\n\n.. code:: ini\n\n\t  [aio]\n\t  modules = aio.web.server\n\t          aio.manhole.server\n\nConfiguration for each module is read from a file named \"aio.conf\" in the module's path, if it exists.\n\nThe initialized modules can be accessed from aio.app\n\n.. code:: python\n\n\t  from aio.app import modules\n\n\nSchedulers\n~~~~~~~~~~\n\nSchedule definition sections are in the following format\n\n.. code:: ini\n\n\t  [schedule/SCHEDULE_NAME]\n\n\nSpecify the frequency and the function to call. The function will be wrapped in a coroutine if it isnt one already\n\n.. code:: ini\n\n\t  [schedule/example]\n\t  every = 2\n\t  func = my.scheduler.example_scheduler\n\nThe scheduler function receives a ScheduledEvent object\n\n.. code:: python\n\n\t  def example_scheduler(event):\n              yield from asyncio.sleep(2)\n\t      # do something\n\t      print(event.name)\n\t      pass\n\nServers\n~~~~~~~\n\nServer definition sections are in the following format\n\n.. code:: ini\n\n\t  [server/SERVER_NAME]\n\nThe server requires either a factory or a protocol to start\n\nProtocol configuration example:\n\n.. code:: ini\n\n\t  [server/example]\n\t  protocol = my.example.MyServerProtocol\n\t  port = 8888\n\nProtocol example code:\n\n.. code:: python\n\n\t  class MyServerProtocol(asyncio.Protocol):\n\n\t      def connection_made(self, transport):\n\t          self.transport = transport\n\n\t      def data_received(self, data):\n\t          # do stuff\n\t          self.transport.close()\n\nFor the protocol option you can either specify a subclass of asyncio.Protocol or you can use a function decorated with aio.app.server.protocol\n\n.. code:: ini\n\n\t  [server/example]\n\t  protocol = my.example.protocol\n\t  port = 8888\n\nExample code for a server protocol function\n\n.. code:: python\n\n\t  import asyncio\n\t  import aio.app\n\t  \n\t  @aio.app.server.protocol\n\t  def server_protocol():\n\t      yield from asyncio.sleep(1)\n\t      # do something\n\t      \n\t      return MyServerProtocol\n\t  \n\nIf you need further control over how the protocol is attached you can specify a factory method\n\nFactory configuration example:\n\n.. code:: ini\n\n\t  [server/example]\n\t  factory = my.example.server_factory\n\t  port = 8080\n\nThe factory method must be wrapped in aio.app.server.factory, and is called in a coroutine\n\n.. code:: python\n\n\t  @aio.app.server.factory\n\t  def server_factory(name, protocol, address, port):\n\t      yield from asyncio.sleep(1)\n\t      # do something\n\t  \n\t      loop = asyncio.get_event_loop()\n\t      return (\n\t          yield from loop.create_server(\n\t\t     MyServerProtocol, address, port))\n\n\nSignals\n~~~~~~~\n\nSignal definition sections are in the following format\n\n.. code:: ini\n\n\t  [signal/SIGNAL_NAME]\n\nAn example listen configuration section\n\n.. code:: ini\n\n\t  [listen/example]\n\t  example-signal = my.example.listener\n\nAnd an example listener function. The listener function will be called as a coroutine\n\n.. code:: python\n\n\t  def listener(signal):\n\t      yield from asyncio.sleep(2)\n\t      print(signal.data)\n\nSignals are emitted in a coroutine\n\n.. code:: python\n\n\t  yield from app.signals.emit(\n              'example-signal', \"BOOM!\")\n\nYou can add multiple subscriptions within each configuration section\n\nYou can also subscribe multiple functions to a signal, and you can have multiple \"listen/\" sections\n\n.. code:: ini\n\n\t  [listen/example]\n\t  example-signal = my.example.listener\n\t  example-signal-2 = my.example.listener2\n\t                  my.example.listener\n\n\t  [listen/example-2]\n\t  example-signal-3 = my.example.listener2\t\t\t \n\n   \nThe *aio test* command\n----------------------\n\nYou can test the modules set in the aio:modules configuration option\n\n.. code:: ini\n\n\t  [aio]\n\t  modules = aio.config\n                   aio.core\n\t           aio.signals\n\nBy default the aio test command will test all of your test modules\n\t\t   \n.. code:: bash\n\n\t  aio test\n\nYou can also specify a module, or modules\n\n.. code:: bash\n\n\t  aio test aio.app\n\n\t  aio test aio.app aio.core\n\nIf you want to specify a set of modules for testing other than your app modules, you can list them in aio/testing:modules\n\n.. code:: ini\n\n\t  [aio/testing]\n\t  modules = aio.config\n                   aio.core\n\nThese can include the app modules\n\n.. code:: ini\n\n\t  [aio/testing]\n\t  modules = ${aio:modules}\n\t           aio.web.page\n\t\t   aio.web.server\n\t\t   \n\nDependencies\n------------\n\naio.app depends on the following packages\n\n- aio.core_\n- aio.signals_\n- aio.config_\n\n\nRelated software\n----------------\n\n- aio.testing_\n- aio.http.server_\n- aio.web.server_\n- aio.manhole.server_\n\n.. _aio.testing: https://github.com/phlax/aio.testing\n.. _aio.core: https://github.com/phlax/aio.core\n.. _aio.signals: https://github.com/phlax/aio.signals\n.. _aio.config: https://github.com/phlax/aio.config\n\n.. _aio.http.server: https://github.com/phlax/aio.http.server\n.. _aio.web.server: https://github.com/phlax/aio.web.server\n.. _aio.manhole.server: https://github.com/phlax/aio.manhole.server\n\n.. _ExtendedInterpolation: https://docs.python.org/3/library/configparser.html#interpolation-of-values\n\n\n\n\n\naio.app usage\n-------------\n\nThe aio command can be run with any commands listed in the [aio/commands] section of its configuration\n\nThere are also 3 builtin commands - run, config and test\n\nInitially aio.app does not have any config, signals, modules or servers\n\n>>> import aio.app\n\n>>> print(aio.app.signals, aio.app.config, aio.app.modules, aio.app.servers)\nNone None () {}\n\n\nLets start the app runner in a test loop with the default configuration and print out the signals and config objects\n\n>>> import aio.testing\n>>> from aio.app.runner import runner\n\n>>> @aio.testing.run_until_complete\n... def run_app():\n...     runner(['run'])\n... \n...     print(aio.app.signals)\n...     print(aio.app.config)\n...     print(aio.app.modules)\n...     print(aio.app.servers)\n\n>>> run_app()\n<aio.signals.Signals object ...>\n<configparser.ConfigParser ...>\n(<module 'aio.app' from ...>,)\n{}\n\n\nClear the app\n-------------\n\nWe can clear the app vars.\n\nThis will also close any socket servers that are currently running\n\n>>> aio.app.clear()\n\n>>> print(aio.app.signals, aio.app.config, aio.app.modules, aio.app.servers)\nNone None () {}\n\n\nAdding a signal listener\n------------------------\n\nWe can add a signal listener in the app config\n\n>>> config = \"\"\"\n... [listen/testlistener]\n... test-signal = aio.app.tests._example_listener\n... \"\"\"\n\nLets create a test listener and make it importable\n\nThe listener needs to be wrapped with aio.app.signal.listener and is called in a coroutine\n\n>>> import asyncio\n\n>>> @aio.app.signal.listener\n... def listener(signal):\n...     yield from asyncio.sleep(1)\n...     print(\"Listener received: %s\" % signal.data)\n\n>>> aio.app.tests._example_listener = listener\n\nRunning the test...\n\n>>> @aio.testing.run_until_complete \n... def run_app(message):\n...     runner(['run'], config_string=config)\n...     yield from aio.app.signals.emit('test-signal', message)\n...     aio.app.clear()\n\n>>> run_app('BOOM!')\nListener received: BOOM!\n\n\nWe can also add listeners programatically\n\n>>> @aio.testing.run_until_complete \n... def run_app(message):\n...     runner(['run'])\n... \n...     aio.app.signals.listen('test-signal-2', aio.app.signal.listener(listener))\n...     yield from aio.app.signals.emit('test-signal-2', message)\n...     aio.app.clear()  \n\n>>> run_app('BOOM AGAIN!')\nListener received: BOOM AGAIN!\n  \n\nAdding app modules\n------------------\n\nWhen you run the app with the default configuration, the only module listed is aio.app\n\n>>> @aio.testing.run_until_complete\n... def run_app(config_string=None):\n...     runner(['run'], config_string=config_string)\n...     print(aio.app.modules)\n...     aio.app.clear()\n\n>>> run_app()\n(<module 'aio.app' from ...>,)\n\nWe can make the app runner aware of any modules that we want to include, these are imported at runtime\n\n>>> config = \"\"\"\n... [aio]\n... modules = aio.app\n...          aio.core\n... \"\"\"\n\n>>> run_app(config_string=config)\n(<module 'aio.app' from ...>, <module 'aio.core' from ...>)\n\n\nRunning a scheduler\n-------------------\n\nA basic configuration for a scheduler\n\n>>> config = \"\"\"\n... [schedule/test-scheduler]\n... every: 2\n... func: aio.app.tests._example_scheduler\n... \"\"\"\n\nLets create a scheduler function and make it importable.\n\nThe scheduler function is wrapped in a coroutine\n\n>>> def scheduler(event):\n...      print('HIT: %s' % event.name)\n\n>>> aio.app.tests._example_scheduler = scheduler\n\nWe need to use a aio.testing.run_forever to wait for the scheduled events to occur\n\n>>> @aio.testing.run_forever(timeout=5)\n... def run_app():\n...     runner(['run'], config_string=config)\n... \n...     return aio.app.clear\n    \nRunning the test for 5 seconds we get 3 hits\n\n>>> run_app()\nHIT: test-scheduler\nHIT: test-scheduler\nHIT: test-scheduler\n\n\nRunning a server\n----------------\n\nLets set up and run an addition server\n\nAt a minimum we should provide a protocol and a port to listen on\n\n>>> config_server_protocol = \"\"\"\n... [server/additiontest]\n... protocol: aio.app.tests._example_AdditionServerProtocol\n... port: 8888\n... \"\"\"\n\nLets create the server protocol and make it importable\n\n>>> class AdditionServerProtocol(asyncio.Protocol):\n... \n...     def connection_made(self, transport):\n...         self.transport = transport\n... \n...     def data_received(self, data):\n...         nums = [\n...            int(x.strip())\n...            for x in\n...            data.decode(\"utf-8\").split(\"+\")] \n...         self.transport.write(str(sum(nums)).encode())\n...         self.transport.close()\n\n>>> aio.app.tests._example_AdditionServerProtocol = AdditionServerProtocol\n\nAfter the server is set up, let's call it with a simple addition\n\n\n>>> @aio.testing.run_forever\n... def run_addition_server(config_string, addition):\n...     runner(['run'], config_string=config_string)\n... \n...     def call_addition_server():\n...          reader, writer = yield from asyncio.open_connection(\n...              '127.0.0.1', 8888)\n...          writer.write(addition.encode())\n...          yield from writer.drain()\n...          result = yield from reader.read()\n...          aio.app.clear()\n... \n...          print(int(result))\n... \n...     return call_addition_server\n\n>>> run_addition_server(\n...     config_server_protocol,\n...     '2 + 2 + 3')\n7\n\nIf you need more control over how the server protocol is created you can specify a factory instead\n\n>>> config_server_factory = \"\"\"\n... [server/additiontest]\n... factory = aio.app.tests._example_addition_server_factory\n... port: 8888\n... \"\"\"\n\nThe factory method must be decorated with aio.app.server.factory\n\n>>> @aio.app.server.factory\n... def addition_server_factory(name, protocol, address, port):\n...     loop = asyncio.get_event_loop()\n...     return (\n...         yield from loop.create_server(\n...            AdditionServerProtocol,\n...            address, port))\n\n>>> aio.app.tests._example_addition_server_factory = addition_server_factory\n\n>>> run_addition_server(\n...     config_server_protocol,\n...     '17 + 5 + 1')\n23",
        "url": "http://pypi.python.org/pypi/aio.app",
        "summary": "Aio application runner",
        "command": "pip install 'aio.app'"
      },
      "aioauth-client": {
        "name": "aioauth-client",
        "description": "AIOHTTP OAuth Client\n####################\n\n.. _description:\n\nAIOHTTP OAuth Client -- Short description.\n\n.. _badges:\n\n.. image:: http://img.shields.io/travis/klen/aioauth-client.svg?style=flat-square\n    :target: http://travis-ci.org/klen/aioauth-client\n    :alt: Build Status\n\n.. image:: http://img.shields.io/pypi/v/aioauth-client.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/aioauth-client\n\n.. image:: http://img.shields.io/pypi/dm/aioauth-client.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/aioauth-client\n\n.. _contents:\n\n.. contents::\n\n.. _requirements:\n\nRequirements\n=============\n\n- python >= 3.3\n\n.. _installation:\n\nInstallation\n=============\n\n**AIOHTTP OAuth Client** should be installed using pip: ::\n\n    pip install aioauth-client\n\n.. _usage:\n\nUsage\n=====\n\n\n.. code:: python\n\n    # OAuth1\n    from aioauth_client import TwitterClient\n\n    twitter = TwitterClient(\n        consumer_key='J8MoJG4bQ9gcmGh8H7XhMg',\n        consumer_secret='7WAscbSy65GmiVOvMU5EBYn5z80fhQkcFWSLMJJu4',\n    )\n\n    request_token, request_token_secret = yield from twitter.get_request_token()\n\n    authorize_url = twitter.get_authorize_url(request_token)\n    print(\"Open\",authorize_url,\"in a browser\")\n    # ...\n    # Reload client to authorize_url and get oauth_verifier\n    # ...\n    print(\"PIN code:\")\n    oauth_verifier = input()\n    oauth_token, oauth_token_secret = yield from twitter.get_access_token(oauth_verifier)\n\n    # Save the tokens for later use\n\n    # ...\n\n    twitter = TwitterClient(\n        consumer_key='J8MoJG4bQ9gcmGh8H7XhMg',\n        consumer_secret='7WAscbSy65GmiVOvMU5EBYn5z80fhQkcFWSLMJJu4',\n        oauth_token=oauth_token,\n        oauth_token_secret=oauth_token_secret,\n    )\n\n    timeline = yield from twitter.request('GET', 'statuses/home_timeline.json')\n    content = yield from timeline.read()\n    print(content)\n\n.. code:: python\n\n    # OAuth2\n    from aioauth_client import GithubClient\n\n    github = GithubClient(\n        client_id='b6281b6fe88fa4c313e6',\n        client_secret='21ff23d9f1cad775daee6a38d230e1ee05b04f7c',\n    )\n\n    authorize_url = github.get_authorize_url(scope=\"user:email\")\n\n    # ...\n    # Reload client to authorize_url and get code\n    # ...\n\n    otoken = yield from github.get_access_token(code)\n\n    # Save the token for later use\n\n    # ...\n\n    github = GithubClient(\n        client_id='b6281b6fe88fa4c313e6',\n        client_secret='21ff23d9f1cad775daee6a38d230e1ee05b04f7c',\n        access_token=otoken,\n    )\n\n    response = github.request('GET', 'user')\n    user_info = yield from response.json()\n\n\nExample\n-------\n\nRun example with command: ::\n\n    make run\n\nOpen http://fuf.me:5000 in your browser.\n\n.. _bugtracker:\n\nBug tracker\n===========\n\nIf you have any suggestions, bug reports or\nannoyances please report them to the issue tracker\nat https://github.com/klen/aioauth-client/issues\n\n.. _contributing:\n\nContributing\n============\n\nDevelopment of AIOHTTP OAuth Client happens at: https://github.com/klen/aioauth-client\n\n\nContributors\n=============\n\n* klen_ (Kirill Klenov)\n\n.. _license:\n\nLicense\n=======\n\nLicensed under a `MIT license`_.\n\nIf you wish to express your appreciation for the role, you are welcome to send\na postcard to:\n\n    Kirill Klenov\n    pos. Severny 8-3\n    MO, Istra, 143500\n    Russia\n\n.. _links:\n\n\n.. _klen: https://github.com/klen\n\n.. _MIT license: http://opensource.org/licenses/MIT",
        "url": "http://pypi.python.org/pypi/aioauth-client",
        "summary": null,
        "command": "pip install 'aioauth-client'"
      },
      "aioavast": {
        "name": "aioavast",
        "description": "Asyncio library for Avast Antivirus\n===================================\n\nasyncio (PEP 3156) Avast Linux support\n\nFeatures\n--------\n\n- Scanning files and/or directories.\n- Checking URLs.\n- Exclude files from the scanning.\n- Get and set the list of enabled or disabled pack and flags.\n\n\nRequirements\n------------\n\n- Python >= 3.3\n- asyncio https://pypi.python.org/pypi/asyncio\n\n\nLicense\n-------\n\n``aioavast`` is offered under the MIT license.\n\n\nSource code\n------------\n\nThe latest developer version is available in a github repository:\nhttps://github.com/earada/aioavast\n\nGetting started\n---------------\n\nScanning\n^^^^^^^^\n\nScan a file and prints its output:\n\n.. code-block:: python\n\n  import asyncio\n  from aioavast import Avast\n\n  @asyncio.coroutine\n  def scan(item):\n      av = Avast()\n      yield from av.connect()\n      return (yield from av.scan(item))\n\n  if __name__ == '__main__':\n      loop = asyncio.get_event_loop()\n      results = loop.run_until_complete(scan('/bin/ls'))\n      print(results)\n\n\nYou can check an url too:\n\n.. code-block:: python\n\n  return (yield from av.checkurl('http://python.org'))\n\n\nExclude items\n^^^^^^^^^^^^^\n\nThere is also a possibility to exclude certain files from being scanned.\n\n.. code-block:: python\n\n  import asyncio\n  from aioavast import Avast\n\n  @asyncio.coroutine\n  def dont_scan(item):\n      av = Avast()\n      yield from av.connect()\n      yield from av.exclude(item)\n      return (yield from av.scan(item))\n\n  if __name__ == '__main__':\n      loop = asyncio.get_event_loop()\n      results = loop.run_until_complete(scan('/bin/ls'))\n      print(results)\n\nYou can retrieve excluded items by:\n\n.. code-block:: python\n\n  excluded = yield from av.exclude()\n\n\nOther methods\n^^^^^^^^^^^^^\n\nYou could modify Flags and Packs too.\n\n.. code-block:: python\n\n  flags = yield from av.flags()\n  yield from av.flags(\"-allfiles\")\n\n  packs = yield from av.pack()\n  yield from av.flags(\"-ole\")",
        "url": "http://pypi.python.org/pypi/aioavast",
        "summary": "Asyncio library for Avast antivirus",
        "command": "pip install 'aioavast'"
      },
      "aioawait": {
        "name": "aioawait",
        "description": "aioawait\n========\n\nThis package implements two primitives (**await** and **spawn**) on top\nof asyncio infrastructure of Python 3. This two functions allow us to call\nasynchronous functions from synchronous code. \n \nInstallation\n------------\n\n.. code:: bash\n\n    pip3 install aioawait\n\nExample\n-------\n\n.. code:: python\n\n    from asyncio.tasks import coroutine, sleep, async\n    from aioawait import await, spawn\n    \n    @coroutine\n    def monitor(name, size, total):\n        while True:\n            print('\\ttotal', name, total)\n            yield from sleep(1)\n    \n    @coroutine\n    def counter(name, size, total):\n        \"\"\"sums into total all numbers from 0 to size\"\"\"\n        m = async(monitor(name, size, total))\n    \n        # monitor could be called using spawn. eg:\n        # m = spawn(monitor(name, size, total))\n    \n        for n in range(size):\n            total[0] += n\n            if n % 5 == 0:\n                print('sleeping', name, n)\n                yield from sleep(2)\n            else:\n                print('counting', name, n)\n                yield\n    \n        # stops monitor\n        m.cancel()\n    \n        return name, 'done', n, total\n    \n    class Counter:\n        \"\"\"note that this class has no asynchronous code\"\"\"\n        \n        def __init__(self):\n            self.cb = spawn(counter('b', 40, [0]))\n    \n        @property\n        def counter_a(self):\n            return await(counter('a', 20, [0]))\n    \n        @property\n        def counter_b(self):\n            return await(self.cb)\n     \n    if __name__ == '__main__':\n        c = Counter()\n        print(c.counter_a)\n        print(c.counter_b)",
        "url": "http://pypi.python.org/pypi/aioawait",
        "summary": "Call asynchronous functions of Python 3.4.3 asyncio infrastructure from synchronous code",
        "command": "pip install 'aioawait'"
      },
      "aio-beanstalk": {
        "name": "aio-beanstalk",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aio-beanstalk",
        "summary": "Asyncio-based client for beanstalkd task server",
        "command": "pip install 'aio-beanstalk'"
      },
      "aiobottle": {
        "name": "aiobottle",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aiobottle",
        "summary": "Aiobottle, a warper bottle use aiohttp base on  Asyncio (PEP-3156)",
        "command": "pip install 'aiobottle'"
      },
      "aiocoap": {
        "name": "aiocoap",
        "description": "aiocoap -- The Python CoAP library\n==================================\n\nThe aiocoap package is a Python implementation of CoAP, the Constrained\nApplication Protocl (`RFC 7252`_, more info at http://coap.technology/).\n\nIt uses the asyncio module introduced in Python 3.4 to facilitate concurrent\noperations while maintaining a simple to use interface and not depending on\nanything outside the standard library.\n\naiocoap is originally based on txThings_. If you want to use CoAP in your\nexisting twisted application, or can not migrate to Python 3 yet, that is\nprobably more useful to you than aiocoap.\n\n.. _`RFC 7252`: http://tools.ietf.org/html/rfc7252\n.. _txThings: https://github.com/siskin/txThings\n\nUsage\n-----\n\nFor details on how to usethe aiocoap library, have a look at the :mod:`aiocoap`\nmodule documentation, or at the :doc:`examples` and :doc:`tools` provided.\n\nAll examples can be run directly from a source code copy. If you prefer to\ninstall it, the usual Python mechanisms apply.\n\nDevelopment\n-----------\n\naiocoap tries to stay close to PEP8_ recommendations and general best practice,\nand should thus be easy to contribute to. Unit tests are implemented in the\n``./tests/`` directory; complete test coverage is aimed for, but not yet\ncomplete (and might never be, as the error handling for pathological network\npartners is hard to trigger with a library designed not to missbehave).\n\nDocumentation is built using sphinx_; hacks used there are described in\n``./doc/README.doc``.\n\nBugs from design goal and wishlist to typos are currently tracked in github\n(see below).\n\n.. _PEP8: http://legacy.python.org/dev/peps/pep-0008/\n.. _sphinx: http://sphinx-doc.org/\n\nRelevant URLs\n-------------\n\n* https://github.com/chrysn/aiocoap\n\n  This is where the latest source code can be found, and bugs can be reported.\n  Generally, this serves as the project web site.\n\n* http://aiocoap.readthedocs.org/\n\n  Online documentation built from the sources.\n\n\nLicensing\n---------\n\naiocoap is published under the MIT License, see :doc:`LICENSE` for details.\n\nCopyright (c) 2012-2014 Maciej Wasilak <http://sixpinetrees.blogspot.com/>,\n              2013-2014 Christian Amsüss <c.amsuess@energyharvesting.at>\n",
        "url": "http://pypi.python.org/pypi/aiocoap",
        "summary": "Python CoAP library",
        "command": "pip install 'aiocoap'"
      },
      "aio.config": {
        "name": "aio.config",
        "description": "aio.config\n==========\n\nConfiguration utilities for the aio_ asyncio framework\n\n.. _aio: https://github.com/phlax/aio\n\n\nBuild status\n------------\n\n.. image:: https://travis-ci.org/phlax/aio.config.svg?branch=master\n\t       :target: https://travis-ci.org/phlax/aio.config\n\n\nInstallation\n------------\n\nInstall with:\n\n.. code:: bash\n\n\t  pip install aio.config\n\n\nConfiguration finder\n--------------------\n\nThe configuration finder will search the following directory paths in search of configuration files\n\n- aio.conf\n\n- etc/aio.conf\n\n- /etc/aio.conf\n\n\nConfiguration parser\n--------------------\n\nThe configuration parser uses *configparser.ExtendedInterpolation*",
        "url": "http://pypi.python.org/pypi/aio.config",
        "summary": "Aio configuration utilities",
        "command": "pip install 'aio.config'"
      },
      "aioconsul": {
        "name": "aioconsul",
        "description": "AIO Consul\n----------\n\nConsul_ has multiple components, but as a whole, it is a tool for discovering and configuring services in your infrastructure, like :\n\n* Service Discovery\n* Health Checking\n* Key/Value Store\n* Multi Datacenter\n\n\nThis library provides several features to interact with its API. It is build in top of asyncio_ and aiohttp_. It works with Python >= 3.3, and is still a work in progress.\n\nThe documentation_ has more details, but sparsely this is how to work with it.\n\nInstallation\n~~~~~~~~~~~~\n\n::\n\n    pip install aioconsul\n\n\nUsage\n~~~~~\n\nMost of the functions are coroutines, so it must be embedded into asyncio tasks::\n\n    from aioconsul import Consul\n    client = Consul()\n\n    @asyncio.coroutine\n    def main():\n        node_name = yield from client.agent.config().node_name\n        print('I am %s!' % node_name)\n\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(main)\n    loop.run_until_complete(future)\n\n\nAgent checks\n~~~~~~~~~~~~\n\nCurrently this library can handle simple checks::\n\n    from aioconsul import Consul\n    client = Consul()\n\n    # list all checks\n    for check in (yield from client.agent.checks()):\n        print(check.id)\n\n    # look for a check\n    check = yield from client.agent.checks.get('my-check')\n\n    # register a script check\n    check = yield from client.agent.checks.register_script('my-script-check',\n                                                           script='~/script.sh',\n                                                           interval='5m')\n\n    # register a http check\n    check = yield from client.agent.checks.register_ttl('my-http-check',\n                                                        http='http://example.com',\n                                                        interval='10h')\n\n    # register a ttl check\n    check = yield from client.agent.checks.register_ttl('my-ttl-check',\n                                                        ttl='10s')\n\n    # mark ttl check passing\n    yield from client.agent.checks.passing(check, note='Make it so')\n\n    # deregister any check\n    yield from client.agent.checks.deregister(check)\n\n\nAgent services\n~~~~~~~~~~~~~~\n\nCurrently this library can handle simple checks::\n\n    from aioconsul import Consul\n    client = Consul()\n\n    # list all services\n    for srv in (yield from client.agent.services()):\n        print(srv.id)\n\n    # search a service by its name\n    srv = yield from client.agent.services.get('my-service')\n\n    # disable a service\n    yield from client.agent.services.maintenance(srv,\n                                                 enable=False,\n                                                 reason='Migrating stuff')\n\n    # and reenable it\n    yield from client.agent.services.maintenance(srv,\n                                                 enable=True,\n                                                 reason='Done')\n\n\nCatalog\n~~~~~~~\n\nThis library can consult catalog::\n\n    from aioconsul import Consul\n    client = Consul()\n\n    # listing all nodes from catalog\n    for node in (yield from client.catalog.nodes()):\n        print(node.name)\n        print(node.address)\n\n    # getting a node with all of its service\n    node = yield from client.catalog.get('my-node')\n    print(node.services)\n\n    # getting all nodes that belong to a service\n    nodes = yield from client.catalog.nodes(service='my-service')\n    print(nodes)\n\nAnd register checks, services and nodes::\n\n    from aioconsul import Consul\n    client = Consul()\n\n    node = {'name': 'my-local-node',\n            'address': '127.0.0.1'}\n    check = {'name': 'baz',\n             'state': 'passing',\n             'service_id': 'bar'}\n    service={'name': 'bar'}\n\n    resp = yield from client.catalog.register(node, check=check, service=service)\n    assert resp\n\n    resp = yield from client.catalog.deregister(node, check=check, service=service)\n    assert resp\n\n\nEvents\n~~~~~~\n\n::\n\n    from aioconsul import Consul\n    client = Consul()\n\n    # send an event\n    event = yield from client.event.fire('my-event', node_filter='.*')\n\n    # list all events\n    for event in (yield from client.event.items()):\n        print(event.name)\n\n\nHealth\n~~~~~~\n\n::\n\n    from aioconsul import Consul\n    client = Consul()\n\n    # checks for a node\n    for check in (yield from client.health.node('my-local-node')):\n        assert check.status == 'passing'\n\n    # health of a node\n    for check in (yield from client.health.node('my-local-node')):\n        assert check.status == 'passing'\n\n    # health of a check id\n    for check in (yield from client.health.checks('serfHealth')):\n        assert check.status == 'passing'\n\n    # health of a check id\n    for check in (yield from client.health.checks('serfHealth')):\n        assert check.status == 'passing'\n\n    # health of a service\n    for node in (yield from client.health.service('foo', state='any')):\n        for check in node.checks:\n            if check.id == 'service:foo':\n                assert check.status == 'passing'\n\n    # passing checks\n    for check in (yield from client.health.state('passing')):\n        assert check.status == 'passing'\n\n\nKV and Sessions\n~~~~~~~~~~~~~~~\n\nSimple example::\n\n    from aioconsul import Consul\n    client = Consul()\n\n    # set a k/v\n    yield from client.kv.set('my.key', 'my.value')\n\n    # fetch a k/v\n    obj = yield from client.kv.get('my.key')\n\n    # fetched values have a special attribute `consul`\n    assert obj.key.name == 'my.key'\n\n    # delete a k/v\n    yield from client.kv.delete('my.key')\n\n\nMany k/v::\n\n    # list many k/v\n    for key, value in (yield from client.kv.items('')):\n        print(key, value)\n\n\nEphemeral k/v::\n\n    session = yield from client.sessions.create(behavior='delete')\n    yield from client.kv.create('my.key', 'my.key')\n    yield from client.sessions.delete(session)\n\n    try:\n        # try to fetch previous k/v\n        obj = yield from client.kv.get('my.key')\n    except client.kv.NotFound:\n        # but it was destroyed with the session\n        pass\n\n\nACL\n~~~\n\n::\n\n    from aioconsul import Consul, PermissionDenied\n    client = Consul(token=master_token)\n\n    # create a token\n    token = (yield from client.acl.create('my-acl', rules=[\n        ('key', '', 'read'),\n        ('key', 'foo/', 'deny'),\n    ]))\n\n    # access to kv with the fresh token\n    node = Consul(token=token)\n    yield from node.kv.get('foo')\n    with pytest.raises(PermissionDenied):\n        yield from node.kv.set('foo', 'baz')\n    with pytest.raises(node.kv.NotFound):\n        yield from node.kv.get('foo/bar')\n\n\nTesting\n~~~~~~~\n\nTests rely on Consul_ binary and `py.test`_.\n\n1. Install consul binary, it must be reachable in your ``$PATH``.\n2. Install test requirements::\n\n    pip install -r requirements-tests.txt\n\n3. Then run tests::\n\n    py.test --cov-report html --cov aioconsul tests\n\n\nPublish to pypi\n---------------\n\n::\n\n    python setup.py sdist bdist_wheel upload\n\n\nCredits\n-------\n\n- Consul_\n- aiohttp_\n- asyncio_\n- `py.test`_\n\n\n.. _Consul: http://consul.io\n.. _aiohttp: http://aiohttp.readthedocs.org\n.. _asyncio: http://asyncio.org\n.. _`py.test`: http://pytest.org\n.. _documentation: http://aioconsul.readthedocs.org",
        "url": "http://pypi.python.org/pypi/aioconsul",
        "summary": "Consul wrapper for asyncio",
        "command": "pip install 'aioconsul'"
      },
      "aiocore": {
        "name": "aiocore",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aiocore",
        "summary": "does some stuff with things & stuff",
        "command": "pip install 'aiocore'"
      },
      "aio.core": {
        "name": "aio.core",
        "description": "Detailed documentation\n**********************\n\n\naio.core\n========\n\nCore definitions and utilities for the aio_ asyncio framework\n\n.. _aio: https://github.com/phlax/aio\n\n\nInstallation\n------------\n\nInstall with:\n\n.. code:: bash\n\n\t  pip install aio.core\n\n\naio.core.exceptions usage\n=========================\n\n\nMissingConfiguration\n--------------------\n\n>>> from configparser import ConfigParser\n>>> from aio.core.exceptions import MissingConfiguration\n\n>>> def get_configuration(conf, section, option):\n...     try:\n...         conf[section][option]\n...     except KeyError:\n...         raise MissingConfiguration(\n...             \"Configuration option is missing: %s:%s\" % (\n...                 section, option))\n  \n>>> try:\n...     get_configuration(ConfigParser(), \"foo\", \"bar\")\n... except MissingConfiguration as e:\n...     print(e)\nConfiguration option is missing: foo:bar\n\n\nBadConfiguration\n--------------------  \n  \n>>> from aio.core.exceptions import BadConfiguration  \n\n>>> def get_configuration(conf, section, option, option_type):\n...     option_value = conf[section][option]\n...     try:\n...         option_type(option_value)\n...     except ValueError:\n...         raise BadConfiguration(\n...             'Configuration is bad: %s:%s expected type %s, but got \"%s\"' % (\n...                 section, option, option_type.__name__, option_value))\n\n>>> config = ConfigParser()\n>>> config.read_dict({\"foo\": {\"bar\": \"baz\"}})\n\n>>> try:\n...     get_configuration(config, \"foo\", \"bar\", int)\n... except BadConfiguration as e:\n...     print(e)\nConfiguration is bad: foo:bar expected type int, but got \"baz\"\n\n\nCommandError\n------------\n  \n>>> from aio.core.exceptions import CommandError  \n\n>>> def run_command(command):\n...     options = [\"egg\", \"chips\"]\n...     if command not in options:\n...         raise CommandError(\"This command cannot be called with %s\" % command)\n\n\n>>> try:\n...     run_command(\"spam\")\n... except CommandError as e:\n...     print(e)\nThis command cannot be called with spam",
        "url": "http://pypi.python.org/pypi/aio.core",
        "summary": "Aio core utils",
        "command": "pip install 'aio.core'"
      },
      "aiocouchdb": {
        "name": "aiocouchdb",
        "description": "==========\r\naiocouchdb\r\n==========\r\n\r\n:source: https://github.com/kxepal/aiocouchdb\r\n:documentation: http://aiocouchdb.readthedocs.org/en/latest/\r\n:license: BSD\r\n\r\nCouchDB client built on top of `aiohttp`_ and made for `asyncio`_.\r\n\r\nCurrent status: **beta**. `aiocouchdb` has all CouchDB API implements up to\r\n1.6.1 release. However, it may lack of some usability and stability bits, but\r\nwork is in progress. Feel free to `send pull request`_ or `open issue`_ if\r\nyou'd found something that should be fixed.\r\n\r\nFeatures:\r\n\r\n- Modern CouchDB client for Python 3.3+ based on `aiohttp`_\r\n- Complete CouchDB API support (JSON and Multipart) up to 1.6.1 version\r\n- Multiuser workflow with Basic Auth, Cookie, Proxy and OAuth support\r\n- Stateless behavior\r\n- Stream-like handling views, changes feeds and bulk docs upload\r\n\r\nRoadmap (not exactly in that order):\r\n\r\n- Cloudant support\r\n- CouchDB 2.0 support\r\n- ElasticSearch CouchDB river support\r\n- GeoCouch support\r\n- Microframework for OS daemons and external handlers\r\n- Native integration with Python Query Server\r\n- Replicator-as-a-Library / Replicator-as-a-Service\r\n- Stateful API\r\n\r\nRequirements\r\n============\r\n\r\n- Python 3.3+\r\n- `aiohttp`_\r\n- `oauthlib`_ (optional)\r\n\r\n.. _aiohttp: https://github.com/KeepSafe/aiohttp\r\n.. _asyncio: https://docs.python.org/3/library/asyncio.html\r\n.. _oauthlib: https://github.com/idan/oauthlib\r\n\r\n.. _open issue: https://github.com/kxepal/aiocouchdb/issues\r\n.. _send pull request: https://github.com/kxepal/aiocouchdb/pulls\r\n\r\nChanges\r\n=======\r\n\r\n0.8.0 (2015-03-20)\r\n------------------\r\n\r\n- Source tree was refactored in the way to support multiple major CouchDB\r\n  versions as like as the other friendly forks\r\n- Database create and delete methods now return exact the same response as\r\n  CouchDB sends back\r\n- Each module now contains __all__ list to normalize their exports\r\n- API classes and Resource now has nicer __repr__ output\r\n- Better error messages format\r\n- Fix function_clause error on attempt to update a document with attachments\r\n  by using multipart request\r\n- Document.update doesn't makes document's dict invalid for further requests\r\n  after multipart one\r\n- Fixed accidental payload sent with HEAD/GET/DELETE requests which caused\r\n  connection close from CouchDB side\r\n- Added integration with Travis CI\r\n- Code cleaned by following pylint and flake8 notices\r\n- Added short tutorial for documentation\r\n- Minor fixes and Makefile improvements\r\n\r\n0.7.0 (2015-02-18)\r\n------------------\r\n\r\n- Greatly improved multipart module, added multipart writer\r\n- Document.update now supports multipart requests to upload\r\n  multiple attachments in single request\r\n- Added Proxy Authentication provider\r\n- Minimal requirements for aiohttp raised up to 0.14.0 version\r\n\r\n0.6.0 (2014-11-12)\r\n------------------\r\n\r\n- Adopt test suite to run against real CouchDB instance\r\n- Database, documents and attachments now provides access to their name/id\r\n- Remove redundant longnamed constructors\r\n- Construct Database/Document/Attachment instances through __getitem__ protocol\r\n- Add Document.rev method to get current document`s revision\r\n- Add helpers to work with authentication database (_users)\r\n- Add optional limitation of feeds buffer\r\n- All remove(...) methods are renamed to delete(...) ones\r\n- Add support for config option existence check\r\n- Correctly set members for database security\r\n- Fix requests with Accept-Ranges header against attachments\r\n- Fix views requests when startkey/endkey should be null\r\n- Allow to pass custom query parameters and request headers onto changes feed\r\n  request\r\n- Handle correctly HTTP 416 error response\r\n- Minor code fixes and cleanup\r\n\r\n0.5.0 (2014-09-26)\r\n------------------\r\n\r\n- Last checkpoint release. It's in beta now!\r\n- Implements CouchDB Design Documents HTTP API\r\n- Views refactoring and implementation consolidation\r\n\r\n0.4.0 (2014-09-17)\r\n------------------\r\n\r\n- Another checkpoint release\r\n- Implements CouchDB Attachment HTTP API\r\n- Minimal requirements for aiohttp raised up to 0.9.1 version\r\n- Minor fixes for Document API\r\n\r\n0.3.0 (2014-08-18)\r\n------------------\r\n\r\n- Third checkpoint release\r\n- Implements CouchDB Document HTTP API\r\n- Support document`s multipart API (but not doc update due to COUCHDB-2295)\r\n- Minimal requirements for aiohttp raised up to 0.9.0 version\r\n- Better documentation\r\n\r\n0.2.0 (2014-07-08)\r\n------------------\r\n\r\n- Second checkpoint release\r\n- Implements CouchDB Database HTTP API\r\n- Bulk docs accepts generator as an argument and streams request doc by doc\r\n- Views are processed as stream\r\n- Unified output for various changes feed types\r\n- Basic Auth accepts non-ASCII credentials\r\n- Minimal requirements for aiohttp raised up to 0.8.4 version\r\n\r\n0.1.0 (2014-07-01)\r\n------------------\r\n\r\n- Initial checkpoint release\r\n- Implements CouchDB Server HTTP API\r\n- BasicAuth, Cookie, OAuth authentication providers\r\n- Multi-session workflow",
        "url": "http://pypi.python.org/pypi/aiocouchdb",
        "summary": "CouchDB client built on top of aiohttp (asyncio)",
        "command": "pip install 'aiocouchdb'"
      },
      "aiocron": {
        "name": "aiocron",
        "description": "================================================\naiocron - Crontabs for asyncio\n================================================\n\n.. image:: https://travis-ci.org/gawel/aiocron.png?branch=master\n  :target: https://travis-ci.org/gawel/aiocron\n.. image:: https://pypip.in/v/aiocron/badge.png\n   :target: https://crate.io/packages/aiocron/\n.. image:: https://pypip.in/d/aiocron/badge.png\n   :target: https://crate.io/packages/aiocron/\n\nUsage\n=====\n\n``aiocron`` provide a decorator to run function at time::\n\n    >>> @aiocron.crontab('*/30 * * * *')\n    ... @asyncio.coroutine\n    ... def attime():\n    ...     print('run')\n    >>> asyncio.get_event_loop().run_forever()\n\nYou can also use it as an object::\n\n    >>> @aiocron.crontab('1 9 * * 1-5', start=False)\n    ... @asyncio.coroutine\n    ... def attime():\n    ...     print('run')\n    >>> attime.start()\n    >>> asyncio.get_event_loop().run_forever()\n\nYour function still be available at ``attime.func``\n\nYou can also yield from a crontab. In this case, your coroutine can accept\narguments::\n\n    >>> @aiocron.crontab('0 9,10 * * * mon,fri', start=False)\n    ... @asyncio.coroutine\n    ... def attime(i):\n    ...     print('run %i' % i)\n\n    >>> @asyncio.coroutine\n    ... def once():\n    ...     try:\n    ...         res = yield from attime.next(1)\n    ...     except Exception as e:\n    ...         print('It failed (%r)' % e)\n    ...     else:\n    ...         print(res)\n    >>> asyncio.get_event_loop().run_forever()\n\nFinally you can use it as a sleep coroutine. The following will wait until\nnext hour::\n\n    >>> yield from crontab('0 * * * *').next()\n\nIf you don't like the decorator magic you can set the function by yourself::\n\n    >>> cron = crontab('0 * * * *', func=yourcoroutine, start=False)\n\nNotice that unlike standard unix crontab you can specify seconds at the 6th\nposition.\n\n``aiocron`` use `croniter <https://pypi.python.org/pypi/croniter>`_. Refer to\nit's documentation to know more about crontab format.",
        "url": "http://pypi.python.org/pypi/aiocron",
        "summary": "Crontabs for asyncio",
        "command": "pip install 'aiocron'"
      },
      "aiocutter": {
        "name": "aiocutter",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aiocutter",
        "summary": "scraping tool for asyncio",
        "command": "pip install 'aiocutter'"
      },
      "aiodbus": {
        "name": "aiodbus",
        "description": "Port of txdbus to the asyncio world",
        "url": "http://pypi.python.org/pypi/aiodbus",
        "summary": "DBus for asyncio",
        "command": "pip install 'aiodbus'"
      },
      "aiodcard": {
        "name": "aiodcard",
        "description": "aiodcard\n==============\n\nDcard crawler using asyncio(coroutine)\n\n\nFeature\n-------\n| Get article list and content using coroutine\n\n\nDependencies\n------------\n* Python 3.3 and :mod:`asyncio` or Python 3.4+\n* aiohttp\n\n\nInstallation\n------------\n::\n\n\tpython setup.py install\n\nor \n\n::\n\n    pip install aiodcard\n\n\nExample\n-------\n\n::\n\n    import asyncio\n\n    import aiohttp\n    import aiodcard\n\n    @asyncio.coroutine\n    def get_funny_articles():\n        session = aiohttp.ClientSession()\n        forum_name = 'funny'\n        page_index = 1\n        result = yield from aiodcard.get_articles_of_page(session, forum_name, page_index)\n        print(result)\n\n    def main():\n        loop = asyncio.get_event_loop()\n        loop.run_until_complete(get_funny_articles())\n\n    if __name__ == '__main__':\n        main()\n\n\nTodo\n----\n* test all functions\n  \n\nAuthors and License\n-------------------\nThe ``aiodcard`` package is written by Chien-Wei Huang. It’s MIT licensed and freely available.\n\nFeel free to improve this package and send a pull request to GitHub.",
        "url": "http://pypi.python.org/pypi/aiodcard",
        "summary": "Dcard crawler using asyncio(coroutine)",
        "command": "pip install 'aiodcard'"
      },
      "aiodns": {
        "name": "aiodns",
        "description": "===============================\nSimple DNS resolver for asyncio\n===============================\n\n.. image:: https://secure.travis-ci.org/saghul/aiodns.png?branch=master\n    :target: http://travis-ci.org/saghul/aiodns\n\naiodns provides a simple way for doing asynchronous DNS resolutions\nwith a synchronous looking interface by using `pycares <https://github.com/saghul/pycares>`_.\n\n\nExample\n=======\n\n::\n\n    import asyncio\n    import aiodns\n\n    loop = asyncio.get_event_loop()\n    resolver = aiodns.DNSResolver(loop=loop)\n    f = resolver.query('google.com','A')\n    result = loop.run_until_complete(f)\n    print(result)\n\n\nThe following query types are supported: A, AAAA, CNAME, MX, NAPTR, NS, PTR, SOA, SRV, TXT.\n\nThe library supports both *asyncio* and *Trollius*.\n\nIf you use Python 3 you may use `yield from` statement::\n\n    @asyncio.coroutine\n    def func():\n        result = yield from resolver.query('google.com','A')\n\nFor Trollius you should use another syntax like::\n\n    @trollius.coroutine\n    def func():\n         result = yield trollius.From(resolver.query('google.com','A'))\n\nAPI\n===\n\nThe API is pretty simple, two functions are provided in the ``DNSResolver`` class:\n\n* ``query(host, type)``: Do a DNS resolution of the given type for the given hostname. It returns an\n  instance of ``asyncio.Future``. The actual result of the DNS query is taken directly from pycares.\n  As of version 1.0.0 of aiodns (and pycares, for that matter) results are always namedtuple-like\n  objects with different attributes. Please check `the documentation <http://pycares.readthedocs.org/en/latest/channel.html#pycares.Channel.query>`_\n  for the result fields.\n* ``cancel()``: Cancel all pending DNS queries. All futures will get ``DNSError`` exception set, with\n  ``ARES_ECANCELLED`` errno.\n\n\nRunning the test suite\n======================\n\nTo run the test suite: ``python test_aiodns.py``\n\n\nAuthor\n======\n\nSaúl Ibarra Corretgé <saghul@gmail.com>\n\n\nLicense\n=======\n\naiodns uses the MIT license, check LICENSE file.\n\n\nPython versions\n===============\n\nPython 3.4 is natively supported. Python 3.3 supported using the `asyncio package <https://pypi.python.org/pypi/asyncio>`_.\nOlder Python versions(2.6 - 3.2) are supported using `trollius <https://pypi.python.org/pypi/trollius>`_.\n\n\nContributing\n============\n\nIf you'd like to contribute, fork the project, make a patch and send a pull\nrequest. Have a look at the surrounding code and please, make yours look\nalike :-)",
        "url": "http://pypi.python.org/pypi/aiodns",
        "summary": "Simple DNS resolver for asyncio",
        "command": "pip install 'aiodns'"
      },
      "aiodocker": {
        "name": "aiodocker",
        "description": "AsyncIO Docker bindings",
        "url": "http://pypi.python.org/pypi/aiodocker",
        "summary": "does some stuff with things & stuff",
        "command": "pip install 'aiodocker'"
      },
      "aioes": {
        "name": "aioes",
        "description": "asyncio client library for elasticsearch\n=========================================\n\n**aioes** is a asyncio_ compatible library for working with ElasticSearch_\n\nExample\n-------\n\n::\n\n    import asyncio\n    from aioes import Elasticsearch\n\n    @asyncio.coroutine\n    def go():\n        es = Elasticsearch(['localhost:9200'])\n        ret = yield from es.create(index=\"my-index\",\n                                   doc_type=\"test-type\",\n                                   id=42,\n                                   body={\"str\": \"data\",\n                                         \"int\": 1})\n        assert (ret == {'_id': '42',\n                        '_index': 'my-index',\n                        '_type': 'test-type',\n                        '_version': 1,\n                        'ok': True})\n\n        answer = yield from es.get(index=\"my-index\",\n                                   doc_type=\"test-type\",\n                                   id=42)\n        assert answer['_source'] == {'str': 'data', 'int': 1}\n\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(go())\n\n\nRequirements\n------------\n\n* Python_ 3.3+\n* asyncio_ or Python 3.4+\n* aiohttp_ 0.9.1+\n\n\n\nLicense\n-------\n\naioes is offered under the BSD license.\n\n.. _python: https://www.python.org/downloads/\n.. _asyncio: https://pypi.python.org/pypi/asyncio\n.. _aiohttp: https://pypi.python.org/pypi/aiohttp\n.. _ElasticSearch: http://www.elasticsearch.org/\n\nCHANGES\n-------\n\n\n0.1.0 (XXXX-XX-XX)\n^^^^^^^^^^^^^^^^^^\n\n* Initial release",
        "url": "http://pypi.python.org/pypi/aioes",
        "summary": "Elasticsearch integration with asyncio.",
        "command": "pip install 'aioes'"
      },
      "aioeventlet": {
        "name": "aioeventlet",
        "description": "aioeventlet implements the asyncio API (PEP 3156) on top of eventlet. It makes\npossible to write asyncio code in a project currently written for eventlet.\n\naioeventlet allows to use greenthreads in asyncio coroutines, and to use\nasyncio coroutines, tasks and futures in greenthreads: see ``link_future()``\nand ``wrap_greenthread()`` functions.\n\nThe main visible difference between aioeventlet and trollius is the behaviour\nof ``run_forever()``: ``run_forever()`` blocks with trollius, whereas it runs\nin a greenthread with aioeventlet. It means that aioeventlet event loop can run\nin an greenthread while the Python main thread runs other greenthreads in\nparallel.\n\n* `aioeventlet documentation <http://aioeventlet.readthedocs.org/>`_\n* `aioeventlet project in the Python Cheeseshop (PyPI)\n  <https://pypi.python.org/pypi/aioeventlet>`_\n* `aioeventlet project at Bitbucket <https://bitbucket.org/haypo/aioeventlet>`_\n* Copyright/license: Open source, Apache 2.0. Enjoy!",
        "url": "http://pypi.python.org/pypi/aioeventlet",
        "summary": "asyncio event loop scheduling callbacks in eventlet.",
        "command": "pip install 'aioeventlet'"
      },
      "aioevents": {
        "name": "aioevents",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aioevents",
        "summary": "Events for asyncio (PEP 3156)",
        "command": "pip install 'aioevents'"
      },
      "aiofiles": {
        "name": "aiofiles",
        "description": "aiofiles: file support for asyncio\n==================================\n\n.. image:: https://img.shields.io/pypi/v/aiofiles.svg\n    :target: https://pypi.python.org/pypi/aiofiles\n.. image:: https://travis-ci.org/Tinche/aiofiles.svg?branch=master\n    :target: https://travis-ci.org/Tinche/aiofiles\n.. image:: https://coveralls.io/repos/Tinche/aiofiles/badge.svg?branch=master\n    :target: https://coveralls.io/r/Tinche/aiofiles?branch=master\n\naiofiles is an Apache2 licensed library, written in Python, for handling local\ndisk files in asyncio applications.\n\nOrdinary local file IO is blocking, and cannot easily and portably made\nasynchronous. This means doing file IO may interfere with asyncio applications,\nwhich shouldn't block the executing thread. aiofiles helps with this by\nintroducing asynchronous versions of files that support delegating operations to\na separate thread pool.\n\n.. code-block:: python\n\n    f = yield from aiofiles.open('filename', mode='r')\n    try:\n        contents = yield from f.read()\n    finally:\n        yield from f.close()\n    print(contents)\n    'My file contents'\n\nFeatures\n--------\n\n- a file API very similar to Python's standard, blocking API\n- support for buffered and unbuffered binary files, and buffered text files\n\n\nInstallation\n------------\n\nTo install aiofiles, simply:\n\n.. code-block:: bash\n\n    $ pip install aiofiles\n\nUsage\n-----\n\nFiles are opened using the ``aiofiles.open()`` coroutine, which in addition to\nmirroring the builtin ``open`` accepts optional ``loop`` and ``executor``\narguments. If ``loop`` is absent, the default loop will be used, as per the\nset asyncio policy. If ``executor`` is not specified, the default event loop\nexecutor will be used.\n\nIn case of success, an asynchronous file object is returned with an\nAPI identical to an ordinary file, except the following methods are coroutines\nand delegate to an executor:\n\n* ``close``\n* ``flush``\n* ``isatty``\n* ``read``\n* ``readall``\n* ``read1``\n* ``readinto``\n* ``readline``\n* ``readlines``\n* ``seek``\n* ``seekable``\n* ``tell``\n* ``truncate``\n* ``writable``\n* ``write``\n* ``writelines``\n\nIn case of failure, one of the usual exceptions will be raised.\n\nThe ``aiofiles.os`` module contains executor-enabled coroutine versions of\nseveral useful ``os`` functions that deal with files:\n\n* ``stat``\n* ``sendfile``\n\nLimitations and Differences from the Builtin File API\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe closing of a file may block, and yielding from a coroutine while exiting\nfrom a context manager isn't possible, so aiofiles file objects can't be used\nas context managers. Use the ``try/finally`` construct from the introductory\nsection to ensure files are closed.\n\nIteration is also unsupported. To iterate over a file, call ``readline``\nrepeatedly until an empty result is returned. Keep in mind ``readline`` doesn't\nstrip newline characters.\n\n.. code-block:: python\n\n    f = yield from aiofiles.open('filename')\n    try:\n        while True:\n            line = yield from f.readline()\n            if not line:\n                break\n            line = line.strip()\n            ...\n    finally:\n        yield from f.close()\n\nContributing\n~~~~~~~~~~~~\nContributions are very welcome. Tests can be run with ``tox``, please ensure\nthe coverage at least stays the same before you submit a pull request.",
        "url": "http://pypi.python.org/pypi/aiofiles",
        "summary": "File support for asyncio.",
        "command": "pip install 'aiofiles'"
      },
      "aioflock": {
        "name": "aioflock",
        "description": "aioflock: file lock support for asyncio (based on fcntl.flock)\r\n==================================\r\n\r\n.. image:: https://coveralls.io/repos/kolko/aioflock/badge.svg?branch=master&service=github\r\n    :target: https://coveralls.io/github/kolko/aioflock?branch=master\r\n\r\n.. image:: https://travis-ci.org/kolko/aioflock.svg?branch=master\r\n    :target: https://travis-ci.org/kolko/aioflock\r\n\r\n\r\n\r\nExample:\r\n\r\n.. code-block:: python\r\n\r\n    from aioflock import LockFilename\r\n    lock = LockFilename('/tmp/test_lock')\r\n    yield from lock.acquire()\r\n    ..inside lock..\r\n    lock.release()\r\n\r\n\r\n\r\nWith stategment:\r\n\r\n.. code-block:: python\r\n\r\n    from aioflock import LockFilename\r\n    with (yield from LockFilename('/tmp/test_lock')):\r\n        ..inside lock..\r\n\r\n\r\n\r\nCan use timeout:\r\n\r\n.. code-block:: python\r\n\r\n    from aioflock import LockFilename, LockFilenameTimeout\r\n\r\n    try:\r\n        with (yield from LockFilename('/tmp/test_lock')):\r\n            with (yield from LockFilename('/tmp/test_lock', timeout=1)):\r\n                ...newer here...\r\n    except LockFilenameTimeout:\r\n        ...here...",
        "url": "http://pypi.python.org/pypi/aioflock",
        "summary": "File lock support for asyncio.",
        "command": "pip install 'aioflock'"
      },
      "aioftp": {
        "name": "aioftp",
        "description": ".. aioftp documentation master file, created by\n   sphinx-quickstart on Fri Apr 17 16:21:03 2015.\n   You can adapt this file completely to your liking, but it should at least\n   contain the root `toctree` directive.\n\naioftp\n======\n\n.. image:: https://img.shields.io/travis/pohmelie/aioftp.svg\n    :target: https://travis-ci.org/pohmelie/aioftp\n\n.. image:: https://img.shields.io/coveralls/pohmelie/aioftp.svg\n    :target: https://coveralls.io/github/pohmelie/aioftp\n\n.. image:: https://img.shields.io/pypi/v/aioftp.svg\n    :target: https://pypi.python.org/pypi/aioftp\n\n.. image:: https://img.shields.io/pypi/pyversions/aioftp.svg\n    :target: https://pypi.python.org/pypi/aioftp\n\nftp client/server for asyncio. (http://aioftp.readthedocs.org)\n\n.. _GitHub: https://github.com/pohmelie/aioftp\n\nFeatures\n--------\n\n- Simple.\n- Extensible.\n- Proxy via `twunnel3 <https://github.com/jvansteirteghem/twunnel3>`_.\n\nGoals\n-----\n\n- Minimum usable core.\n- Do not use deprecated or overridden commands and features (if possible).\n- Very high level api.\n\nClient use this commands: USER, PASS, ACCT, PWD, CWD, CDUP, MKD, RMD, MLSD,\nMLST, RNFR, RNTO, DELE, STOR, APPE, RETR, TYPE, PASV, ABOR, QUIT\n\nServer support this commands: USER, PASS, QUIT, PWD, CWD, CDUP, MKD, RMD, MLSD,\nLIST (but it's not recommended to use it, cause it has no standard format),\nMLST, RNFR, RNTO, DELE, STOR, RETR, TYPE (only \"I\"), PASV, ABOR, APPE\n\nThis subsets are enough for 99% of tasks, but if you need something, then you\ncan easily extend current set of commands.\n\nDependencies\n------------\n\n- Python 3.4+\n- docopt (for execution module as script only)\n\nLicense\n-------\n\naioftp is offered under the Apache 2 license.\n\nLibrary Installation\n--------------------\n\n::\n\n   pip install aioftp\n\nGetting started\n---------------\n\nClient example\n\n.. code-block:: python\n\n    import asyncio\n    import aioftp\n\n\n    @asyncio.coroutine\n    def get_mp3(host, login, password):\n\n        ftp = aioftp.Client()\n        yield from ftp.connect(host)\n        yield from ftp.login(login, password)\n        for path, info in (yield from ftp.list(recursive=True)):\n\n            if info[\"type\"] == \"file\" and path.suffix == \".mp3\":\n\n                yield from ftp.download(path)\n\n\n    loop = asyncio.get_event_loop()\n    tasks = (\n        asyncio.async(get_mp3(\"server1.com\", \"login\", \"password\")),\n        asyncio.async(get_mp3(\"server2.com\", \"login\", \"password\")),\n        asyncio.async(get_mp3(\"server3.com\", \"login\", \"password\")),\n    )\n    loop.run_until_complete(asyncio.wait(tasks))\n    loop.close()\n\nServer example\n\n.. code-block:: python\n\n    import asyncio\n    import aioftp\n\n\n    loop = asyncio.get_event_loop()\n    ftp = aioftp.Server()\n    asyncio.async(ftp.start(None, 8021), loop=loop)\n    try:\n\n        loop.run_forever()\n\n    except KeyboardInterrupt:\n\n        ftp.close()\n        loop.run_until_complete(ftp.wait_closed())\n        loop.close()\n\nOr just use simple server\n\n.. code-block:: shell\n\n    python -m aioftp --help",
        "url": "http://pypi.python.org/pypi/aioftp",
        "summary": "ftp client/server for asyncio",
        "command": "pip install 'aioftp'"
      },
      "aiogearman": {
        "name": "aiogearman",
        "description": "aiogearman (work in progress)\n=============================\n\n\nRequirements\n------------\n\n* Python_ 3.3+\n* asyncio_ or Python_ 3.4+\n\n\nLicense\n-------\n\nThe *aiogearman* is offered under MIT license.\n\n.. _Python: https://www.python.org\n.. _asyncio: http://docs.python.org/3.4/library/asyncio.html",
        "url": "http://pypi.python.org/pypi/aiogearman",
        "summary": "asyncio (PEP 3156) gearman job server support",
        "command": "pip install 'aiogearman'"
      },
      "aiogevent": {
        "name": "aiogevent",
        "description": "aiogevent implements the asyncio API (PEP 3156) on top of gevent. It makes\npossible to write asyncio code in a project currently written for gevent.\n\naiogevent allows to use greenlets in asyncio coroutines, and to use asyncio\ncoroutines, tasks and futures in greenlets: see ``yield_future()`` and\n``wrap_greenlet()`` functions.\n\nThe main visible difference between aiogevent and trollius is the behaviour of\n``run_forever()``: ``run_forever()`` blocks with trollius, whereas it runs in a\ngreenlet with aiogevent. It means that aiogevent event loop can run in an\ngreenlet while the Python main thread runs other greenlets in parallel.\n\n* `aiogevent on Python Cheeseshop (PyPI)\n  <https://pypi.python.org/pypi/aiogevent>`_\n* `aiogevent at Bitbucket\n  <https://bitbucket.org/haypo/aiogevent>`_\n* Copyright/license: Open source, Apache 2.0. Enjoy!\n\nSee also the `aioeventlet project <http://aioeventlet.readthedocs.org/>`_.\n\n\nHello World\n===========\n\nCode::\n\n    import aiogevent\n    import trollius as asyncio\n\n    def hello_world():\n        print(\"Hello World\")\n        loop.stop()\n\n    asyncio.set_event_loop_policy(aiogevent.EventLoopPolicy())\n    loop = asyncio.get_event_loop()\n    loop.call_soon(hello_world)\n    loop.run_forever()\n    loop.close()\n\n\n\nAPI\n===\n\naiogevent specific functions:\n\n.. warning::\n   aiogevent API is not considered as stable yet.\n\nyield_future\n------------\n\nyield_future(future, loop=None):\n\n   Wait for a future, a task, or a coroutine object from a greenlet.\n\n   Yield control other eligible greenlet until the future is done (finished\n   successfully or failed with an exception).\n\n   Return the result or raise the exception of the future.\n\n   The function must not be called from the greenlet running the aiogreen\n   event loop.\n\n   Example of greenlet waiting for a trollius task. The ``progress()``\n   callback is called regulary to see that the event loop in not blocked::\n\n        import aiogevent\n        import gevent\n        import trollius as asyncio\n        from trollius import From, Return\n\n        def progress():\n            print(\"computation in progress...\")\n            loop.call_later(0.5, progress)\n\n        @asyncio.coroutine\n        def coro_slow_sum(x, y):\n            yield From(asyncio.sleep(1.0))\n            raise Return(x + y)\n\n        def green_sum():\n            loop.call_soon(progress)\n\n            task = asyncio.async(coro_slow_sum(1, 2))\n\n            value = aiogevent.yield_future(task)\n            print(\"1 + 2 = %s\" % value)\n\n            loop.stop()\n\n        asyncio.set_event_loop_policy(aiogevent.EventLoopPolicy())\n        gevent.spawn(green_sum)\n        loop = asyncio.get_event_loop()\n        loop.run_forever()\n        loop.close()\n\n   Output::\n\n        computation in progress...\n        computation in progress...\n        computation in progress...\n        1 + 2 = 3\n\nwrap_greenlet\n-------------\n\nwrap_greenlet(gt):\n\n   Wrap a greenlet into a Future object.\n\n   The Future object waits for the completion of a greenlet. The result or\n   the exception of the greenlet will be stored in the Future object.\n\n   Greenlet of greenlet and gevent modules are supported: ``gevent.greenlet``\n   and ``greenlet.greenlet``.\n\n   The greenlet must be wrapped before its execution starts. If the\n   greenlet is running or already finished, an exception is raised.\n\n   For ``gevent.Greenlet``, the ``_run`` attribute must be set. For\n   ``greenlet.greenlet``, the ``run`` attribute must be set.\n\n   Example of trollius coroutine waiting for a greenlet. The ``progress()``\n   callback is called regulary to see that the event loop in not blocked::\n\n        import aiogevent\n        import gevent\n        import trollius as asyncio\n        from trollius import From, Return\n\n        def progress():\n            print(\"computation in progress...\")\n            loop.call_later(0.5, progress)\n\n        def slow_sum(x, y):\n            gevent.sleep(1.0)\n            return x + y\n\n        @asyncio.coroutine\n        def coro_sum():\n            loop.call_soon(progress)\n\n            gt = gevent.spawn(slow_sum, 1, 2)\n            fut = aiogevent.wrap_greenlet(gt, loop=loop)\n\n            result = yield From(fut)\n            print(\"1 + 2 = %s\" % result)\n\n        asyncio.set_event_loop_policy(aiogevent.EventLoopPolicy())\n        loop = asyncio.get_event_loop()\n        loop.run_until_complete(coro_sum())\n        loop.close()\n\n   Output::\n\n        computation in progress...\n        computation in progress...\n        computation in progress...\n        1 + 2 = 3\n\n\nInstallation\n============\n\nInstall aiogevent with pip\n--------------------------\n\nType::\n\n    pip install aiogevent\n\nInstall aiogevent on Windows with pip\n-------------------------------------\n\nProcedure for Python 2.7:\n\n* If pip is not installed yet, `install pip\n  <http://www.pip-installer.org/en/latest/installing.html>`_: download\n  ``get-pip.py`` and type::\n\n  \\Python27\\python.exe get-pip.py\n\n* Install aiogevent with pip::\n\n  \\Python27\\python.exe -m pip install aiogevent\n\n* pip also installs dependencies: ``eventlet`` and ``trollius``\n\nManual installation of aiogevent\n--------------------------------\n\nRequirements:\n\n- Python 2.6 or 2.7\n- gevent 0.13 or newer\n- trollius 0.3 or newer (``pip install trollius``), but trollius 1.0 or newer\n  is recommended\n\nType::\n\n    python setup.py install\n\n\nTo do\n=====\n\n* support gevent versions older than 0.13. With version older than 0.13, import\n  gevent raise \"ImportError: .../python2.7/site-packages/gevent/core.so:\n  undefined symbol: current_base\"\n* support gevent monkey patching: enable py27_patch in tox.ini\n* enable py33 environments in tox.ini: gevent 1.0.1 does not support Python 3,\n  need a new release. Tests pass on the development (git) version of gevent.\n\n\ngevent and Python 3\n===================\n\nThe development version of gevent has an experimental support of Python 3.\nSee the `gevent issue #38: python3\n<https://github.com/gevent/gevent/issues/38>`_.\n\n\nThreading\n=========\n\ngevent does not support threads: the aiogevent must run in the main thread.\n\n\nChangelog\n=========\n\n2014-12-18: Version 0.2\n-----------------------\n\n* Rename the ``link_future()`` function to ``yield_future()``\n* Add run_aiotest.py\n* tox now also runs aiotest test suite\n\n2014-11-25: Version 0.1\n-----------------------\n\n* First public release",
        "url": "http://pypi.python.org/pypi/aiogevent",
        "summary": "asyncio API (PEP 3156) implemented on top of gevent",
        "command": "pip install 'aiogevent'"
      },
      "aiogibson": {
        "name": "aiogibson",
        "description": "aiogibson\n=========\n\n.. image:: https://travis-ci.org/jettify/aiogibson.svg?branch=master\n    :target: https://travis-ci.org/jettify/aiogibson\n    :alt: |Build status|\n.. image:: https://coveralls.io/repos/jettify/aiogibson/badge.png?branch=master\n    :target: https://coveralls.io/r/jettify/aiogibson?branch=master\n    :alt: |Coverage|\n.. image:: https://pypip.in/v/aiogibson/badge.svg\n    :target: https://pypi.python.org/pypi/aiogibson/\n    :alt: |Latest PyPI version|\n.. image:: https://pypip.in/d/aiogibson/badge.svg\n    :target: https://pypi.python.org/pypi/aiogibson/\n    :alt: |Number of PyPI downloads|\n.. image:: https://pypip.in/license/aiogibson/badge.svg\n    :target: https://pypi.python.org/pypi/aiogibson/\n    :alt: |License|\n\n\n**aiogibson** is a library for accessing a gibson_ cache database\nfrom the asyncio_ (PEP-3156/tulip) framework.\n\nGibson is a high efficiency, tree based memory cache server.\nIt uses a special trie_ structure allowing the\nuser to perform operations on multiple key sets using a prefix\nexpression achieving the same performance grades in the worst case,\neven better on an average case then regular cache implementations\nbased on hash tables.\n\n\nCode heavily reused from awesome aioredis_ library. ``GibsonPool``,\n``GibsonConnection``, almost direct copy of ``RedisPool`` and\n``RedisConnection``, so I highly recommend to checkout aioredis_.\n\n\nDocumentation\n-------------\nhttp://aiogibson.readthedocs.org/\n\n\nInstallation\n------------\n\nMake sure that you have gibson_ server compiled and running. The easiest way\nto install *aiogibson* is by using the package on PyPi::\n\n   pip install aiogibson\n\n\nExample\n-------\n\n.. code:: python\n\n    import asyncio\n    from aiogibson import create_gibson\n\n    loop = asyncio.get_event_loop()\n\n\n    @asyncio.coroutine\n    def go():\n        gibson = yield from create_gibson('/tmp/gibson.sock', loop=loop)\n        # set value\n        yield from gibson.set(b'foo', b'bar', 7)\n        yield from gibson.set(b'numfoo', 100, 7)\n\n        # get value\n        result = yield from gibson.get(b'foo')\n        print(result)\n\n        # set ttl to the value\n        yield from gibson.ttl(b'foo', 10)\n\n        # increment given key\n        yield from gibson.inc(b'numfoo')\n\n        # decrement given key\n        yield from gibson.dec(b'numfoo')\n\n        # lock key from modification\n        yield from gibson.lock(b'numfoo')\n\n        # unlock given key\n        yield from gibson.unlock(b'numfoo')\n\n        # fetch keys with given prefix\n        yield from gibson.keys(b'foo')\n\n        # delete value\n        yield from gibson.delete(b'foo')\n\n\n    loop.run_until_complete(go())\n\nUnderlying data structure trie_ allows us to perform operations on multiple\nkey sets using a prefix expression:\n\n\nMulti Commands\n--------------\n\n.. code:: python\n\n    import asyncio\n    from aiogibson import create_gibson\n\n    loop = asyncio.get_event_loop()\n\n\n    @asyncio.coroutine\n    def go():\n        gibson = yield from create_gibson('/tmp/gibson.sock', loop=loop)\n\n        # set the value for keys verifying the given prefix\n        yield from gibson.mset(b'fo', b'bar', 7)\n        yield from gibson.mset(b'numfo', 100, 7)\n\n        # get the values for keys with given prefix\n        result = yield from gibson.mget(b'fo')\n\n        # set the TTL for keys verifying the given prefix\n        yield from gibson.mttl(b'fo', 10)\n\n        # increment by one keys verifying the given prefix.\n        yield from gibson.minc(b'numfo')\n\n        # decrement by one keys verifying the given prefix\n        yield from gibson.mdec(b'numfoo')\n\n        # lock keys with prefix from modification\n        yield from gibson.mlock(b'fo')\n\n        # unlock keys with given prefix\n        yield from gibson.munlock(b'fo')\n\n        # delete keys verifying the given prefix.\n        yield from gibson.mdelete(b'fo')\n\n        # return list of keys with given prefix ``fo``\n        yield from gibson.keys(b'fo')\n\n        # count items for a given prefi\n        info = yield from gibson.stats()\n\n\n    loop.run_until_complete(go())\n\n**aiogibson** has connection pooling support using context-manager:\n\n\nConnection Pool Example\n-----------------------\n\n.. code:: python\n\n    import asyncio\n    from aiogibson import create_pool\n\n    loop = asyncio.get_event_loop()\n\n    @asyncio.coroutine\n    def go():\n        pool = yield from create_pool('/tmp/gibson.sock', minsize=5, maxsize=10,\n                                      loop=loop)\n        # using context manager\n        with (yield from pool) as gibson:\n            yield from gibson.set('foo', 'bar')\n            value = yield from gibson.get('foo')\n            print(value)\n\n        # NOTE: experimental feature\n        # or without context manager\n        yield from pool.set('foo', 'bar')\n        resp = yield from pool.get('foo')\n        yield from pool.delete('foo')\n\n        pool.clear()\n\n    loop.run_until_complete(go())\n\n\nAlso you can have simple low-level interface to *gibson* server:\n\n\nLow Level Commands\n------------------\n\n.. code:: python\n\n    import asyncio\n    from aiogibson import create_gibson\n\n    loop = asyncio.get_event_loop()\n\n\n    @asyncio.coroutine\n    def go():\n        gibson = yield from create_connection('/tmp/gibson.sock', loop=loop)\n\n        # set value\n        yield from gibson.execute(b'set', b'foo', b'bar', 7)\n\n        # get value\n        result = yield from gibson.execute(b'get', b'foo')\n        print(result)\n        # delete value\n        yield from gibson.execute(b'del', b'foo')\n\n\n    loop.run_until_complete(go())\n\n\nRequirements\n------------\n\n* Python_ 3.3+\n* asyncio_ or Python_ 3.4+\n\n\nLicense\n-------\n\nThe *aiogibson* is offered under MIT license.\n\n.. _Python: https://www.python.org\n.. _asyncio: http://docs.python.org/3.4/library/asyncio.html\n.. _gibson: http://gibson-db.in/\n.. _aioredis: https://github.com/aio-libs/aioredis\n.. _trie: http://en.wikipedia.org/wiki/Trie\n\nChanges\n-------\n\n0.1.3 (2015-02-10)\n^^^^^^^^^^^^^^^^^^\n* Documentation published on http://aiogibson.readthedocs.org/:\n\n* Added wait closed finalizer;\n\n* Improved test coverage to 99%;\n\n* Fixed bug with canceled future;\n\n* Added limit argument to mget command;\n\n0.1.2 (2014-10-15)\n^^^^^^^^^^^^^^^^^^\n* Changed Reader interface to be similar to hiredis;\n\n* Most methods from high level interface now return Future;\n\n* Connection pool, works as drop in replacement for high level connection;\n\n* Added more docstrings;\n\n\n0.1.1 (2014-09-06)\n^^^^^^^^^^^^^^^^^^\n* Improved protocol parser;\n\n* Added type checking in high-level commands;\n\n* Added check for None arguments in connection execute command;\n\n\n0.1.0 (2014-08-17)\n^^^^^^^^^^^^^^^^^^\n* Initial release;",
        "url": "http://pypi.python.org/pypi/aiogibson",
        "summary": "asyncio (PEP 3156) Gibson cache support",
        "command": "pip install 'aiogibson'"
      },
      "aiogreen": {
        "name": "aiogreen",
        "description": "aiogreen implements the asyncio API (PEP 3156) on top of eventlet. It makes\npossible to write asyncio code in a project currently written for eventlet.\n\naiogreen allows to use greenthreads in asyncio coroutines, and to use asyncio\ncoroutines, tasks and futures in greenthreads: see ``link_future()`` and\n``wrap_greenthread()`` functions.\n\nThe main visible difference between aiogreen and trollius is the behaviour of\n``run_forever()``: ``run_forever()`` blocks with trollius, whereas it runs in a\ngreenthread with aiogreen. It means that aiogreen event loop can run in an\ngreenthread while the Python main thread runs other greenthreads in parallel.\n\n* `aiogreen documentation <http://aiogreen.readthedocs.org/>`_\n* `aiogreen project in the Python Cheeseshop (PyPI)\n  <https://pypi.python.org/pypi/aiogreen>`_\n* `aiogreen project at Bitbucket <https://bitbucket.org/haypo/aiogreen>`_\n* Copyright/license: Open source, Apache 2.0. Enjoy!",
        "url": "http://pypi.python.org/pypi/aiogreen",
        "summary": "asyncio event loop scheduling callbacks in eventlet.",
        "command": "pip install 'aiogreen'"
      },
      "aiogremlin": {
        "name": "aiogremlin",
        "description": "=========================================================\naiogremlin - Async Python 3 driver for TP3 Gremlin Server\n=========================================================\n\n**alpha**\n\n\n`Official Documentation`_\n\n\n.. _Official Documentation: http://aiogremlin.readthedocs.org/en/latest/",
        "url": "http://pypi.python.org/pypi/aiogremlin",
        "summary": "Python 3 driver for TP3 Gremlin Server built on Asyncio and aiohttp",
        "command": "pip install 'aiogremlin'"
      },
      "aiohdfs": {
        "name": "aiohdfs",
        "description": "Asyncio Python wrapper for the Hadoop WebHDFS REST API",
        "url": "http://pypi.python.org/pypi/aiohdfs",
        "summary": "UNKNOWN",
        "command": "pip install 'aiohdfs'"
      },
      "aio-hs2": {
        "name": "aio-hs2",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aio-hs2",
        "summary": "Asyncio-based client for hiveserver2 (and sharkserver2)",
        "command": "pip install 'aio-hs2'"
      },
      "aiohttp": {
        "name": "aiohttp",
        "description": "http client/server for asyncio\n==============================\n\n.. image:: https://raw.github.com/KeepSafe/aiohttp/master/docs/_static/aiohttp-icon-128x128.png\n  :height: 64px\n  :width: 64px\n  :alt: aiohttp logo\n\n.. image:: https://secure.travis-ci.org/KeepSafe/aiohttp.png\n  :target:  https://secure.travis-ci.org/KeepSafe/aiohttp\n  :align: right\n\nFeatures\n--------\n\n- Supports both client and server side of HTTP protocol.\n- Supports both client and server Web-Sockets out-of-the-box.\n- Web-server has middlewares and pluggable routing.\n\n\nRequirements\n------------\n\n- Python >= 3.3\n- asyncio https://pypi.python.org/pypi/asyncio\n\n\nLicense\n-------\n\n``aiohttp`` is offered under the Apache 2 license.\n\n\nDocumentation\n-------------\n\nhttp://aiohttp.readthedocs.org/\n\nSource code\n------------\n\nThe latest developer version is available in a github repository:\nhttps://github.com/KeepSafe/aiohttp\n\nBenchmarks\n----------\n\nIf you are interested in by efficiency, AsyncIO community maintains a list of benchmarks on the official wiki:\nhttps://github.com/python/asyncio/wiki/Benchmarks\n\nGetting started\n---------------\n\nClient\n^^^^^^\n\nTo retrieve something from the web:\n\n.. code-block:: python\n\n  import aiohttp\n  import asyncio\n\n  def get_body(url):\n      response = yield from aiohttp.request('GET', url)\n      return (yield from response.read())\n\n  if __name__ == '__main__':\n      loop = asyncio.get_event_loop()\n      raw_html = loop.run_until_complete(get_body('http://python.org'))\n      print(raw_html)\n\n\nYou can use the get command like this anywhere in your ``asyncio``\npowered program:\n\n.. code-block:: python\n\n  response = yield from aiohttp.request('GET', 'http://python.org')\n  body = yield from response.read()\n  print(body)\n\nIf you want to use timeouts for aiohttp client side please use standard\nasyncio approach:\n\n.. code-block:: python\n\n   yield from asyncio.wait_for(request('GET', url), 10)\n\n\nServer\n^^^^^^\n\nThis is simple usage example:\n\n.. code-block:: python\n\n    import asyncio\n    from aiohttp import web\n\n\n    @asyncio.coroutine\n    def handle(request):\n        name = request.match_info.get('name', \"Anonymous\")\n        text = \"Hello, \" + name\n        return web.Response(body=text.encode('utf-8'))\n\n\n    @asyncio.coroutine\n    def wshandler(request):\n        ws = web.WebSocketResponse()\n        ws.start(request)\n\n        while True:\n            msg = yield from ws.receive()\n\n            if msg.tp == web.MsgType.text:\n                ws.send_str(\"Hello, {}\".format(msg.data))\n            elif msg.tp == web.MsgType.binary:\n                ws.send_bytes(msg.data)\n            elif msg.tp == web.MsgType.close:\n                break\n\n        return ws\n\n\n    @asyncio.coroutine\n    def init(loop):\n        app = web.Application(loop=loop)\n        app.router.add_route('GET', '/echo', wshandler)\n        app.router.add_route('GET', '/{name}', handle)\n\n        srv = yield from loop.create_server(app.make_handler(),\n                                            '127.0.0.1', 8080)\n        print(\"Server started at http://127.0.0.1:8080\")\n        return srv\n\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(init(loop))\n    loop.run_forever()\n\nCHANGES\n=======\n\n0.17.4 (09-29-2015)\n-------------------\n\n- Properly parse URL path in aiohttp.web.Request #489\n\n- Add missing coroutine decorator, the client api is await-compatible now\n\n0.17.3 (08-28-2015)\n---------------------\n\n- Remove Content-Length header on compressed responses #450\n\n- Support Python 3.5\n\n- Improve performance of transport in-use list #472\n\n- Fix connection pooling #473\n\n0.17.2 (08-11-2015)\n---------------------\n\n- Don't forget to pass `data` argument forward #462\n\n- Fix multipart read bytes count #463\n\n0.17.1 (08-10-2015)\n---------------------\n\n- Fix multidict comparsion to arbitrary abc.Mapping\n\n0.17.0 (08-04-2015)\n---------------------\n\n- Make StaticRoute support Last-Modified and If-Modified-Since headers #386\n\n- Add Request.if_modified_since and Stream.Response.last_modified properties\n\n- Fix deflate compression when writing a chunked response #395\n\n- Request`s content-length header is cleared now after redirect from\n  POST method #391\n\n- Return a 400 if server received a non HTTP content #405\n\n- Fix keep-alive support for aiohttp clients #406\n\n- Allow gzip compression in high-level server response interface #403\n\n- Rename TCPConnector.resolve and family to dns_cache #415\n\n- Make UrlDispatcher ignore quoted characters during url matching #414\n  Backward-compatibility warning: this may change the url matched by\n  your queries if they send quoted character (like %2F for /) #414\n\n- Use optional cchardet accelerator if present #418\n\n- Borrow loop from Connector in ClientSession if loop is not set\n\n- Add context manager support to ClientSession for session closing.\n\n- Add toplevel get(), post(), put(), head(), delete(), options(),\n  patch() coroutines.\n\n- Fix IPv6 support for client API #425\n\n- Pass SSL context through proxy connector #421\n\n- Make the rule: path for add_route should start with slash\n\n- Don't process request finishing by low-level server on closed event loop\n\n- Don't override data if multiple files are uploaded with same key #433\n\n- Ensure multipart.BodyPartReader.read_chunk read all the necessary data\n  to avoid false assertions about malformed multipart payload\n\n- Dont sent body for  204, 205 and 304 http exceptions #442\n\n- Correctly skip Cython compilation in MSVC not found #453\n\n- Add response factory to StaticRoute #456\n\n- Don't append trailing CRLF for multipart.BodyPartReader #454",
        "url": "http://pypi.python.org/pypi/aiohttp",
        "summary": "http client/server for asyncio",
        "command": "pip install 'aiohttp'"
      },
      "aio.http": {
        "name": "aio.http",
        "description": "Detailed documentation\n**********************\n\naio.http\n========\n\nThis package has been moved to aio.http.server_ (pypi_)\n\n.. _aio.http.server: https://github.com/phlax/aio.http.server\n.. _pypi: https://pypi.python.org/pypi/aio.http.server",
        "url": "http://pypi.python.org/pypi/aio.http",
        "summary": "HTTP server for the aio asyncio framework",
        "command": "pip install 'aio.http'"
      },
      "aiohttp_ac_hipchat": {
        "name": "aiohttp_ac_hipchat",
        "description": "aiohttp_ac_hipchat\n==================\n\nA Python 3 [aiohttp](aiohttp.readthedocs.org)-based library for building [HipChat Connect add-ons](https://www.hipchat.com/docs/apiv2/addons).  This is an early, alpha-quality release,\nbut can be used to build real add-ons today.  Future versions may include backward-incompatible changes.\n\nRequirements\n------------\n\n- Python >= 3.3\n- asyncio https://pypi.python.org/pypi/asyncio\n\nLicense\n-------\n\n``aiohttp_ac_hipchat`` is offered under the Apache 2 license.\n\nSource code\n-----------\n\nThe latest developer version is available in a BitBucket repository:\nhttps://bitbucket.org/atlassianlabs/aiohttp_ac_hipchat",
        "url": "http://pypi.python.org/pypi/aiohttp_ac_hipchat",
        "summary": "Aiohttp extension to support Atlassian Connect for HipChat",
        "command": "pip install 'aiohttp_ac_hipchat'"
      },
      "aiohttp_ac_hipchat_postgre": {
        "name": "aiohttp_ac_hipchat_postgre",
        "description": "aiohttp_ac_hipchat_postgre\n==================\n\nA Python 3 [aiohttp](http://aiohttp.readthedocs.org) -based library for using PostgreSQL stores with [aiohttp_ac_hipchat](http://bitbucket.org/atlassianlabs/aiohttp_ac_hipchat).  This is an early, alpha-quality release,\nbut can be used to build real add-ons today.  Future versions may include backward-incompatible changes.\n\n\nRequirements\n------------\n\n- Python >= 3.3\n- asyncio https://pypi.python.org/pypi/asyncio\n- aiopg https://github.com/aio-libs/aiopg\nLicense\n-------\n\n``aiohttp_ac_hipchat_postgre`` is offered under the Apache 2 license.\n\n\nSource code\n-----------\n\nThe latest developer version is available in a BitBucket repository:\nhttps://bitbucket.org/ramiroberrelleza/aiohttp_ac_hipchat_postgre",
        "url": "http://pypi.python.org/pypi/aiohttp_ac_hipchat_postgre",
        "summary": "Postgre store for aiohttp_ac_hipchat",
        "command": "pip install 'aiohttp_ac_hipchat_postgre'"
      },
      "aiohttp_debugtoolbar": {
        "name": "aiohttp_debugtoolbar",
        "description": "aiohttp_debugtoolbar\n====================\n.. image:: https://travis-ci.org/aio-libs/aiohttp_debugtoolbar.svg?branch=master\n    :target: https://travis-ci.org/aio-libs/aiohttp_debugtoolbar\n    :alt: |Build status|\n.. image:: https://coveralls.io/repos/aio-libs/aiohttp_debugtoolbar/badge.svg\n    :target: https://coveralls.io/r/aio-libs/aiohttp_debugtoolbar\n    :alt: |Coverage status|\n\n\n**aiohttp_debugtoolbar** provides a debug toolbar for your aiohttp_\nweb application.  Library is port of pyramid_debugtoolbar_ and\nstill in early development stages. Basic functionality has been\nported:\n\n* basic panels\n* intercept redirects\n* intercept and pretty print exception\n* interactive python console\n* show source code\n\n.. image:: https://raw.githubusercontent.com/aio-libs/aiohttp_debugtoolbar/master/demo/aiohttp_debugtoolba_sceenshot.png\n\n\nPorted Panels\n-------------\n``HeaderDebugPanel``, ``PerformanceDebugPanel``, ``TracebackPanel``,\n``SettingsDebugPanel``, ``MiddlewaresDebugPanel``, ``VersionDebugPanel``,\n``RoutesDebugPanel``,  ``RequestVarsDebugPanel``, ``LoggingPanel``\n\n\nHelp Needed\n-----------\nAre you coder looking for a project to contribute to\npython/asyncio libraries? This is the project for you!\n\n\nInstall and Configuration\n-------------------------\n::\n\n    $ pip install aiohttp_debugtoolbar\n\n\nIn order to plug in ``aiohttp_debugtoolbar`` you have to attach middleware to\nyour ``aiohttp.web.Application``, and call ``aiohttp_debugtoolbar.setup``\n\n.. code:: python\n\n    import aiohttp_debugtoolbar\n    app = web.Application(loop=loop,\n                          middlewares=[aiohttp_debugtoolbar.middleware])\n    aiohttp_debugtoolbar.setup(app)\n\n\nFull Example\n------------\n\n.. code:: python\n\n    import asyncio\n    import jinja2\n    import aiohttp_debugtoolbar\n    import aiohttp_jinja2\n\n    from aiohttp import web\n\n\n    @aiohttp_jinja2.template('index.html')\n    def basic_handler(request):\n        return {'title': 'example aiohttp_debugtoolbar!',\n                'text': 'Hello aiohttp_debugtoolbar!',\n                'app': request.app}\n\n\n    @asyncio.coroutine\n    def exception_handler(request):\n        raise NotImplementedError\n\n\n    @asyncio.coroutine\n    def init(loop):\n        # add aiohttp_debugtoolbar middleware to you application\n        app = web.Application(loop=loop,\n                              middlewares=[aiohttp_debugtoolbar.middleware])\n        # install aiohttp_debugtoolbar\n        aiohttp_debugtoolbar.setup(app)\n\n        template = \"\"\"\n        <html>\n            <head>\n                <title>{{ title }}</title>\n            </head>\n            <body>\n                <h1>{{ text }}</h1>\n                <p>\n                  <a href=\"{{ app.router['exc_example'].url() }}\">\n                  Exception example</a>\n                </p>\n            </body>\n        </html>\n        \"\"\"\n        # install jinja2 templates\n        loader = jinja2.DictLoader({'index.html': template})\n        aiohttp_jinja2.setup(app, loader=loader)\n\n        # init routes for index page, and page with error\n        app.router.add_route('GET', '/', basic_handler, name='index')\n        app.router.add_route('GET', '/exc', exception_handler,\n                             name='exc_example')\n\n        handler = app.make_handler()\n        srv = yield from loop.create_server(handler, '127.0.0.1', 9000)\n        print(\"Server started at http://127.0.0.1:9000\")\n        return srv, handler\n\n\n    loop = asyncio.get_event_loop()\n    srv, handler = loop.run_until_complete(init(loop))\n    try:\n        loop.run_forever()\n    except KeyboardInterrupt:\n        loop.run_until_complete(handler.finish_connections())\n\nThanks!\n-------\nI've borrowed a lot of code from following projects. I highly recommend to check them out:\n\n* `pyramid_debugtoolbar <https://github.com/Pylons/pyramid_debugtoolbar>`_  \n* `django-debug-toolbar <https://github.com/django-debug-toolbar/django-debug-toolbar>`_  \n* `flask-debugtoolbar <https://github.com/mgood/flask-debugtoolbar>`_  \n\nPlay With Demo\n--------------\n\nhttps://github.com/aio-libs/aiohttp_debugtoolbar/tree/master/demo\n\nRequirements\n------------\n\n* Python_ 3.3+\n* asyncio_ or Python_ 3.4+\n* aiohttp_\n* aiohttp_jinja2_\n\n\n.. _Python: https://www.python.org\n.. _asyncio: http://docs.python.org/3.4/library/asyncio.html\n.. _aiohttp: https://github.com/KeepSafe/aiohttp\n.. _aiopg: https://github.com/aio-libs/aiopg\n.. _aiomysql: https://github.com/aio-libs/aiomysql\n.. _aiohttp_jinja2: https://github.com/aio-libs/aiohttp_jinja2\n.. _pyramid_debugtoolbar: https://github.com/Pylons/pyramid_debugtoolbar\n\nCHANGES\n=======\n\n0.0.5 (2015-09-13)\n^^^^^^^^^^^^^^^^^^\n\n* Fixed IPv6 socket family error (Thanks @stormandco!)\n\n\n0.0.4 (2015-09-05)\n^^^^^^^^^^^^^^^^^^\n\n* Fixed support for aiohttp>=0.17. (Thanks @himikof!)\n\n\n0.0.3 (2015-07-03)\n^^^^^^^^^^^^^^^^^^\n\n* Switched template engine from mako to jinja2. (Thanks @iho!)\n\n* Added custom *yield from* to track context switches inside coroutine.\n\n* Implemented panel for collecting request log messages.\n\n* Disable toolbar code injecting for non web.Response answers\n  (StreamResponse or WebSocketResponse for example) #12\n\n\n0.0.2 (2015-05-26)\n^^^^^^^^^^^^^^^^^^\n\n* Redesign UI look-and-feel\n\n* Rename `toolbar_middleware_factory` to just `middleware`.\n\n\n0.0.1 (2015-05-18)\n^^^^^^^^^^^^^^^^^^\n\n* Initial release.",
        "url": "http://pypi.python.org/pypi/aiohttp_debugtoolbar",
        "summary": "debugtoolbar for aiohttp",
        "command": "pip install 'aiohttp_debugtoolbar'"
      },
      "aiohttp_jinja2": {
        "name": "aiohttp_jinja2",
        "description": "aiohttp_jinja2\n==============\n\njinja2_ template renderer for `aiohttp.web`__.\n\n\n.. _jinja2: http://jinja.pocoo.org\n\n.. _aiohttp_web: http://aiohttp.readthedocs.org/en/latest/web.html\n\n__ aiohttp_web_\n\n\nUsage\n-----\n\nBefore template rendering you have to setup *jinja2 environment* first::\n\n    app = web.Application()\n    aiohttp_jinja2.setup(app,\n        loader=jinja2.FileSystemLoader('/path/to/templates/folder'))\n\n\nAfter that you may to use template engine in your *web-handlers*. The\nmost convinient way is to decorate *web-handler*::\n\n    @aiohttp_jinja2.template('tmpl.jinja2')\n    def handler(request):\n        return {'name': 'Andrew', 'surname': 'Svetlov'}\n\nOn handler call the ``aiohttp_jinja2.template`` decorator will pass\nreturned dictionary ``{'name': 'Andrew', 'surname': 'Svetlov'}`` into\ntemplate named ``tmpl.jinja2`` for getting resulting HTML text.\n\nIf you need more complex processing (set response headers for example)\nyou may call ``render_template`` function::\n\n    @asyncio.coroutine\n    def handler(request):\n        context = {'name': 'Andrew', 'surname': 'Svetlov'}\n        response = aiohttp_jinja2.render_template('tmpl.jinja2',\n                                                  request,\n                                                  context)\n        response.headers['Content-Language'] = 'ru'\n        return response\n\nLicense\n-------\n\n``aiohttp_jinja2`` is offered under the Apache 2 license.\n\nCHANGES\n=======\n\n0.5.0 (2015-07-09)\n------------------\n\n- Introduce context processors #14\n\n- Bypass StreamResponse #15\n\n0.4.3 (2015-06-01)\n------------------\n\n- Fix distribution building: add manifest file\n\n0.4.2 (2015-05-21)\n------------------\n\n- Make HTTPInternalServerError exceptions more verbose on console\n  output\n\n0.4.1 (2015-04-05)\n------------------\n\n- Documentation update\n\n0.4.0 (2015-04-02)\n------------------\n\n- Add `render_string` method\n\n0.3.1 (2015-04-01)\n------------------\n\n- Don't allow non-mapping context\n\n- Fix tiny documentation issues\n\n- Change the library logo\n\n0.3.0 (2015-03-15)\n------------------\n\n- Documentation release\n\n0.2.1 (2015-02-15)\n------------------\n\n- Fix `render_template` function\n\n0.2.0 (2015-02-05)\n------------------\n\n- Migrate to aiohttp 0.14\n\n- Add `status` parameter to template decorator\n\n- Drop optional `response` parameter\n\n0.1.0 (2015-01-08)\n------------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/aiohttp_jinja2",
        "summary": "jinja2 template renderer for aiohttp.web (http server for asyncio)",
        "command": "pip install 'aiohttp_jinja2'"
      },
      "aiohttp_mako": {
        "name": "aiohttp_mako",
        "description": "aiohttp_mako\n============\n.. image:: https://travis-ci.org/aio-libs/aiohttp_mako.svg?branch=master\n    :target: https://travis-ci.org/aio-libs/aiohttp_mako\n.. image:: https://coveralls.io/repos/aio-libs/aiohttp_mako/badge.svg\n    :target: https://coveralls.io/r/aio-libs/aiohttp_mako\n\nmako_ template renderer for `aiohttp.web`__ based on aiohttp_jinja2_. Library\nsupports almost same api. It is used in aiohttp_debugtoolbar_.\n\n__ aiohttp_web_\n\n\nExample\n-------\n\n.. code:: python\n\n    import asyncio\n    import aiohttp_mako\n    from aiohttp import web\n\n\n    @aiohttp_mako.template('index.html')\n    def func(request):\n        return {'head': 'aiohttp_mako', 'text': 'Hello World!'}\n\n\n    @asyncio.coroutine\n    def init(loop):\n        app = web.Application(loop=loop)\n        lookup = aiohttp_mako.setup(app, input_encoding='utf-8',\n                                    output_encoding='utf-8',\n                                    default_filters=['decode.utf8'])\n        template = \"\"\"<html><body><h1>${head}</h1>${text}</body></html>\"\"\"\n        template_bug = \"\"\"<html><body><h1>${head}</h1>${text}</body></html>\"\"\"\n\n        lookup.put_string('index.html', template)\n        lookup.put_string('bug.html', template_bug)\n\n        app.router.add_route('GET', '/', func)\n\n        handler = app.make_handler()\n        srv = yield from loop.create_server(handler, '127.0.0.1', 8080)\n        print(\"Server started at http://127.0.0.1:8080\")\n        return srv, handler\n\n    loop = asyncio.get_event_loop()\n    srv, handler = loop.run_until_complete(init(loop))\n    try:\n        loop.run_forever()\n    except KeyboardInterrupt:\n        loop.run_until_complete(handler.finish_connections())\n\n\nLicense\n-------\n\n``aiohttp_mako`` is offered under the Apache 2 license.\n\n\n.. _mako: http://www.makotemplates.org/\n.. _aiohttp_jinja2: https://github.com/aio-libs/aiohttp_jinja2\n.. _aiohttp_web: http://aiohttp.readthedocs.org/en/latest/web.html\n.. _html_error_template: http://docs.makotemplates.org/en/latest/usage.html#mako.exceptions.html_error_template\n.. _aiohttp_debugtoolbar: https://github.com/aio-libs/aiohttp_debugtoolbar\n",
        "url": "http://pypi.python.org/pypi/aiohttp_mako",
        "summary": "mako template renderer for aiohttp.web (http server for asyncio)",
        "command": "pip install 'aiohttp_mako'"
      },
      "aiohttp-negotiate": {
        "name": "aiohttp-negotiate",
        "description": "aiohttp-negotiate\n=================\n\nA mixin for supporting Negotiate authentication with aiohttp.\n\nUsage\n-----\n\n.. code::\n\n   from aiohttp_negotiate import NegotiateClientSession\n\n   session = NegotiateClientSession()\n   resp = yield from session.get('https://example.com/')",
        "url": "http://pypi.python.org/pypi/aiohttp-negotiate",
        "summary": "Mixin for Negotiate authentication for aiohttp",
        "command": "pip install 'aiohttp-negotiate'"
      },
      "aiohttp_security": {
        "name": "aiohttp_security",
        "description": "aiohttp_security\n================\n\nThe library provides identity and autorization for `aiohttp.web`__.\n\n.. _aiohttp_web: http://aiohttp.readthedocs.org/en/latest/web.html\n\n__ aiohttp_web_\n\nUsage\n-----\n\n\nLicense\n-------\n\n``aiohttp_security`` is offered under the Apache 2 license.\n\nChanges\n=======",
        "url": "http://pypi.python.org/pypi/aiohttp_security",
        "summary": "security for aiohttp.web",
        "command": "pip install 'aiohttp_security'"
      },
      "aio.http.server": {
        "name": "aio.http.server",
        "description": "Detailed documentation\n**********************\n\naio.http.server\n===============\n\nHTTP server for the aio_ asyncio framework\n\n.. _aio: https://github.com/phlax/aio\n\n\nBuild status\n------------\n\n.. image:: https://travis-ci.org/phlax/aio.http.server.svg?branch=master\n\t       :target: https://travis-ci.org/phlax/aio.http.server\n\n\nInstallation\n------------\n\nRequires python >= 3.4\n\nInstall with:\n\n.. code:: bash\n\n\t  pip install aio.http.server\n\n\nQuick start - Hello world http server\n-------------------------------------\n\nCreate a web server that says hello\n\nSave the following into a file \"hello.conf\"\n\n.. code:: ini\n\t  \n\t  [server/my_server]\n\t  factory = aio.http.server.factory\n\t  port = 8080\n\t  protocol = my_example.protocol\n\n\t  \nAnd save the following into a file named my_example.py\n\t  \n.. code:: python\n\n\t  import asyncio\n\t  import aiohttp\n\n\t  import aio.app\n\n\t  @aio.app.server.protocol\n\t  def protocol(name):\n\t      loop = asyncio.get_event_loop()\n\t      webapp = aiohttp.web.Application(loop=loop)\n\n\t      @asyncio.coroutine\n\t      def handle_hello_world(webapp):\n\t          return aiohttp.web.Response(body=b\"Hello, world\")\n\n\t      webapp.router.add_route(\"GET\", \"/\", handle_hello_world)\n\t      return webapp.make_handler()\n\t      \t     \t      \n\nRun with the aio run command\n\n.. code:: bash\n\n\t  aio run -c hello.conf\n\n\t  \n\n\naio.http.server usage\n=====================\n\n\nConfiguration\n-------------\n\nCreate a server config with the aio.http.server.factory factory and suppressing normal output\n\n>>> config = \"\"\"\n... [aio]\n... log_level = ERROR\n... \n... [server/test]\n... factory: aio.http.server.factory\n... port: 7070\n... \"\"\"  \n\n\nRunning an http server\n----------------------\n\nBy default the http server will respond with a 404 as there are no routes set up\n\n>>> import asyncio\n>>> import aiohttp\n>>> from aio.app.runner import runner\n>>> import aio.testing\n\n>>> @aio.testing.run_forever(sleep=1)\n... def run_http_server():\n...     runner(['run'], config_string=config)\n... \n...     def call_http_server():\n...         result = yield from (\n...             yield from aiohttp.request(\n...                \"GET\", \"http://localhost:7070\")).read()  \n...         print(result)\n... \n...     return call_http_server\n\n>>> run_http_server()\nb'404: Not Found'\n\nThe server object is accessible from the aio.app.servers[{name}] var\n\n>>> import aio.app\n  \n>>> aio.app.servers['test']\n<Server sockets=[<socket.socket...laddr=('0.0.0.0', 7070)...]>\n\nLets clear the app\n\n>>> aio.app.clear()\n  \n\nRunning the server with a custom protocol\n-----------------------------------------\n\nIf you specify a protocol in the \"server/\" config, the http server will use that function as a protocol factory.\n\nThe function should be a coroutine and is called with the name of the server\n\n>>> config_with_protocol = \"\"\"\n... [aio]\n... log_level = ERROR\n... \n... [server/test]\n... factory = aio.http.server.factory\n... protocol = aio.http.server.tests._example_http_protocol\n... port = 7070\n... \"\"\"  \n\nWe need to decorate the protocol with aio.app.server.protocol\n\n>>> @aio.app.server.protocol\n... def http_protocol(name):\n...     loop = asyncio.get_event_loop()\n...     http_app = aiohttp.web.Application(loop=loop)\n...     http_app['name'] = name\n... \n...     @asyncio.coroutine  \n...     def handle_hello_world(http_app):\n...         return aiohttp.web.Response(body=b\"Hello, world\")\n... \n...     http_app.router.add_route(\"GET\", \"/\", handle_hello_world)\n...     return http_app.make_handler()\n\n>>> aio.http.server.tests._example_http_protocol = http_protocol\n\n>>> @aio.testing.run_forever(sleep=1)\n... def run_http_server():\n...     runner(['run'], config_string=config_with_protocol)\n... \n...     def call_http_server():\n...         result = yield from (\n...             yield from aiohttp.request(\n...                \"GET\", \"http://localhost:7070\")).read()\n... \n...         print(result)\n... \n...     return call_http_server\n  \n>>> run_http_server()\nb'Hello, world'",
        "url": "http://pypi.python.org/pypi/aio.http.server",
        "summary": "HTTP server for the aio asyncio framework",
        "command": "pip install 'aio.http.server'"
      },
      "aiohttp_session": {
        "name": "aiohttp_session",
        "description": "aiohttp_session\n===============\n\nThe library provides sessions for `aiohttp.web`__.\n\n.. _aiohttp_web: http://aiohttp.readthedocs.org/en/latest/web.html\n\n__ aiohttp_web_\n\nUsage\n-----\n\nThe library allows to store user-specific data into session object.\n\nThe session object has dict-like interface (operations like\n``session[key] = value``, ``value = session[key]`` etc. are present).\n\n\nBefore processing session in web-handler you have to register *session\nmiddleware* in ``aiohttp.web.Application``.\n\nA trivial usage example::\n\n    import asyncio\n    import time\n    from aiohttp import web\n    from aiohttp_session import get_session, session_middleware\n    from aiohttp_session.cookie_storage import EncryptedCookieStorage\n\n    @asyncio.coroutine\n    def handler(request):\n        session = yield from get_session(request)\n        session['last_visit'] = time.time()\n        return web.Response(body=b'OK')\n\n    @asyncio.coroutine\n    def init(loop):\n        app = web.Application(middlewares=[session_middleware(\n            EncryptedCookieStorage(b'Sixteen byte key'))])\n        app.router.add_route('GET', '/', handler)\n        srv = yield from loop.create_server(\n            app.make_handler(), '0.0.0.0', 8080)\n        return srv\n\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(init(loop))\n    try:\n        loop.run_forever()\n    except KeyboardInterrupt:\n        pass\n\nAll storages uses HTTP Cookie named ``AIOHTTP_COOKIE_SESSION`` for storing data.\n\nAvailable session storages are:\n\n* ``aiohttp_session.SimpleCookieStorage()`` -- keeps session data as\n  plain JSON string in cookie body. Use the storage only for testing\n  purposes, it's very non-secure.\n\n* ``aiohttp_session.cookie_storage.EncryptedCookieStorage(secret_key)``\n  -- stores session data into cookies as ``SimpleCookieStorage`` but\n  encodes it via AES cipher. ``secrect_key`` is a ``bytes`` key for AES\n  encryption/decryption, the length should be 16 bytes.\n\n  Requires ``crypotgraphy`` library::\n\n      $ pip install aiohttp_session[secure]\n\n* ``aiohttp_session.redis_storage.RedisStorage(redis_pool)`` -- stores\n  JSON-ed data into *redis*, keepeng into cookie only redis key\n  (random UUID). ``redis_pool`` is ``aioredis`` pool object, created by\n  ``yield from aioredis.create_pool(...)`` call.\n\n  Requires ``aioredis`` library::\n\n      $ pip install aiohttp_session[aioredis]\n\nLicense\n-------\n\n``aiohttp_session`` is offered under the Apache 2 license.\n\nChanges\n=======\n\n0.2.0 (2015-09-07)\n------------------\n\n- Add session.created property #14\n\n- Replaced PyCrypto with crypthography library #16\n\n0.1.2 (2015-08-07)\n------------------\n\n- Add manifest file #15\n\n0.1.1 (2015-04-20)\n------------------\n\n- Fix #7: stop cookie name growing each time session is saved\n\n\n0.1.0 (2015-04-13)\n------------------\n\n- First public release",
        "url": "http://pypi.python.org/pypi/aiohttp_session",
        "summary": "sessions for aiohttp.web",
        "command": "pip install 'aiohttp_session'"
      },
      "aiohttp_traversal": {
        "name": "aiohttp_traversal",
        "description": "======================================\nTraversal based router for aiohttp.web\n======================================\n\n.. image:: https://api.travis-ci.org/zzzsochi/aiohttp_traversal.svg\n  :target:  https://secure.travis-ci.org/zzzsochi/aiohttp_traversal\n  :align: center\n\n.. image:: https://coveralls.io/repos/zzzsochi/aiohttp_traversal/badge.svg\n  :target:  https://coveralls.io/r/zzzsochi/aiohttp_traversal\n  :align: center\n\n\n-------\nSchemes\n-------\n\n**Request lifetime**\n\n.. image:: https://raw.githubusercontent.com/zzzsochi/aiohttp_traversal/master/doc/img/request_lifetime.png\n   :alt: Request lifetime\n   :align: center\n\n\n**Traversal algorithm**\n\n.. image:: https://raw.githubusercontent.com/zzzsochi/aiohttp_traversal/master/doc/img/traversal_algorithm.png\n   :alt: Traversal algorithm\n   :align: center\n\n-----\nTests\n-----\n\n.. code:: shell\n\n    $ pip install pytest\n    $ py.test tests -v\n",
        "url": "http://pypi.python.org/pypi/aiohttp_traversal",
        "summary": "Traversal based router for aiohttp.web",
        "command": "pip install 'aiohttp_traversal'"
      },
      "aiohttp-wsgi": {
        "name": "aiohttp-wsgi",
        "description": "aiohttp-wsgi\n============\n\n**aiohttp-wsgi** is a WSGI adapter for aiohttp.\n\n\nFeatures\n--------\n\n- Run WSGI applications (e.g. Django, Flask) on `aiohttp <http://aiohttp.readthedocs.org>`_.\n- Handle thousands of client connections, using the latest `evented networking library <https://docs.python.org/3.4/library/asyncio.html>`_.\n- Add `websockets <http://aiohttp.readthedocs.org/en/v0.15.3/web.html#websockets>`_ to your\n  existing Python app!\n\n\nInstallation\n------------\n\n1. Install using ``pip install aiohttp-wsgi``.\n\n\nUsage\n-----\n\n\n``WSGIHandler(application, **kwargs)``\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n`Handler <http://aiohttp.readthedocs.org/en/v0.15.3/web.html#handler>`_ that wraps a WSGI application for use inside an aiohttp `Application <http://aiohttp.readthedocs.org/en/v0.15.3/web_reference.html#aiohttp.web.Application>`_.\n\n::\n\n    from aiohttp.web import Application\n    from aiohttp_wsgi import WSGIHandler\n    from your_app.wsgi import application\n\n    aiohttp_application = Application()\n    wsgi_handler = WSGIHandler(application)\n    aiohttp_application.router.add_route(\"*\", \"/{path_info:.*}\", wsgi_handler.handle_request)\n\n\n**Available arguments:**\n\n``url_scheme``\n    hint about the URL scheme used to access the application. Corresponds to ``environ[\"wsgi.uri_scheme\"]``. Default value auto-detected to ``\"http\"`` or ``\"https\"``.\n\n``stderr``\n    A file-like value for WSGI error logging. Corresponds to ``environ[\"wsgi.errors\"]``.  Defaults to ``sys.stderr``.\n\n``executor``\n    An `Executor <https://docs.python.org/dev/library/concurrent.futures.html#executor-objects>`_ instance used to run WSGI requests. Defaults to the asyncio base executor.\n\n``loop``\n    The asyncio `loop <https://docs.python.org/3.4/library/asyncio-eventloop.html#base-event-loop>`_. Defaults to ``asyncio.get_event_loop()``.\n\n\n``configure_server(application, **kwargs)``\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nHigh-level factory method that wraps a WSGI application in an asyncio `server <https://docs.python.org/3.4/library/asyncio-eventloop.html#server>`_ and aiohttp `Application <http://aiohttp.readthedocs.org/en/v0.15.3/web_reference.html#aiohttp.web.Application>`_.\n\n::\n\n    from aiohttp_wsgi import configure_server\n    from your_app.wsgi import application\n\n    server, app = configure_server(application)\n\n\n**Available arguments:**\n\n``host``\n    The IP address to bind the server. Defaults to ``\"0.0.0.0\"``.\n\n``port``\n    The network port to bind the server. Defaults to ``8080``.\n\n``unix_socket``\n    The path to a unix socket to bind the server. Overrides ``host``.\n\n``unix_socket_perms``\n    A set of filesystem permissions to apply to the unix socket. Defaults to ``0o600``.\n\n``socket``\n    A preexisting socket object to use for the server. Overrides ``host``.\n\n``backlog``\n    The maximum number of queued connections for the socket. Defaults to ``1024``.\n\n``routes``\n    A list of ``(method, path, handler)`` routes to add to the aiohttp `Application <http://aiohttp.readthedocs.org/en/v0.15.3/web_reference.html#aiohttp.web.Application>`_. Defaults to ``[]``.\n\n``static``\n    A list of ``(path, dirname)`` static routes to add to the aiohttp `Application <http://aiohttp.readthedocs.org/en/v0.15.3/web_reference.html#aiohttp.web.Application>`_. Defaults to ``[]``.\n\n``on_finish``\n    A list of callbacks to be executed when the server shuts down. Each callback will be passed the aiohttp `Application <http://aiohttp.readthedocs.org/en/v0.15.3/web_reference.html#aiohttp.web.Application>`_.\n\n``script_name``\n    The URL prefix to mount the WSGI application. Corresponds to ``environ[\"SCRIPT_NAME\"]``. This should **not** end with a slash. Defaults to ``\"\"``.\n\n\n``configure_server()`` also accepts all arguments available to ``WSGIHandler()``.\n\n\n\n``serve(application, **kwargs)``\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nHigh-level factory method that starts a `server <https://docs.python.org/3.4/library/asyncio-eventloop.html#server>`_ running a WSGI application.\n\n::\n\n    from aiohttp_wsgi import serve\n    from your_app.wsgi import application\n\n    serve(application)\n\n\n``serve()`` accepts all arguments available to ``configure_server()``.\n\n\nDesign\n------\n\nWSGI applications are run on an asyncio `executor <https://docs.python.org/3.4/library/asyncio-eventloop.html#executor>`_.\nThis allows existing Python frameworks like Django and Flask to run normally without\nblocking the main event loop or resorting to hacks like monkey-patching the Python\nstandard library. This enables you to write the majority of your application code in a safe,\npredictable environment.\n\nAsyncronous parts of your application (e.g. `websockets <http://aiohttp.readthedocs.org/en/v0.15.3/web.html#websockets>`_)\ncan be run on the same network port, using the `aiohttp router <http://aiohttp.readthedocs.org/en/v0.15.3/web.html#run-a-simple-web-server>`_\nto switch between your WSGI app and asyncronous code.\n\n\nBuild status\n------------\n\nThis project is built on every push using the Travis-CI service.\n\n.. image:: https://travis-ci.org/etianen/aiohttp-wsgi.svg?branch=master\n    :target: https://travis-ci.org/etianen/aiohttp-wsgi\n\n\nSupport and announcements\n-------------------------\n\nDownloads and bug tracking can be found at the `main project\nwebsite <http://github.com/etianen/aiohttp-wsgi>`_.\n\n\nMore information\n----------------\n\nThe aiohttp-wsgi project was developed by Dave Hall. You can get the code\nfrom the `aiohttp-wsgi project site <http://github.com/etianen/aiohttp-wsgi>`_.\n\nDave Hall is a freelance web developer, based in Cambridge, UK. You can usually\nfind him on the Internet in a number of different places:\n\n-  `Website <http://www.etianen.com/>`_\n-  `Twitter <http://twitter.com/etianen>`_\n-  `Google Profile <http://www.google.com/profiles/david.etianen>`_\n",
        "url": "http://pypi.python.org/pypi/aiohttp-wsgi",
        "summary": "WSGI adapter for aiohttp.",
        "command": "pip install 'aiohttp-wsgi'"
      },
      "aioirc": {
        "name": "aioirc",
        "description": "aioirc\n======\n\nAsyncIO IRC Library for >= Python 3.3\n\nIn Pre-Alpha now.",
        "url": "http://pypi.python.org/pypi/aioirc",
        "summary": "AsyncIO IRC Library for >= Python 3.3",
        "command": "pip install 'aioirc'"
      },
      "aiokafka": {
        "name": "aiokafka",
        "description": "aiokafka\n========\n\nasyncio client for kafka\n\nCHANGES\n--------\n\n0.0.1 (XXXX-XX-XX)\n^^^^^^^^^^^^^^^^^^\n\nInitial release",
        "url": "http://pypi.python.org/pypi/aiokafka",
        "summary": "Kafka integration with asyncio.",
        "command": "pip install 'aiokafka'"
      },
      "aioli": {
        "name": "aioli",
        "description": "Aioli\n=====\n\n**Aioli (ayo-OH-lee)** is a little sauce on top of Python's asyncio\npackage. With a little **aioli** it makes it easier to take advantage of\nasyncio in synchronous code.\n\nThese helpers are intended for IO bound tasks that yield. If you're not\nyield'ing or if your code is CPU bound then **aioli** probably won't\nhelp you much unless you start getting fancy with passing in your own\nloops in with their own executors.\n\nAwait\n~~~~~\n\n.. code:: python\n\n    @asyncio.coroutine\n    def func(x):\n        yield from asyncio.sleep(random())\n        return x\n    result = aioli.await(func(1))\n\nMap\n~~~\n\n.. code:: python\n\n    # Func will be run asynchronously for each item in iterable and results\n    # will be returned in order as their available.\n    def func(x):\n        yield from asyncio.sleep(random())\n        return x\n\n    for result in aioli.map(func, iterable):\n        print(result)\n\nParallel\n~~~~~~~~\n\n.. code:: python\n\n    # Func will be run asynchronously for each item in iterable and results\n    # will be returned as they are available.  Order is not guaranteed.\n    def inc(x):\n        yield from asyncio.sleep(random())\n        return x + 1\n\n    for result in aioli.parallel(func, iterable):\n        print(result)\n\nFilter\n~~~~~~\n\n.. code:: python\n\n    # Func will be run asynchronously for each item in iterable and results\n    # will be returned in order as their available.\n    is_even = lambda x: x % 2 == 0\n    for result in aioli.map(is_even, range(0, 100)):\n        print(result)\n\nFilter false\n~~~~~~~~~~~~\n\n.. code:: python\n\n    # Func will be run asynchronously for each item in iterable and results\n    # will be returned in order as their available.\n    is_even = lambda x: x % 2 == 0\n    for result in aioli.map(is_even, range(0, 100)):\n        print(result)\n\nFilter false\n~~~~~~~~~~~~\n\n.. code:: python\n\n    # Func will be run asynchronously for each item in iterable and results\n    # will be returned in order as their available.\n    is_even = lambda x: x % 2 == 0\n    for result in aioli.map(is_even, range(0, 100)):\n        print(result)",
        "url": "http://pypi.python.org/pypi/aioli",
        "summary": "asyncio special sauce",
        "command": "pip install 'aioli'"
      },
      "aiomanhole": {
        "name": "aiomanhole",
        "description": "aiomanhole\n==========\n\nManhole for accessing asyncio applications. This is useful for debugging\napplication state in situations where you have access to the process, but need\nto access internal application state.\n\nAdding a manhole to your application is simple::\n\n    from aiomanhole import start_manhole\n\n    start_manhole(namespace={\n        'gizmo': application_state_gizmo,\n        'whatsit': application_state_whatsit,\n    })\n\nQuick example, in one shell, run this::\n\n    $ python -m aiomanhole\n\nIn a secondary shell, run this::\n\n    $ nc -U /var/tmp/testing.manhole\n    Well this is neat\n    >>> f = 5 + 5\n    >>> f\n    10\n    >>> import os\n    >>> os.getpid()\n    4238\n    >>> import sys\n    >>> sys.exit(0)\n\n\nAnd you'll see the manhole you started has exited.\n\nThe package provides both a threaded and non-threaded interpreter, and allows\nyou to share the namespace between clients if you want.\n\n\nCan I specify what is available in the manhole?\n===============================================\nYes! When you call `start_manhole`, just pass along a dictionary of what you\nwant to provide as the namespace parameter::\n\n    from aiomanhole import start_manhole\n\n    start_manhole(namespace={\n        'gizmo': application_state_gizmo,\n        'whatsit': application_state_whatsit,\n        'None': 5,  # don't do this though\n    })\n\n\nWhen should I use threaded=True?\n================================\n\nSpecifying threaded=True means that statements in the interactive session are\nexecuted in a thread, as opposed to executing them in the event loop.\n\nSay for example you did this in a non-threaded interactive session::\n\n    >>> while True:\n    ...  pass\n    ...\n\nYou've just broken your application! You can't abort that without restarting\nthe application. If however you ran that in a threaded application, you'd\n'only' have a thread trashing the CPU, slowing down your application, as\nopposed to making it totally unresponsive.\n\nBy default, a threaded interpreter will time out commands after 5 seconds,\nthough this is configurable. Not that this will **not** kill the thread, but\nallow you to keep running commands.",
        "url": "http://pypi.python.org/pypi/aiomanhole",
        "summary": "Python module to provide a manhole in asyncio applications",
        "command": "pip install 'aiomanhole'"
      },
      "aio.manhole.server": {
        "name": "aio.manhole.server",
        "description": "Detailed documentation\n**********************\n\naio.manhole.server\n==================\n\nManhole server for the aio_ asyncio framework\n\n.. _aio: https://github.com/phlax/aio\n\n\n\nBuild status\n------------\n\n.. image:: https://travis-ci.org/phlax/aio.manhole.server.svg?branch=master\n\t       :target: https://travis-ci.org/phlax/aio.manhole.server\n\n\nInstallation\n------------\n\nRequires python >= 3.4\n\nInstall with:\n\n.. code:: bash\n\n\t  pip install aio.manhole.server\n\n\t  \nQuick start - Manhole server\n----------------------------\n\nSave the following into a file \"manhole.conf\"\n\n.. code:: ini\n\n\t  [server/my_manhole_server]\n\t  factory = aio.manhole.server.factory\n\t  port = 7373\n\n\t  \nRun with the aio run command\n\n.. code:: bash\n\n\t  aio run -c manhole.conf\n\nYou should now be able to telnet into the running server on port 7373\n\n\n\naio.manhole.server usage\n------------------------\n\n\nConfiguration\n-------------\n\nLets create a manhole configuration\n  \n>>> config = \"\"\"\n... [aio]\n... log_level = ERROR\n... \n... [server/server_name]\n... factory = aio.manhole.server.factory\n... port = 7373\n... \n... \"\"\"  \n\n>>> import sys\n>>> import io\n>>> import aiomanhole\n\n>>> import aio.testing\n>>> import aio.app\n>>> from aio.app.runner import runner\n\nWhen we run the manhole server, its accessible as \"server_name\" from aio.app.servers\n\n>>> @aio.testing.run_forever(sleep=1)\n... def run_manhole_server(config):\n...     yield from runner(['run'], config_string=config)\n... \n...     def call_manhole():\n...         print(aio.app.servers[\"server_name\"])\n...         aio.app.clear()\n...          \n...     return call_manhole\n\n>>> run_manhole_server(config)\n<Server sockets=[<socket.socket ...laddr=('0.0.0.0', 7373)...>\n\nLets try calling the manhole server\n\n>>> import asyncio\n>>> import telnetlib3\n\n>>> @aio.testing.run_forever(sleep=1)\n... def run_manhole_server(config):\n...     yield from runner(['run'], config_string=config)\n...     \n...     class TestTelnetClient(telnetlib3.TelnetClient):\n... \n...         def data_received(self, data):\n...             print(data)\n... \n...     def call_manhole():\n...         loop = asyncio.get_event_loop()\n...         transport, protocol = yield from loop.create_connection(\n...             TestTelnetClient, \"127.0.0.1\", 7373)\n...         aio.app.clear()\n...          \n...     return call_manhole\n\n>>> run_manhole_server(config)\nb'hello...\\n>>> '",
        "url": "http://pypi.python.org/pypi/aio.manhole.server",
        "summary": "Manhole server for the aio asyncio framework",
        "command": "pip install 'aio.manhole.server'"
      },
      "aiomas": {
        "name": "aiomas",
        "description": "aiomas – A library for multi-agent systems and RPC based on asyncio\n===================================================================\n\n*aiomas* is an easy-to-use library for *remote procedure calls (RPC)* and\n*multi-agent systems (MAS)*. It’s written in pure Python on top of asyncio__.\n\nHere is an example how you can write a simple multi-agent system:\n\n.. code-block:: pycon\n\n   >>> import aiomas\n   >>>\n   >>> class TestAgent(aiomas.Agent):\n   ...     def __init__(self, container):\n   ...         super().__init__(container)\n   ...         print('Ohai, I am %s' % self)\n   ...\n   ...     async def run(self, addr):\n   ...         remote_agent = await self.container.connect(addr)\n   ...         ret = await remote_agent.service(42)\n   ...         print('%s got %s from %s' % (self, ret, remote_agent))\n   ...\n   ...     @aiomas.expose\n   ...     def service(self, value):\n   ...         return value\n   >>>\n   >>> c = aiomas.Container.create(('localhost', 5555))\n   >>> agents = [TestAgent(c) for i in range(2)]\n   Ohai, I am TestAgent('tcp://localhost:5555/0')\n   Ohai, I am TestAgent('tcp://localhost:5555/1')\n   >>> aiomas.run(until=agents[0].run(agents[1].addr))\n   TestAgent('tcp://localhost:5555/0') got 42 from TestAgentProxy('tcp://localhost:5555/1')\n   >>> c.shutdown()\n\n*aiomas* is released under the MIT license. It requires Python 3.4 and above\nand runs on Linux, OS X, and Windows.\n\n__ https://docs.python.org/3/library/asyncio.html\n\n\nInstallation\n------------\n\n*aiomas* requires Python >= 3.4.  It uses the *JSON* codec by default and only\nhas pure Python dependencies.\n\nInstall *aiomas* via pip__ by running:\n\n.. code-block:: bash\n\n   $ pip install aiomas\n\nYou can enable the optional MsgPack__ codec or its Blosc__ compressed version\nby installing the corresponding features (note, that you need a C compiler to\ninstall them):\n\n.. code-block:: bash\n\n   $ pip install aiomas[mp]   # Enables the MsgPack codec\n   $ pip install aiomas[mpb]  # Enables the MsgPack and MsgPackBlosc codecs\n\n__ https://pip.pypa.io/\n__ https://pypi.python.org/pypi/msgpack-python/\n__ https://pypi.python.org/pypi/blosc/\n\n\nFeatures\n--------\n\n*aiomas* just puts three layers of abstraction around raw TCP / unix domain\nsockets provided by *asyncio*:\n\nAgents and agent containers:\n  The top-layer provides a simple base class for your own agents. All agents\n  live in a container.\n\n  Containers take care of creating agent instances and performing the\n  communication between them.\n\n  The container provides a *clock* for the agents. This clock can either be\n  synchronized with the real (wall-clock) time or be set by an external process\n  (e.g., other simulators).\n\nRPC:\n  The *rpc* layer implements remote procedure calls which let you call methods\n  on remote objects nearly as if they were normal objects:\n\n  Instead of ``ret = obj.meth(arg)`` you write ``ret = await obj.meth(arg)``.\n\nRequest-reply channel:\n  The *channel* layer is the basis for the *rpc* layer. It sends JSON__ or\n  MsgPack__ encoded byte strings over TCP or unix domain sockets. It also maps\n  replies (of success or failure) to their corresponding request.\n\nAlthough you usually want to use the *agent* layer, it is perfectly okay to\nonly use the *rpc* or *channel* layer.\n\n__ http://www.json.org/\n__ http://msgpack.org/\n\n\nPlanned features\n^^^^^^^^^^^^^^^^\n\nSome ideas for future releases:\n\n- SSL/TLS support for TCP sockets\n\n- Optional automatic re-connect after connection loss\n\n- Helper for binding a socket to a random free port\n\n\nContribute\n----------\n\n- Issue Tracker: https://bitbucket.org/ssc/aiomas/issues?status=new&status=open\n- Source Code: https://bitbucket.org/ssc/aiomas/src\n\nSet-up a development environment with:\n\n.. code-block:: bash\n\n   $ virtualenv -p `which python3` aiomas\n   $ pip install -r requirements.txt\n\nRun the tests with:\n\n.. code-block:: bash\n\n   $ py.test\n   $ # or\n   $ tox\n\n\nSupport\n-------\n\n- Documentation: http://aiomas.readthedocs.org/en/latest/\n\n- Mailing list: https://groups.google.com/forum/#!forum/aiomas\n\n- Stack Overflow: http://stackoverflow.com/questions/tagged/aiomas\n\n- IRC: #aiomas\n\n\nLicense\n-------\n\nThe project is licensed under the MIT license.\n\n\nChangelog\n=========\n\n0.6.0 – 2015-09-18\n------------------\n\n- [CHANGE] Asserted Python 3.5 compatibility and converted all examples to use\n  the new ``async`` and ``await`` keywords.\n\n- [CHANGE] ``Container.__init__()`` no longer contains an asynchronous task.\n  Instead, you now need to call the factory function ``Container.create()``.\n\n- [CHANGE] Removed ``Container.spawn()``.  You can now directly instantiate\n  agent instances but you still need to pass a reference to the agent's\n  container to ``Agent.__init__()``.\n\n- [NEW] ``AiomasError`` is the new base class for all errors in aiomas (`issue\n  #15`_).\n\n- [NEW] Documentation tests now have their own *tox* environment (``tox -e\n  docs``).\n\n- [NEW] Added support and docs_ for TLS encryption.\n\n- [NEW] Added some documentation about the channel layer.\n\n.. _docs: https://aiomas.readthedocs.org/en/latest/tls.html\n.. _`issue #15`: https://bitbucket.org/ssc/aiomas/issue/15/\n\n\n0.5.0 – 2015-06-27\n------------------\n\n- [CHANGE] Agent addresses now start with *tcp://* or *ipc://* (for Unix domain\n  sockets) instead of just *agent://*.\n\n- [CHANGE] Using dictionaries as routers is now easier (`issue #13`_).\n\n- [CHANGE] Renamed the ``rpc`` attribute for routers to ``router``.\n\n- [CHANGE] Renamed ``Agent.name`` to ``Agent.addr`` and improved agent's *str*\n  representation.\n\n- [CHANGE] Updated and improved *str* and *repr* for agents, proxies and agent\n  proxies.\n\n- [CHANGE] ``Codec.add_serializer()`` now raises an exception if there is\n  already a serializer for a given type (`issue #9`_).\n\n- [NEW] Added ``aiomas.util.run()`` (and an ``aiomas.run()`` alias) which are\n  shortcuts for ``loop = asyncio.get_event_loop();\n  loop_run_{until_complete|forever}()``.\n\n- [NEW] Added a ``@serializable`` decorator to ``aiomas.codecs`` which\n  simplifies making a type serializable.\n\n- [NEW] Documentation: Overview, Agents, Codecs, Clocks (draft), Testing (draft).\n\n- [NEW] ``Container.connect()`` checks if an agent exists in the remote\n  container.\n\n- [NEW] Proxies are now cached with weakrefs.\n\n- [FIX] `issue #12`_: ``Router.path`` reversed the order of path components.\n\n- [FIX] Fixed a bug where concurrent calls to ``Container.connect()`` would\n  lead to multiple connections to the same address.\n\n.. _`issue #9`: https://bitbucket.org/ssc/aiomas/issue/9/\n.. _`issue #12`: https://bitbucket.org/ssc/aiomas/issue/12/\n.. _`issue #13`: https://bitbucket.org/ssc/aiomas/issue/13/\n\n\n0.4.0 – 2015-04-15\n------------------\n\n- [CHANGE] ``Channel`` and ``Container`` no longer take codec instances but\n  classes.  They also accept a list of factories for extra serializers.\n\n- [CHANGE] The ``rpc.open_connection()`` and ``rpc.start_server()`` methods\n  no longer accept the ``add_to`` parameter.  ``rpc.start_server()`` accept\n  a *client_connected_cb* instead, which should be a function with one\n  argument, the ``RpcClient`` for each new connection.\n  ``rpc.open_connection()`` already returns the ``RpcClient()``.\n\n- [CHANGE] Renamed the package extras from *MsgPack* to *mp* and from\n  *MsgPackBlosc* to *mpb* to work around a bug in pip/setuptools.  They are\n  also shorter now. ;-)\n\n- [NEW] ``RpcClient`` no has a ``channel`` and a ``service`` attribute.\n\n- [NEW] Improved error message for ``LookupError``.\n\n- [FIX] `issue #8`_:  Every channel instance created by\n  ``channel.start_server()`` now has a separate codec instance to avoid\n  problems with some serializers.\n\n.. _`issue #8`: https://bitbucket.org/ssc/aiomas/issue/8/\n\n\n0.3.0 – 2015-03-11\n------------------\n\n- [CHANGE] Removed LocalProxies and everything related to it because they\n  caused several problems.  That means that agents within a single container\n  now also communicate via TCP sockets.  Maybe something similar but more\n  robust will be reintroduced in a later release.\n\n- [CHANGE] ``Channel.send()`` is no longer a coroutine.  It returns a Future\n  instead.\n\n- [CHANGE] Removed ``Container.get_url_for()`` which didn’t (and couldn’t) work\n  as I originally assumed.\n\n- [CHANGE] ``JSON`` is now the default codec.  msgpack and blosc don’t get\n  installed by default.  This way, we only have pure Python dependencies for\n  the default installation which is very handy if you are on Windows.  You can\n  enable the other codecs via ``pip install -U aiomas[MsgPack]`` or ``pip\n  install -U aiomas[MsgPackBlosc]``.\n\n- [NEW] Support for Python 3.4.0 and 3.4.1 (yes, Python 3.3 with asyncio works,\n  too, but I’ll drop support for it as soon as it becomes a burden) (Resolves\n  `issue #6`_).\n\n- [NEW] ``ExternalClock`` accepts a date string or an Arrow object to set the\n  inital date and time.\n\n- [NEW] ``aiomas.util.async()`` which is like ``asyncio.async()`` but registers\n  a callback that instantly captures and raises exceptions, instead of delaying\n  them until the task gets garbage collected.\n\n- [NEW] The agent container adds a serializer for Arrow dates.\n\n- [NEW] ``Proxy`` implements ``__eq__()`` and ``__hash__()``.  Two different\n  proxy objects sharing the same channel and pointing to the same remote\n  function will no appear to be equal.  This makes it less error prone to use\n  Proxy instances as keys in dictionaries.\n\n- [NEW] Updated and improved flow-control for ``Channel`` and its protocol.\n\n- [NEW] Improved error handling if the future returned by ``Channel.send()``\n  is triggered or cancelled by an external party (e.g., by going out of scope).\n  If asyncio’s DEBUG mode is enabled, you will even get more detailed error\n  messages.\n\n- [NEW] ``MessagePackBlosc`` codec.  It uses msgpack to serialize messages and\n  blosc to compress them.  It can massively reduce the message size and\n  consumes very little CPU time.\n\n- [NEW] A Contract Net example\n  (https://bitbucket.org/ssc/aiomas/src/tip/examples/contractnet.py)\n\n- [NEW] ``__str__()`` representations for agents, containers and codecs (fixes\n  `issue #5`_).\n\n- [FIX] `issue #7`_: Improved error handling and messages if the\n  (de)serialization raises an exception.\n\n- [FIX] Containers now work with unix domain sockets.\n\n- [FIX] Various minor bug-fixes\n\n.. _`issue #5`: https://bitbucket.org/ssc/aiomas/issue/5/\n.. _`issue #6`: https://bitbucket.org/ssc/aiomas/issue/6/\n.. _`issue #7`: https://bitbucket.org/ssc/aiomas/issue/7/\n\n\n0.2.0 - 2015-01-23\n------------------\n\n- [CHANGE] The *MsgPack* codec is now the default.  Thus, *msgpack-python* is\n  now a mandatory dependency.\n\n- [CHANGE] Renamed ``RpcClient.call`` to ``RpcClient.remote``.\n\n- [NEW] ``aiomas.agent`` module with an ``Agent`` base class and\n  a ``Container`` for agents.  Agents within a container communicate via direct\n  method calls.  Agents in different containers use RPC.\n\n- [NEW] ``aiomas.clock`` module which offers various clocks for a MAS:\n\n  - ``AsyncioClock`` is a real-time clock and wraps asyncio's ``time()``,\n    ``sleep()``, ``call_later()`` and ``call_at()`` functions.\n\n  - ``ExternalClock`` can be synchronized with external simulation\n    environments.  This allows you to *stop* the time or let it pass\n    faster/slower than the wall-clock time.\n\n- [NEW] Support for unix domain sockets in ``aiomas.channel`` and\n  ``aiomas.rpc``.\n\n- [NEW] \"rpc_service()\" tasks created by an RPC server can now be collected\n  so that you can wait for their completion before you shutdown your program.\n\n- [NEW] Added contents to the README and created a Sphinx project.  Only the\n  API reference is done yet.  A tutorial and topical guides will follow.\n\n- [FIX] aiomas with the JSON codec is now compatible to simpy.io\n\n\n\n0.1.0 – 2014-12-18\n------------------\n\nInitial release with the following features:\n\n- A *request-reply channel* via TCP that allows to send multiple messages and\n  to asynconously wait for results (or an exception).\n\n- Messages can be serialized with *JSON* or *msgpack*.\n\n- The underlying communication protocol should be compatible with `simpy.io\n  <https://bitbucket.org/simpy/simpy.io/>`_ (if you use JSON and no custom\n  serializers).\n\n- Remote procedure calls (RPCs) supporting nested handlers and bidirectional\n  calls (callees can make calls to the caller before returning the actual\n  result).\n\n\nAuthors\n=======\n\nThe original author of aiomas is Stefan Scherfke.\n\nThe development is kindly supported by `OFFIS <www.offis.de/en/>`_.",
        "url": "http://pypi.python.org/pypi/aiomas",
        "summary": "A library for multi-agent systems, based on asyncio",
        "command": "pip install 'aiomas'"
      },
      "aiomcache": {
        "name": "aiomcache",
        "description": "memcached client for asyncio\n============================\n\nasyncio (PEP 3156) library to work with memcached.\n\n.. image:: https://travis-ci.org/aio-libs/aiomcache.svg?branch=master\n   :target: https://travis-ci.org/aio-libs/aiomcache\n\n\nRequirements\n------------\n\n- Python >= 3.3\n- asyncio https://pypi.python.org/pypi/asyncio/\n\n\nGetting started\n---------------\n\nThe API looks very similar to the other memcache clients::\n\n    import aiomcache\n    mc = aiomcache.Client(\"127.0.0.1\", 11211, pool_size)\n    yield from mc.set(b\"some_key\", b\"Some value\")\n    value = yield from mc.get(b\"some_key\")\n    values = yield from mc.multi_get(b\"some_key\")\n    yield from mc.delete(b\"another_key\")\n\nCHANGES\n=======\n\n0.1 (06-18-2014)\n----------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/aiomcache",
        "summary": "Minimal pure python memcached client",
        "command": "pip install 'aiomcache'"
      },
      "aiomeasures": {
        "name": "aiomeasures",
        "description": "AIO Measures\n============\n\nThis library allows you to send metrics to your StatsD server.\nThis works on Python >= 3.3 and relies or asyncio.\n\n\nInstallation::\n\n    python -m pip install aiomeasures\n\n\nUsage::\n\n    from aiomeasures import StatsD\n\n    client = StatsD('udp://127.0.0.1:6789')\n    client.incr('foo')\n    client.decr('bar', tags={'one': 'two'})\n    with client.timer('baz'):\n        # long process\n        pass\n\n\nThe client will send metrics to server as possible.\n",
        "url": "http://pypi.python.org/pypi/aiomeasures",
        "summary": "Collect and send metrics to StatsD",
        "command": "pip install 'aiomeasures'"
      },
      "aiomemcache": {
        "name": "aiomemcache",
        "description": "memcached client for asyncio\n============================\n\naiomemcache is a minimal, pure python client for memcached, kestrel, etc.\n\n\nRequirements\n------------\n\n- Python >= 3.3\n- asyncio https://pypi.python.org/pypi/asyncio/\n\n\nGetting started\n---------------\n\nThe API looks very similar to the other memcache clients::\n\n    import aiomemcache\n    mc = aiomemcache.Client(\"127.0.0.1\", 11211, connect_timeout=5)\n    yield from mc.set(b\"some_key\", b\"Some value\")\n    value = yield from mc.get(b\"some_key\")\n    yield from mc.delete(b\"another_key\")\n\nCHANGES\n=======\n\n0.1 (02-04-2014)\n----------------\n\n- Initial release",
        "url": "http://pypi.python.org/pypi/aiomemcache",
        "summary": "Minimal pure python memcached client",
        "command": "pip install 'aiomemcache'"
      },
      "aiompd": {
        "name": "aiompd",
        "description": "============================================\nMPD (Music Player Daemon) client for asyncio\n============================================\n\nUsage example:\n\n.. code:: python\n\n    import asyncio\n    import aiompd\n\n    URLS = [\n        \"http://mega5.fast-serv.com:8134\",\n        \"http://176.31.240.114:8326\",\n        \"http://74.86.186.4:10042\",\n        \"http://s14.myradiostream.com:4668\",\n    ]\n    PLAY_TIME = 10\n\n\n    @asyncio.coroutine\n    def nexter(mpc):\n        yield from mpc.clear()\n\n        for url in URLS:\n            yield from mpc.add(url)\n\n        for n in range(len(URLS)):\n            print('play', n)\n            yield from mpc.play(track=n)\n            yield from asyncio.sleep(PLAY_TIME)\n\n\n    @asyncio.coroutine\n    def volumer(mpc):\n        timeout = (len(URLS) * PLAY_TIME) / 200\n\n        for volume in range(0, 101, 1):\n            print('volume', volume)\n            yield from mpc.set_volume(volume)\n            yield from asyncio.sleep(timeout)\n\n        for volume in range(100, -1, -1):\n            print('volume', volume)\n            yield from mpc.set_volume(volume)\n            yield from asyncio.sleep(timeout)\n\n\n    def main():\n        loop = asyncio.get_event_loop()\n        mpc = loop.run_until_complete(aiompd.Client.make_connection())\n        loop.run_until_complete(asyncio.wait([nexter(mpc), volumer(mpc)]))\n\n\n    if __name__ == '__main__':\n        main()",
        "url": "http://pypi.python.org/pypi/aiompd",
        "summary": "MPD (Music Player Daemon) client for asyncio",
        "command": "pip install 'aiompd'"
      },
      "aiomultiprocessing": {
        "name": "aiomultiprocessing",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aiomultiprocessing",
        "summary": "n/a",
        "command": "pip install 'aiomultiprocessing'"
      },
      "aiomysql": {
        "name": "aiomysql",
        "description": "aiomysql\n========\n.. image:: https://travis-ci.org/aio-libs/aiomysql.svg?branch=master\n    :target: https://travis-ci.org/aio-libs/aiomysql\n.. image:: https://coveralls.io/repos/aio-libs/aiomysql/badge.svg\n    :target: https://coveralls.io/r/aio-libs/aiomysql\n.. image:: https://pypip.in/version/aiomysql/badge.svg\n    :target: https://pypi.python.org/pypi/aiomysql/\n    :alt: Latest Version\n.. image:: https://readthedocs.org/projects/aiomysql/badge/?version=latest\n    :target: http://aiomysql.readthedocs.org/\n    :alt: Documentation Status\n\n**aiomysql** is a \"driver\" for accessing a `MySQL` database\nfrom the asyncio_ (PEP-3156/tulip) framework. It depends on and reuses most\nparts of PyMySQL_ . *aiomysql* tries to be like awesome aiopg_ library and\npreserve same api, look and feel.\n\nInternally **aiomysql** is copy of PyMySQL, underlying io calls switched\nto async, basically ``yield from`` and ``asyncio.coroutine`` added in\nproper places)). `sqlalchemy` support ported from aiopg_.\n\n\nDocumentation\n-------------\n\nhttp://aiomysql.readthedocs.org/\n\n\nBasic Example\n-------------\n\n**aiomysql** based on PyMySQL_ , and provides same api, you just need\nto use  ``yield from conn.f()`` instead of just call ``conn.f()`` for\nevery method.\n\nProperties are unchanged, so ``conn.prop`` is correct as well as\n``conn.prop = val``.\n\n\n.. code:: python\n\n    import asyncio\n    import aiomysql\n\n    loop = asyncio.get_event_loop()\n\n    @asyncio.coroutine\n    def test_example():\n        conn = yield from aiomysql.connect(host='127.0.0.1', port=3306,\n                                           user='root', password='', db='mysql',\n                                           loop=loop)\n\n        cur = yield from conn.cursor()\n        yield from cur.execute(\"SELECT Host,User FROM user\")\n        print(cur.description)\n        r = yield from cur.fetchall()\n        print(r)\n        yield from cur.close()\n        conn.close()\n\n    loop.run_until_complete(test_example())\n\n\nConnection Pool\n---------------\nConnection pooling ported from aiopg_ :\n\n.. code:: python\n\n    import asyncio\n    import aiomysql\n\n\n    loop = asyncio.get_event_loop()\n\n\n    @asyncio.coroutine\n    def test_example():\n        pool = yield from aiomysql.create_pool(host='127.0.0.1', port=3306,\n                                               user='root', password='',\n                                               db='mysql', loop=loop)\n        with (yield from pool) as conn:\n            cur = yield from conn.cursor()\n            yield from cur.execute(\"SELECT 10\")\n            # print(cur.description)\n            (r,) = yield from cur.fetchone()\n            assert r == 10\n        pool.close()\n        yield from pool.wait_closed()\n\n    loop.run_until_complete(test_example())\n\n\nExample of SQLAlchemy optional integration\n------------------------------------------\nSqlalchemy support has been ported from aiopg_ so api should be very familiar\nfor aiopg_ user.:\n\n.. code:: python\n\n   import asyncio\n   from aiomysql.sa import create_engine\n   import sqlalchemy as sa\n\n\n   metadata = sa.MetaData()\n\n   tbl = sa.Table('tbl', metadata,\n       sa.Column('id', sa.Integer, primary_key=True),\n       sa.Column('val', sa.String(255)))\n\n\n   @asyncio.coroutine\n   def go():\n       engine = yield from create_engine(user='root',\n                                         db='aiomysql',\n                                         host='127.0.0.1',\n                                         password='')\n\n       with (yield from engine) as conn:\n           yield from conn.execute(tbl.insert().values(val='abc'))\n\n           res = yield from conn.execute(tbl.select())\n           for row in res:\n               print(row.id, row.val)\n\n\n   asyncio.get_event_loop().run_until_complete(go())\n\n\nRequirements\n------------\n\n* Python_ 3.3+\n* asyncio_ or Python_ 3.4+\n* PyMySQL_\n\n\n.. _Python: https://www.python.org\n.. _asyncio: http://docs.python.org/3.4/library/asyncio.html\n.. _aiopg: https://github.com/aio-libs/aiopg\n.. _PyMySQL: https://github.com/PyMySQL/PyMySQL\n.. _Tornado-MySQL: https://github.com/PyMySQL/Tornado-MySQL\n\nChanges\n-------\n\n0.0.4 (2015-05-23)\n^^^^^^^^^^^^^^^^^^\n\n* Allow to call connection.wait_closed twice.\n\n* Fixed sqlalchemy 1.0.0 support.\n\n* Fix #11: Rename Connection.wait_closed() to .ensure_closed()\n\n* Raise ResourceWarning on non-closed Connection\n\n* Rename Connection.connect to _connect\n\n\n0.0.3 (2015-03-10)\n^^^^^^^^^^^^^^^^^^\n\n* Added support for PyMySQL up to 0.6.6.\n\n* Ported improvements from PyMySQL.\n\n* Added basic documentation.\n\n* Fixed and added more examples.\n\n\n0.0.2 (2015-02-17)\n^^^^^^^^^^^^^^^^^^\n\n* Added MANIFEST.in.\n\n\n0.0.1 (2015-02-17)\n^^^^^^^^^^^^^^^^^^\n\n* Initial release.\n\n* Implemented plain connections: connect, Connection, Cursor.\n\n* Implemented database pools.\n\n* Ported sqlalchemy optional support.",
        "url": "http://pypi.python.org/pypi/aiomysql",
        "summary": "MySQL driver for asyncio.",
        "command": "pip install 'aiomysql'"
      },
      "aioodbc": {
        "name": "aioodbc",
        "description": "aioodbc\n=======\n.. image:: https://travis-ci.org/jettify/aioodbc.svg?branch=master\n    :target: https://travis-ci.org/jettify/aioodbc\n.. image:: https://coveralls.io/repos/jettify/aioodbc/badge.svg?branch=master&service=github\n    :target: https://coveralls.io/github/jettify/aioodbc?branch=master\n\n**aioodbc** is Python module that makes possible accessing ODBC_ databases\nwith asyncio_. It is rely on awesome pyodbc_ library, preserve same look and\nfeel.\n\n\nBasic Example\n-------------\n\n**aioodbc** based on pyodbc_ , and provides same api, you just need\nto use  ``yield from conn.f()`` or ``await conn.f()`` instead of just\ncall ``conn.f()`` for every method.\n\nProperties are unchanged, so ``conn.prop`` is correct as well as\n``conn.prop = val``.\n\n\n.. code:: python\n\n    import asyncio\n    import aioodbc\n\n\n    loop = asyncio.get_event_loop()\n\n\n    @asyncio.coroutine\n    def test_example():\n        dsn = 'Driver=SQLite;Database=sqlite.db'\n        conn = yield from aioodbc.connect(dsn=dsn, loop=loop)\n\n        cur = yield from conn.cursor()\n        yield from cur.execute(\"SELECT 42;\")\n        r = yield from cur.fetchall()\n        print(r)\n        yield from cur.close()\n        yield from conn.close()\n\n    loop.run_until_complete(test_example())\n\n\nConnection Pool\n---------------\nConnection pooling ported from aiopg_ and rely on PEP492_ features:\n\n.. code:: python\n\n    import asyncio\n    import aioodbc\n\n\n    loop = asyncio.get_event_loop()\n\n\n    async def test_pool():\n        dsn = 'Driver=SQLite;Database=sqlite.db'\n        pool = await aioodbc.create_pool(dsn=dsn, loop=loop)\n\n        async with (await pool) as conn:\n            cur = await conn.cursor()\n            await cur.execute(\"SELECT 42;\")\n            r = await cur.fetchall()\n            print(r)\n            await cur.close()\n            await conn.close()\n        pool.close()\n        await pool.wait_closed()\n\n    loop.run_until_complete(test_example())\n\n\nInstallation\n------------\n\n.. code::\n\n   pip3 install git+https://github.com/jettify/aioodbc.git\n\nIn Linux environment pyodbc_ (hence *aioodbc*) requires unixODBC_ library.\nYou can use standard one from your distro like::\n\n      $ sudo apt-get install unixodbc\n      $ sudo apt-get install unixodbc-dev\n\n\nOther SQL Drivers\n-----------------\n\n* aiopg_ - asyncio client for PostgreSQL\n* aiomysql_ - asyncio client form MySQL\n\n\nRequirements\n------------\n\n* Python_ 3.3+\n* asyncio_ or Python_ 3.4+\n* pyodbc_\n\n\n.. _Python: https://www.python.org\n.. _asyncio: http://docs.python.org/3.4/library/asyncio.html\n.. _pyodbc: https://github.com/mkleehammer/pyodbc\n.. _ODBC: https://en.wikipedia.org/wiki/Open_Database_Connectivity\n.. _aiopg: https://github.com/aio-libs/aiopg\n.. _aiomysql: https://github.com/aio-libs/aiomysql\n.. _PEP492: https://www.python.org/dev/peps/pep-0492/\n.. _unixODBC: http://www.unixodbc.org/\n\nChanges\n-------",
        "url": "http://pypi.python.org/pypi/aioodbc",
        "summary": "ODBC driver for asyncio.",
        "command": "pip install 'aioodbc'"
      },
      "aiopeewee": {
        "name": "aiopeewee",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aiopeewee",
        "summary": "Asynchronous interface for peewee ORM powered by asyncio.",
        "command": "pip install 'aiopeewee'"
      },
      "aio_periodic": {
        "name": "aio_periodic",
        "description": "The periodic task system client for python3 base on asyncio.\n\ninstall\n-------\n\n    pip3 install aio_periodic\n",
        "url": "http://pypi.python.org/pypi/aio_periodic",
        "summary": "The periodic task system client for python3 base on asyncio",
        "command": "pip install 'aio_periodic'"
      },
      "aiopg": {
        "name": "aiopg",
        "description": "aiopg\n=======\n.. image:: https://travis-ci.org/aio-libs/aiopg.svg?branch=master\n    :target: https://travis-ci.org/aio-libs/aiopg\n.. image:: https://coveralls.io/repos/aio-libs/aiopg/badge.svg\n    :target: https://coveralls.io/r/aio-libs/aiopg\n\n**aiopg** is a library for accessing a PostgreSQL_ database\nfrom the asyncio_ (PEP-3156/tulip) framework. It wraps\nasynchronous features of the Psycopg database driver.\n\nExample\n-------\n\n::\n\n   import asyncio\n   from aiopg.pool import create_pool\n\n   dsn = 'dbname=jetty user=nick password=1234 host=localhost port=5432'\n\n\n   @asyncio.coroutine\n   def test_select():\n       pool = yield from create_pool(dsn)\n\n       with (yield from pool) as conn:\n           cur = yield from conn.cursor()\n           yield from cur.execute('SELECT 1')\n           ret = yield from cur.fetchone()\n           assert ret == (1,), ret\n\n\n   asyncio.get_event_loop().run_until_complete(test_select())\n\n\nExample of SQLAlchemy optional integration\n-------------------------------------------\n\n::\n\n   import asyncio\n   from aiopg.sa import create_engine\n   import sqlalchemy as sa\n\n\n   metadata = sa.MetaData()\n\n   tbl = sa.Table('tbl', metadata,\n       sa.Column('id', sa.Integer, primary_key=True),\n       sa.Column('val', sa.String(255)))\n\n\n   @asyncio.coroutine\n   def go():\n       engine = yield from create_engine(user='aiopg',\n                                         database='aiopg',\n                                         host='127.0.0.1',\n                                         password='passwd')\n\n       with (yield from engine) as conn:\n           yield from conn.execute(tbl.insert().values(val='abc'))\n\n           res = yield from conn.execute(tbl.select())\n           for row in res:\n               print(row.id, row.val)\n\n\n   asyncio.get_event_loop().run_until_complete(go())\n\n.. _PostgreSQL: http://www.postgresql.org/\n.. _asyncio: http://docs.python.org/3.4/library/asyncio.html\n\nPlease use::\n\n   $ python3 runtests.py\n\nfor executing project's unittests\n\nCHANGES\n-------\n\n0.7.0 (2015-04-22)\n^^^^^^^^^^^^^^^^^^\n\n* Get rid of resource leak on connection failure.\n\n* Report ResourceWarning on non-closed connections.\n\n* Deprecate iteration protocol support in cursor and ResultProxy.\n\n* Release sa connection to pool on `connection.close()`.\n\n0.6.0 (2015-02-03)\n^^^^^^^^^^^^^^^^^^\n\n* Accept dict, list, tuple, named and positional parameters in\n  `SAConnection.execute()`\n\n0.5.2 (2014-12-08)\n^^^^^^^^^^^^^^^^^^\n\n* Minor release, fixes a bug that leaves connection in broken state\n  after `cursor.execute()` failure.\n\n0.5.1 (2014-10-31)\n^^^^^^^^^^^^^^^^^^\n\n* Fix a bug for processing transactions in line.\n\n0.5.0 (2014-10-31)\n^^^^^^^^^^^^^^^^^^\n\n* Add .terminate() to Pool and Engine\n\n* Reimplement connection pool (now pool size cannot be greater than pool.maxsize)\n\n* Add .close() and .wait_closed() to Pool and Engine\n\n* Add minsize, maxsize, size and freesize properties to sa.Engine\n\n* Support *echo* parameter for logging executed SQL commands\n\n* Connection.close() is not a coroutine (but we keep backward compatibility).\n\n0.4.1 (2014-10-02)\n^^^^^^^^^^^^^^^^^^\n\n* make cursor iterable\n\n* update docs\n\n0.4.0 (2014-10-02)\n^^^^^^^^^^^^^^^^^^\n\n* add timeouts for database operations.\n\n* Autoregister psycopg2 support for json data type.\n\n* Support JSON in aiopg.sa\n\n* Support ARRAY in aiopg.sa\n\n* Autoregister hstore support if present in connected DB\n\n* Support HSTORE in aiopg.sa\n\n0.3.2 (2014-07-07)\n^^^^^^^^^^^^^^^^^^\n\n* change signature to cursor.execute(operation, parameters=None) to\n  follow psycopg2 convention.\n\n0.3.1 (2014-07-04)\n^^^^^^^^^^^^^^^^^^\n\n* Forward arguments to cursor constructor for pooled connections.\n\n0.3.0 (2014-06-22)\n^^^^^^^^^^^^^^^^^^\n\n* Allow executing SQLAlchemy DDL statements.\n\n* Fix bug with race conditions on acquiring/releasing connections from pool.\n\n0.2.3 (2014-06-12)\n^^^^^^^^^^^^^^^^^^\n\n* Fix bug in connection pool.\n\n0.2.2 (2014-06-07)\n^^^^^^^^^^^^^^^^^^\n\n* Fix bug with passing parameters into SAConnection.execute when\n  executing raw SQL expression.\n\n0.2.1 (2014-05-08)\n^^^^^^^^^^^^^^^^^^\n\n* Close connection with invalid transaction status on returning to pool.\n\n0.2.0 (2014-05-04)\n^^^^^^^^^^^^^^^^^^\n\n* Implemented optional support for sqlalchemy functional sql layer.\n\n0.1.0 (2014-04-06)\n^^^^^^^^^^^^^^^^^^\n\n* Implemented plain connections: connect, Connection, Cursor.\n\n* Implemented database pools: create_pool and Pool.",
        "url": "http://pypi.python.org/pypi/aiopg",
        "summary": "Postgres integration with asyncio.",
        "command": "pip install 'aiopg'"
      },
      "aiopg8000": {
        "name": "aiopg8000",
        "description": "aiopg8000\r\n---------\r\n\r\n\r\n\r\n**NOTE:** aiopg8000 (this project) is a fork of pg8000 to support asyncio.\r\n\r\npg8000 (https://github.com/mfenniak/pg8000) is a Pure-Python interface to the PostgreSQL database engine.  It is one of many PostgreSQL interfaces for the Python programming language. pg8000 is somewhat distinctive in that it is written entirely in Python and does not rely on any external libraries (such as a compiled python module, or PostgreSQL's libpq library). pg8000 supports the standard Python DB-API version 2.0.\r\n\r\npg8000's name comes from the belief that it is probably about the 8000th \\\r\nPostgreSQL interface for Python.",
        "url": "http://pypi.python.org/pypi/aiopg8000",
        "summary": "PostgreSQL interface library, for asyncio",
        "command": "pip install 'aiopg8000'"
      },
      "aiopgx": {
        "name": "aiopgx",
        "description": "aiopg\n=======\n.. image:: https://travis-ci.org/aio-libs/aiopg.svg?branch=master\n    :target: https://travis-ci.org/aio-libs/aiopg\n.. image:: https://coveralls.io/repos/aio-libs/aiopg/badge.svg\n    :target: https://coveralls.io/r/aio-libs/aiopg\n\n**aiopg** is a library for accessing a PostgreSQL_ database\nfrom the asyncio_ (PEP-3156/tulip) framework. It wraps\nasynchronous features of the Psycopg database driver.\n\nExample\n-------\n\n::\n\n   import asyncio\n   from aiopg.pool import create_pool\n\n   dsn = 'dbname=jetty user=nick password=1234 host=localhost port=5432'\n\n\n   @asyncio.coroutine\n   def test_select():\n       pool = yield from create_pool(dsn)\n\n       with (yield from pool) as conn:\n           cur = yield from conn.cursor()\n           yield from cur.execute('SELECT 1')\n           ret = yield from cur.fetchone()\n           assert ret == (1,), ret\n\n\n   asyncio.get_event_loop().run_until_complete(test_select())\n\n\nExample of SQLAlchemy optional integration\n-------------------------------------------\n\n::\n\n   import asyncio\n   from aiopg.sa import create_engine\n   import sqlalchemy as sa\n\n\n   metadata = sa.MetaData()\n\n   tbl = sa.Table('tbl', metadata,\n       sa.Column('id', sa.Integer, primary_key=True),\n       sa.Column('val', sa.String(255)))\n\n\n   @asyncio.coroutine\n   def go():\n       engine = yield from create_engine(user='aiopg',\n                                         database='aiopg',\n                                         host='127.0.0.1',\n                                         password='passwd')\n\n       with (yield from engine) as conn:\n           yield from conn.execute(tbl.insert().values(val='abc'))\n\n           res = yield from conn.execute(tbl.select())\n           for row in res:\n               print(row.id, row.val)\n\n\n   asyncio.get_event_loop().run_until_complete(go())\n\n.. _PostgreSQL: http://www.postgresql.org/\n.. _asyncio: http://docs.python.org/3.4/library/asyncio.html\n\nPlease use::\n\n   $ python3 runtests.py\n\nfor executing project's unittests\n\nCHANGES\n-------\n\n0.8.0 (XXXX-XX-XX)\n^^^^^^^^^^^^^^^^^^\n\n* Add PostgreSQL notification support #58\n\n* Support pools with unlimited size #59\n\n\n0.7.0 (2015-04-22)\n^^^^^^^^^^^^^^^^^^\n\n* Get rid of resource leak on connection failure.\n\n* Report ResourceWarning on non-closed connections.\n\n* Deprecate iteration protocol support in cursor and ResultProxy.\n\n* Release sa connection to pool on `connection.close()`.\n\n0.6.0 (2015-02-03)\n^^^^^^^^^^^^^^^^^^\n\n* Accept dict, list, tuple, named and positional parameters in\n  `SAConnection.execute()`\n\n0.5.2 (2014-12-08)\n^^^^^^^^^^^^^^^^^^\n\n* Minor release, fixes a bug that leaves connection in broken state\n  after `cursor.execute()` failure.\n\n0.5.1 (2014-10-31)\n^^^^^^^^^^^^^^^^^^\n\n* Fix a bug for processing transactions in line.\n\n0.5.0 (2014-10-31)\n^^^^^^^^^^^^^^^^^^\n\n* Add .terminate() to Pool and Engine\n\n* Reimplement connection pool (now pool size cannot be greater than pool.maxsize)\n\n* Add .close() and .wait_closed() to Pool and Engine\n\n* Add minsize, maxsize, size and freesize properties to sa.Engine\n\n* Support *echo* parameter for logging executed SQL commands\n\n* Connection.close() is not a coroutine (but we keep backward compatibility).\n\n0.4.1 (2014-10-02)\n^^^^^^^^^^^^^^^^^^\n\n* make cursor iterable\n\n* update docs\n\n0.4.0 (2014-10-02)\n^^^^^^^^^^^^^^^^^^\n\n* add timeouts for database operations.\n\n* Autoregister psycopg2 support for json data type.\n\n* Support JSON in aiopg.sa\n\n* Support ARRAY in aiopg.sa\n\n* Autoregister hstore support if present in connected DB\n\n* Support HSTORE in aiopg.sa\n\n0.3.2 (2014-07-07)\n^^^^^^^^^^^^^^^^^^\n\n* change signature to cursor.execute(operation, parameters=None) to\n  follow psycopg2 convention.\n\n0.3.1 (2014-07-04)\n^^^^^^^^^^^^^^^^^^\n\n* Forward arguments to cursor constructor for pooled connections.\n\n0.3.0 (2014-06-22)\n^^^^^^^^^^^^^^^^^^\n\n* Allow executing SQLAlchemy DDL statements.\n\n* Fix bug with race conditions on acquiring/releasing connections from pool.\n\n0.2.3 (2014-06-12)\n^^^^^^^^^^^^^^^^^^\n\n* Fix bug in connection pool.\n\n0.2.2 (2014-06-07)\n^^^^^^^^^^^^^^^^^^\n\n* Fix bug with passing parameters into SAConnection.execute when\n  executing raw SQL expression.\n\n0.2.1 (2014-05-08)\n^^^^^^^^^^^^^^^^^^\n\n* Close connection with invalid transaction status on returning to pool.\n\n0.2.0 (2014-05-04)\n^^^^^^^^^^^^^^^^^^\n\n* Implemented optional support for sqlalchemy functional sql layer.\n\n0.1.0 (2014-04-06)\n^^^^^^^^^^^^^^^^^^\n\n* Implemented plain connections: connect, Connection, Cursor.\n\n* Implemented database pools: create_pool and Pool.",
        "url": "http://pypi.python.org/pypi/aiopgx",
        "summary": "Postgres integration with asyncio.",
        "command": "pip install 'aiopgx'"
      },
      "aiopipes": {
        "name": "aiopipes",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aiopipes",
        "summary": "Asyncio pipe structures",
        "command": "pip install 'aiopipes'"
      },
      "aiopool": {
        "name": "aiopool",
        "description": "A library for running separated subprocesses with asyncio.",
        "url": "http://pypi.python.org/pypi/aiopool",
        "summary": "Subprocesses for asyncio",
        "command": "pip install 'aiopool'"
      },
      "aioprocessing": {
        "name": "aioprocessing",
        "description": "aioprocessing\n=============\n\n``aioprocessing`` provides non-blocking, |asyncio|_ compatible, coroutine versions of many blocking instance methods on objects in the |multiprocessing|_ library. Here's an example showing non-blocking usage of ``Event``, ``Queue``, and ``Lock``:\n\n.. code-block:: python\n\n    import time\n    import asyncio\n    import aioprocessing\n    import multiprocessing\n\n\n    def func(queue, event, lock, items):\n        \"\"\" Demo worker function.\n\n        This worker function runs in its own process, and uses\n        normal blocking calls to aioprocessing objects.\n\n        \"\"\"\n        with lock:\n            event.set()\n            for item in items:\n                time.sleep(3)\n                queue.put(item+5)\n        queue.close()\n\n    @asyncio.coroutine\n    def example(queue, event, lock):\n        l = [1,2,3,4,5]\n        p = aioprocessing.AioProcess(target=func, args=(queue, event, lock, l))\n        p.start()\n        while True:\n            result = yield from queue.coro_get()  # Non-blocking\n            if result is None:\n                break\n            print(\"Got result {}\".format(result))\n        yield from p.coro_join()  # Non-blocking\n\n    @asyncio.coroutine\n    def example2(queue, event, lock):\n        yield from event.coro_wait()  # Non-blocking\n        with (yield from lock):  # Non-blocking\n            yield from queue.coro_put(78)\n            yield from queue.coro_put(None) # Shut it down\n\n    if __name__ == \"__main__\":\n        loop = asyncio.get_event_loop()\n        queue = aioprocessing.AioQueue()\n        lock = aioprocessing.AioLock()\n        event = aioprocessing.AioEvent()\n        tasks = [\n            asyncio.async(example(queue, event, lock)), \n            asyncio.async(example2(queue, event, lock)),\n        ]\n        loop.run_until_complete(asyncio.wait(tasks))\n        loop.close()\n\nHow does it work?\n-----------------\n\nIn most cases, this library makes blocking calls to |multiprocessing|_ methods\nnon-blocking by executing the call in a |ThreadPoolExecutor|_, using\n|asyncio.run_in_executor()|_. \nIt does *not* re-implement multiprocessing using asynchronous I/O. This means \nthere is extra overhead added when you use ``aioprocessing`` objects instead of \n``multiprocessing`` objects, because each one is generally introducing at least \none |threading.Thread|_\nobject, along with a ``ThreadPoolExecutor``. It also means that all the normal\nrisks you get when you mix threads with fork apply here, too.\n\nThe one exception to this is ``aioprocessing.AioPool``, which makes use of the \nexisting ``callback`` and ``error_callback`` keyword arguments in the various \n|Pool.*_async|_ methods to run them as ``asyncio`` coroutines. Note that \n``multiprocessing.Pool`` is actually using threads internally, so the thread/fork\nmixing caveat still applies.\n\nEach ``multiprocessing`` class is replaced by an equivalent ``aioprocessing`` class,\ndistinguished by the ``Aio`` prefix. So, ``Pool`` becomes ``AioPool``, etc. All methods\nthat could block on I/O also have a coroutine version that can be used with ``asyncio``. For example, ``multiprocessing.Lock.acquire()`` can be replaced with ``aioprocessing.AioLock.coro_acquire()``.  \n\n.. |multiprocessing| replace:: ``multiprocessing`` \n.. _multiprocessing: https://docs.python.org/3/library/multiprocessing.html \n\n.. |asyncio| replace:: ``asyncio`` \n.. _asyncio: https://docs.python.org/3/library/asyncio.html\n\n.. |ThreadPoolExecutor| replace:: ``ThreadPoolExecutor``\n.. _ThreadPoolExecutor: https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor\n\n.. |asyncio.run_in_executor()| replace:: ``asyncio.run_in_executor()``\n.. _asyncio.run_in_executor(): https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.BaseEventLoop.run_in_executor\n\n.. |threading.Thread| replace:: ``threading.Thread``\n.. _threading.Thread: https://docs.python.org/2/library/threading.html#thread-objects\n\n.. |Pool.*_async| replace:: ``Pool.*_async``\n.. _Pool.*_async: https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.apply_async\n\nWhat parts of multiprocessing are supported?\n--------------------------------------------\n\nMost of them! All methods that could do blocking I/O in the following objects\nhave equivalent versions in ``aioprocessing`` that extend the ``multiprocessing``\nversions by adding coroutine versions of all the blocking methods.\n\n- ``Pool``\n- ``Process``\n- ``Lock``\n- ``RLock``\n- ``Semaphore``\n- ``BoundedSemaphore``\n- ``Event``\n- ``Condition``\n- ``Barrier``\n- ``connection.Connection``\n- ``connection.Listener``\n- ``connection.Client``\n- ``Queue``\n- ``JoinableQueue``\n- ``SimpleQueue``\n- All ``managers.SyncManager`` ``Proxy`` versions of the items above (``SyncManager.Queue``, ``SyncManager.Lock()``, etc.).\n\nNote\n----\n\nThis project is currently in alpha stages, and likely has bugs. Use at your own risk. (I do appreciate bug reports, though :).",
        "url": "http://pypi.python.org/pypi/aioprocessing",
        "summary": "A Python 3.3+ library that integrates the multiprocessing module with asyncio.",
        "command": "pip install 'aioprocessing'"
      },
      "aiopy": {
        "name": "aiopy",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aiopy",
        "summary": "Simple Web Frame about mysql",
        "command": "pip install 'aiopy'"
      },
      "aiopyramid": {
        "name": "aiopyramid",
        "description": "Introduction\n============\n\nA library for leveraging pyramid infrastructure asynchronously using the new ``asyncio``.\n\n``Aiopyramid`` provides tools for making web applications with ``Pyramid`` and ``asyncio``.\nIt will not necessarily make your application run faster. Instead, it gives you some tools\nand patterns to build an application on asynchronous servers.\nBear in mind that you will need to use asynchronous libraries for io where appropriate.\n\nSince this library is built on relatively new technology, it is not intended for production use.\n\nGetting Started\n---------------\n\n``Aiopyramid`` includes a scaffold that creates a \"hello world\" application,\ncheck it out. The scaffold is designed to work with either `gunicorn`_\nvia a custom worker or `uWSGI`_ via the `uWSGI asyncio plugin`_.\n\nFor example:\n\n::\n\n    pip install aiopyramid gunicorn\n    pcreate -s aio_starter <project>\n    cd <project>\n    python setup.py develop\n    pserve development.ini\n\nThere is also a ``websocket`` scaffold `aio_websocket` for those who basic tools for setting up\na ``websocket`` server.\n\nDocumentation\n-------------\n\nFull documentation for ``Aiopyramid`` can be found `here`_.\n\n.. _gunicorn: http://gunicorn.org\n.. _uWSGI: https://github.com/unbit/uwsgi\n.. _uWSGI asyncio plugin: http://uwsgi-docs.readthedocs.org/en/latest/asyncio.html\n.. _here: http://aiopyramid.readthedocs.org/en/latest/\n\n\n\n\nChanges\n=======\n\n.. :changelog:\n\n0.3.2 (2015-09-24)\n------------------\n    - Support Python3.5\n\n0.3.1 (2015-01-31)\n-------------------\n    - Fix issues related to POST requests\n    - Fix issues related to coroutine mappers\n    - Sync with Gunicorn settings a la issue #917\n\n0.3.0 (2014-12-06)\n------------------\n    - Add sphinx\n    - Migrate README to sphinx docs\n    - Add helpers for authentication\n    - Deprecated aiopyramid.traversal, use aiopyramid.helpers.synchronize\n    - Deprecated aiopyramid.tweens, moved examples to docs\n\n0.2.4 (2014-10-06)\n------------------\n    - Fix issue with gunicorn websockets\n    - Fix issue with class-based view mappers\n\n0.2.3 (2014-10-01)\n------------------\n    - Fix issue with `synchronize`\n\n0.2.2 (2014-09-30)\n------------------\n    - Update example tween to work with gunicorn\n    - Add kwargs support to helpers\n    - Add tox for testing\n    - Add decorator `synchronize` for wrapping coroutines\n    - Refactored mappers and tween example to use `synchronize`\n    - Bug fixes\n\n0.2.1 (2014-09-15)\n------------------\n    - Update scaffold example tests\n    - Add test suite\n    - Update README\n\n0.2.0 (2014-09-01)\n------------------\n    - Update README\n    - added websocket mappers for uwsgi and gunicorn\n    - added websocket view class\n\n0.1.2 (2014-08-02)\n------------------\n    - Update MANIFEST.in\n\n0.1.0 (2014-08-01)\n------------------\n    - Update README ready for release\n    - Added asyncio traverser (patched from `ResourceTreeTraverser`)\n    - Added custom gunicorn worker\n    - Fix issue with uwsgi and executor threads\n    - Update starter scaffold\n\n0.0.3 (2014-07-30)\n------------------\n    - Moving to an extension-based rather than patched-based approach\n    - removed most code based on pyramid_asyncio except testing and scaffolds\n    - added view mappers for running views in asyncio\n    - added example tween that can come before or after synchronous tweens\n\n0.0.2 (2014-07-22)\n------------------\n    - Removed Gunicorn specific code\n    - disabled excview_tween_factory\n    - made viewresult_to_response a coroutine\n    - added dummy code for testing with uwsgi\n\n0.0.1 (2014-07-22)\n------------------\n    - Migrated from pyramid_asyncio (Thank you Guillaume)\n    - Removed worker.py and Gunicorn dependency\n    - Added greenlet dependency\n    - Changed contact information in setup.py",
        "url": "http://pypi.python.org/pypi/aiopyramid",
        "summary": "Tools for running pyramid using asyncio.",
        "command": "pip install 'aiopyramid'"
      },
      "aioredis": {
        "name": "aioredis",
        "description": "aioredis\n========\n\nasyncio (PEP 3156) Redis support\n\n.. image:: https://travis-ci.org/aio-libs/aioredis.svg?branch=master\n   :target: https://travis-ci.org/aio-libs/aioredis\n\n\n.. image:: https://coveralls.io/repos/aio-libs/aioredis/badge.png?branch=master\n   :target: https://coveralls.io/r/aio-libs/aioredis?branch=master\n\n\nDocumentation\n-------------\n\nhttp://aioredis.readthedocs.org/\n\nUsage examples\n--------------\n\nSimple low-level interface:\n\n.. code:: python\n\n    import asyncio\n    import aioredis\n\n    loop = asyncio.get_event_loop()\n\n    @asyncio.coroutine\n    def go():\n        conn = yield from aioredis.create_connection(\n            ('localhost', 6379), loop=loop)\n        yield from conn.execute('set', 'my-key', 'value')\n        val = yield from conn.execute('get', 'my-key')\n        print(val)\n        conn.close()\n    loop.run_until_complete(go())\n    # will print 'value'\n\nSimple high-level interface:\n\n.. code:: python\n\n    import asyncio\n    import aioredis\n\n    loop = asyncio.get_event_loop()\n\n    @asyncio.coroutine\n    def go():\n        redis = yield from aioredis.create_redis(\n            ('localhost', 6379), loop=loop)\n        yield from redis.set('my-key', 'value')\n        val = yield from redis.get('my-key')\n        print(val)\n        redis.close()\n    loop.run_until_complete(go())\n    # will print 'value'\n\nConnections pool:\n\n.. code:: python\n\n    import asyncio\n    import aioredis\n\n    loop = asyncio.get_event_loop()\n\n    @asyncio.coroutine\n    def go():\n        pool = yield from aioredis.create_pool(\n            ('localhost', 6379),\n            minsize=5, maxsize=10,\n            loop=loop)\n        with (yield from pool) as redis:    # high-level redis API instance\n            yield from redis.set('my-key', 'value')\n            print((yield from redis.get('my-key')))\n        pool.clear()    # closing all open connections\n\n    loop.run_until_complete(go())\n\n\nRequirements\n------------\n\n* Python_ 3.3+\n* asyncio_ or Python_ 3.4+\n* hiredis_\n\n.. note::\n\n    hiredis is preferred requirement.\n    Pure-python fallback protocol parser is TBD.\n\n\nLicense\n-------\n\nThe aioredis is offered under MIT license.\n\n.. _Python: https://www.python.org\n.. _asyncio: https://pypi.python.org/pypi/asyncio\n.. _hiredis: https://pypi.python.org/pypi/hiredis\n\nChanges\n-------\n\n0.2.4 (xxxx-xx-xx)\n^^^^^^^^^^^^^^^^^^\n\n\n0.2.3 (2015-08-14)\n^^^^^^^^^^^^^^^^^^\n\n* Redis cluster support work in progress;\n\n* Fixed pool issue causing pool growth over max size & ``acquire`` call hangs\n  (see https://github.com/aio-libs/aioredis/issues/71);\n\n* ``info`` server command result parsing implemented;\n\n* Fixed behavior of util functions\n  (see https://github.com/aio-libs/aioredis/issues/70);\n\n* ``hstrlen`` command added;\n\n* Few fixes in examples;\n\n* Few fixes in documentation;\n\n\n0.2.2 (2015-07-07)\n^^^^^^^^^^^^^^^^^^\n\n* Decoding data with ``encoding`` paramter now takes into account\n  list (array) replies\n  (see https://github.com/aio-libs/aioredis/pull/68);\n\n* ``encoding`` parameter added to following commands:\n  - generic commands: keys, randomkey;\n  - hash commands: hgetall, hkeys, hmget, hvals;\n  - list commands: blpop, brpop, brpoplpush, lindex, lpop, lrange, rpop, rpoplpush;\n  - set commands: smembers, spop, srandmember;\n  - string commands: getrange, getset, mget;\n\n* Backward incompatibility:\n\n  ``ltrim`` command now returns bool value instead of 'OK';\n\n* Tests updated;\n\n\n0.2.1 (2015-07-06)\n^^^^^^^^^^^^^^^^^^\n\n* Logging added (aioredis.log module);\n\n* Fixed issue with ``wait_message`` in pub/sub\n  (see https://github.com/aio-libs/aioredis/issues/66);\n\n\n0.2.0 (2015-06-04)\n^^^^^^^^^^^^^^^^^^\n\n* Pub/Sub support added;\n\n* Fix in ``zrevrangebyscore`` command\n  (see https://github.com/aio-libs/aioredis/pull/62);\n\n* Fixes/tests/docs;\n\n\n0.1.5 (2014-12-09)\n^^^^^^^^^^^^^^^^^^\n\n* AutoConnector added;\n\n* wait_closed method added for clean connections shutdown;\n\n* ``zscore`` command fixed;\n\n* Test fixes;\n\n\n0.1.4 (2014-09-22)\n^^^^^^^^^^^^^^^^^^\n\n* Dropped following Redis methods -- Redis.multi(), Redis.exec(), Redis.discard()\n\n* Redis.multi_exec hack'ish property removed\n\n* Redis.multi_exec() method added\n\n* High-level commands implemented:\n\n  * generic commands (tests);\n  * transactions commands (api stabilization).\n\n* Backward incompatibilities:\n\n  * Following sorted set commands' API changed:\n\n    zcount, zrangebyscore, zremrangebyscore, zrevrangebyscore;\n\n  * set string command' API changed;\n\n\n\n0.1.3 (2014-08-08)\n^^^^^^^^^^^^^^^^^^\n\n* RedisConnection.execute refactored to support commands pipelining\n  (see http://github.com/aio-libs/aioredis/issues/33);\n\n* Several fixes;\n\n* WIP on transactions and commands interface;\n\n* High-level commands implemented and tested:\n\n  * hash commands;\n  * hyperloglog commands;\n  * set commands;\n  * scripting commands;\n  * string commands;\n  * list commands;\n\n\n0.1.2 (2014-07-31)\n^^^^^^^^^^^^^^^^^^\n\n* create_connection, create_pool, create_redis functions updated:\n  db and password arguments made keyword-only\n  (see http://github.com/aio-libs/aioredis/issues/26);\n\n* Fixed transaction handling\n  (see http://github.com/aio-libs/aioredis/issues/32);\n\n* Response decoding\n  (see http://github.com/aio-libs/aioredis/issues/16);\n\n\n0.1.1 (2014-07-07)\n^^^^^^^^^^^^^^^^^^\n\n* Transactions support (in connection, high-level commands have some issues);\n* Docs & tests updated.\n\n\n0.1.0 (2014-06-24)\n^^^^^^^^^^^^^^^^^^\n\n* Initial release;\n* RedisConnection implemented;\n* RedisPool implemented;\n* Docs for RedisConnection & RedisPool;\n* WIP on high-level API.",
        "url": "http://pypi.python.org/pypi/aioredis",
        "summary": "asyncio (PEP 3156) Redis support",
        "command": "pip install 'aioredis'"
      },
      "aioredux": {
        "name": "aioredux",
        "description": "========\naioredux\n========\n\nPythonic `Redux <https://github.com/rackt/redux>`_\n\nPythonic `Redux <https://github.com/rackt/redux>`_ using asyncio. ``aioredux``\nprovides a predictable state container with the following goal: \"[Redux] helps\nyou write applications that behave consistently, run in different environments\n..., and are easy to test\" (from the `Redux <https://github.com/rackt/redux>`_\ndocumentation).\n\n* Free software: Mozilla Public License",
        "url": "http://pypi.python.org/pypi/aioredux",
        "summary": "Pythonic redux",
        "command": "pip install 'aioredux'"
      },
      "aiorequests": {
        "name": "aiorequests",
        "description": "aiorequests\n===========\n\n|build|_\n\n``aiorequests`` is an HTTP library inspired by\n`requests <http://www.python-requests.org>`_ but written on top of\n`asyncio <http://www.twistedmatrix.com>`_'s\n\naiorequests is based on `treq <http://github.com/dred/treq>` , the\nrequests API for twisted.\n\nIt provides a simple, higher level API for making HTTP requests when\nusing Twisted.\n\n.. code-block:: python\n\n    >>> from aiorequests import get\n\n    >>> def main():\n    ...     resp = yield from get(\"http://www.github.com\")\n    ...     resp.status\n    ...     reactor.stop()\n\n    >>>\n\n    >>> from aysncio imoprt get_event_loop\n    >>> get_event_loop().run_until_complete(main())\n    200\n\nFor more info `read the docs <http://treq.readthedocs.org>`_.\n\nContribute\n==========\n\n``aiorequests`` is hosted on `GitHub <http://github.com/jsandovalc/aiorequests>`_.\n\nFeel free to fork and send contributions over.",
        "url": "http://pypi.python.org/pypi/aiorequests",
        "summary": "A requests-like API built on top of aiohttp client",
        "command": "pip install 'aiorequests'"
      },
      "aiorest": {
        "name": "aiorest",
        "description": "aiorest\n=======\n\nJSON REST framework based on aiohttp (an asyncio (PEP 3156) http server).\n\n.. image:: https://travis-ci.org/aio-libs/aiorest.svg?branch=master\n   :target: https://travis-ci.org/aio-libs/aiorest\n\n\naiorest development has stopped\n-------------------------------\n\nThe project always was in experimental status: we have tried to make the proof\nof concept for ``aiohttp`` high level server.\n\nNow the work is done, the most important parts transplanted to\n``aiohttp.web``: ``Request`` and ``Response``.\n\nSome ``aiorest`` features are not supported by ``aiohttp.web`` yet:\nsessions, CORS and security.\n\nWe are working hard on the issue by making ``aiohttp`` extension\nlibraries for those ones.\n\nWe will keep *aiorest* work on top of *aiohttp* new versions for a\nwhile.\n\nPlease report about incompatibility bugs to *aiorest github\nissue tracker* -- we'll fix those.\n\n\n\n\n\nExample usage\n-------------\n\nSimple REST server can be run like this::\n\n   import asyncio\n   import aiohttp\n   import aiorest\n\n\n   # define a simple request handler\n   # which accept no arguments\n   # and responds with json\n   def hello(request):\n       return {'hello': 'world'}\n\n\n   loop = asyncio.get_event_loop()\n   server = aiorest.RESTServer(hostname='127.0.0.1',\n                               loop=loop)\n\n   # configure routes\n   server.add_url('GET', '/hello', hello)\n   # create server\n   srv = loop.run_until_complete(loop.create_server(\n       server.make_handler, '127.0.0.1', 8080))\n\n\n   @asyncio.coroutine\n   def query():\n       resp = yield from aiohttp.request(\n           'GET', 'http://127.0.0.1:8080/hello', loop=loop)\n       data = yield from resp.read_and_close(decode=True)\n       print(data)\n\n\n   loop.run_until_complete(query())\n   srv.close()\n   loop.run_until_complete(srv.wait_closed())\n   loop.close()\n\nthis will print ``{'hello': 'world'}`` json\n\nSee `examples <https://github.com/aio-libs/aiorest/tree/master/examples>`_ for more.\n\n\nRequirements\n------------\n\n- Python 3.3\n\n- asyncio http://code.google.com/p/tulip/ or Python 3.4+\n\n- aiohttp http://github.com/KeepSafe/aiohttp\n\n- optional module ``aiorest.redis_session`` requires aioredis\n  https://github.com/aio-libs/aioredis\n\nLicense\n-------\n\naiorest is offered under the MIT license.\n\nCHANGES\n-------\n\n0.4.0 (2015-01-18)\n^^^^^^^^^^^^^^^^^^\n\n* The aiorest library development has stopped, use aiohttp.web instead.\n\n* Update *aiorest* code to be compatible with *aiohttp 0.14 release*.\n\n0.3.1 (2014-12-22)\n^^^^^^^^^^^^^^^^^^\n\n* Fixed exceptions logging for unhandled errors\n\n0.3.0 (2014-12-17)\n^^^^^^^^^^^^^^^^^^\n\n* Made aiorest compatible to aiohttp v0.12\n\n0.2.5 (2014-10-30)\n^^^^^^^^^^^^^^^^^^\n\n* Fix response.write_eof() to follow aiohttp changes\n\n0.2.4 (2014-09-12)\n^^^^^^^^^^^^^^^^^^\n\n* Make loop keywork-only parameter in create_session_factory() function\n\n0.2.3 (2014-08-28)\n^^^^^^^^^^^^^^^^^^\n\n* Redis session switched from asyncio_redis to aioredis\n\n\n0.2.2 (2014-08-15)\n^^^^^^^^^^^^^^^^^^\n\n* Added Pyramid-like matchdict to request\n  (see https://github.com/aio-libs/aiorest/pull/18)\n\n* Return \"400 Bad Request\" for incorrect JSON body in POST/PUT methods\n\n* README fixed\n\n* Custom response status code\n  (see https://github.com/aio-libs/aiorest/pull/23)\n\n\n0.1.1 (2014-07-09)\n^^^^^^^^^^^^^^^^^^\n\n* Switched to aiohttp v0.9.0\n\n\n0.1.0 (2014-07-07)\n^^^^^^^^^^^^^^^^^^\n\n* Basic REST API",
        "url": "http://pypi.python.org/pypi/aiorest",
        "summary": "Support REST calls for asyncio+aiohttp.",
        "command": "pip install 'aiorest'"
      },
      "aio-routes": {
        "name": "aio-routes",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aio-routes",
        "summary": "Routing for asyncio",
        "command": "pip install 'aio-routes'"
      },
      "aiorwlock": {
        "name": "aiorwlock",
        "description": "aiorwlock\n=========\n.. image:: https://travis-ci.org/aio-libs/aiorwlock.svg?branch=master\n    :target: https://travis-ci.org/aio-libs/aiorwlock\n.. image:: https://coveralls.io/repos/jettify/aiorwlock/badge.png?branch=master\n    :target: https://coveralls.io/r/aio-libs/aiorwlock?branch=master\n\nRead write lock for asyncio_ . A ``RWLock`` maintains a pair of associated\nlocks, one for read-only operations and one for writing. The read lock may be\nheld simultaneously by multiple reader tasks, so long as there are\nno writers. The write lock is exclusive.\n\nWhether or not a read-write lock will improve performance over the use of\na mutual exclusion lock depends on the frequency that the data is *read*\ncompared to being *modified*. For example, a collection that is initially\npopulated with data and thereafter infrequently modified, while being\nfrequently searched is an ideal candidate for the use of a read-write lock.\nHowever, if updates become frequent then the data spends most of its time\nbeing exclusively locked and there is little, if any increase in concurrency.\n\n\nImplementation is almost direct port from this patch_.\n\n\nExample with async def\n----------------------\n\nRequires Python 3.5+\n\n.. code:: python\n\n    import asyncio\n    import aiorwlock\n    loop = asyncio.get_event_loop()\n\n\n    async def go():\n        rwlock = aiorwlock.RWLock(loop=loop)\n        async with rwlock.writer:\n            # or same way you can acquire reader lock\n            # async with rwlock.reader: pass\n            print(\"inside writer\")\n            yield from asyncio.sleep(0.1, loop=loop)\n\n    loop.run_until_complete(go())\n\nOld-school way\n--------------\n\nRequires Python 3.3+\n\n.. code:: python\n\n    import asyncio\n    import aiorwlock\n    loop = asyncio.get_event_loop()\n\n\n    @asyncio.coroutine\n    def go():\n        rwlock = aiorwlock.RWLock(loop=loop)\n        with (yield from rwlock.writer):\n            # or same way you can acquire reader lock\n            # with (yield from rwlock.reader): pass\n            print(\"inside writer\")\n            yield from asyncio.sleep(0.1, loop=loop)\n\n    loop.run_until_complete(go())\n\n\nFast path\n---------\n\nBy default `RWLock` switches context on lock acquiring. That allows to\nother waiting tasks get the lock even if task that holds the lock\ndoesn't contain context switches (`await fut` statements).\n\nThe default behavior can be switched off by `fast` argument:\n`RWLock(fast=True)`.\n\nLong story short:  lock is safe by  default, but if you  sure you have\ncontext switches (`await`,  `async with`, `async for`  or `yield from`\nstatements) inside  locked code  you may want  to use  `fast=True` for\nminor speedup.\n\n\nLicense\n-------\n\n``aiorwlock`` is offered under the Apache 2 license.\n\n\n.. _asyncio: http://docs.python.org/3.4/library/asyncio.html\n.. _patch: http://bugs.python.org/issue8800\n\nChanges\n-------\n\n0.4.0 (2015-09-20)\n^^^^^^^^^^^^^^^^^^\n\n* Support Python 3.5 and `async with` statement\n\n* rename `.reader_lock` -> `.reader`, `.writer_lock` ->\n  `.writer`. Backward compatibility is preserved.\n\n0.3.0 (2014-02-11)\n^^^^^^^^^^^^^^^^^^\n\n* Add `.locked` property\n\n0.2.0 (2014-02-09)\n^^^^^^^^^^^^^^^^^^\n\n* Make `.release()` non-coroutine\n\n\n0.1.0 (2014-12-22)\n^^^^^^^^^^^^^^^^^^\n\n* Initial release",
        "url": "http://pypi.python.org/pypi/aiorwlock",
        "summary": "Read write lock for asyncio.",
        "command": "pip install 'aiorwlock'"
      },
      "aio-s3": {
        "name": "aio-s3",
        "description": "===================\nAsyncio S3 Bindings\n===================\n\n:Status: Alpha\n\nThe `aio-s3` is a small library for accessing Amazon S3 Service that leverages\npython's standard `asyncio` library.\n\nOnly read operations are supported so far, contributions are welcome.\n\n\nExample\n=======\n\nBasically all methods supported so far are shown in this example:\n\n.. code-block:: yaml\n\n    import asyncio\n\n    from aios3.bucket import Bucket\n\n\n    @asyncio.coroutine\n    def main():\n        bucket = Bucket('uaprom-logs',\n            aws_region='eu-west-1',\n            aws_endpoint='s3-eu-west-1.amazonaws.com',\n            aws_key='AKIAIOSFODNN7EXAMPLE',\n            aws_secret='wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY')\n        # List keys based on prefix\n        lst = yield from bu.list('some-prefix')\n        response = yield from bu.get(lst[0])\n        print(len(response))\n        response = yield from bu.download(lst[0])\n        print(\"GOT Response\", dir(response))\n        while 1:\n            chunk = yield from response.read(65536)\n            print(\"Received\", len(chunk))\n            if not chunk:\n                break\n\n    asyncio.get_event_loop().run_until_complete(main())\n\n\nReference\n=========\n\n``Bucket(name, *, aws_key, aws_secret, aws_region, aws_endpoint, connector)``:\n    Creates a wrapper object for accessing S3 bucket. Note unlike in many\n    other bindings you need to specify aws_region (and probably aws_endpoint)\n    correctly (see a table_). The ``connector`` is an aiohttp_ connector,\n    which might be used to setup proxy or other useful things.\n\n``Bucket.list(prefix='', max_keys=1000)``:\n    Lists items which start with prefix. Each returned item is a ``Key``\n    object. This method is coroutine.\n\n    .. note:: This method raises assertion error if there are more keys than\n       max_keys. We do not have a method to return keys iteratively yet.\n\n``Bucket.get(key)``:\n    Fetches object names ``key``. The ``key`` might be a string or ``Key``\n    object. Returns bytes. This method is coroutine.\n\n``Bucket.download(key)``:\n    Allows iteratively download the ``key``. The object returned by the\n    coroutine is an object having method ``.read(bufsize)`` which is a\n    coroutine too.\n\n``Key``\n    Represents an S3 key returned by ``Bucket.list``. Key has at least the\n    following attributes:\n\n    * ``key`` -- the full name of the key stored in a bucket\n    * ``last_modified`` -- ``datetime.datetime`` object\n    * ``etag`` -- The ETag, usually md5 of the content with additional quotes\n    * ``size`` -- Size of the object in bytes\n    * ``storage_class`` -- Storage class of the object\n\n\n.. _table: http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region\n.. _aiohttp: http://aiohttp.readthedocs.org\n\n\n",
        "url": "http://pypi.python.org/pypi/aio-s3",
        "summary": "Asyncio-based client for S3",
        "command": "pip install 'aio-s3'"
      },
      "aiosc": {
        "name": "aiosc",
        "description": "=====\naiosc\n=====\n\nThis is an experimental minimalistic Open Sound Control (OSC) communication\nmodule which uses asyncio for network operations and is compatible with the\nasyncio event loop.\n\nInstallation\n============\n\naiosc requires at least Python 3.4. It can be installed using pip::\n\n    pip3 install aiosc\n    pip3 install --user aiosc\n\nUsage\n=====\n\nTo send an OSC message just use ``aiosc.send``:\n\n.. code-block:: python\n\n    import asyncio\n    import aiosc\n\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(\n        aiosc.send(('127.0.0.1', 9000), '/hello', 'world')\n    )\n\nTo implement an OSC server with ``aiosc`` you should create an UDP endpoint\nusing ``aiosc.OSCProtocol`` as the protocol. ``OSCProtocol`` can be subclassed\nor directly constructed with a dictionary mapping OSC address patterns to\nhandler methods for incoming messages:\n\n.. code-block:: python\n\n    def protocol_factory():\n        osc = aiosc.OSCProtocol({\n            '//*': lambda addr, path, *args: print(addr, path, args)\n        })\n        return osc\n\n    loop = asyncio.get_event_loop()\n    coro = loop.create_datagram_endpoint(protocol_factory, local_addr=('127.0.0.1', 9000))\n    transport, protocol = loop.run_until_complete(coro)\n\n    loop.run_forever()\n\nFor more examples, see ``examples/``.\n\nOSC address patterns\n====================\n\n``aiosc`` dispatches messages to handler methods using glob-style address\npattern matching as described in the OSC 1.0 specification. The ``//`` operator\nfrom OSC 1.1 preliminary specification is also supported.\n\nExamples:\n\n* ``/hello/world`` matches ``/hello/world``.\n* ``/hello/*`` matches ``/hello/world`` and ``/hello/sarah``.\n* ``/{hello,goodbye}//world`` matches ``/hello/world`` and ``/goodbye/cruel/world``.\n* ``//*`` matches any address.\n\nNotes\n=====\n\nBundles are not yet supported.\n\nContrary to most OSC implementations, OSC data types are picked from the\npreliminary spec documented in Features and Future of Open Sound Control\nversion 1.1 for NIME paper. For example, 'I' typetag is decoded to Impulse\n(aka \"bang\") which is passed around as ``aiosc.Impulse`` singleton.\n\nSuggestions, bug reports, issues and/or pull requests are, of course, welcome.\n\nLicense\n=======\n\nCopyright (c) 2014 Artem Popov <artfwo@gmail.com>\n\naiosc is licensed under the MIT license, please see LICENSE file for details.",
        "url": "http://pypi.python.org/pypi/aiosc",
        "summary": "Minimalistic Open Sound Control (OSC) communication module using asyncio",
        "command": "pip install 'aiosc'"
      },
      "aio.signals": {
        "name": "aio.signals",
        "description": "Detailed documentation\n**********************\n\naio.signals\n===========\n\nPubsub system for the aio_ asyncio framework\n\n.. _aio: https://github.com/phlax/aio\n\n\n\nBuild status\n------------\n\n.. image:: https://travis-ci.org/phlax/aio.signals.svg?branch=master\n\t       :target: https://travis-ci.org/phlax/aio.signals\n\n\nInstallation\n------------\n\nRequires python >= 3.4\n\nInstall with:\n\n.. code:: bash\n\n\t  pip install aio.signals\n\n\nQuickstart\n----------\n\nThe listen function is called synchronously, but the callback listener will be called as a coroutine if it isnt one\n\nThe callback listener receives a signal object that has the name of the signal and the object that the signal was emitted with\n\nThe emit function is a coroutine\n\nAdd the following code to a file my_signals.py\n\n.. code:: python\n\n\t  import asyncio\n\t  from aio.signals import Signals\t  \n\t  \n\t  def listener(signal):\n\t      yield from asyncio.sleep(1)\n\t      print(signal.data)\n\n\t  signals = Signals()\n\t  signals.listen(\"my-signal\", listener)\n\n\t  loop = asyncio.get_event_loop()\n\t  loop.run_until_complete(\n\t      signals.emit(\"my-signal\", 'BOOM!'))\n\n\nRun with\n\n.. code:: bash\n\n\t  python my_signals.py\n\n\n\naio.signals usage\n=================\n\nUsing\n-----\n\n>>> import asyncio\n>>> import aio.testing\n>>> from aio.signals import Signals\n\nThe handler receives a signal object\n\nsignal.name is the name of the signal\n\nsignal.data contains the emitted object\n\n>>> @asyncio.coroutine\n... def callback(signal):\n...     print(\"%s received with %s\" % (signal.name, signal.data))\n\n>>> @aio.testing.run_until_complete\n... def run_test(_signals, name, message):\n...     yield from _signals.emit(name, message)\n\n>>> signals = Signals()\n>>> signals.listen(\"test-signal\", callback)\n\n>>> run_test(signals, \"test-signal\", 'BOOM!')\ntest-signal received with BOOM!\n\nThe handler is wrapped in a co-routine if its not one already\n\n>>> def callback(signal):\n...     yield from asyncio.sleep(1)\n...     print(\"%s received with %s\" % (signal.name, signal.data))\n\n>>> signals = Signals()\n>>> signals.listen(\"test-signal-2\", callback)\n\n>>> run_test(signals, \"test-signal-2\", 'BOOM AGAIN!')\ntest-signal-2 received with BOOM AGAIN!",
        "url": "http://pypi.python.org/pypi/aio.signals",
        "summary": "Pubsub system for aio framework",
        "command": "pip install 'aio.signals'"
      },
      "aiosip": {
        "name": "aiosip",
        "description": "======\naiosip\n======\n\n.. image:: https://badge.fury.io/py/aiosip.png\n    :target: http://badge.fury.io/py/aiosip\n\n\nSIP support for AsyncIO written in pure Python.\n\n**Warning: SIP knowledge is necessary to use this library.**\n\nSee **examples/** folder for examples.\n\n* Free software: Apache2 license\n\nFeatures tested on production\n-----------------------------\n\n* SIP endpoint client mode\n* UDP support\n* REGISTER\n* NOTIFY\n* SUBSCRIBE\n* MESSAGE\n\nMissing features\n----------------\n\n* Documentation\n* unit tests\n* TCP support\n* SIP proxy/server mode\n* SDP support\n\n\n\n\nHistory\n-------\n\n0.0.1 (2014-12-28)\n---------------------\n\n* First release on PyPI.",
        "url": "http://pypi.python.org/pypi/aiosip",
        "summary": "SIP support for AsyncIO",
        "command": "pip install 'aiosip'"
      },
      "aiotarantool": {
        "name": "aiotarantool",
        "description": "Tarantool connection driver for work with asyncio\n----------------------------------------------------------\nConnector required tarantool version 1.6:\n\n    $ pip install aiotarantool\n\nAlso, you need to install experimental branch tarantool-python for python 3.4:\n\n    $ pip install git+https://github.com/shveenkov/tarantool-python.git@for_python3.4\n\nTry it example:\n\n.. code:: python\n\n    import asyncio\n    import aiotarantool\n\n    cnt = 0\n\n    @asyncio.coroutine\n    def insert_job(tnt):\n        global cnt\n\n        for it in range(2500):\n            cnt += 1\n            r = yield from tnt.insert(\"tester\", (cnt, cnt))\n\n    loop = asyncio.get_event_loop()\n\n    tnt = aiotarantool.connect(\"127.0.0.1\", 3301)\n    tasks = [asyncio.async(insert_job(tnt))\n             for _ in range(40)]\n\n    loop.run_until_complete(asyncio.wait(tasks))\n    loop.run_until_complete(tnt.close())\n    loop.close()\n\nUnder this scheme the aiotarantool driver makes a smaller number of read/write tarantool socket.\n\nSee benchmark results time for insert/select/delete 100K tuples on 1.5KBytes:\n\n=========  =========  ==========\ncall       tarantool  aiotarantool\n=========  =========  ==========\ninsert     35.938047  12.701088\nselect     24.389748  12.746204\ndelete     35.224515  13.905095\n=========  =========  ==========",
        "url": "http://pypi.python.org/pypi/aiotarantool",
        "summary": "Tarantool connection driver for work with asyncio",
        "command": "pip install 'aiotarantool'"
      },
      "aiotest": {
        "name": "aiotest",
        "description": "aiotest is a test suite to validate an implementation of the asyncio API, the\nPEP 3156.\n\n* `aiotest at Bitbucket\n  <https://bitbucket.org/haypo/aiotest>`_\n* `aiotest at the Python Cheeseshop (PyPI)\n  <https://pypi.python.org/pypi/aiotest>`_\n* `PEP 3156\n  <http://www.python.org/dev/peps/pep-3156/>`_\n\nEvent loops:\n\n* `asyncio <https://docs.python.org/dev/library/asyncio.html>`_\n  (Python 3.4 and newer)\n* `tulip <http://code.google.com/p/tulip/>`_ (asyncio for Python 3.3)\n* `trollius <http://trollius.readthedocs.org/>`_\n\n\nUsage\n=====\n\nScript to run aiotest on trollius::\n\n    import aiotest.run\n    import trollius\n\n    config = aiotest.TestConfig()\n    config.asyncio = trollius\n    config.new_event_pool_policy = trollius.DefaultEventLoopPolicy\n    aiotest.run.main(config)\n\nThe script has command line options, use ``--help`` to list them.\n\n\nInstallation\n============\n\nType::\n\n    pip install aiotest\n\nEvent loops:\n\n* On Python 2 and Python 3.2, aiotest requires trollius:\n  ``pip install trollius``\n* On Python 3.3, aiotest requires asyncio (or trollius):\n  ``pip install asyncio``\n* On Python 3.4 and newer, no extra dependency is needed\n\nTests:\n\n* Run ``tox``, need the ``tox`` program (``pip install tox``)\n* Run ``python test_trollius.py``, need trollius\n* Run ``python test_asyncio.py``, need asyncio\n\n\nChangelog\n=========\n\n2014-12-18: Version 0.2\n-----------------------\n\n* Add CallbackTests.test_call_soon_control()\n* Fix ThreadTests.test_policy(): asyncio.get_event_loop() now runs a\n  RuntimeError, not an AssertionError\n* Drop support for usage on the command line, there was a design issue\n  when testing Trollius when the asyncio module was also importable\n  (ex: Python 3.4)\n\n2014-12-12: Version 0.1\n-----------------------\n\n* First public release",
        "url": "http://pypi.python.org/pypi/aiotest",
        "summary": "test suite to validate an implementation of the asyncio API, the PEP 3156",
        "command": "pip install 'aiotest'"
      },
      "aio.testing": {
        "name": "aio.testing",
        "description": "Detailed documentation\n**********************\n\naio.testing\n===========\n\nTest utils for the aio_ asyncio framework\n\n.. _aio: https://github.com/phlax/aio\n\n\nBuild status\n------------\n\n.. image:: https://travis-ci.org/phlax/aio.testing.svg?branch=master\n\t       :target: https://travis-ci.org/phlax/aio.testing\n\n\nInstallation\n------------\n\nRequires python >= 3.4\n\nInstall with:\n\n.. code:: bash\n\n\t  pip install aio.testing\n\n\nAio testing provides 2 decorators for running asyncio tests\n\n- *aio.testing.run_until_complete*:\n\n  - creates a test loop\n  - calls the test with loop.run_until_complete\n\n- *aio.testing.run_forever*:\n  \n  - creates a test loop\n  - calls test using loop.run_forever\n  - waits for number of seconds specified in \"timeout\" (default = 1)\n  - if test returns a callable, calls it as a coroutine\n  - waits for number of seconds specified in \"sleep\" (default = 0)\n\n\t  \n\n@aio.testing.run_until_complete\n-------------------------------\n\naio.testing provides a method decorator for running asyncio-based tests\n\n.. code:: python\n\n\t  import unittest\n\t  import asyncio\n\n\t  import aio.testing\n\n\n\t  class MyTestCase(unittest.TestCase):\n\n\t      @aio.testing.run_until_complete\n\t      def test_example():\n\t          yield from asyncio.sleep(2)\n\t\t  self.assertTrue(True)\n\n\t\t  \nPrior to the test running asyncio.get_new_loop() is called and set using asyncio.set_event_loop().\n\nOn completion of the test asyncio.set_event_loop() is again called with the original event loop.\n\n\n@aio.testing.run_forever\n------------------------\n\nIf your code needs to test long-running tasks, you can use the @aio.testing.run_forever decorator.\n\nThe @aio.testing.run_forever decorator uses loop.run_forever to run the test.\n\nAny setup required can be done in the body of the test function which can optionally return a test callback\n\nThe callback is wrapped in a coroutine, and called after 1 second\n\n.. code:: python\n\n\t  import unittest\n\t  import asyncio\n\n\t  import aio.testing\n\n\n\t  class MyFutureTestCase(unittest.TestCase):\n\n\t      @aio.testing.run_forever\n\t      def test_example():\n\t          yield from asyncio.sleep(2)\n\n\t\t  def callback_test(self):\n\t\t      yield from asyncio.sleep(2)\t\t  \n\t\t      self.assertTrue(True)\n\n\t\t  # this function is called 1 second after being returned\t\t      \n\t\t  return callback_test\n\n\nAs with aio.testing.run_until_complete, the test is run in a separate loop.\n\n\t\t  \n@aio.testing.run_forever with timeout\n-------------------------------------\n\nYou can specify how many seconds to wait *before* running the callback tests by setting the timeout value\n\n\n.. code:: python\n\n\t  import unittest\n\t  import asyncio\n\n\t  import aio.testing\n\n\n\t  class MyFutureTestCase(unittest.TestCase):\n\n\t      @aio.testing.run_forever(timeout=10)\n\t      def test_example():\n\t          yield from asyncio.sleep(2)\n\n\t\t  def callback_test(self):\n\t\t      yield from asyncio.sleep(2)\t\t  \n\t\t      self.assertTrue(True)\n\n\t\t  # this function is called 10 seconds after being returned\t\t      \n\t\t  return callback_test\n\n\n@aio.testing.run_forever with sleep\n-----------------------------------\n\nSometimes a test needs to wait for some time after services have been stopped and the test loop has been destroyed.\n\nYou can specify how many seconds to wait *after* running the callback tests by setting the sleep value\n\n\n.. code:: python\n\n\t  import unittest\n\t  import asyncio\n\n\t  import aio.testing\n\n\n\t  class MyFutureTestCase(unittest.TestCase):\n\n\t      @aio.testing.run_forever(sleep=10)\n\t      def test_example():\n\t          yield from asyncio.sleep(2)\n\n\t\t  def callback_test(self):\n\t\t      yield from asyncio.sleep(2)\t\t  \n\t\t      self.assertTrue(True)\n\n\t\t  return callback_test\n\t\t  \n\n\naio.testing usage\n=================\n\n\naio.testing.run_until_complete\n------------------------------\n\nLets create a test\n\n>>> import asyncio\n>>> import aio.testing\n\n>>> @aio.testing.run_until_complete\n... def run_test(parent_loop):\n...     yield from asyncio.sleep(1)\n... \n...     print(asyncio.get_event_loop() != parent_loop)\n\nAnd lets check that the test loop is not the same as the current one\n\n>>> loop_before_test = asyncio.get_event_loop()\n>>> run_test(loop_before_test)\nTrue\n\nAfter the test has run we have the original event loop back\n\n>>> asyncio.get_event_loop() == loop_before_test\nTrue\n\nWe can raise an error in the test\n\n>>> @aio.testing.run_until_complete\n... def run_test():\n...     assert(True == False)\n\n>>> try:\n...     run_test()\n... except Exception as e:\n...     print(repr(e))\nAssertionError()\n\n  \naio.testing.run_forever\n-----------------------\n\nLets create a future test\n\n>>> import asyncio\n\n>>> @aio.testing.run_forever\n... def run_test(parent_loop):\n...     yield from asyncio.sleep(1)\n... \n...     print(asyncio.get_event_loop() != parent_loop)\n\nJust like with aio.testing.run_until_complete, the test is run in a separate loop\n\n>>> loop_before_test = asyncio.get_event_loop()  \n>>> run_test(loop_before_test)\nTrue\n\nAnd again, after the test has run we have the original event loop back\n\n>>> asyncio.get_event_loop() == loop_before_test\nTrue\n  \nIf the test returns a callable, its called 1 second later.\n\nThe test_callback runs in the same loop as the test\n  \n>>> @aio.testing.run_forever\n... def run_test():\n...     test_loop = asyncio.get_event_loop()\n... \n...     @asyncio.coroutine\n...     def test_callback():\n...         print(\n...             asyncio.get_event_loop() == test_loop)\n... \n...     return test_callback\n  \n>>> run_test()\nTrue\n\nThe test_callback is always wrapped in asyncio.coroutine if its not one already\n\n>>> @aio.testing.run_forever\n... def run_test():\n... \n...     def test_callback():\n...         yield from asyncio.sleep(1)\n...         print(\"test_callback is always wrapped in a coroutine!\")\n... \n...     return test_callback\n  \n>>> run_test()\ntest_callback is always wrapped in a coroutine!\n\n\nWe can raise an error in the test\n\n>>> @aio.testing.run_forever\n... def run_test():\n...     assert(True == False)\n\n>>> try:\n...     run_test()\n... except Exception as e:\n...     print(repr(e))\nAssertionError()\n\nAnd we can raise an error in the test callback\n\n>>> @aio.testing.run_forever\n... def run_test():\n... \n...     def test_callback():\n...         assert(True == False)\n... \n...     return test_callback\n  \n>>> try:\n...     run_test()\n... except Exception as e:\n...     print(repr(e))\nAssertionError()\n\nBy default the test_callback is called 1 second after being returned\n\n>>> import time\n\n>>> @aio.testing.run_forever\n... def run_test():\n...     test_run_at = int(time.time())\n... \n...     return lambda: (\n...         print(\"callback called %s second(s) after test\" % (\n...             int(time.time()) - test_run_at)))\n  \n>>> run_test()\ncallback called 1 second(s) after test\n\nYou can set the amount of time to wait before calling the test_callback by setting the \"timeout\" argument in the decorator\n\n>>> import time\n\n>>> @aio.testing.run_forever(timeout=3)\n... def run_test():\n...     test_run_at = int(time.time())\n... \n...     return lambda: print(\n...         \"callback called %s second(s) after test\" % (\n...             int(time.time()) - test_run_at))\n  \n>>> run_test()\ncallback called 3 second(s) after test\n  \nYou can also set the amount of time to wait after the test has completely finished, by setting the \"sleep\" argument on the decorator\n\n>>> @aio.testing.run_forever(sleep=3)\n... def run_test(test_time):\n...     return lambda: (\n...         test_time.__setitem__('completed_at', int(time.time())))\n\n>>> test_time = {}\n>>> run_test(test_time)\n  \n>>> print(\"test waited %s second(s) after completing\" % (\n...     int(time.time()) - test_time['completed_at']))\ntest waited 3 second(s) after completing",
        "url": "http://pypi.python.org/pypi/aio.testing",
        "summary": "Testing utils for aio asyncio framework",
        "command": "pip install 'aio.testing'"
      },
      "aiotg": {
        "name": "aiotg",
        "description": "aiotg\n=====\n\nAsynchronous Python API for building Telegram bots\n\nThis module is under heavy development, so the API is not stable yet,\nbut you are encouraged to play with it and report any issues and suggestions.\n\nInstall it with pip:\n\n.. code:: sh\n\n    pip install aiotg\n\nThen you can create a new bot in few lines:\n\n.. code:: python\n\n    import os\n    from aiotg import TgBot\n\n    bot = TgBot(os.environ[\"API_TOKEN\"])\n\n    @bot.command(r\"/echo (.+)\")\n    def echo(message, match):\n        return message.reply(match.group(1))\n\n    if __name__ == '__main__':\n        bot.run()\n\nRun it with a proper API\\_TOKEN and it should reply to /echo commands.\n\nFor a more complete example, take a look at\n`WhatisBot <https://github.com/szastupov/whatisbot/blob/master/main.py>`__.\n",
        "url": "http://pypi.python.org/pypi/aiotg",
        "summary": "Asynchronous Python API for building Telegram bots",
        "command": "pip install 'aiotg'"
      },
      "aiothrottle": {
        "name": "aiothrottle",
        "description": "aiothrottle\n===========\n\nThrottling, flow controlling StreamReader for aiohttp\n\n.. image:: https://img.shields.io/pypi/v/aiothrottle.svg\n    :target: https://pypi.python.org/pypi/aiothrottle\n    :alt: Package Version\n\n.. image:: https://travis-ci.org/panda73111/aiothrottle.svg?branch=master\n    :target: https://travis-ci.org/panda73111/aiothrottle\n    :alt: Build Status\n\n.. image:: https://coveralls.io/repos/panda73111/aiothrottle/badge.svg?branch=master&service=github\n    :target: https://coveralls.io/github/panda73111/aiothrottle?branch=master\n    :alt: Coverage Status\n\n.. image:: https://readthedocs.org/projects/aiothrottle/badge/?version=latest\n    :target: https://readthedocs.org/projects/aiothrottle/?badge=latest\n    :alt: Documentation Status\n\n.. image:: https://img.shields.io/pypi/pyversions/aiothrottle.svg\n    :target: https://www.python.org/\n    :alt: Python Version\n\n.. image:: https://img.shields.io/pypi/l/aiothrottle.svg\n    :target: http://opensource.org/licenses/GPL-3.0\n    :alt: GPLv3\n\nRequirements\n------------\n\n- Python >= 3.3\n- asyncio https://pypi.python.org/pypi/asyncio\n- aiohttp https://pypi.python.org/pypi/aiohttp\n\n\nLicense\n-------\n\n``aiothrottle`` is offered under the GPL v3 license.\n\n\nDocumentation\n-------------\n\nhttps://aiothrottle.readthedocs.org/\n\n\nSource code\n-----------\n\nThe latest developer version is available in a github repository:\nhttps://github.com/panda73111/aiothrottle\n\n\nUsage\n-----\n\n.. code:: python\n\n    import asyncio\n    import aiohttp\n    import aiothrottle\n\n    @asyncio.coroutine\n    def load_file(url):\n        response = yield from aiohttp.request(\"GET\", url)\n\n        data = yield from response.read()\n        with open(\"largefile.zip\", \"wb\") as file:\n            file.write(data)\n\n        response.close()\n\n    # setup the rate limit to 200 KB/s\n    aiothrottle.limit_rate(200 * 1024)\n\n    # download a large file without blocking bandwidth\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(load_file(\n        \"http://example.com/largefile.zip\"))\n\n    # unset the rate limit\n    aiothrottle.unlimit_rate()\n\n\nTODO\n----\n\n- Upload rate limiting class\n- General socket limiting class\n\nCHANGES\n=======\n\n0.1.2 (08-08-2015)\n------------------\n\n- Fixed resuming transport too often\n\n- Added 'rate_limit' and 'throttling' properties\n\n- Fixed buffer limit control\n\n0.1.1 (08-02-2015)\n------------------\n\n- Added limit_rate() and unlimit_rate() globally and response-wise\n\n- Raising ValueError on invalid rate limit\n\n- Cancelling _check_handle in Throttle's destructor\n\n0.1.0 (08-01-2015)\n------------------\n\n- Initial release with basic throttling functionality",
        "url": "http://pypi.python.org/pypi/aiothrottle",
        "summary": "Throttling, flow controlling StreamReader for aiohttp",
        "command": "pip install 'aiothrottle'"
      },
      "aiourlstatus": {
        "name": "aiourlstatus",
        "description": "Aiourlstatus\n============\n\nA link checker that checks the urls in text files - using Python 3.4 and asyncio.\n\nThis used to be called alinkcheck, but I changed the name to avoid confusion\nwith another program.\n\nFeatures\n~~~~~~~~\n\nAiourlstatus can be used as a command line application, or it can be imported and\ncalled from an interactive python, or ipython, shell.\n\nAiourlstatus parses text files, and then checks all the urls it finds.\nIt can be used, for example, to check the links in files output by databases.\n\nThe links are checked asynchronously, so the program does not block while waiting for responses.\nHowever, the number of times each domain is checked is limited.\nThis means that aiourlstatus will run slower if the links you are checking are from\na small number of domains.\n\nUse\n~~~\n\nPlease read the `wiki <https://github.com/riverrun/aiourlstatus/wiki>`_ for\ninformation about how to use aiourlstatus.\n\nDependencies\n~~~~~~~~~~~~\n\nPython 3.4, click and aiohttp.\n\nAuthor\n~~~~~~\n\nThis program has been developed by David Whitlock.\n\nLicense\n~~~~~~~\n\nAiourlstatus is free software: you can redistribute it and/or modify it under\nthe terms of the GNU General Public License as published by the Free\nSoftware Foundation, either version 3 of the License, or (at your\noption) any later version.",
        "url": "http://pypi.python.org/pypi/aiourlstatus",
        "summary": "A tool to check links from a json / text file",
        "command": "pip install 'aiourlstatus'"
      },
      "aioutils": {
        "name": "aioutils",
        "description": "## History\n\n### 2015.03.12\n\n0.3.10 release\n\n- do not raise asyncio.InvalidStateError\n\n### 2015.03.11\n\n0.3.9 release\n\n- fix a bug will cause yielder stuck\n\n### 2015.03.05\n\n0.3.8 release\n\n- when GeneratorExit cancel all pending tasks\n- yielder related status cleanups\n\n### 2015.03.02\n\n0.3.4-0.3.7 release\n\n- create new event loop if using in a thread\n- fix semaphore order so that loop must exist\n- add test to test this behaviour\n- cleanup _safe_yield_from that are not needed anymore\n- use is_running (how can I not using that!!)\n\n### 2015.02.28\n\n0.3.3 release\n\n- fixed Pool's potential thread unsafe problem\n- fixed Yielder hangs when no items to yield\n- add pool size argument to yielder family\n\n### 2015.02.27\n\n0.3.2 release\n\n- typo fix\n\n0.3.1 release\n\n- add put method for manually yield items\n\n0.3.0 release\n\n- add Yielder and OrderedYielder to replace Bag and OrderedBag\n- fix thread safe problem #2 in Yielder and Group mixed usage\n\n### 2015.02.26\n\n0.2.1 release\n\n- fix thread unsafe problem\n\n### 2015.02.26\n\n0.2.0 release\n\n- add Bag and OrderedBag\n- rename to \"aioutils\"\n\n### 2015.02.25\n\n0.1.2 release\n\n- fix some release problems\n\n0.1.1 release\n\n- basic group and pool implemenation\n\n\n### 2015.02.23\n\nideas, prototypes",
        "url": "http://pypi.python.org/pypi/aioutils",
        "summary": "Python3 Asyncio Utils",
        "command": "pip install 'aioutils'"
      },
      "aiouv": {
        "name": "aiouv",
        "description": "",
        "url": "http://pypi.python.org/pypi/aiouv",
        "summary": "libuv based event loop for asyncio",
        "command": "pip install 'aiouv'"
      },
      "aioweb": {
        "name": "aioweb",
        "description": "Webserver using the asyncio(pep3156) modules.",
        "url": "http://pypi.python.org/pypi/aioweb",
        "summary": "Asynchronous web framework, based on asyncio",
        "command": "pip install 'aioweb'"
      },
      "aio.web": {
        "name": "aio.web",
        "description": "Detailed documentation\n**********************\n\naio.web\n=======\n\nThis package has been moved to aio.web.server_ (pypi_)\n\n.. _aio.web.server: https://github.com/phlax/aio.web.server\n.. _pypi: https://pypi.python.org/pypi/aio.web.server",
        "url": "http://pypi.python.org/pypi/aio.web",
        "summary": "Aio web server",
        "command": "pip install 'aio.web'"
      },
      "aio.web.page": {
        "name": "aio.web.page",
        "description": "Detailed documentation\n**********************\n\naio.web.page\n============\n\nWeb page templates for the aio_ asyncio framework\n\n.. _aio: https://github.com/phlax/aio\n\n\n\nBuild status\n------------\n\n.. image:: https://travis-ci.org/phlax/aio.web.page.svg?branch=master\n\t       :target: https://travis-ci.org/phlax/aio.web.page\n\n\nInstallation\n------------\n\nRequires python >= 3.4\n\nInstall with:\n\n.. code:: bash\n\n\t  pip install aio.web.page\n\n\nQuick start - hello world web page\n----------------------------------\n\nSave the following into a file \"hello.conf\"\n\n.. code:: ini\n\n\t  [aio]\n\t  modules = aio.web.server\n\n\t  [server/my_server]\n\t  factory = aio.web.server.factory\n\t  port = 8080\n\n\t  [web/my_server]\n\t  template_dirs = templates\n\t  \n\t  [web/my_server/my_route]\n\t  match = /\n\t  route = my_example.route_handler\n\n\nAnd save the following into a file named \"my_example.py\"\n\n.. code:: python\n\n\t  import aio.web.page\t  \n\t  import aio.web.server\n\n\t  @aio.web.page.template('example_page.html')\n\t  def template_handler(request):\n\t      return {\"message\": \"Hello template world\"}\t  \n\t  \n\t  @aio.web.server.route\n\t  def route_handler(request, config):\n\t      return (yield from template_handler(request))\n\n\nAnd the following into a file named \"templates/example_page.html\"\n\n.. code:: html\n\t  \n\t  <html>\n\t    <body>\n\t      {{ message }}\n\t    </body>\n\t  </html>\n\t    \nRun with the aio run command\n\n.. code:: bash\n\n\t  aio run -c hello.conf\n\n\n\naio.web.page usage\n------------------\n\naio.web.page provides templates and fragments for building web pages\n\nLets set up a test to run a server and request a web page\n\n>>> from aio.app.runner import runner    \n>>> import aio.testing\n>>> import aiohttp  \n\n>>> @aio.testing.run_forever(sleep=1)\n... def run_web_server(config, request_page=\"http://localhost:7070\"):\n...     yield from runner(['run'], config_string=config)\n... \n...     def call_web_server():\n...         result = yield from (\n...             yield from aiohttp.request(\n...                \"GET\", request_page)).read()\n...         aio.web.server.clear()\n... \n...         print(result.decode())\n... \n...     return call_web_server\n\n\nTemplates\n---------\n  \nAn @aio.web.server.route handler can defer to other templates, for example according to the matched path.\n\n>>> example_config = \"\"\"\n... [aio]\n... log_level = CRITICAL\n... modules = aio.web.server\n...        aio.web.server.tests  \n... \n... [server/server_name]\n... factory: aio.web.server.factory\n... port: 7070\n... \n... [web/server_name/route_name]\n... match = /{path:.*}\n... route = aio.web.page.tests._example_route_handler\n... \"\"\"\n\nLets create a couple of template handlers\n\n>>> import aio.web.page\n\n>>> @aio.web.page.template(\"test_template.html\")    \n... def template_handler_1(request):  \n...     return {\n...         'message': \"Hello, world from template handler 1\"}\n\nTemplate handlers can return a response object, in which case the template is not rendered\n  \n>>> @aio.web.page.template(\"test_template.html\")\n... def template_handler_2(request):\n...     return aiohttp.web.Response(\n...         body=b\"Hello, world from template handler 2\")\n\n\nAnd lets set up a route handler which will defer to a template accordingly\n\n>>> import aio.web.server\n\n>>> @aio.web.server.route\n... def route_handler(request, config):\n...     path = request.match_info['path']\n... \n...     if path == \"path1\":\n...         return (yield from template_handler_1(request))\n... \n...     elif path == \"path2\":\n...         return (yield from template_handler_2(request))\n... \n...     raise aiohttp.web.HTTPNotFound\n\nAnd make it importable\n  \n>>> import aio.web.page.tests\n>>> aio.web.page.tests._example_route_handler = route_handler\n\nCalling the server at /path1 we get the templated handler\n  \n>>> run_web_server(\n...     example_config,\n...     request_page=\"http://localhost:7070/path1\")  \n<html>\n  <body>\n    Hello, world from template handler 1\n  </body>\n</html>\n\nAnd calling on /path2 we get the response without the template\n  \n>>> run_web_server(\n...     example_config,\n...     request_page=\"http://localhost:7070/path2\")  \nHello, world from template handler 2\n\n\nTemplates must always specify a template, even if they dont use it\n\n>>> try:\n...     @aio.web.page.template\n...     def template_handler(request, test_list):  \n...         return {'test_list': test_list}\n... except Exception as e:\n...     print(repr(e))\nTypeError('Template decorator must specify template: <function template_handler ...>',)\n\nTemplates can take arbitrary arguments\n\n>>> @aio.web.page.template(\"test_template.html\")    \n... def template_handler(request, foo, bar):  \n...     return {\n...         'message': \"Hello, world with %s and %s\" % (foo, bar)}\n\n>>> @aio.web.server.route\n... def route_handler(request, config):\n...     return (yield from(template_handler(request, \"spam\", \"tuesday\")))\n>>> aio.web.page.tests._example_route_handler = route_handler\n\n>>> run_web_server(example_config)\n<html>\n  <body>\n    Hello, world with spam and tuesday\n  </body>\n</html>\n\nThe first argument to a template should always be a request object\n\n>>> @aio.web.page.template(\"test_template.html\")    \n... def template_handler(foo, bar):  \n...     return {\n...         'message': \"Hello, world with %s and %s\" % (foo, bar)}\n\n>>> @aio.web.server.route\n... def route_handler(request, config):\n...     try:\n...         return (yield from(template_handler(\"spam\", \"tuesday\")))\n...     except TypeError as e:\n...         return aiohttp.web.Response(body=repr(e).encode())\n>>> aio.web.page.tests._example_route_handler = route_handler\n\n>>> run_web_server(example_config)\nTypeError(\"Template handler (<function template_handler at ...>) should be called with a request object, got: <class 'str'> spam\",)\n\n\nFragments\n---------\n\nFragments render a snippet of html for embedding in other templates.\n\nFragments can specify a template and return a context object to render it with\n\nA fragment can take an arbitrary number of arguments\n\n>>> @aio.web.page.fragment(\"fragments/test_fragment.html\")\n... def fragment_handler(request, foo, bar):\n...     return {\"test_list\": [foo, bar]}\n\n>>> @aio.web.page.template(\"test_template.html\")    \n... def template_handler(request):\n...     return {'message': (yield from fragment_handler(request, \"eggs\", \"thursday\"))}\n\n>>> @aio.web.server.route\n... def route_handler(request, config):\n...     return (yield from(template_handler(request)))\n>>> aio.web.page.tests._example_route_handler = route_handler\n\n>>> run_web_server(example_config)\n<html>\n  <body>\n    <ul>\n      <li>eggs</li><li>thursday</li>\n    </ul>\n  </body>\n</html>\n\nThe first argument to a fragment should always be an aiohttp.web.Request object\n\n>>> @aio.web.page.fragment(\"fragments/test_fragment.html\")\n... def fragment_handler(foo, bar):\n...     return {\"test_list\": [foo, bar]}\n\n>>> @aio.web.page.template(\"test_template.html\")    \n... def template_handler(request):\n...     try:\n...         message = (yield from(fragment_handler(\"eggs\", \"thursday\")))\n...     except Exception as e:\n...         message = repr(e)\n...     return {'message': message}\n\n>>> @aio.web.server.route\n... def route_handler(request, config):\n...     return (yield from(template_handler(request)))\n>>> aio.web.page.tests._example_route_handler = route_handler\n\n>>> run_web_server(example_config)\n<html>\n  <body>\n    TypeError(\"Fragment handler (<function fragment_handler ...>) should be called with a request object, got: <class 'str'> eggs\",)\n  </body>\n</html>\n\n\nFragments do not need to specify a template\n\n>>> @aio.web.page.fragment\n... def fragment_handler(request):\n...     return \"Hello from fragment\"\n\n>>> @aio.web.page.template(\"test_template.html\")  \n... def template_handler(request):\n...     return {'message': (yield from fragment_handler(request))}  \n\n>>> @aio.web.server.route\n... def route_handler(request, config):\n...     return (yield from(template_handler(request)))\n>>> aio.web.page.tests._example_route_handler = route_handler\n\n>>> run_web_server(example_config)\n<html>\n  <body>\n    Hello from fragment\n  </body>\n</html>\n\nIf a fragment doesnt specify a template, it must return a string\n\n>>> @aio.web.page.fragment\n... def fragment_handler(request):\n...     return {\"foo\": \"bar\"}\n\n>>> @aio.web.page.template(\"test_template.html\")  \n... def template_handler(request):\n...     try:\n...         fragment = yield from fragment_handler(request)\n...     except Exception as e:\n...         fragment = repr(e)\n...     return {'message': fragment}\n\n>>> @aio.web.server.route\n... def route_handler(request, config):\n...     return (yield from(template_handler(request)))\n>>> aio.web.page.tests._example_route_handler = route_handler\n\n>>> run_web_server(example_config)\n<html>\n  <body>\n    TypeError('Fragment handler (<function fragment_handler at ...>) should specify a template or return a string',)\n  </body>\n</html>\n\nFragments should only return strings or context dictionaries, and should not return an aiohttp.web.Response object.\n\n>>> @aio.web.page.fragment(\"fragments/test_fragment.html\")\n... def fragment_handler(request):\n...     return aiohttp.web.Response(body=b\"Fragments should not return Response objects\")\n\n>>> @aio.web.page.template(\"test_template.html\")  \n... def template_handler(request):\n...     try:\n...         fragment = yield from fragment_handler(request)\n...     except Exception as e:\n...         fragment = repr(e)\n...     return {'message': fragment}\n\n>>> @aio.web.server.route\n... def route_handler(request, config):\n...     return (yield from(template_handler(request)))\n>>> aio.web.page.tests._example_route_handler = route_handler\n\n>>> run_web_server(example_config)\n<html>\n  <body>\n    TypeError(\"Fragment handler (<function fragment_handler ...>) should return a string or context dictionary, got: <class 'aiohttp.web_reqrep.Response'> <Response OK not started>\",)\n  </body>\n</html>",
        "url": "http://pypi.python.org/pypi/aio.web.page",
        "summary": "Web page templates for the aio asyncio framework",
        "command": "pip install 'aio.web.page'"
      },
      "aiowebrtc": {
        "name": "aiowebrtc",
        "description": "WebRTC (Real-Time Communication) uses a variety of peer to peer protocols\nfor audio, video, and data streaming.",
        "url": "http://pypi.python.org/pypi/aiowebrtc",
        "summary": "AsyncIO WebRTC Package",
        "command": "pip install 'aiowebrtc'"
      },
      "aio.web.server": {
        "name": "aio.web.server",
        "description": "Detailed documentation\n**********************\n\naio.web.server\n==============\n\nWeb server for the aio_ asyncio framework\n\n.. _aio: https://github.com/phlax/aio\n\n\n\nBuild status\n------------\n\n.. image:: https://travis-ci.org/phlax/aio.web.server.svg?branch=master\n\t       :target: https://travis-ci.org/phlax/aio.web.server\n\n\nInstallation\n------------\n\nRequires python >= 3.4\n\nInstall with:\n\n.. code:: bash\n\n\t  pip install aio.web.server\n\n\t  \nQuick start - Hello world web server\n------------------------------------\n\nCreate a web server that says hello\n\nSave the following into a file \"hello.conf\"\n\n.. code:: ini\n\n\t  [aio]\n\t  modules = aio.web.server\n\n\t  [server/my_server]\n\t  factory = aio.web.server.factory\n\t  port = 8080\n\n\t  [web/my_server/my_route]\n\t  match = /\n\t  route = my_example.handler\n\n\t  \nAnd save the following into a file named my_example.py\n\t  \n.. code:: python\n\n\t  import aiohttp\n\t  import aio.web.server\n\n\t  @aio.web.server.route\n\t  def handler(request, config):\n\t      return aiohttp.web.Response(body=b\"Hello, web world\")\n\n\nRun with the aio run command\n\n.. code:: bash\n\n\t  aio run -c hello.conf\n\n\t  \nWeb server configuration\n------------------------\n\t  \nWeb server definitions are in the following format, where SERVER_NAME corresponds to the server/SERVER_NAME\n\n\n.. code:: ini\n\n\t  [web/SERVER_NAME]\n\n\nSo for example you might have the following\n\n.. code:: ini\n\t  \n\t  [server/my_server]\n\t  factory = aio.web.server.factory\n\t  port = 8080\n\n\t  [web/my_server]\n\t  modules = ${aio:modules}\n\t          some.web.module\n\n\nRoute configuration\n-------------------\n\t\t  \nRoute definitions are in defined in sections with the following format\n\n.. code:: ini\n\n\t  [web/SERVER_NAME/ROUTE_NAME]\n\t  \n\nSo an example server configuation with a route defined for the path / might be\n\n.. code:: ini\n\t  \n\t  [aio]\n\t  modules = aio.web.server\n   \n\t  [server/my_server]\n\t  factory = aio.web.server.factory\n\t  port = 8080\n\n\t  [web/my_server/my_route]\n\t  match = /\n\t  route = my.route.handler\n\t  \n\n\naio.web.server usage\n--------------------\n\n\nConfiguration\n-------------\n\nTo set up the web server, we need to:\n\n- add \"aio.web.server\" to aio:modules initialize the web server\n- add a \"server/SERVERNAME\" section to create the http server\n- add a \"web/SERVERNAME/ROUTENAME\" to create a route\n\nLets create a basic web server configuration\n  \n>>> web_server_config = \"\"\"\n... [aio]\n... log_level = ERROR\n... modules = aio.web.server\n... \n... [server/server_name]\n... factory = aio.web.server.factory\n... port = 7070\n... \n... [web/server_name/route_name]\n... match = /\n... route = aio.web.server.tests._example_handler\n... \"\"\"  \n\nNow lets create a route and make it importable\n \n>>> import aiohttp\n>>> import aio.web.server\n\n>>> @aio.web.server.route\n... def route_handler(route):\n...     return aiohttp.web.Response(body=b\"Hello, web world\")    \n\n>>> import aio.web.server.tests\n>>> aio.web.server.tests._example_handler = route_handler\n\n\nLets set up a test to run the server and request a web page\n  \n>>> from aio.app.runner import runner    \n>>> import aio.testing\n\n>>> @aio.testing.run_forever(sleep=1)\n... def run_web_server(config, request_page=\"http://localhost:7070\"):\n...     runner(['run'], config_string=config)\n... \n...     def call_web_server():\n...         result = yield from (\n...             yield from aiohttp.request(\n...                \"GET\", request_page)).read()\n...         \n...         print(result.decode())\n... \n...     return call_web_server\n\nAnd run the test\n  \n>>> run_web_server(web_server_config)  \nHello, web world\n\nWe can access the aiohttp web app by name\n\n>>> import aio.web.server\n>>> web_app = aio.web.server.apps['server_name']\n>>> web_app\n<Application>\n\n>>> web_app['name']\n'server_name'\n\nAnd we can access the jinja environment for the web app\n\n>>> import aiohttp_jinja2\n>>> jinja_env = aiohttp_jinja2.get_env(web_app)\n>>> jinja_env\n<jinja2.environment.Environment object ...>\n\nWe dont have any templates registered yet\n\n>>> jinja_env.list_templates()\n[]\n  \nLet's clear the web apps, this will also call aio.app.clear()\n\n>>> aio.web.server.clear()\n>>> aio.web.server.apps\n{}\n\n>>> print(aio.app.config, aio.app.signals)\nNone None\n\n  \nWeb app modules\n---------------\n\nBy default template resources are registered for any modules listed in aio:modules\n\n>>> config = \"\"\"\n... [aio]\n... modules = aio.web.server\n...          aio.web.server.tests\n... \n... [server/server_name]\n... factory = aio.web.server.factory\n... port = 7070  \n... \"\"\"  \n\nLets create a test to run the server and print the list of installed jinja templates\n\n>>> @aio.testing.run_forever(sleep=1)\n... def run_server_print_templates(config_string):\n...     runner(['run'], config_string=config_string)\n... \n...     def print_templates():\n...         web_app = aio.web.server.apps['server_name']\n...         print(\n...             [x for x in\n...              aiohttp_jinja2.get_env(\n...                  web_app).list_templates(extensions=[\"html\"])])\n...         aio.web.server.clear()\n... \n...     return print_templates\n\nThe aio.web.server.tests module has 2 html templates\n  \n>>> run_server_print_templates(config)\n['fragments/test_fragment.html', 'test_template.html']\n  \nWe can set the modules for all web apps in the aio/web:modules option\n\nThis will override the setting in aio:modules\n\n>>> config = \"\"\"\n... [aio]\n... modules = aio.web.server\n...       aio.web.server.tests\n... \n... [aio/web]\n... modules = aio.web.server\n... \n... [server/server_name]\n... factory = aio.web.server.factory\n... port = 7070  \n... \"\"\"  \n\n>>> run_server_print_templates(config)\n[]\n\nOr you can set the modules in the web/*SERVER_NAME*:modules option.\n\nThis will override the setting in both aio/web:modules and aio:modules\n  \n>>> config = \"\"\"\n... [aio]\n... modules = aio.web.server\n...          aio.web.server.tests\n... \n... [aio/web]\n... modules = aio.web.server\n... \n... [web/server_name]\n... modules = aio.web.server.tests\n... \n... [server/server_name]\n... factory = aio.web.server.factory\n... port = 7070  \n... \"\"\"  \n\n>>> run_server_print_templates(config)\n['fragments/test_fragment.html', 'test_template.html']\n\nRoutes\n------\n\n>>> config_template = \"\"\"\n... [aio]\n... modules = aio.web.server\n...        aio.web.server.tests\n... log_level: ERROR\n... \n... [server/server_name]\n... factory: aio.web.server.factory\n... port: 7070\n... \n... [web/server_name/route_name]\n... match = /\n... route = aio.web.server.tests._example_route_handler\n... \"\"\"\n\nRoute functions must be decorated with aio.server.route, and receive a aio.server.Route object\n\nThe route object has a request property and a config property containing the routes configuration\n\n>>> @aio.web.server.route(\"test_template.html\")  \n... def route_handler(route):\n...     return {\n...         'message': 'Hello, world at %s from match(%s) handled by: %s' % (\n...             route.request.path, route.config['match'], route.config['route'])}\n\n>>> aio.web.server.tests._example_route_handler = route_handler\n\n>>> run_web_server(config_template)\n<html>\n  <body>\n    Hello, world at / from match(/) handled by: aio.web.server.tests._example_route_handler\n  </body>\n</html>\n  \n>>> aio.web.server.clear()\n\n\nStatic directory\n----------------\n\nThe web/*SERVER_NAME* section takes a static_url and a static_dir option for hosting static files\n\n>>> config_static = \"\"\"\n... [aio]\n... log_level: ERROR\n... modules = aio.web.server  \n... \n... [server/test]\n... factory: aio.web.server.factory\n... port: 7070\n... \n... [web/test]\n... static_url: /static\n... static_dir: %s\n... \"\"\"\n\n>>> import os\n>>> import tempfile\n\nLets create a temporary directory and add a css file to it\n  \n>>> with tempfile.TemporaryDirectory() as tmp:\n...     with open(os.path.join(tmp, \"test.css\"), 'w') as cssfile:\n...         result = cssfile.write(\"body {background: black}\")\n... \n...     run_web_server(\n...         config_static % tmp,\n...         request_page=\"http://localhost:7070/static/test.css\")  \nbody {background: black}\n\n>>> aio.web.server.clear()\n  \n\nTemplate filters\n----------------\n\nYou can configure jinja filters by adding them to the aio/web:filters option\n\n\n>>> config = \"\"\"\n... [aio]\n... log_level: ERROR\n... modules = aio.web.server  \n... \n... [server/server_name]\n... factory: aio.web.server.factory\n... port: 7070\n... \n... [aio/web]\n... filters = example_filter aio.web.server.tests._example_filter\n... \"\"\"\n\nThe filter is *not* called in a coroutine\n\n>>> def filter(value, *la):\n...     return value\n\n>>> aio.web.server.tests._example_filter = filter\n\n>>> @aio.testing.run_forever(sleep=1)\n... def run_server_check_filter(config_string):\n...     runner(['run'], config_string=config_string)\n... \n...     def check_filter():\n...         web_app = aio.web.server.apps['server_name']\n...         env = aiohttp_jinja2.get_env(web_app)\n... \n...         if \"example_filter\" in env.filters.keys():\n...             print(\"example_filter is in the jinja environment!\")\n... \n...     return check_filter\n\n\n>>> run_server_check_filter(config)\nexample_filter is in the jinja environment!\n\n>>> aio.web.server.clear()\n\nYou can also add filters to the the web/server_name section, this will override the setting in aio/web\n\n>>> config = \"\"\"\n... [aio]\n... log_level: ERROR\n... modules = aio.web.server  \n... \n... [server/server_name]\n... factory: aio.web.server.factory\n... port: 7070\n... \n... [aio/web]\n... filters = example_filter aio.web.server.tests._example_filter\n... \n... [web/server_name]\n... filters = example_filter_2 aio.web.server.tests._example_filter\n... \"\"\"\n\n>>> @aio.testing.run_forever(sleep=1)\n... def run_server_check_filter(config_string):\n...     runner(['run'], config_string=config_string)\n... \n...     def check_filter():\n...         web_app = aio.web.server.apps['server_name']\n...         env = aiohttp_jinja2.get_env(web_app)\n... \n...         if \"example_filter\" not in env.filters.keys():\n...             print(\"example_filter is not in the jinja environment!\")\n... \n...         if \"example_filter_2\" in env.filters.keys():\n...             print(\"example_filter_2 is in the jinja environment!\")\n... \n...     return check_filter\n\n\n>>> run_server_check_filter(config)\nexample_filter is not in the jinja environment!\nexample_filter_2 is in the jinja environment!\n\n\n>>> aio.web.server.clear()",
        "url": "http://pypi.python.org/pypi/aio.web.server",
        "summary": "Web server for the aio asyncio framework",
        "command": "pip install 'aio.web.server'"
      },
      "aiowebsocketclient": {
        "name": "aiowebsocketclient",
        "description": "==================\naiowebsocketclient\n==================\n\n**alpha**\n\n\n`Official Documentation`_\n\n\n.. _Official Documentation: https://github.com/davebshow/aiowebsocketclient",
        "url": "http://pypi.python.org/pypi/aiowebsocketclient",
        "summary": "WebSocket client connection manager for aiohttp",
        "command": "pip install 'aiowebsocketclient'"
      },
      "aiowerkzeug": {
        "name": "aiowerkzeug",
        "description": "|travis-master| |coverall-master| |doc-master| |pypi-downloads| |pypi-lastrelease| |python-versions|\n|project-status| |project-license| |project-format| |project-implementation|\n\n.. |travis-master| image:: https://travis-ci.org/alfred82santa/aiowerkzeug.svg?branch=master   \n    :target: https://travis-ci.org/alfred82santa/aiowerkzeug\n    \n.. |coverall-master| image:: https://coveralls.io/repos/alfred82santa/aiowerkzeug/badge.png?branch=master \n    :target: https://coveralls.io/r/alfred82santa/aiowerkzeug?branch=master\n    \n.. |doc-master| image:: https://readthedocs.org/projects/aiowerkzeug/badge/?version=latest\n    :target: https://readthedocs.org/projects/aiowerkzeug/?badge=latest\n    :alt: Documentation Status\n    \n.. |pypi-downloads| image:: https://pypip.in/download/aiowerkzeug/badge.svg\n    :target: https://pypi.python.org/pypi/aiowerkzeug/\n    :alt: Downloads\n    \n.. |pypi-lastrelease| image:: https://pypip.in/version/aiowerkzeug/badge.svg\n    :target: https://pypi.python.org/pypi/aiowerkzeug/\n    :alt: Latest Version\n    \n.. |python-versions| image:: https://pypip.in/py_versions/aiowerkzeug/badge.svg\n    :target: https://pypi.python.org/pypi/aiowerkzeug/\n    :alt: Supported Python versions\n    \n.. |project-status| image:: https://pypip.in/status/aiowerkzeug/badge.svg\n    :target: https://pypi.python.org/pypi/aiowerkzeug/\n    :alt: Development Status\n\n.. |project-license| image:: https://pypip.in/license/aiowerkzeug/badge.svg\n    :target: https://pypi.python.org/pypi/aiowerkzeug/\n    :alt: License\n\n.. |project-format| image:: https://pypip.in/format/aiowerkzeug/badge.svg\n    :target: https://pypi.python.org/pypi/aiowerkzeug/\n    :alt: Download format\n\n.. |project-implementation| image:: https://pypip.in/implementation/aiowerkzeug/badge.svg\n    :target: https://pypi.python.org/pypi/aiowerkzeug/\n    :alt: Supported Python implementations\n\n===========\naiowerkzeug\n===========\n\nLibrary to make werkzeug working with asyncio.\n\n--------\nFeatures\n--------\n\n* Locals work on asyncio Tasks. `werkzeug.local.Local` or `werkzeug.local.LocalStack` must be patched\n  with `aiowerkzeug.local.patch_local`\n\n  Patched `werkzeug.local.Local` or `werkzeug.local.LocalStack` use current `asyncio.tasks.Task`\n  to determine context.\n\n* Decorator factory to mark coroutines to run in a context. Useful for Flask. It allows to run corountines\n  in new `asyncio.tasks.Task` inside a specific context.\n\n  For example, in Flask to run coroutines in Application context it is possible to create a decorator like that:\n\n  .. code-block:: python\n\n        def _get_app_context():\n            return current_app.app_context()\n\n        app_coroutine = partial(context_coroutine, ctx=_get_app_context)\n\n        @app_coroutine\n        def foo_bar():\n            print(current_app.debug)\n\n        @flask_app.route('/')\n        def caller():\n            asyncio.ensure_future(foo_bar())\n\n* Asyncio HTTP server runner with reload\n\n  .. code-block:: bash\n\n    $ python aiowerkzeug/serving.py --reload app_test.app\n\n----\nTODO\n----\n\n* Form parser\n* Debug middleware\n* Static files middleware",
        "url": "http://pypi.python.org/pypi/aiowerkzeug",
        "summary": "Werkzeug for asyncio",
        "command": "pip install 'aiowerkzeug'"
      },
      "aiowhoosh": {
        "name": "aiowhoosh",
        "description": "Whoosh HTTP Server with aiohttp\n===============================",
        "url": "http://pypi.python.org/pypi/aiowhoosh",
        "summary": "Whoosh HTTP Server with aiohttp",
        "command": "pip install 'aiowhoosh'"
      },
      "aiowsgi": {
        "name": "aiowsgi",
        "description": "================================================\naiowsgi - minimalist wsgi server using asyncio\n================================================\n\n.. image:: https://travis-ci.org/gawel/aiowsgi.png?branch=master\n  :target: https://travis-ci.org/gawel/aiowsgi\n.. image:: https://coveralls.io/repos/gawel/aiowsgi/badge.png?branch=master\n  :target: https://coveralls.io/r/gawel/aiowsgi?branch=master\n.. image:: https://pypip.in/v/aiowsgi/badge.png\n   :target: https://crate.io/packages/aiowsgi/\n.. image:: https://pypip.in/d/aiowsgi/badge.png\n   :target: https://crate.io/packages/aiowsgi/\n\nRequire python 2.7, 3.3+\n\nSource: https://github.com/gawel/aiowsgi/\n\nDocs: https://aiowsgi.readthedocs.org/\n\nYou like it ? => https://www.gittip.com/gawel/",
        "url": "http://pypi.python.org/pypi/aiowsgi",
        "summary": "minimalist wsgi server using asyncio",
        "command": "pip install 'aiowsgi'"
      },
      "aioxmlrpc": {
        "name": "aioxmlrpc",
        "description": "=========\r\naioxmlrpc\r\n=========\r\n\r\n\r\n.. image:: https://travis-ci.org/mardiros/aioxmlrpc.png?branch=master\r\n   :target: https://travis-ci.org/mardiros/aioxmlrpc\r\n\r\n\r\nGetting Started\r\n===============\r\n\r\nAsyncio version of the standard lib ``xmlrpc``\r\n\r\nCurrently only ``aioxmlrpc.client``, which works like ``xmlrpc.client`` but\r\nwith coroutine is implemented.\r\n\r\nFill free to fork me if you want to implement the server part.\r\n\r\n\r\n``aioxmlrpc`` is based on ``aiohttp`` for the transport, and just patch\r\nthe necessary from the python standard library to get it working.\r\n\r\n\r\nInstallation\r\n------------\r\n\r\n::\r\n\r\n    pip install aioxmlrpc\r\n\r\n\r\nExample of usage\r\n----------------\r\n\r\nThis example show how to print the current version of the Gandi XML-RPC api.\r\n\r\n\r\n::\r\n\r\n    import asyncio\r\n    from aioxmlrpc.client import ServerProxy\r\n\r\n\r\n    @asyncio.coroutine\r\n    def print_gandi_api_version():\r\n        api = ServerProxy('https://rpc.gandi.net/xmlrpc/')\r\n        result = yield from api.version.info()\r\n        print(result)\r\n\r\n    if __name__ == '__main__':\r\n        loop = asyncio.get_event_loop()\r\n        loop.run_until_complete(print_gandi_api_version())\r\n        loop.stop()\r\n\r\n\r\nChangelist\r\n==========\r\n\r\n0.1 released on 2014-05-17\r\n--------------------------\r\n\r\n * Initial version implementing ``aioxmlrpc.client``",
        "url": "http://pypi.python.org/pypi/aioxmlrpc",
        "summary": "XML-RPC for asyncio",
        "command": "pip install 'aioxmlrpc'"
      },
      "aioxmpp": {
        "name": "aioxmpp",
        "description": "``aioxmpp``\n###########\n\n... is a pure-python XMPP library using the\n`asyncio <https://docs.python.org/3/library/asyncio.html>`_\nstandard library module from Python 3.4 (and `available as a third-party module to Python\n3.3 <https://code.google.com/p/tulip/>`_ ).\n\nDependencies\n------------\n\n* Python ≥ 3.4 (or Python = 3.3 with tulip and enum34)\n* DNSPython\n* libxml2-devel (for some XML helpers)\n* lxml\n\nDesign goals\n------------\n\n* Powerful API to implement all sorts of XEPs\n* Reliable message transmission even under dire network circumstances\n* Well-tested code base\n* A more compelling README than this",
        "url": "http://pypi.python.org/pypi/aioxmpp",
        "summary": "Pure-python XMPP library for asyncio",
        "command": "pip install 'aioxmpp'"
      },
      "aiozmq": {
        "name": "aiozmq",
        "description": "asyncio integration with ZeroMQ\n===============================\n\nasyncio (PEP 3156) support for ZeroMQ.\n\n.. image:: https://travis-ci.org/aio-libs/aiozmq.svg?branch=master\n   :target: https://travis-ci.org/aio-libs/aiozmq\n\nDocumentation\n-------------\n\nSee http://aiozmq.readthedocs.org\n\nSimple high-level client-server RPC example::\n\n    import asyncio\n    import aiozmq.rpc\n\n\n    class ServerHandler(aiozmq.rpc.AttrHandler):\n\n        @aiozmq.rpc.method\n        def remote_func(self, a:int, b:int) -> int:\n            return a + b\n\n\n    @asyncio.coroutine\n    def go():\n        server = yield from aiozmq.rpc.serve_rpc(\n            ServerHandler(), bind='tcp://127.0.0.1:5555')\n        client = yield from aiozmq.rpc.connect_rpc(\n            connect='tcp://127.0.0.1:5555')\n\n        ret = yield from client.call.remote_func(1, 2)\n        assert 3 == ret\n\n        server.close()\n        client.close()\n\n    asyncio.get_event_loop().run_until_complete(go())\n\nLow-level request-reply example::\n\n    import asyncio\n    import aiozmq\n    import zmq\n\n    @asyncio.coroutine\n    def go():\n        router = yield from aiozmq.create_zmq_stream(\n            zmq.ROUTER,\n            bind='tcp://127.0.0.1:*')\n\n        addr = list(router.transport.bindings())[0]\n        dealer = yield from aiozmq.create_zmq_stream(\n            zmq.DEALER,\n            connect=addr)\n\n        for i in range(10):\n            msg = (b'data', b'ask', str(i).encode('utf-8'))\n            dealer.write(msg)\n            data = yield from router.read()\n            router.write(data)\n            answer = yield from dealer.read()\n            print(answer)\n        dealer.close()\n        router.close()\n\n    asyncio.get_event_loop().run_until_complete(go())\n\n\nRequirements\n------------\n\n* Python_ 3.3+\n* pyzmq_ 13.1+\n* asyncio_ or Python 3.4+\n* optional submodule ``aiozmq.rpc`` requires msgpack-python_ 0.4+\n\n\n\nLicense\n-------\n\naiozmq is offered under the BSD license.\n\n.. _python: https://www.python.org/\n.. _pyzmq: https://pypi.python.org/pypi/pyzmq\n.. _asyncio: https://pypi.python.org/pypi/asyncio\n.. _msgpack-python: https://pypi.python.org/pypi/msgpack-python\n\nCHANGES\n-------\n\n0.7.1 (2015-09-20)\n^^^^^^^^^^^^^^^^^^\n\n* Fix monitoring events implementation\n\n* Make the library compatible with Python 3.5\n\n0.7.0 (2015-07-31)\n^^^^^^^^^^^^^^^^^^\n\n* Implement monitoring ZMQ events #50\n\n* Do deeper lookup for inhereted classes #54\n\n* Relax endpont check #56\n\n* Implement monitoring events for stream api #52\n\n0.6.1 (2015-05-19)\n^^^^^^^^^^^^^^^^^^\n\n* Dynamically get list of pyzmq socket types\n\n0.6.0 (2015-02-14)\n^^^^^^^^^^^^^^^^^^\n\n* Process asyncio specific exceptions as builtins.\n\n* Add repr(exception) to rpc server call logs if any\n\n* Add transport.get_write_buffer_limits() method\n\n* Add __repr__ to transport\n\n* Add zmq_type to tr.get_extra_info()\n\n* Add zmq streams\n\n0.5.2 (2014-10-09)\n^^^^^^^^^^^^^^^^^^\n\n* Poll events after sending zmq message for eventless transport\n\n0.5.1 (2014-09-27)\n^^^^^^^^^^^^^^^^^^\n\n* Fix loopless transport implementation.\n\n0.5.0 (2014-08-23)\n^^^^^^^^^^^^^^^^^^\n\n* Support zmq devices in aiozmq.rpc.serve_rpc()\n\n* Add loopless 0MQ transport\n\n0.4.1 (2014-07-03)\n^^^^^^^^^^^^^^^^^^\n\n* Add exclude_log_exceptions parameter to rpc servers.\n\n0.4.0 (2014-05-28)\n^^^^^^^^^^^^^^^^^^\n\n* Implement pause_reading/resume_reading methods in ZmqTransport.\n\n0.3.0 (2014-05-17)\n^^^^^^^^^^^^^^^^^^\n\n* Add limited support for Windows.\n\n* Fix unstable test execution, change ZmqEventLoop to use global\n  shared zmq.Context by default.\n\n* Process cancellation on rpc servers and clients.\n\n0.2.0 (2014-04-18)\n^^^^^^^^^^^^^^^^^^\n\n* msg in msg_received now is a list, not tuple\n\n* Allow to send empty msg by trsansport.write()\n\n* Add benchmarks\n\n* Derive ServiceClosedError from aiozmq.rpc.Error, not Exception\n\n* Implement logging from remote calls at server side (log_exceptions parameter).\n\n* Optimize byte counting in ZmqTransport.\n\n0.1.3 (2014-04-10)\n^^^^^^^^^^^^^^^^^^\n\n* Function default values are not passed to an annotaion.\n  Add check for libzmq version (should be >= 3.0)\n\n0.1.2 (2014-04-01)\n^^^^^^^^^^^^^^^^^^\n\n* Function default values are not passed to an annotaion.\n\n0.1.1 (2014-03-31)\n^^^^^^^^^^^^^^^^^^\n\n* Rename plural module names to single ones.\n\n0.1.0 (2014-03-30)\n^^^^^^^^^^^^^^^^^^\n\n* Implement ZmqEventLoop with *create_zmq_connection* method which operates\n  on zmq transport and protocol.\n\n* Implement ZmqEventLoopPolicy.\n\n* Introduce ZmqTransport and ZmqProtocol.\n\n* Implement zmq.rpc with RPC, PUSHPULL and PUBSUB protocols.",
        "url": "http://pypi.python.org/pypi/aiozmq",
        "summary": "ZeroMQ integration with asyncio.",
        "command": "pip install 'aiozmq'"
      },
      "aipsetup": {
        "name": "aipsetup",
        "description": "This README is too old. Low on useful information.\n\n---------\n\nOctober 31 2009\n\nHi All\n\nI'm AGUtilities, and I'm mainteining my own GNU/Linux distribution,\nit's called Atlas WayRound GNU/Linux (Atlas Linux for short). While\ni've moved to my target, I realized that there is no packaging system,\nsuitable by my requests. So I decided to write My own. So here it\nis. I called it `aipsetup'\n\n~~~\n\nWhat does it do?\n\nFor My own, I needed software to easily build pack install and\nuninstall different software packages on system. So, basic properties\nof this tools are follow:\n\n1. easy extraction source tarball\n2. flexible building system\n3. easy and fast pack\n4. installing packages\n5. uninstalling packages\n6. checking installed package integrity\netc\n\n~~~\n\nInstallation.\n\nDownload lattest aipsetup package from\nhttp://wayround.org/mirrors/AtlasLinux/aipsetup/ , extract it\nsomewhere, and do:\n\nmake install\n\nIt will be installed in /usr/lib/aipsetup directory, and executable\nfile, will be placed to /usr/bin.\n\nInstallation is now complite :-)\n\n~~~\n\nUsage.\n\n~~~~~~~~\nOne command program build\n~~~~~~~~\n\nif your' aipsetup has propriaste template installed, then You can\nbuild many apps by one single command:\n\naipsetup bd wine wine-1.1.31.tar.gz\n\n where:\n  aipsetup           - command\n  bd       \t     - aipsetup command\n  wine     \t     - template aipsetup must use to build package\n  wine-1.1.31.tar.gz - sources ( can be multiple filenames or wildcard)\n\naipsetup, internaly, does all staff, including extraction, building\nand packaging.\n\non the end, You'll have pack directory with new, ready to install\npackage, or if any errors will happen, log of all operation\n\n~~~~~~~~\nFile extraction\n~~~~~~~~\n\naipsetup ex filename\n\nwill extract fiven file to current dir\n\n~~~~~~~~\nCompilling building script \n~~~~~~~~\n\naipsetup sc wine\n\nWill create build script for building package.\n\nThis command assumed to be deploid right in the first source dir ofthe\npackage. \n\n~~~~~~~~\nBuilding packare\n~~~~~~~~\n\nexecute script created by aipsetup with bash and it will build\npackage, logging all process to package's 'var' dir.\n\n~~~~~~~~\nCreating installation package\n~~~~~~~~\n\nGo to new package dir and command\n\naipsetup pk\n\nand it will create package in ../pack directory\n\n~~~~~~~~\nInstalling and uninstallin package\n~~~~~~~~\n\npackage can be installed or uninstalled\n\naipsetup in 'package filename or wildcard'\naipsetup in wine-*.tar.bz2\n\naipsetup rm 'package filename or wildcard'\naipsetup rm 'wine-*'\n\n~~~~~~~~\nList installed packages\n~~~~~~~~\n\naipsetup ls 'wine-*'\n\n\n~~~~~~~~~~~\n\naipsetup have also some nice tools for serchid dependenties and things\nlike thet. See aipsetup --help\n\n~~\n\nFinally I have updated this README. \n\nbe Happy\n",
        "url": "http://pypi.python.org/pypi/aipsetup",
        "summary": "software tools for building and maintaining own gnu+linux distro",
        "command": "pip install 'aipsetup'"
      },
      "aipy": {
        "name": "aipy",
        "description": "This package collects together tools for radio astronomical interferometry. In addition to pure-python phasing, calibration, imaging, and deconvolution code, this package includes interfaces to MIRIAD (a Fortran interferometry package) and HEALPix (a package for representing spherical data sets), and some math/fitting routines from SciPy.",
        "url": "http://pypi.python.org/pypi/aipy",
        "summary": "Astronomical Interferometry in PYthon",
        "command": "pip install 'aipy'"
      },
      "aiqpy": {
        "name": "aiqpy",
        "description": "aiqpy\n=====\n\naiqpy is a wrapper library that allows you to interact with an `AppearIQ 8 <https://appeariq.com>`_ platform using Python.\n\nThe library connects to the REST APIs of the platform and takes care of authentication and session management so you can focus on funnier things.\n\n\nExample: Changing the password of a user\n----------------------------------------\n.. code-block:: pycon\n\n    >>> platform = aiqpy.Connection(profile='dev')\n    >>> user = platform.get(['admin', 'users'], username='stephen.falken')[0]\n    >>> user['password'] = 'joshua'\n    >>> updated = platform.put(['admin', 'users'], user)\n\nDependencies\n------------\naiqpy uses `Requests <http://python-requests.org>`_ for performing HTTP requests.\n\nLicense\n-------\naiqpy is licensed under GNU GPL v3.0.\n",
        "url": "http://pypi.python.org/pypi/aiqpy",
        "summary": "Python bindings for connecting to a AIQ8 server",
        "command": "pip install 'aiqpy'"
      },
      "aiqterminal": {
        "name": "aiqterminal",
        "description": "aiqterminal\n===========\n\naiqterminal is a an interactive shell for administrating an `AppearIQ 8 <https://appeariq.com>`_ platform.\n\n\nExample: Changing the password of a user\n----------------------------------------\n.. code-block:: pycon\n\n    admin@wapr/default> set_organization('games')\n    admin@wapr/games> user = get(['admin', 'users'], username='stephen.falken')[0]\n    admin@wapr/games> user['password'] = 'joshua'\n    admin@wapr/games> updated = put(['admin', 'users'], user)\n\nDependencies\n------------\naiqterminal uses `aiqpy <https://pypi.python.org/pypi/aiqpy>`_ for performing HTTP requests.\n\nLicense\n-------\naiqterminal is licensed under GNU GPL v3.0.\n",
        "url": "http://pypi.python.org/pypi/aiqterminal",
        "summary": "Interactive shell for administrating a AIQ8 platform server",
        "command": "pip install 'aiqterminal'"
      },
      "airavata": {
        "name": "airavata",
        "description": "Django Airavata\r\n===============\r\n\r\nAiravata is a mythological white elephant who carries the Hindu god\r\nIndra. Airavata has four tusks and seven trunks and is spotless white.\r\n`source on Wikipedia <https://en.wikipedia.org/wiki/Airavata>`__.\r\n\r\nAiravata is also a Django 1.8+ library that allows you to hosts multiple\r\ndynamic sites running on a single Django instance/db.\r\n\r\nSee source https://bitbucket.org/levit_scs/airavata or  documentation on\r\n`ReadTheDocs <http://django-polla.readthedocs.org/en/latest/>`__",
        "url": "http://pypi.python.org/pypi/airavata",
        "summary": "Multiple dynamic sistes with Django",
        "command": "pip install 'airavata'"
      },
      "airbnb": {
        "name": "airbnb",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/airbnb",
        "summary": "A wrapper for airbnb.com API",
        "command": "pip install 'airbnb'"
      },
      "airbrake": {
        "name": "airbrake",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/airbrake",
        "summary": "Airbrake API implementation",
        "command": "pip install 'airbrake'"
      },
      "airbrake-flask": {
        "name": "airbrake-flask",
        "description": "airbrake-flask is a fast library that use the amazing requests library to send\nerror, exception messages to airbrake.io. You can use this library with the\namazing gevent library to send your request asynchronously.\n\nExample Usage with gevent\n-------------------------\nfrom flask import Flask, request, got_request_exception\nfrom airbrake.airbrake import AirbrakeErrorHandler\nimport gevent\nimport sys\n\napp = Flask(__name__)\nENV = ('ENV' in os.environ and os.environ['ENV']) or 'prod'\n\ndef log_exception(error):\n    handler = AirbrakeErrorHandler(api_key=\"PUT_YOUR_AIRBRAKE_KEY_HERE\",\n            env_name=ENV, request=request)\n    gevent.spawn(handler.emit, error, sys.exc_info())\n\ngot_request_exception.connect(log_exception, app)\n\nContribute\n----------\nThis library is hosted on Github and you can contribute there:\nhttp://github.com/kienpham2000/airbrake-flask",
        "url": "http://pypi.python.org/pypi/airbrake-flask",
        "summary": "airbrake-flask - Airbrake client for Python Flask",
        "command": "pip install 'airbrake-flask'"
      },
      "AirbrakePy": {
        "name": "airbrakepy",
        "description": "Pulse Energy AirbrakePy\n==========================\nAirbrakePy provides a logging.Handler implementation that can be configured to alert Airbrake (http://airbrakeapp.com).\n\n(c) 2012 Pulse Energy, Inc.",
        "url": "http://pypi.python.org/pypi/AirbrakePy",
        "summary": "Airbrake notifier for Python logging framework",
        "command": "pip install 'AirbrakePy'"
      },
      "airbrake-tornado": {
        "name": "airbrake-tornado",
        "description": "# airbrake-tornado\n\nAirbrake notifier for Tornado web framework.\n\n## Installation\n\nInstall via pip:\n\n    pip install airbrake-tornado\n\n## Usage\n\n```python\n  from airbrake import airbrake\n\n  # In your RequestHandler:\n\n  API_KEY = \"Airbrake API key\"\n  ENV_NAME = \"Airbrake env name\"\n\n  def write_error(self, status_code, **kwargs):\n      if exc_info and status_code == 500:\n          airbrake.notify(kwargs[\"exc_info\"],\n                          self.request,\n                          \"My-cool-app\",\n                          api_key=self.API_KEY,\n                          environment=self.ENV_NAME)\n```\n\n\n## License\n\nairbrake-tornado is available under the MIT license. See the [LICENSE](LICENSE) file for more info.",
        "url": "http://pypi.python.org/pypi/airbrake-tornado",
        "summary": "Airbrake notifier for Tornado web framework.",
        "command": "pip install 'airbrake-tornado'"
      },
      "airbrite": {
        "name": "airbrite",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/airbrite",
        "summary": "Airbrite python bindings",
        "command": "pip install 'airbrite'"
      },
      "aircable-library-op": {
        "name": "aircable-library-op",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aircable-library-op",
        "summary": "AIRcable libraries for BlueZ Development",
        "command": "pip install 'aircable-library-op'"
      },
      "aircraft": {
        "name": "aircraft",
        "description": "",
        "url": "http://pypi.python.org/pypi/aircraft",
        "summary": "",
        "command": "pip install 'aircraft'"
      },
      "aircv": {
        "name": "aircv",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aircv",
        "summary": "Image utils based on python-opencv2",
        "command": "pip install 'aircv'"
      },
      "airflow": {
        "name": "airflow",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/airflow",
        "summary": "Programmatically author, schedule and monitor data pipelines",
        "command": "pip install 'airflow'"
      },
      "airflow_plugin_honeypot": {
        "name": "airflow_plugin_honeypot",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/airflow_plugin_honeypot",
        "summary": "Airflow plugin that captures, parses, and visualizes Hive log files",
        "command": "pip install 'airflow_plugin_honeypot'"
      },
      "airframe": {
        "name": "airframe",
        "description": "AirFrame\n===============================\n\n.. image:: https://badge.fury.io/py/airframe.png\n    :target: http://badge.fury.io/py/airframe\n    \n.. image:: https://pypip.in/d/airframe/badge.png\n        :target: https://crate.io/packages/airframe?version=latest\n\nDownload images from an authenticated Flickr account (or local filesystem) and \npush them wirelessly to a Toshiba FlashAir Wifi SD card mounted in a digital \nphoto frame.\n\n* Free software: ASL2 license\n* Documentation: http://documentup.com/virantha/airframe\n* Source: http://github.com/virantha/airframe\n* API docs: http://virantha.github.com/airframe/html\n\nFeatures\n--------\n\n* Authenticates to Flickr to get your private photos\n* Only downloads photos with specified tags\n* Alternativly, can sync files from a local directory\n* Caches and syncs the photos to the Wifi SD card\n\n\nInstallation\n------------\n\n.. code-block:: bash\n\n   $ pip install airframe\n\nUsage\n-----\n\nFirst, go to Flickr and get a private key at http://www.flickr.com/services/api/misc.api_keys.html\n\nThen, create a directory from where you will start airframe, and create a file called flickr_api.yaml:\n\n.. code-block:: yaml\n\n    key: \"YOUR_API_KEY\"\n    secret: \"YOUR_API_SECRET\"\n\nThen, setup your FlashAir card as described in `this post's\n<http://virantha.com/2014/01/09/hacking-together-a-wifi-photo-frame-with-a-toshiba-flashair-sd-card-wireless-photo-uploads>`__\n\"Enabling the FlashAir\" section.  \n\nNow, you're ready to sync some photos!  Just run:\n\n.. code-block:: bash\n\n   $ airframe -n 100 -t photoframe YOUR_AIRFRAME_IP\n\nThis will download and sync the 100 most recent photos tagged with \"photoframe\" to your\nAirFrame. \n\n.. warning:: Any other image files in the FlashAir upload directory will be deleted, so make sure you backup anything you want to keep from your SD card.\n\nThe image files from Flickr will be cached in a sub-directory called\n``.airframe`` in the location you invoked airframe from, so as long as you rerun\nfrom the same directory, the script will only download new files from Flickr.  If you want to\nredownload all the files from scratch, just ``rm .airframe`` these files.\n\nThe script will also only upload new images to the FlashAir card, and ignore any files that are\nalready present on the card.  If you want to force a clean upload, do the following:\n\n.. code-block:: bash\n\n    $ airframe -n 100 -t photoframe -f YOUR_AIRFRAME_IP\n\nThis will delete all images already on the card, and upload every image again.\n\nAlternatively, you can sync files directly from your local computer by pointing\nthe script at a directory of ``.jpg`` files:\n\n.. code-block:: bash\n    $ airframe -l /path/to/photos YOUR_AIRFRAME_IP\n\nNote: other flags are ignored in this mode.\n\n\n.. :changelog:\n\nHistory\n-------\n\n0.1.0 (2014-01-10)\n++++++++++++++++++\n\n* First release on PyPI.\n\nTodo list\n=========\n- Add tests\n- Add docstrings\n- Travis integration\n- Use docopt instead of argparse\n- Better error handling",
        "url": "http://pypi.python.org/pypi/airframe",
        "summary": "Push images to a Toshiba FlashAir Wifi SD card",
        "command": "pip install 'airframe'"
      },
      "airgram": {
        "name": "airgram",
        "description": "##############\npython-airgram\n##############\n\nA python wrapper for making calls to the `Airgram API <http://www.airgramapp.com/api>`_, which enables you to send push notifications to your mobile devices.\n\nSince it is a very shallow wrapper, you can refer to the `official api reference <http://www.airgramapp.com/docs>`_ for details on the functions.\n\nExamples\n========\nAt the time of writing (2015-08-20) airgram is using wrong certificates (`see <https://api.airgramapp.com/1/>`_), which are intended for herokuapp.com. Because of this cert verification needs to be turned off.\n\nUsing as a guest\n----------------\n.. code-block:: python\n\n    from airgram import Airgram\n    \n    ag = Airgram(verify_certs=False)\n    \n    # Send a message to a user\n    ag.send_as_guest(\"your@email.com\", \"Test message from Airgram API\", \"http://example.com\")\n\n\nUsing with an authenticated airgram service\n-------------------------------------------\n.. code-block:: python\n\n    from airgram import Airgram\n    \n    ag = Airgram(key=\"MY_SERVICE_KEY\", secret=\"MY_SERVICE_SECRET\", verify_certs=False)\n    \n    # Subscribe an email to the service\n    ag.subscribe(\"your@email.com\")\n    \n    # Send a message to a subscriber\n    ag.send(\"your@email.com\", \"Hello, how are you?\")\n    \n    # Send a message to ALL subscribers\n    ag.broadcast(\"Airgram for python is awesome\", url=\"https://github.com/the01/python-airgram\")\n\n\n.. :changelog:\n\nHistory\n=======\n\n0.1.3 (2015-08-25)\n------------------\n\nBugFix\n\n* added MANIFEST.in (fix install problem)\n\n\n0.1.2 (2015-08-21)\n------------------\n\nBugFix\n\n* Correct wrong api url\n\n\n0.1.1 (2015-08-21)\n------------------\n\n* Add module logger\n* Add class logger\n* Functions throw AirgramException on failure\n\n\n0.1.0 (2015-07-30)\n------------------\n\n* First release on PyPI.",
        "url": "http://pypi.python.org/pypi/airgram",
        "summary": "Wrapper for the airgram api",
        "command": "pip install 'airgram'"
      },
      "airi": {
        "name": "airi",
        "description": "AIRi is a twisted base Bluetooth service + web server that allows to configure,\ncontrol and watch AIRcable's AIRi cameras, and AIRcable's OptiEyes cameras as \nwell.",
        "url": "http://pypi.python.org/pypi/airi",
        "summary": "AIRi software package",
        "command": "pip install 'airi'"
      },
      "airlock": {
        "name": "airlock",
        "description": "# airlock\n\nAirlock is a lightweight, web-security-concious wrapper for *webapp2* on\nGoogle App Engine. It provides oauth2 integration for identity management\nwith Google Accounts, sessions, and user management.\n\n## Comparison\n\nAirlock is a drop-in replacement for several `webapp2` and `protorpc`\nobjects. Specifically, it wraps `remote.Service`, `webapp2.WSGIApplication`,\nand `webapp2.RequestHandler` to provide authentication and session features\nvia oauth2 and the `oauth2client` library.\n\n| original | airlock variant |\n| -------- | --------------- |\n| `protorpc.remote.Service` | `airlock.Service` |\n| `webapp2.RequestHandler` | `airlock.Handler` |\n| `webapp2.WSGIApplication` | `airlock.WSGIApplication` |\n\n## User features\n\n* Oauth2 integration with Google Accounts (sign in and sign out).\n* Anonymous user/session support.\n\n## Security features\n\n* A standard configuration format for specifying the security characteristics of an application.\n* Provides a framework for setting the following headers:\n  * Content security policy.\n  * HSTS policy.\n  * XSRF.\n\n## Usage\n\n1. Download client secrets.\n1. In appengine config, use airlock.set_config\n1. Use airlock's subclasses.\n1. Set up a `User` model.\n",
        "url": "http://pypi.python.org/pypi/airlock",
        "summary": "A lightweight wrapper providing Google OAuth2 integration, sessions, XSRF validators, and user management for App Engine apps.",
        "command": "pip install 'airlock'"
      },
      "airoscriptng": {
        "name": "airoscriptng",
        "description": "===============================\nAiroscript-ng\n===============================\n\n.. image:: https://travis-ci.org/XayOn/airoscriptng.png?branch=master\n        :target: https://travis-ci.org/XayOn/airoscriptng\n\n.. image:: https://pypip.in/download/airoscriptng/badge.png\n        :target: https://pypi.python.org/pypi/airoscriptng\n        \n.. image:: https://pypip.in/v/airoscriptng/badge.png\n        :target: https://pypi.python.org/pypi/airoscriptng\n\n\nAiroscript-ng python complete implementation\n\n* Free software: GNU GENERAL PUBLIC LICENSE 2\n* Documentation: http://airoscript-ng.readthedocs.org/en/master\n\nFeatures\n--------\n\n* Dynamic aircrack-ng API generation (under airoscriptng.aircrack)\n* Threaded execution\n* Hackability assesment\n* Scanning provides a list of best wireless hacking techniques\n* Session control (for better process control)\n* Wireless monitor interfaces are nicely handled and reused if neccesary\n* XMLRPC server implementation\n\nTODO\n-----\n\n* Better parameter parsing & format for aircrack-ng parameters file, read them from manpages\n* Implement attacks on airoscript-ng class\n* Implement cracking (and control of it, once cracked stop all attacks against that network)\n* Build a user interface (probably more than one)\n\n\n\n\nHistory\n-------\n\n0.0.2 (2015-08-01)\n-------------------\n\n* First usable thing, still no attacks\n* \"Hackability\" property for aps\n* Integrated clients on AP object\n* External plugin support\n* Reaver support\n* XMLRPC Working\n* General cleanup\n\n0.0.1 (2014-12-26)\n---------------------\n\n* First release, monitor mode and scanning working",
        "url": "http://pypi.python.org/pypi/airoscriptng",
        "summary": "Airoscript-ng python complete implementation",
        "command": "pip install 'airoscriptng'"
      },
      "airplane": {
        "name": "airplane",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/airplane",
        "summary": "A little statusbar for to allow switching into an airplane mode under OS X written in Python.",
        "command": "pip install 'airplane'"
      },
      "airpy": {
        "name": "airpy",
        "description": "AirPy: Documentation Installer for the Pythonic Soul\n====================================================\n\n.. image:: https://travis-ci.org/kevinaloys/airpy.svg\n\n.. image:: https://pypip.in/download/airpy/badge.svg?style=flat\n\nUsage\n-----\n\nInstallation::\n\n    $ pip install airpy\n    \nRun::\n\n    $ airpy\n    \n    Usage: airpy [OPTIONS] COMMAND [ARGS]...\n\n        AirPy : Documentation Installer for the Python\n\n    Options:\n        --help  Show this message and exit.\n\n    Commands:\n        autopilot  Auto install docs.\n        install    Install offline doc of a Python module.\n        list       List installed docs.\n        remove     Remove an installed doc.\n        start      Start a doc in a browser.\n\n\nInstall a Documentation::\n\n    $ airpy install requests\n\nStart the Documentation in a browser::\n    \n    $ airpy start requests\n\nRemove a Documentation::\n\n    $ airpy remove requests\n\nAirPy Autopilot : Install Documentation for Python packages already installed in your system.::\n\n    $ airpy autopilot\n    $ airpy list\n      flask   requests   django   sphinx   wheel   setuptools\n\n",
        "url": "http://pypi.python.org/pypi/airpy",
        "summary": "Documentation Installer for the Pythonic Soul",
        "command": "pip install 'airpy'"
      },
      "airsea": {
        "name": "airsea",
        "description": "python-airsea\n=============\n\n.. image:: https://badge.fury.io/py/airsea.png\n   :target: http://badge.fury.io/py/airsea\n   :alt: Latest version\n.. image:: https://api.travis-ci.org/ocefpaf/python-airsea.png?branch=master\n   :target: https://travis-ci.org/ocefpaf/python-airsea\n   :alt: Travs-CI\n.. image:: http://bottlepy.org/docs/dev/_static/Gittip.png\n   :target: https://www.gittip.com/ocefpaf/\n   :alt: Gittip\n\nThis module is a translation of the original AIRSEA-2.0 MATLAB toolbox\nroutines for calculating the properties of airsea fluxes.",
        "url": "http://pypi.python.org/pypi/airsea",
        "summary": "AirSea Libray for Python",
        "command": "pip install 'airsea'"
      },
      "airship": {
        "name": "airship",
        "description": "Airship allows users to synchronize saved games between cloud platforms. Requires subpackages for each cloud service; for example, install airship-steamcloud and airship-icloud to sync between these two services.",
        "url": "http://pypi.python.org/pypi/airship",
        "summary": "A tool to synchronize game saves between clouds",
        "command": "pip install 'airship'"
      },
      "airship-icloud": {
        "name": "airship-icloud",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/airship-icloud",
        "summary": "iCloud plugin for Airship",
        "command": "pip install 'airship-icloud'"
      },
      "airship-steamcloud": {
        "name": "airship-steamcloud",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/airship-steamcloud",
        "summary": "Steam Cloud plugin for Airship",
        "command": "pip install 'airship-steamcloud'"
      },
      "airspeed": {
        "name": "airspeed",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/airspeed",
        "summary": "Airspeed is a powerful and easy-to-use templating engine for Python that aims for a high level of compatibility with the popular Velocity library for Java.",
        "command": "pip install 'airspeed'"
      },
      "airstream": {
        "name": "airstream",
        "description": "",
        "url": "http://pypi.python.org/pypi/airstream",
        "summary": "",
        "command": "pip install 'airstream'"
      },
      "AirStrip": {
        "name": "airstrip",
        "description": "AirStrip.js\n=============\n\nAbout\n-------------\n\nThis project is meant to ease dealing with third-party javascript dependencies in ambitious client-side web projects.\n\nConceptually, Airstrip has similarities with Twitter's Bower, and npm component (https://npmjs.org/package/component).\n\nFor the impatients\n-------------\n\nRead.\n\n\nProblem\n-------------\n\nModern javascript projects usually depend on numerous third-party libraries and frameworks \n(say: requirejs, handlebars, i18n, emberjs, jasmine).\n\nPicking these, building, minifying, tracking versions, possibly patching or forking them, maintaining dependencies, then integrating into a project can quickly become borringly repetitive and tedious.\n\nSolution\n-------------\n\nThe idea here is to help do that, by providing tools to quickly assemble dependencies from numerous, widely used libraries, build them uniformly, list various versions, then \"dispatching\" the results in a build directory to be then used by said projects - and obviously tools that help you do that for your own libraries.\n\n\nInstallation\n-------------\n\n`pip install airstrip`\n`pip install airstrip --upgrade`\n\n\nAPI\n-------------\n\nOnce the airstrip binary has been installed, you should cd to your project root source folder and may use the following commands.\n\n\nCommand:\n```airstrip show ember```\n\nResult:\n  Details about EmberJS, and list of available versions\n\n\nCommand:\n```airstrip require emberjs```\n\nResult:\n  Add emberjs (in version \"master\") to your project dependencies. This will create or update the project \"airfile.json\" listing said dependencies.\n\nCommand:\n```airstrip require emberjs SOMEVERSION```\n\nResult:\n  Same as above, but explicitely require a specific version. The \"master\" version (eg: trunk) keywords should always exist for any library.\n  Multiple different versions of the same library can be required.\n  Note that requiring a project that depends on other projects will require them as well, in the recommended version (XXX, not done yet).\n\nCommand:\n```airstrip remove emberjs```\n```airstrip remove emberjs SOMEVERSION```\n\nResult:\n  Will remove the library from the project dependencies list, if present (possibly in the specified version).\n\n\nCommand:\n```airstrip require```\n\nResult:\n  List currently required libraries for your project, along with versions.\n\nCommand:\n```airstrip build```\n\nResult:\n  Build all required libraries for your project, and output them into a \"dependencies\" folder.\n\nCommand:\n```airstrip build ember```\n\nResult:\n  Build, or rebuild only the specified library (that you requested).\n\n\nCommand:\n```airstrip use```\n\nResult:\n  List configuration flags, possibly with their default value if overriden.\n\n\nCommand:\n```airstrip use key value```\n\nResult:\n  Locally (to your project) override a specific configuration key.\n\n\n\nAPI: risky, untested, undocumented, internal\n-------------\n\nCommand:\n```airstrip seed```\n\nResult:\n  Initialize a new project inside the current working directory, by adding a number of convenient boilerplates files.\n\n\nCommand:\n```airstrip init owner repository```\n\nResult:\n  Initialize (or update) a formula from a project on github (\"repository\") whose owner is \"owner\". Will fetch tags and stuff like that.\n\n\nCommand:\n```airstrip edit somelibrary```\n\nResult:\n  Edit an existing or create a new empty \"formula\" for a given library, locally to your project so you can add new library (XXX untested).\n\nCommand:\n```airstrip edit somelibrary true```\n\nResult:\n  Edit an existing or create a new empty \"formula\" for a given library, globally for airstrip (XXX untested and not recommended).\n\n\n\nLicense\n-------------\n\nMIT.",
        "url": "http://pypi.python.org/pypi/AirStrip",
        "summary": "Third-party js dependencies manager",
        "command": "pip install 'AirStrip'"
      },
      "airtest": {
        "name": "airtest",
        "description": "Airtest\n=====\nPython lib for **android** and **ios** app test.\n\n在线文档 <http://netease.github.io/airtest>\n\n作为在线文档的一个补充，有个pydoc生成的API列表可以作为参考\n <http://netease.github.io/airtest/airtest.devsuit.html>\n\n离线文档使用方法：\n\n\tgit clone https://github.com/netease/airtest && cd airtest\n\tgem install jekyll\n\tgit checkout gh-pages\n\tjekyll serve --baseurl=''\n\n## 如何给给该项目贡献\n因为刚项目常常更新，所以可能会有一些没有测试到的bug。\n\n可以在发现了问题后，提个issue给作者。 另外一些新的思路也可以提到issue中。\n\n## 相关的项目\n1. 实现了touch,swipe,pinch <https://github.com/netease/airinput>\n2. 基于opencv的图像识别库 <https://github.com/netease/aircv>\n\n## License\nThis project is under the MIT License. See the [LICENSE](LICENSE) file for the full license text.",
        "url": "http://pypi.python.org/pypi/airtest",
        "summary": "mobile test(black air) python lib",
        "command": "pip install 'airtest'"
      },
      "airtest_for_h9": {
        "name": "airtest_for_h9",
        "description": "#-*- coding: utf-8 -*-\n\n\nThis program is an extension of airtest for com.netease.H9.\n\nThanks to the authors for their great work.\n\nAbout airtest, Please refer to \"http://netease.github.io/airtest/overview/quick_start.html\"\nfor complete information and details .\n\n\nAuthor: zheng wen\nMail  : wenzheng@whu.edu.cn\nTime  : 2014年12月17日 11:59:28",
        "url": "http://pypi.python.org/pypi/airtest_for_h9",
        "summary": "mobile test(black air) python lib",
        "command": "pip install 'airtest_for_h9'"
      },
      "airwaveapiclient": {
        "name": "airwaveapiclient",
        "description": "===================================================\nairwaveapiclient\n===================================================\n\nAirwaveapiclient is a utility tool for Aruba Networks AirWave users.\nThis module connects to AirWave and gets the information such as the access point list,\ndetail, client, etc.\n\n.. image:: https://secure.travis-ci.org/mtoshi/airwaveapiclient.svg?branch=master\n   :target: http://travis-ci.org/mtoshi/airwaveapiclient\n.. image:: https://coveralls.io/repos/mtoshi/airwaveapiclient/badge.svg?branch=master&service=github\n   :target: https://coveralls.io/github/mtoshi/airwaveapiclient?branch=master\n.. image:: https://img.shields.io/pypi/v/airwaveapiclient.svg\n   :target: https://pypi.python.org/pypi/airwaveapiclient\n   :alt: Latest Version\n.. image:: https://readthedocs.org/projects/airwaveapiclient/badge/?version=latest\n   :target: https://airwaveapiclient.readthedocs.org\n   :alt: Documentation Status\n\nRequirements\n============\n* Python2.7, 3.3, 3.4, PyPy.\n\nInstallation\n============\n* PyPI or Github ::\n\n   $ pip install airwaveapiclient\n\n   or\n\n   $ git clone https://github.com/mtoshi/airwaveapiclient\n   $ cd airwaveapiclient\n   $ sudo python setup.py install\n\n\nUsing example\n=============\n* Documentation: Readthedocs_\n    .. _Readthedocs: https://airwaveapiclient.readthedocs.org\n\n* Sample code: Github_\n    .. _Github: https://github.com/mtoshi/airwaveapiclient/blob/master/samples/sample.py\n\n* Login ::\n\n    >>> airwave = AirWaveAPIClient(username='admin',\n    ...                            password='*****',\n    ...                            url='https://192.168.1.1')\n    >>> airwave.login()\n\n\n* Get Access Point List ::\n\n    >>> res = airwave.ap_list()\n    >>> res.status_code\n    200\n    >>> res.text # xml output\n    '<?xml version=\"1.0\" encoding=\"utf-8\" ...'\n\n\n* Get Access Point Detail ::\n\n    >>> ap_id = 1\n    >>> res = airwave.ap_detail(ap_id)\n    >>> res.status_code\n    200\n    >>> res.text # xml output\n    '<?xml version=\"1.0\" encoding=\"utf-8\" ...'\n\n\n* Logout ::\n\n    >>> airwave.logout()\n\n\nSee also\n========\n* http://www.arubanetworks.com/products/networking/network-management/",
        "url": "http://pypi.python.org/pypi/airwaveapiclient",
        "summary": "Aruba Networks AirWave API Client.",
        "command": "pip install 'airwaveapiclient'"
      },
      "airy": {
        "name": "airy",
        "description": "==============================\nAiry Web Application Framework\n==============================\n\nAiry is a new Web application development framework.\n\nContrast to most currently available frameworks, Airy\ndoesn't use the standard notion of HTTP requests and pages.\n\nInstead, it makes use of WebSockets (via Socket.io) and\nprovides a set of tools to let you focus on the interface,\nnot content delivery.\n\nCurrently Airy supports MongoDB only. We will support other\nNoSQL databases, but we have no plans for supporting SQL.\n\n\nRequirements\n============\n\nAiry will install most required modules itself when you create a new\nproject, so all you need is:\n\n* Python 2.6+\n* MongoDB\n\n\nInstallation\n============\n\n    pip install airy\n\nThis will install Airy itself and the ``airy-admin.py`` script.\n\n\nUsage\n=====\n\nOnce you have it installed, you should be able to use ``airy-admin.py``\n\nTo create a new project, open a terminal and do::\n\n    airy-admin.py startproject project_name\n    cd project_name/\n    python manage.py update_ve\n    python manage.py runserver\n\nYou should have it running locally on port 8000. Open your browser\nand navigate to http://localhost:8000\n\nNote: if it complains about a \"Connection Error\" it means you have\nno MongoDB running, or it's dead.\n\n\nAbout\n=====\n\nAiry is created by Leto, a startup agency based in London, UK.\nCheck out Leto website for help and support: http://letolab.com",
        "url": "http://pypi.python.org/pypi/airy",
        "summary": "Web Application Framework",
        "command": "pip install 'airy'"
      },
      "airypi": {
        "name": "airypi",
        "description": "Information on how to use this library can be found <a href=\"https://www.airypi.com/docs/\">here</a>",
        "url": "http://pypi.python.org/pypi/airypi",
        "summary": "The server libraries for airypi",
        "command": "pip install 'airypi'"
      },
      "airypi-rpi": {
        "name": "airypi-rpi",
        "description": "Information on how to use this library can be found <a href=\"https://www.airypi.com/docs/\">here</a>",
        "url": "http://pypi.python.org/pypi/airypi-rpi",
        "summary": "The airypi client for Raspberry Pi",
        "command": "pip install 'airypi-rpi'"
      },
      "Aito": {
        "name": "aito",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Aito",
        "summary": "Ultra-lightweight test suite focused on REST API end-to-end tests.",
        "command": "pip install 'Aito'"
      },
      "aj": {
        "name": "aj",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aj",
        "summary": "Web UI base toolkit",
        "command": "pip install 'aj'"
      },
      "aja": {
        "name": "aja",
        "description": "Aja\n===\n\n.. image:: https://secure.travis-ci.org/pingviini/aja.png\n   :target: http://travis-ci.org/pingviini/aja\n\nAja provides Fabric_ tasks for deploying buildouts_ from staging server to\nremote production servers:\n\n* it assumes buildout with absolute path (this is the buildout default)\n\n* it assumes that all the relevant paths (python, buildout, shared eggs, etc)\n  are identical for the staging and production servers\n\n* bootstrap and buildout are always run on the staging server only\n\n* buildout is deployed by pushing its bin-, parts- and (local or shared)\n  eggs-directories into the remote production server using rsync\n\n.. _buildout: https://pypi.python.org/pypi/zc.buildout\n.. _buildouts: https://pypi.python.org/pypi/zc.buildout\n.. _Fabric: https://pypi.python.org/pypi/Fabric\n\n\nInstallation\n------------\n\nAja can be installed like any Python package:\n\n.. code:: bash\n\n   $ pip install aja\n\nBut be aware that Aja comes with the following dependencies\n\n* Fabric\n* paramiko\n* zc.buildout\n* setuptools\n* ecdsa\n* pycrypto\n\nand therefore, it's recommended to use a dedicated virtualenv.\n\nAja doesn't have it's own executable, but is executed using Fabric's ``fab``\ncommand. Of course, it is possible to symlink that as ``aja``.\n\n\nConfiguration\n-------------\n\nAja is configured with a fabfile, e.g. ``fabfile.py``:\n\n.. code:: python\n\n   import fabric.api\n   fabric.api.env.update({\n       'buildout_directory_prefix': '',  # optional\n       'buildout_extends_prefix': '',    # optional\n   })\n   from aja.tasks import *\n\n\n``buildout_directory_prefix`` provides optional convenience when creating new\nbuildouts or when looking for buildouts for the other commands.\n\n``buildout_extends_prefix`` provides optional convenience when creating new\nbuildout.\n\n\nUsage\n-----\n\nAja maps Fabric's hosts into buildouts so that for each buildout, it fills\n``fabric.api.env`` with variables from ``[aja]`` part in the buildout (this is\nquite similar to `collective.hostout`_). The rest of the resolved buildout file\ncan be found at ``fabric.api.env.buildout``.\n\n.. _collective.hostout: https://pypi.python.org/pypi/collective.hostout\n\nAn example ``[aja]`` part could look like:\n\n.. code:: ini\n\n   [aja]\n   executable = /usr/local/python/bin/python\n   host_string = buildout@production\n   key_filename = /home/buildout/.ssh/id_rsa\n\nThis part would configure Aja tasks to use particular Python virtualenv for\nrunning the buildout\nand\npush the results into server ``production`` by performing rsync using the\ngiven key file.\n\nExample Aja usage could look like:\n\n.. code:: bash\n\n   $ fab create:/var/buildout/plone,/vagrant/plone-4.3.cfg\n   $ fab -H /var/buildout/plone buildout push\n\nAnd with the following convenience configuration in fabfile:\n\n.. code:: python\n\n   import fabric.api\n   fabric.api.env.update({\n       'buildout_directory_prefix': '/var/buildout',\n       'buildout_extends_prefix': '/vagrant',\n   })\n   from aja.tasks import *\n\nThe previous example usage could look like:\n\n.. code:: bash\n\n   $ fab create:plone,plone-4.3.cfg\n   $ fab -H plone buildout push\n\n.. note::\n\n   ``buildout_extends_prefix`` can also be an URL like\n   ``http://myserver/buildouts/``\n\n\nExtending\n---------\n\nAja provides only the most basic fabric tasks, but it provides a custom\ntask class ``aja.tasks.AjaTask``, which provides resolved buildout\nat ``fabric.api.env.buildout``. This makes it easy to define custom tasks\nin your fabfile, e.g.\n\n.. code:: python\n\n   from fabric import api\n   from fabric.operations import run\n   from aja.tasks import AjaTask\n\n   @task(task_class=AjaTask)\n   def purge():\n       buildout_bin = api.env.buildout['buildout'].get('bin-directory')\n       buildout_parts = api.env.buildout['buildout'].get('parts-directory')\n       run('rm -rf {0:s}'.format(buildout_bin))\n       run('rm -rf {0:s}'.format(buildout_parts))\n   purge.__doc__ = \\\n       \"\"\"Clean bin- and parts-directories (e.g. before push)\n       \"\"\"\n\nChangelog\n=========\n\n0.9.0 (2015-01-14)\n------------------\n\n- First release.",
        "url": "http://pypi.python.org/pypi/aja",
        "summary": "Buildout-based deployment made safe and easy",
        "command": "pip install 'aja'"
      },
      "ajax": {
        "name": "ajax",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ajax",
        "summary": "A simple framework for creating AJAX endpoints in Django.",
        "command": "pip install 'ajax'"
      },
      "ajaxfeed": {
        "name": "ajaxfeed",
        "description": "\\This library provide access to Google Ajax Feed API\nwith similar structure and naming convention as if an extension to GData Python\nClient Library.",
        "url": "http://pypi.python.org/pypi/ajaxfeed",
        "summary": "Python client library for Google Ajax Feed APIs",
        "command": "pip install 'ajaxfeed'"
      },
      "ajaxuploader": {
        "name": "ajaxuploader",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ajaxuploader",
        "summary": "AJAX file uploader for django",
        "command": "pip install 'ajaxuploader'"
      },
      "ajcli": {
        "name": "ajcli",
        "description": "=======\najcli\n=======\n\nexample usage::\n\n    $ jiracli --host \"$JIRA_SERVER\" -u \"$USER\" -p \"$PASSWORD\" projects\n    $ jiracli --host \"$JIRA_SERVER\" -p \"$PASSWORD\" worklogs project=\"$KEY\" and sprint=2\n    $ jiracli --host \"$JIRA_SERVER\" -u \"$USER\" worklogs --user \"Foo Bar\" sprint=2 or sprint=3\n    $ jiracli --host \"$JIRA_SERVER\" issues project=\"$KEY\" and type=story or type=issue\n    $ jiracli --host \"$JIRA_SERVER\" users \"$PROJECT_ID\"",
        "url": "http://pypi.python.org/pypi/ajcli",
        "summary": "another jira interface including cli",
        "command": "pip install 'ajcli'"
      },
      "AJDecimalMathAdditions": {
        "name": "ajdecimalmathadditions",
        "description": "",
        "url": "http://pypi.python.org/pypi/AJDecimalMathAdditions",
        "summary": "This Decimal math library will add additional trig and math functions to the decimal.py module in python.",
        "command": "pip install 'AJDecimalMathAdditions'"
      },
      "ajenti": {
        "name": "ajenti",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ajenti",
        "summary": "The server administration panel",
        "command": "pip install 'ajenti'"
      },
      "ajenti-dev-multitool": {
        "name": "ajenti-dev-multitool",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ajenti-dev-multitool",
        "summary": "-",
        "command": "pip install 'ajenti-dev-multitool'"
      },
      "ajenti-panel": {
        "name": "ajenti-panel",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ajenti-panel",
        "summary": "Ajenti core based panel",
        "command": "pip install 'ajenti-panel'"
      },
      "ajenti.plugin.ace": {
        "name": "ajenti.plugin.ace",
        "description": "A Ace editor plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.ace",
        "summary": "Ace editor",
        "command": "pip install 'ajenti.plugin.ace'"
      },
      "ajenti.plugin.augeas": {
        "name": "ajenti.plugin.augeas",
        "description": "A Augeas API plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.augeas",
        "summary": "Augeas API",
        "command": "pip install 'ajenti.plugin.augeas'"
      },
      "ajenti.plugin.auth-users": {
        "name": "ajenti.plugin.auth-users",
        "description": "A Custom users authentication plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.auth-users",
        "summary": "Custom users authentication",
        "command": "pip install 'ajenti.plugin.auth-users'"
      },
      "ajenti.plugin.core": {
        "name": "ajenti.plugin.core",
        "description": "A Core plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.core",
        "summary": "Core",
        "command": "pip install 'ajenti.plugin.core'"
      },
      "ajenti.plugin.dashboard": {
        "name": "ajenti.plugin.dashboard",
        "description": "A Dashboard plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.dashboard",
        "summary": "Dashboard",
        "command": "pip install 'ajenti.plugin.dashboard'"
      },
      "ajenti.plugin.datetime": {
        "name": "ajenti.plugin.datetime",
        "description": "A Date & time plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.datetime",
        "summary": "Date & time",
        "command": "pip install 'ajenti.plugin.datetime'"
      },
      "ajenti.plugin.filemanager": {
        "name": "ajenti.plugin.filemanager",
        "description": "A File Manager plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.filemanager",
        "summary": "File Manager",
        "command": "pip install 'ajenti.plugin.filemanager'"
      },
      "ajenti.plugin.filesystem": {
        "name": "ajenti.plugin.filesystem",
        "description": "A Filesystem API plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.filesystem",
        "summary": "Filesystem API",
        "command": "pip install 'ajenti.plugin.filesystem'"
      },
      "ajenti.plugin.network": {
        "name": "ajenti.plugin.network",
        "description": "A Network plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.network",
        "summary": "Network",
        "command": "pip install 'ajenti.plugin.network'"
      },
      "ajenti.plugin.notepad": {
        "name": "ajenti.plugin.notepad",
        "description": "A Notepad plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.notepad",
        "summary": "Notepad",
        "command": "pip install 'ajenti.plugin.notepad'"
      },
      "ajenti.plugin.packages": {
        "name": "ajenti.plugin.packages",
        "description": "A Packages plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.packages",
        "summary": "Packages",
        "command": "pip install 'ajenti.plugin.packages'"
      },
      "ajenti.plugin.passwd": {
        "name": "ajenti.plugin.passwd",
        "description": "A User DB API plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.passwd",
        "summary": "User DB API",
        "command": "pip install 'ajenti.plugin.passwd'"
      },
      "ajenti.plugin.plugins": {
        "name": "ajenti.plugin.plugins",
        "description": "A Plugins plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.plugins",
        "summary": "Plugins",
        "command": "pip install 'ajenti.plugin.plugins'"
      },
      "ajenti.plugin.power": {
        "name": "ajenti.plugin.power",
        "description": "A Power management plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.power",
        "summary": "Power management",
        "command": "pip install 'ajenti.plugin.power'"
      },
      "ajenti.plugin.services": {
        "name": "ajenti.plugin.services",
        "description": "A Services plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.services",
        "summary": "Services",
        "command": "pip install 'ajenti.plugin.services'"
      },
      "ajenti.plugin.settings": {
        "name": "ajenti.plugin.settings",
        "description": "A Settings plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.settings",
        "summary": "Settings",
        "command": "pip install 'ajenti.plugin.settings'"
      },
      "ajenti.plugin.supervisor": {
        "name": "ajenti.plugin.supervisor",
        "description": "A Supervisor plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.supervisor",
        "summary": "Supervisor",
        "command": "pip install 'ajenti.plugin.supervisor'"
      },
      "ajenti.plugin.terminal": {
        "name": "ajenti.plugin.terminal",
        "description": "A Terminal plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.terminal",
        "summary": "Terminal",
        "command": "pip install 'ajenti.plugin.terminal'"
      },
      "ajenti.plugin.traffic": {
        "name": "ajenti.plugin.traffic",
        "description": "A Traffic Widget plugin for Ajenti panel",
        "url": "http://pypi.python.org/pypi/ajenti.plugin.traffic",
        "summary": "Traffic Widget",
        "command": "pip install 'ajenti.plugin.traffic'"
      },
      "ajgu": {
        "name": "ajgu",
        "description": "=====================\n Ajgu Graph Database\n=====================\n\n**This program is alpha**\n\n(but you can use it, and report bugs and wishes)\n\n\nKesako?!\n========\n\nAjgu is graph database with several backends. It's meant to be an easy to use, just works persistent property graph for people that want to experiment with graph databases. Hopefully, SQLite for graphs.\n\nThe supported backends are:\n\n- Oracle Berkeley Database (also know as sleepycat database, bsddb or simply db)\n- File based\n\nDevelopment happens @ https://git.framasoft.org/python-graphiti-love-story/AjguGraphDB\n\nChangeLog\n=========\n\n15.07.30\n--------\n\nAdd property indices. Only `str` and `int` can be indexed. To index a property you must register the property name with `graph.index(name)`. This will index properties that have this for both `Edge` and `Vertex` so becarful how you name properties. Then you can use `txn.element.filter(name=value)` where `element` is as usual `edge` or `vertex` to retrieve the interesting elements. Have a look at movielens example for example usage.\n\n15.07.11\n--------\n\n- Major fix in `NoTxnBSDDB3`. Now it's really a ACID less (transaction-less) backend.\n\n\n15.06.25\n--------\n\n- add syncless transaction with `sync=False` in BSDDB3 storage\n- add movielens latest small load script\n- improve http frontend and move it inside ajgu code\n- add documentation in docs directory using mkdocs\n\n\n15.06.21\n--------\n\n- ajgu: storage: Add File based backend\n- ajgu: storage: Add Transaction less bsddb3 backend\n- examples: Add conceptnet load script\n- examples: Add mini microblog app\n\n15.06.15\n--------\n\nImportant changes:\n\n- Several API changes\n- Transaction support was fully broken, please upgrade if you require transactions.\n\nDetails:\n\n- move to unittest.TestCase\n- use ``uuid4`` for identifier generation\n- move ``Element``, ``Vertex`` and ``Edge`` class to ``elements.py`` module\n- rework to implement ``Storage`` based backend to make future work on multiple backends easier\n- rework ``Element.properties()`` now it's ``Element.properties`` and ``Element.props`` with new API (with tests)\n- implement ``Transaction.edge`` & ``Transaction.vertex`` API via manager classes (cf. manager.py). Same API as before but element specific. Now you create a vertex with ``txn.vertex.create('software')``, and retrieve an edge with ``txn.edge.get(ajgu_depends_bsddb)``.\n- add ``txn.*.slice``\n- index elements by labels to speed up ``txn.*.label`` queries.\n- several cleanups, removed old index/query code (``uzelmumu`` module still works)\n- fix pypi example to work with new API\n\n15.06.10\n--------\n\n- add example app\n- better error when magic keys is used but fails\n- fix bug where edge and vertex weren't not saved\n- fix import error in tests\n\nGetting started\n===============\n\nDependencies:\n\n- python3\n- bsddb3\n- msgpack\n\nbsddb3 must be installed on you system. Dependending on the distribution it's called ``db`` or ``bdb``. If you have a ``python3-bsddb3`` package use that one.\n\nYou can use ``python setup.py develop`` or ``pip install ajgu`` but you will need python 3 and bsddb headers.\n\nContact\n=======\n\nFeel free to contact me at ``amirouche+dev@hypermove.net`` if you need suppport or want to discuss matters related to graph databases.\n\n\nFAQ\n===\n\n#. **What ajgu means?**\n   \n   *ajgu* is a beam used in house construction in amazigh language.\n\n#. **Why not use SQLite instead of bsddb3?**\n\n   People say sqlite and relationnal database are not meant to store graph data. I believe them. Also\n   key/value stores offer the necessary flexibility to store many kinds of data.\n   \n#. **Where can I find a graph server with multi *thread* and *python querying*?**\n   \n   `GraphitiDB <https://bitbucket.org/amirouche/java-graphitidb>`_ I never used it for the real. It's relying on old version of Tinkerpop.\n\n#. **Are GraphDBs useful beyond prototyping?**\n   \n   You tell me!\n\n#. **GraphDBs are awesome, where can I learn more?**\n   \n- https://groups.google.com/forum/#!forum/gremlin-users\n- https://groups.google.com/forum/#!forum/neo4j\n- https://groups.google.com/forum/#!forum/aureliusgraphs\n- https://groups.google.com/forum/#!forum/mogwai-python\n- and ArangoDB, OrientDB...",
        "url": "http://pypi.python.org/pypi/ajgu",
        "summary": "Graph Database for everyday use",
        "command": "pip install 'ajgu'"
      },
      "AjguDB": {
        "name": "ajgudb",
        "description": "========\n AjguDB\n========\n\n**This program is alpha becarful**\n\n- graphdb\n- schemaless\n- single thread\n- transaction-less\n- LGPLv2.1 or later\n\nAjguDB wants to be a easy to use graph database for python to help during\ngraph exploration of data that does not fit in RAM and requires a graph API.\n\nIt support three backends LevelDB, WiredTiger and Oracle Berkeley Database.\n\nAjguDB index all fields for the better and the worst. The better\nbeing is that it's easy to use API. Make sure to only import the data you need\nand use something else to store fields you don't need to be indexed.\n\nYou might hit issues regarding encoding, there is I think no way to solve them\nonce on for all without moving to Python 3. \n\nRoadmap\n=======\n\nThe  0.5.x will remain the stable release for the time being. Work on the\n`develop branch <https://github.com/amirouche/AjguDB/tree/develop>`_ will\nbecome 0.7 when its time comes.\n\n\n0.7\n---\n\n- Python 3: missing wiredtiger bindings that works with python 3. my\n  `wiredtiger-ffi <https://github.com/amirouche/python-wiredtiger-ffi>`_ is buggy\n\n- Improve performance. ajgudb doesn't compete at all against sqlite \n  while loading stackexchange's superuser dump (5G), neither does it handle\n  well querying the data, probably because of \"index-all-the-thing\" feature.\n  The ``TupleSpace`` design is a nice but it's not the only tool required to build\n  a graph database that includes many kinds of data.\n\n- wiredtiger backend\n\n  Prelimanry benchmarks show that leveldb and bsddb does not perform as good on\n  batch insert 5G (superuser) and 50G (wikidata) and official benchmarks\n  says that it performs better on random read/write. So the plan is to move to\n  to wiredtiger only.\n\n\nOther stuff\n-----------\n  \n- Add support for wiredtiger transactions. Transactions can improve performance.\n- Add full-text search indices.\n- Add geographic indices.\n- Add Cassandra backend.\n    \n\nChangeLog\n=========\n\n0.5.1\n-----\n\n- ajgudb: when a vertex is deleted its edges must also be deleted\n- wiredtiger: when the table is empty avoid to crash\n- gremlin: add ``path(number_of_steps)`` step wich returns the current node\n  and its ancestors.\n\n\n0.5\n---\n\n- ajgudb\n\n  - add bsddb backend\n  - add wiredtiger backend\n  - leveldb: increase block size to 1GB\n\n- gremlin:\n\n  - add ``keys`` to retrieve several keys at the same time\n  - use lazy ``itertools.imap`` instead of the gready python2's ``map``\n\n\n0.4.2\n-----\n\n- ajgudb:\n\n  - add a shortcut method ``AjguDB.one(**kwargs)`` to query for one element.\n\n- gremlin:\n\n  - fix ``group_count``, now it's a step and not a *final step*\n  - fix ``each`` to return ``GremlinResult`` so that history is not lost\n    and ``back`` can be used\n  - add ``scatter``, it's only useful after ``group_count`` so far.\n\n- tools:\n\n  - add a converstion function ``ajgudb.tools.to_gt`` to convert the database to\n    `graph-tool <https://graph-tool.skewed.de/>`_ graph.\n  - there is also a function ``to_nx`` to convert the database to\n    `networkx <http://networkx.github.io/>`_\n\n\nAPI Reference\n=============\n\n``from ajgudb import AjguDB``\n\n\n``AjguDB(path)``\n----------------\nCreate or open a database at ``path``\n\n``AjguDB.close()``\n~~~~~~~~~~~~~~~~~~\nclose the database.\n\n``AjguDB.get(uid)``\n~~~~~~~~~~~~~~~~~~~\nRetrieve ``Vertex`` or ``Edge`` with ``uid`` as identifier.\n\n``AjguDB.vertex(**properties)``\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nCreate a new vertes with ``properties`` as initial properties.\n\n``AjguDB.get_or_create(**properties)``\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nGet or create ``Vertex`` with the provided ``properties``.\n\n``AjguDB.one(**properties)``\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nGet a vertex or edge that match the given ``properties`` or return `None`.\n\n``AjguDB.query(*steps)``\n~~~~~~~~~~~~~~~~~~~~~~~~\nCreate a query against this graph using gremlin `steps`. This returns a function\nthat can take an iterator, an edge, a vertex or nothing as arguments. It depends\nof the query.\n\nHere is an exemple query against movielens that takes a vertex as first argument:\n\n.. code::\n\n   query = db.query(incomings, filter(isgood), count)\n\nIf you want to know the number of good rating that a `movie` has received use\ncall `query` as follow:\n\n.. code::\n\n   good_rating_count = query(movie)\n\n\n``Vertex``\n----------\n\n``Vertex`` inherit the dictionary, so you can use ``dict`` method to access\nits properties as dictionary key.\n\n``Vertex.uid``\n~~~~~~~~~~~~~~\nReturn the ``Vertex`` unique identifier.\n\n``Vertex.incomings()``\n~~~~~~~~~~~~~~~~~~~~~~\nRetrieve incoming edges.\n\n``Vertex.outgoings()``\n~~~~~~~~~~~~~~~~~~~~~~\nRetrieve outgoing edges.\n\n``Vertex.save()``\n~~~~~~~~~~~~~~~~~\nIf the ``Vertex`` is mutated after creation you must save it.\n\n``Vertex.delete()``\n~~~~~~~~~~~~~~~~~~~\nDelete the ``Vertex`` object.\n\n``Vertex.link(other, **properties)``\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nCreate an ``Edge`` from the current ``Vertex`` to ``other`` with ``properties``.\n\n\n``Edge``\n--------\n\n``Edge`` inherit the dictionary, so you can use ``dict`` method to access\nits properties as dictionary keys.\n\n``Edge.start()'``\n~~~~~~~~~~~~~~~~~\nReturn the ``Edge`` starting ``Vertex``.\n\n``Edge.end()``\n~~~~~~~~~~~~~~\nReturn the ``Edge`` ending ``Vertex``.\n\n``Edge.save()``\n~~~~~~~~~~~~~~~\nIf the ``Edge`` is mutated after creation you must save it.\n\n``Edge.delete()``\n~~~~~~~~~~~~~~~~~\nDelete the ``Edge`` object.\n\n\n``gremlin``\n-----------\n\nThis where the magic happens. You can query the graph by composing steps. It is\nsimilar to tinkerpop's `Gremlin language <http://gremlindocs.spmallette.documentup.com>`_.\n\nThis are the functions that you have to use to query the graph using\n`AjguDB.query`.\n\nHere are the provided steps:\n\n- ``count``: count the number of items in the iterator.\n- ``incomings``: get incomings edges.\n- ``outgoings``: get outgoings edges.\n- ``both``: get both incomings and outgoings edges.\n- ``start``: get start vertex.\n- ``end``: get end vertex.\n- ``value``: get the ``dict`` of the value.\n- ``order(key=lambda x: x, reverse=False)``: order the iterator.\n- ``key(name)`` Get the value of ``name`` key.\n- ``key(*names)`` Get the values of keys in ``names``.\n- ``unique`` return an iterator with unique values.\n- ``select(**kwargs)`` return values matching ``kwargs``.\n- ``filter(predicate)`` return values satisfying ``predicate``.\n  ``predicate`` takes ``AjguDB`` and ``GremlinResult`` as arugments\n- ``each(proc)``: apply proc to very value in the iterator.\n  ``proc`` takes the ``AjguDB`` and ``GremlinResult`` as arugments.\n- ``mean`` compute the mean value.\n- ``group_count`` Return a counter made of the values from the previous step\n- ``scatter`` unroll the content of the iterator\n- ``back`` retrieve the parent element\n- ``path(number_of_steps)`` return ``number_of_steps`` of previous elements\n  starting with the current element. The returned object is a list of size\n  ``number_of_steps + 1`` formed of the elements of the path that leads to the\n  current element included. It allows to do ``join`` operations.\n\nThey are a few steps missing compared to gremlin reference implementation.\nThat said, you can easily implement them yourself:\n\nMissing steps with comments:\n\n- both, bothE, bothV => use incomings, outgoings, start and end)\n- gather, groupBy => ???\n- memoize => ???\n- cap => ???\n- select => ???\n- and, or => use python\n- except, retain => use filter instead\n- hasNot => use filter instead\n- interval => use filter instead\n- random, shuffle => ???\n- optional => can't implement that without troubles\n- sideEffect => ???\n- store => ???\n- table => ???\n- tree => ???\n- branch steps => use python\n\n\nAuthor\n======\n\n`Say héllo! <amirouche@hypermove.net>`_",
        "url": "http://pypi.python.org/pypi/AjguDB",
        "summary": "Graph Database for everyday",
        "command": "pip install 'AjguDB'"
      },
      "ajk_ios_buildTools": {
        "name": "ajk_ios_buildtools",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ajk_ios_buildTools",
        "summary": "for daily build,RC test...",
        "command": "pip install 'ajk_ios_buildTools'"
      },
      "ajl_nester": {
        "name": "ajl_nester",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ajl_nester",
        "summary": "[This is a test-only module] Printer of the nested list",
        "command": "pip install 'ajl_nester'"
      },
      "ajnester": {
        "name": "ajnester",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ajnester",
        "summary": "A simple printer of Nested List",
        "command": "pip install 'ajnester'"
      },
      "aj_nester": {
        "name": "aj_nester",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aj_nester",
        "summary": "A simple printer of Nested List",
        "command": "pip install 'aj_nester'"
      },
      "ajrnester": {
        "name": "ajrnester",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ajrnester",
        "summary": "A simple printer of Nested List",
        "command": "pip install 'ajrnester'"
      },
      "ak": {
        "name": "ak",
        "command": "pip install 'ak'"
      },
      "aka": {
        "name": "aka",
        "description": "Aka - Rename files in complicated ways easily\n=============================================\nAbstract\n--------\n\nThis package provides a command line utility called ``aka`` for swiftly renaming (or copying) files using Python code.\nThis makes it easy to rename files even when the changes you are making are quite complicated. It always\nrenames files in two passes to avoid collisions; it tries to detect miscellaneous errors in advance; and\nif errors occur underways it will put you in an emergency mode to resolve the problem or roll back changes.\nIt also provides the functions ``aka.rename`` and ``aka.copy``, which is the underlying interface.\n\nThe problem being solved\n------------------------\n\nLets say you have a directory with the files ``File0``, ``File1``, and ``File2``. Then some people comes along and complains\n(rightly or wrongly) that the numbering starts at zero. So you decide to write a program to rename all those files, but a\nproblem arises. You cannot do it in any order you like, you have to start with ``File2 -> File3`` in order to avoid conflicts.\nIt'd be nice to just write a function that knows how to change the names of individual files and let another program sort out the rest.\nThis is what ``aka.rename`` is about:\n\n.. code-block:: pycon\n\n   >>> import aka\n   >>> from contex import rules\n   >>> def machine(fn):\n           return rules(r'File(\\d+)', {1: lambda digit: int(digit) + 1}).apply(fn)\n   >>> machine('File42')\n   'File43'\n   >>> aka.rename(machine)\n   Actions to be taken (simplified; doesn't show the temporary stage):\n     /home/uglemat/Documents/File0           -> /home/uglemat/Documents/File1\n     /home/uglemat/Documents/File1           -> /home/uglemat/Documents/File2\n     /home/uglemat/Documents/File2           -> /home/uglemat/Documents/File3\n   Target directories:\n     /home/uglemat/Documents\n   \n   The files will be renamed as shown above (in two passes though, in order to avoid\n   collisions). This program searched for name conflicts in all target directories\n   and did not find any. If errors do pop up, you'll be taken to an emergency mode\n   where you can roll back changes. Continue? [N/y]: y\n   Renaming /home/uglemat/Documents/File0 -> /tmp/aka_maok91r8/File0\n   Renaming /home/uglemat/Documents/File1 -> /tmp/aka_maok91r8/File1\n   Renaming /home/uglemat/Documents/File2 -> /tmp/aka_maok91r8/File2\n   Renaming /tmp/aka_maok91r8/File0 -> /home/uglemat/Documents/File1\n   Renaming /tmp/aka_maok91r8/File1 -> /home/uglemat/Documents/File2\n   Renaming /tmp/aka_maok91r8/File2 -> /home/uglemat/Documents/File3\n   True\n\nI used `contex.rules <https://pypi.python.org/pypi/contex/>`_ to manipulate the string, but you can do whatever you like inside ``machine``, you\njust need to return the new name of the file.\n\nBy default it renames files in the current working directory, but that can be changed with the ``location`` argument to ``aka.rename``. ``aka.copy``\nis basically the same, it just copies files instead. Read the docstrings of those functions to learn the details.\n\nCommand line utility\n--------------------\n\nThat's all fine and dandy, but when you just have some files and you need to rename them, you want to do it with a command line utility. This is the basics:\n\n.. code-block:: bash\n   \n   $ aka --help\n   Useful information ...\n   $ aka -p 'fn+\".jpg\"'\n\nThat will add a \".jpg\" suffix to all files in the working directory. But lets do what we did above with ``aka.rename``:\n\n.. code-block:: bash\n   \n   $ aka -p 'rules(r\"File(\\d+)\", {1: lambda digit: int(digit) + 1})'\n\nThe expression after ``-p`` doesn't need to be a new filename, it can also be a unary callable (like ``machine`` above) that returns the new filename.\nThat is why the example above works; ``contex.rules`` returns a callable. If you want to copy instead of rename, just add in the ``-c`` option:\n\n.. code-block:: bash\n   \n   $ aka -c -p 'rules(r\"File(\\d+)\", {1: lambda digit: int(digit) + 1})'\n   \n    -- COPYING FILES IN . --\n   \n   ERROR: /home/uglemat/Documents/File1 -> /home/uglemat/Documents/File2 is a conflict!\n   ERROR: /home/uglemat/Documents/File2 -> /home/uglemat/Documents/File3 is a conflict!\n   Aborting...\n\nErr, yes, that won't work, of course. Good thing ``aka`` detects naming conflicts in advance!\n\nMore complicated renaming schemes\n---------------------------------\n\nThat's great, but what if it's not a simple one-liner? Then you need to create a new file,\nwrite some python code, launch the python interpreter, import the stuff you need... It's cumbersome, which is why ``aka`` can help with that:\n\n.. code-block:: bash\n   \n   $ aka -e emacs\n\nThis will launch emacs and take you to a temporary file which looks kind of like this:\n\n.. code-block:: python\n   \n   import re\n   from os.path import join\n   from contex import rules\n   \n   # Directories in which to perform changes:\n   #   /home/uglemat/Documents\n   \n   def rename(fn, dirname):\n       return fn\n\n\nYour job is to complete ``rename``, and when you exit the editor it will do the job (after asking you if you want to continue).\n   \nLets do something more advanced, say you have lots of files in ``~/Documents/files`` of the format ``File<num>`` and you want to split\nthem into the folders ``odd`` and ``even``, like this:\n\n.. code-block:: bash\n   \n   ~/Documents/files $ for i in {0..20}; do touch \"File$i\"; done\n   ~/Documents/files $ ls\n   File0  File1  File10  File11  File12  File13  File14  File15  File16  File17  File18  File19  File2  File20  File3  File4  File5  File6  File7  File8  File9\n   ~/Documents/files $ mkdir odd even\n   \nThere is a slight problem in that you can't rename ``odd`` and ``even``, but they are in the same directory. You just\ngot to make sure that the rename function returns a falsy value for those filenames (btw, aka treats directories like files and\nwill rename them too). Lets go to the editor with ``aka -e 'emacs -nw'`` and write this:\n\n.. code-block:: python\n\n   import re\n   from os.path import join\n   from contex import rules\n\n   # Directories in which to perform changes:\n   #   /home/uglemat/Documents/files\n\n   def rename(fn, dirname):\n       match = re.search(r'\\d+', fn)\n       if match:\n           digit = int(match.group(0))\n           return join('even' if even(digit) else 'odd', fn)\n   \n\n   def even(d):\n       return (d % 2) == 0\n\nThe directories ``odd`` and ``even`` doesn't match, so ``rename`` returns ``None`` for those names and thus they are ignored, and\nthe code above works as expected:\n\n.. code-block:: shell-session\n   \n   ~/Documents/files $ aka -e 'emacs -nw'\n   running $ emacs -nw +9:14 /tmp/aka_3uvuyn8c.py\n   Aka: Proceed? [Y/n]: y\n   \n    -- RENAMING FILES IN . --\n   \n   Actions to be taken (simplified; doesn't show the temporary stage):\n     /home/uglemat/Documents/files/File3           -> /home/uglemat/Documents/files/odd/File3\n     /home/uglemat/Documents/files/File18          -> /home/uglemat/Documents/files/even/File18\n     /home/uglemat/Documents/files/File13          -> /home/uglemat/Documents/files/odd/File13\n     ...\n   Target directories:\n     /home/uglemat/Documents/files/odd\n     /home/uglemat/Documents/files/even\n   \n   The files will be renamed as shown above (in two passes though, in order to avoid\n   collisions). This program searched for name conflicts in all target directories\n   and did not find any. If errors do pop up, you'll be taken to an emergency mode\n   where you can roll back changes. Continue? [N/y]: y\n   Renaming /home/uglemat/Documents/files/File3 -> /tmp/aka_st72r5jp/File3\n   Renaming /home/uglemat/Documents/files/File18 -> /tmp/aka_st72r5jp/File18\n   Renaming /home/uglemat/Documents/files/File13 -> /tmp/aka_st72r5jp/File13\n   ...\n   Renaming /tmp/aka_st72r5jp/File3 -> /home/uglemat/Documents/files/odd/File3\n   Renaming /tmp/aka_st72r5jp/File18 -> /home/uglemat/Documents/files/even/File18\n   Renaming /tmp/aka_st72r5jp/File13 -> /home/uglemat/Documents/files/odd/File13\n   ~/Documents/files $ ls *\n   even:\n   File0  File10  File12  File14  File16  File18  File2  File20  File4  File6  File8\n   \n   odd:\n   File1  File11  File13  File15  File17  File19  File3  File5  File7  File9\n\n\nRollbacks\n---------\n\nTo test the rollback feature of ``aka``, lets first launch this command:\n\n.. code-block:: shell-session\n\n    $ aka -p 'rules(r\"File(\\d+)\", {1: lambda digit: int(digit) + 1})'\n    \n     -- RENAMING FILES IN . --\n    \n    Actions to be taken (simplified; doesn't show the temporary stage):\n      /home/uglemat/Documents/File3           -> /home/uglemat/Documents/File4\n      /home/uglemat/Documents/File1           -> /home/uglemat/Documents/File2\n      /home/uglemat/Documents/File2           -> /home/uglemat/Documents/File3\n    Target directories:\n      /home/uglemat/Documents\n    \n    The files will be renamed as shown above (in two passes though, in order to avoid\n    collisions). This program searched for name conflicts in all target directories\n    and did not find any. If errors do pop up, you'll be taken to an emergency mode\n    where you can roll back changes. Continue? [N/y]:\n    \nNow it's waiting for confirmation from the user. So we have time to do some sabotage in another shell:\n                \n.. code-block:: bash\n   \n   $ touch File4\n   $ ls\n   File1  File2  File3  File4\n\nIn the first shell, lets enter ``y`` to see how it fails:\n                \n.. code-block:: shell-session\n                \n   Renaming /home/uglemat/Documents/File3 -> /tmp/aka_1ozr4w4b/File3\n   Renaming /home/uglemat/Documents/File1 -> /tmp/aka_1ozr4w4b/File1\n   Renaming /home/uglemat/Documents/File2 -> /tmp/aka_1ozr4w4b/File2\n   Renaming /tmp/aka_1ozr4w4b/File3 -> /home/uglemat/Documents/File4\n   \n   \n   EMERGENCY MODE: File /home/uglemat/Documents/File4 already exists!\n   ERROR: Error happened when trying to rename /tmp/aka_1ozr4w4b/File3 -> /home/uglemat/Documents/File4\n   \n   What should the program do?\n   retry    : try again (presumably you've fixed something in the meantime)\n   rollback : attempt to undo changes (except for the ones previously continue'd)\n   showroll : show which actions will be taken if you choose `rollback`\n   exit     : exit the program\n   continue : ignore the error and move on\n   > \n\nOh my, looks like think didn't go as planned. You're now in the emergency prompt of ``aka``. You can easily fix the problem\nby deleting ``File4`` and entering ``retry``, but that's boring. Let's first see what happens when you select ``continue``:\n                \n.. code-block:: shell-session\n   \n   > continue\n   Renaming /tmp/aka_1ozr4w4b/File1 -> /home/uglemat/Documents/File2\n   Renaming /tmp/aka_1ozr4w4b/File2 -> /home/uglemat/Documents/File3\n   LOST FILES IN TEMP DIR: '/tmp/aka_1ozr4w4b'\n   $ ls /tmp/aka_1ozr4w4b\n   File3\n\nIt's not very nice that it just left the file in the temp dir. ``continue`` is probably rarely a good option. Lets be more sophisticated\nand choose ``rollback``:\n\n.. code-block:: shell-session\n   \n   > showroll\n   Rollback actions:\n     /tmp/aka_1ozr4w4b/File2              -> /home/uglemat/Documents/File2\n     /tmp/aka_1ozr4w4b/File1              -> /home/uglemat/Documents/File1\n     /tmp/aka_1ozr4w4b/File3              -> /home/uglemat/Documents/File3\n   What should the program do?\n   retry    : try again (presumably you've fixed something in the meantime)\n   rollback : attempt to undo changes (except for the ones previously continue'd)\n   showroll : show which actions will be taken if you choose `rollback`\n   exit     : exit the program\n   continue : ignore the error and move on\n   > rollback\n   Rollback renaming /tmp/aka_1ozr4w4b/File2 -> /home/uglemat/Documents/File2\n   Rollback renaming /tmp/aka_1ozr4w4b/File1 -> /home/uglemat/Documents/File1\n   Rollback renaming /tmp/aka_1ozr4w4b/File3 -> /home/uglemat/Documents/File3\n   $ ls\n   File1  File2  File3  File4\n\n\nRollback will \"undo\" all previous actions, in the reverse order that they were \"done'd\". If you use the ``--copy`` option then the undoing\nconsists of deleting files already copied. If any of the rollback actions fails, then ``aka`` will ignore it and try to undo as much as possible.\n\nInstalling\n----------\n\n``aka`` works only in Python 3. \n\nInstall with ``$ pip3 install aka``. You might want to replace ``pip3`` with ``pip``, depending on how your system is configured.\n\nWindows Compatability\n---------------------\n\nI developed this program on GNU/Linux, but it should be working on Windows as well. It understands that filenames are\ncase insensitive on Windows when checking for naming conflicts, yet the case sensitivity is preserved when the actual renames are done.\n\nDeveloping\n----------\n\nAka has some tests. Run ``$ nosetests`` or\n``$ python3 setup.py test`` to run the tests. The code is hosted at https://notabug.org/Uglemat/aka\n\nYou can install in development mode with ``$ python3 setup.py develop``, then your changes to aka will take effect immediately. Launch the same command with the ``--uninstall`` option to (kind of) remove.\n\nLicense\n-------\n\nThe code is licensed under the GNU General Public License 3 or later.\nThis README file is public domain.",
        "url": "http://pypi.python.org/pypi/aka",
        "summary": "Rename/copy files using Python code",
        "command": "pip install 'aka'"
      },
      "akadav": {
        "name": "akadav",
        "description": "akaDAV is a python module to provide WebDAV (RFC 2518) capabilities\nfor Twisted 1.3. It enables you to quickly write your own WebDAV\nserver application in Python. The package also includes easy-to-use\nand lightweight WebDAV server application.",
        "url": "http://pypi.python.org/pypi/akadav",
        "summary": "WebDAV module for Twisted",
        "command": "pip install 'akadav'"
      },
      "Akamu": {
        "name": "akamu",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Akamu",
        "summary": "An Akara module for managing the use of an RDF dataset, a XML/RDF filesystem, and XSLT extension functions within a web application",
        "command": "pip install 'Akamu'"
      },
      "Akara": {
        "name": "akara",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Akara",
        "summary": "Web components for Amara 2.x",
        "command": "pip install 'Akara'"
      },
      "akatsuki": {
        "name": "akatsuki",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/akatsuki",
        "summary": "BibTeX to HTML converter",
        "command": "pip install 'akatsuki'"
      },
      "akaudit": {
        "name": "akaudit",
        "description": "See README.md.\n",
        "url": "http://pypi.python.org/pypi/akaudit",
        "summary": "Audit who has SSH access to your user homes via authorized_keys.",
        "command": "pip install 'akaudit'"
      },
      "AKBusGpsParser": {
        "name": "akbusgpsparser",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AKBusGpsParser",
        "summary": "A bus-gps parser module.It's easy to use! For more, please visit my blog",
        "command": "pip install 'AKBusGpsParser'"
      },
      "akcli": {
        "name": "akcli",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/akcli",
        "summary": "Akamai CLI tool written in Python",
        "command": "pip install 'akcli'"
      },
      "ake": {
        "name": "ake",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ake",
        "summary": "UNKNOWN",
        "command": "pip install 'ake'"
      },
      "Akhet": {
        "name": "akhet",
        "description": "**Main changes in version 2: (A)** The 'akhet' scaffold gone, replaced by a demo\r\napplication, which you can cut and paste from. **(B)** General Pyramid/Pylons\r\nmaterial has been moved out of the manual to the Pyramid Cookbook, section\r\nPyramid for Pylons Users guide. *(The guide is not yet online as of February\r\n2012.)* **(C)** The include for static routes has changed to \"akhet.static\", but\r\n\"akhet\" is still allowed for backward compatibility. **(D)** A new pony module.\r\n**(E)** The repository is now on GitHub in the Pylons Project.\r\n\r\nThe demo is distributed separately from the Akhet. Its repository URL is in the\r\nDemo section of the docs.\r\n\r\nAkhet runs on Python 2.5 - 2.7. Version 2 has been tested on Pyramid\r\n1.3a6 and 1.2.4 using Pyramid 2.7.2 on Ubuntu Linux 11.10.  The next Akhet\r\nversion, 2.1, will focus on Python 3 and will drop Python 2.5.\r\nThe demo application currently has the same compatibility range as Akhet\r\nitself.",
        "url": "http://pypi.python.org/pypi/Akhet",
        "summary": "A Pyramid library and demo app with a Pylons-like feel.",
        "command": "pip install 'Akhet'"
      },
      "akiban-automation": {
        "name": "akiban-automation",
        "description": "",
        "url": "http://pypi.python.org/pypi/akiban-automation",
        "summary": "Performance Automation Tool for Akiban",
        "command": "pip install 'akiban-automation'"
      },
      "akiokio-django-geoposition": {
        "name": "akiokio-django-geoposition",
        "description": "==================\ndjango-geoposition\n==================\n\nA model field that can hold a geoposition (latitude/longitude), and corresponding admin/form widget.\n\n.. image:: https://pypip.in/v/django-geoposition/badge.png\n   :target: https://pypi.python.org/pypi/django-geoposition\n\n.. image:: https://travis-ci.org/philippbosch/django-geoposition.png?branch=master\n   :target: https://travis-ci.org/philippbosch/django-geoposition\n\n\nPrerequisites\n-------------\n\nStarting with version 0.2, django-geoposition requires Django 1.4.10 or greater. If you need to support\nDjango versions prior to 1.4.10, please use django-geoposition 0.1.5.\n\n\nInstallation\n------------\n\n- Use your favorite Python packaging tool to install ``geoposition``\n  from `PyPI`_, e.g.::\n\n    pip install django-geoposition\n\n- Add ``\"geoposition\"`` to your ``INSTALLED_APPS`` setting::\n\n    INSTALLED_APPS = (\n        # …\n        \"geoposition\",\n    )\n\n- If you are still using Django <1.3, you are advised to install\n  `django-staticfiles`_ for static file serving.\n\n\nUsage\n-----\n\n``django-geoposition`` comes with a model field that makes it pretty\neasy to add a geoposition field to one of your models. To make use of\nit:\n\n- In your ``myapp/models.py``::\n\n    from django.db import models\n    from geoposition.fields import GeopositionField\n\n    class PointOfInterest(models.Model):\n        name = models.CharField(max_length=100)\n        position = GeopositionField()\n\n- This enables the following simple API::\n\n    >>> from myapp.models import PointOfInterest\n    >>> poi = PointOfInterest.objects.get(id=1)\n    >>> poi.position\n    Geoposition(52.522906,13.41156)\n    >>> poi.position.latitude\n    52.522906\n    >>> poi.position.longitude\n    13.41156\n\n\nForm field and widget\n---------------------\n\nAdmin\n^^^^^\n\nIf you use a ``GeopositionField`` in the admin it will automatically\nshow a `Google Maps`_ widget with a marker at the currently stored\nposition. You can drag and drop the marker with the mouse and the\ncorresponding latitude and longitude fields will be updated\naccordingly.\n\nIt looks like this:\n\n|geoposition-widget-admin|\n\n\nRegular Forms\n^^^^^^^^^^^^^\n\nUsing the map widget on a regular form outside of the admin requires\njust a little more work. In your template make sure that\n\n- `jQuery`_ is included\n- the static files (JS, CSS) of the map widget are included (just use\n  ``{{ form.media }}``)\n\n**Example**::\n\n    <script src=\"//ajax.googleapis.com/ajax/libs/jquery/1.8/jquery.min.js\"></script>\n    <form method=\"POST\" action=\"\">{% csrf_token %}\n        {{ form.media }}\n        {{ form.as_p }}\n    </form>\n\n\nSettings\n--------\n\nYou can customize the `MapOptions`_ and `MarkerOptions`_ used to initialize the\nmap and marker in JavaScript by defining ``GEOPOSITION_MAP_OPTIONS`` or\n``GEOPOSITION_MARKER_OPTIONS`` in your ``settings.py``.\n\n**Example**::\n\n    GEOPOSITION_MAP_OPTIONS = {\n        'minZoom': 3,\n        'maxZoom': 15,\n    }\n\n    GEOPOSITION_MARKER_OPTIONS = {\n        'cursor': 'move'\n    }\n\nPlease note that you cannot use a value like ``new google.maps.LatLng(52.5,13.4)``\nfor a setting like ``center`` or ``position`` because that would end up as a\nstring in the JavaScript code and not be evaluated. Please use\n`Lat/Lng Object Literals`_ for that purpose, e.g. ``{'lat': 52.5, 'lng': 13.4}``.\n\nYou can also customize the height of the displayed map widget by setting\n``GEOPOSITION_MAP_WIDGET_HEIGHT`` to an integer value (default is 480).\n\n\nLicense\n-------\n\n`MIT`_\n\n\n.. _PyPI: http://pypi.python.org/pypi/django-geoposition\n.. _django-staticfiles: http://github.com/jezdez/django-staticfiles\n.. _Google Maps: http://code.google.com/apis/maps/documentation/javascript/\n.. |geoposition-widget-admin| image:: docs/images/geoposition-widget-admin.jpg\n.. _jQuery: http://jquery.com\n.. _MIT: http://philippbosch.mit-license.org/\n.. _MapOptions: https://developers.google.com/maps/documentation/javascript/reference?csw=1#MapOptions\n.. _MarkerOptions: https://developers.google.com/maps/documentation/javascript/reference?csw=1#MarkerOptions\n.. _Lat/Lng Object Literals: https://developers.google.com/maps/documentation/javascript/examples/map-latlng-literal\n",
        "url": "http://pypi.python.org/pypi/akiokio-django-geoposition",
        "summary": "Django model field that can hold a geoposition, and corresponding admin widget.",
        "command": "pip install 'akiokio-django-geoposition'"
      },
      "akismet": {
        "name": "akismet",
        "description": "`Akismet <http://www.akismet.com>`_ is a web service for recognising spam\r\ncomments. It promises to be almost 100% effective at catching comment spam. They\r\nsay that currently 81% of all comments submitted to them are spam.\r\n\r\nIt's designed to work with the `Wordpress Blog Tool <http://wordpress.org/>`_,\r\nbut it's not restricted to that - so this is a Python interface to the `Akismet\r\nAPI <http://akismet.com/development/api/>`_.\r\n\r\nYou'll need a `Wordpress Key <http://wordpress.com>`_ to use it. This script\r\nwill allow you to plug akismet into any CGI script or web application, and there\r\nare full docs in the code. It's extremely easy to use, because the folks at\r\nakismet have implemented a nice and straightforward REST API.\r\n\r\nIt also comes with an `example CGI\r\n<http://www.voidspace.org.uk/cgi-bin/akismet/test_akismet.py>`_.\r\n\r\nYou can read the full (Python) docs at :\r\n\r\n* `akismet.py docs <http://www.voidspace.org.uk/python/akismet_python.html>`_\r\n\r\nAs of 0.2.0 this module should work on Google AppEngine.",
        "url": "http://pypi.python.org/pypi/akismet",
        "summary": "A Python interface to the Akismet anti comment-spam API.",
        "command": "pip install 'akismet'"
      },
      "Akispy": {
        "name": "akispy",
        "description": "Easy to use client for filtering comment spam using Akismet <akismet.com>.",
        "url": "http://pypi.python.org/pypi/Akispy",
        "summary": "Light weight python client for Akismet API.",
        "command": "pip install 'Akispy'"
      },
      "AKnester": {
        "name": "aknester",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AKnester",
        "summary": "A simple printer of nested lists",
        "command": "pip install 'AKnester'"
      },
      "AKparser": {
        "name": "akparser",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AKparser",
        "summary": "A simple parser,you just tell me what item you want,and set a list for the parser,it is will return a dict.For more,please visit my blog !",
        "command": "pip install 'AKparser'"
      },
      "akshat": {
        "name": "akshat",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/akshat",
        "summary": "UNKNOWN",
        "command": "pip install 'akshat'"
      },
      "akshay_choche_nester": {
        "name": "akshay_choche_nester",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/akshay_choche_nester",
        "summary": "UNKNOWN",
        "command": "pip install 'akshay_choche_nester'"
      },
      "akshell": {
        "name": "akshell",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/akshell",
        "summary": "An utility and a library for development access to http://www.akshell.com/",
        "command": "pip install 'akshell'"
      },
      "aksy": {
        "name": "aksy",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aksy",
        "summary": "Control S5000/S6000, Z4/Z8 and MPC4000 Akai sampler models with System Exclusive over USB",
        "command": "pip install 'aksy'"
      },
      "ak_temp_test": {
        "name": "ak_temp_test",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ak_temp_test",
        "summary": "This is temporary module",
        "command": "pip install 'ak_temp_test'"
      },
      "alabastermobile": {
        "name": "alabastermobile",
        "description": "# alabastermobile\r\n\r\nThis theme is a modified \"alabaster\" Sphinx theme (https://github.com/bitprophet/alabaster)\r\n\r\nAdd sidebar top in mobile view\r\n\r\n# Installation\r\n\r\n```\r\n    pip install alabastermobile\r\n```\r\n\r\nOr\r\n\r\n```\r\n    git clone https://github.com/fraoustin/alabastermobile.git\r\n    cd alabastermobile\r\n    python setup.py install\r\n```\r\n\r\n# Use\r\n\r\nIn your conf.py\r\n\r\n```\r\n    import alabastermobile\r\n    html_theme = 'alabastermobile'\r\n    html_theme_path = [alabastermobile.get_path()]\r\n    extensions = ['alabaster']\r\n\r\n    html_sidebars = {\r\n        '**': [ 'about.html',\r\n                'postcard.html', 'navigation.html',\r\n                'tagcloud.html',\r\n                'categories.html',  'archives.html',\r\n                'searchbox.html',\r\n                ],\r\n        }\r\n```\r\n\n\n0.1.9\n=====\n\nmanage read more\n\n0.1.8\n=====\n\nmanage text-decoration of menu\n\nmanage setup.py",
        "url": "http://pypi.python.org/pypi/alabastermobile",
        "summary": "theme for ablog",
        "command": "pip install 'alabastermobile'"
      },
      "alacarte": {
        "name": "alacarte",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alacarte",
        "summary": "A common templating interface for Python applications.",
        "command": "pip install 'alacarte'"
      },
      "alamatic": {
        "name": "alamatic",
        "description": "",
        "url": "http://pypi.python.org/pypi/alamatic",
        "summary": "",
        "command": "pip install 'alamatic'"
      },
      "AL---Application-Launcher": {
        "name": "al---application-launcher",
        "description": "AL is an application launcher. Simply put it's a tiny application that helps \r\nyou to find and execute other applications faster and easier by suffix search \r\nrather than manualy browsing through your start menu. Check it out!",
        "url": "http://pypi.python.org/pypi/AL---Application-Launcher",
        "summary": "Freeware application launcher for windows",
        "command": "pip install 'AL---Application-Launcher'"
      },
      "alarm": {
        "name": "alarm",
        "description": ".. image:: https://img.shields.io/pypi/v/alarm.svg\r\n    :target: https://pypi.python.org/pypi/alarm\r\n.. image:: https://travis-ci.org/dslackw/alarm.svg?branch=master\r\n    :target: https://travis-ci.org/dslackw/alarm\r\n.. image:: https://landscape.io/github/dslackw/alarm/master/landscape.png\r\n    :target: https://landscape.io/github/dslackw/alarm/master\r\n.. image:: https://img.shields.io/codacy/22fbb1e64acc45a78de3c86233d88d9a.svg\r\n    :target: https://www.codacy.com/public/dzlatanidis/alarm/dashboard\r\n.. image:: https://img.shields.io/pypi/dm/alarm.svg\r\n    :target: https://pypi.python.org/pypi/alarm\r\n.. image:: https://img.shields.io/badge/license-GPLv3-blue.svg\r\n    :target: https://github.com/dslackw/alarm\r\n.. image:: https://img.shields.io/github/stars/dslackw/alarm.svg\r\n    :target: https://github.com/dslackw/alarm\r\n.. image:: https://img.shields.io/github/forks/dslackw/alarm.svg\r\n    :target: https://github.com/dslackw/alarm\r\n.. image:: https://img.shields.io/github/issues/dslackw/alarm.svg\r\n    :target: https://github.com/dslackw/alarm/issues\r\n\r\n.. contents:: Table of Contents:\r\n\r\nCLI Alarm Clock\r\n===============\r\n\r\n.. image:: https://raw.githubusercontent.com/dslackw/images/master/alarm/alarm-clock-icon.png\r\n    :target: https://github.com/dslackw/alarm\r\n\r\nAlarm is command line alarm clock utility written in Python language.\r\n\r\nHow works\r\n---------\r\n\r\nWhen the date and time coincides with the current the alarm starts \r\nplaying the sound is selected for five consecutive times. You can \r\npause the alarm by pressing 'p' or 'space' is an attempt to cancel the \r\n'q' or 'ESC'. Change the volume of the alarm by pressing '*' or '/'.\r\n\r\nYou can create a list and use it as an alarm sound:\r\n\r\n.. code-block:: bash\r\n    \r\n    $ cat *.mp3 > playlist.m3u\r\n    $ alarm -s 17 07:05 ~/Music/playlist.m3u\r\n\r\nYou will find some sounds in folder alarm/sounds\r\nonly GitHub tar archive `alarm-2.1.tar.gz <https://github.com/dslackw/alarm/archive/v2.1.tar.gz>`_ or\r\nzip archive `alarm-2.1.zip <https://github.com/dslackw/alarm/archive/v2.1.zip>`_.\r\nSome will make you laugh, have fun !!!\r\n    \r\nRequirements\r\n------------\r\n\r\n.. code-block:: bash\r\n\r\n    - Python 2 or 3\r\n    - Mplayer\r\n\r\nInstallation\r\n------------\r\n\r\nUsing `pip <https://pip.pypa.io/en/latest/>`_ :\r\n\r\n.. code-block:: bash\r\n\r\n    $ pip install alarm --upgrade\r\n\r\n    uninstall:\r\n\r\n    $ pip uninstall alarm\r\n   \r\n\r\nGet the source 'git clone https://github.com/dslackw/alarm.git'\r\n\r\n.. code-block:: bash\r\n    \r\n    $ python setup.py --install\r\n\r\n\r\nCommand Line Tool Usage\r\n-----------------------\r\n\r\n.. code-block:: bash\r\n\r\n    usage: alarm [-h] [-v]\r\n                 [-s] <day> <alarm time> <song>\r\n\r\n    optional arguments\r\n      -h, --help       show this help message and exit\r\n      -v, --version    print version and exit\r\n      -s, --set        set alarm day, time and sound\r\n    \r\n      --config         use config file\r\n\r\n    example: alarm -s 21 06:00 /path/to/song.mp3\r\n\r\nExample:\r\n\r\n.. code-block:: bash\r\n   \r\n    $ alarm -s 18 22:05 ~/alarm/sounds/wake_up.mp3\r\n\r\n    +==============================================================================+\r\n    |                              CLI Alarm Clock                                 |\r\n    +==============================================================================+\r\n    | Alarm set at : Wednesday 22:05                                               |\r\n    | Sound file : ~/alarm/sounds/wake_up.mp3                                      |\r\n    | Time : 21:06:41                                                              |\r\n    +==============================================================================+\r\n    Press 'Ctrl + c' to cancel alarm ...\r\n\r\n\r\n    +==============================================================================+\r\n    |                              CLI Alarm Clock                                 |\r\n    +==============================================================================+\r\n    | Alarm set at : Wednesday 22:05                                               |\r\n    | Sound file :  ~/alarm/sounds/wake_up.mp3                                     |\r\n    | Time : 22:05 Wake Up !                                                       |\r\n    +==============================================================================+\r\n    Press 'Ctrl + c' to cancel alarm ...\r\n    __        __    _          _   _         _ \r\n    \\ \\      / /_ _| | _____  | | | |_ __   | |\r\n     \\ \\ /\\ / / _` | |/ / _ \\ | | | | '_ \\  | |\r\n      \\ V  V / (_| |   <  __/ | |_| | |_) | |_|\r\n       \\_/\\_/ \\__,_|_|\\_\\___|  \\___/| .__/  (_)\r\n                                    |_|\r\n    \r\n    Press 'SPACE' to pause alarm ...                                    \r\n    \r\n    Attempt 1\r\n\r\n    Attempt 2\r\n\r\nUse config file in $HOME/.ararm/config:\r\n\r\n.. code-block:: bash\r\n\r\n    $ alarm --config\r\n\r\n    +==============================================================================+\r\n    |                              CLI Alarm Clock                                 |\r\n    +==============================================================================+\r\n    | Alarm set at : Wednesday 07:00                                               |\r\n    | Sound file : /home/user/alarm/sounds/funny.mp3                               |\r\n    | Time : 00:09:22                                                              |\r\n    +==============================================================================+\r\n    Press 'Ctrl + c' to cancel alarm ...",
        "url": "http://pypi.python.org/pypi/alarm",
        "summary": "CLI Alarm Clock",
        "command": "pip install 'alarm'"
      },
      "Alarmageddon": {
        "name": "alarmageddon",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Alarmageddon",
        "summary": "Automated testing and reporting",
        "command": "pip install 'Alarmageddon'"
      },
      "alarmdecoder": {
        "name": "alarmdecoder",
        "description": ".. _AlarmDecoder: http://www.alarmdecoder.com\n.. _ser2sock: http://github.com/nutechsoftware/ser2sock\n.. _pyftdi: https://github.com/eblot/pyftdi\n.. _pyusb: http://sourceforge.net/apps/trac/pyusb\n.. _pyserial: http://pyserial.sourceforge.net\n.. _pyopenssl: https://launchpad.net/pyopenssl\n.. _readthedocs: http://alarmdecoder.readthedocs.org\n.. _examples: http://github.com/nutechsoftware/alarmdecoder/tree/master/examples\n\n============\nAlarmDecoder\n============\n\n-------\nSummary\n-------\n\nThis Python library aims to provide a consistent interface for the `AlarmDecoder`_ product line. (AD2USB, AD2SERIAL and AD2PI)\nThis also includes devices that have been exposed via `ser2sock`_, which\nsupports encryption via SSL/TLS.\n\n------------\nInstallation\n------------\nAlarmDecoder can be installed through pip:\n    pip install alarmdecoder\n\nor from source:\n    python setup.py install\n\n* Note: python-setuptools is required for installation.\n\n------------\nRequirements\n------------\nRequired:\n* An `AlarmDecoder`_ device\n* Python 2.7\n* `pyserial`_ >= 2.7\n\nOptional:\n* `pyftdi`_ >= 0.9.0\n* `pyusb`_ >= 1.0.0b1\n* `pyopenssl`_\n\n-------------\nDocumentation\n-------------\nAPI documentation can be found at `readthedocs`_.\n\n--------\nExamples\n--------\nA basic example is included below.  Please see the `examples`_ directory for more.::\n\n    import time\n    from alarmdecoder import AlarmDecoder\n    from alarmdecoder.devices import SerialDevice\n\n    def main():\n        \"\"\"\n        Example application that prints messages from the panel to the terminal.\n        \"\"\"\n        try:\n            # Retrieve the first USB device\n            device = AlarmDecoder(SerialDevice(interface='/dev/ttyUSB0'))\n\n            # Set up an event handler and open the device\n            device.on_message += handle_message\n            with device.open(baudrate=115200):\n                while True:\n                    time.sleep(1)\n\n        except Exception, ex:\n            print 'Exception:', ex\n\n    def handle_message(sender, message):\n        \"\"\"\n        Handles message events from the AlarmDecoder.\n        \"\"\"\n        print sender, message.raw\n\n    if __name__ == '__main__':\n        main()",
        "url": "http://pypi.python.org/pypi/alarmdecoder",
        "summary": "Python interface for the AlarmDecoder (AD2) family of alarm devices which includes the AD2USB, AD2SERIAL and AD2PI.",
        "command": "pip install 'alarmdecoder'"
      },
      "alarmserver": {
        "name": "alarmserver",
        "description": "This package provides an AlarmServer class which is able to handle\r\nalarms. It is intended for HMI software where alarm handling is often\r\nnecessary.\r\n\r\nThe following features are provided:\r\n    - defining alarms with numbers and alarm texts\r\n    - alarms are handled and identified by their alarm number\r\n    - alarms can come and leave\r\n    - alarms can be acknowledged and cleared by the user\r\n\r\nIn addition to the basic AlarmServer class there is an AlarmServerModel\r\nclass which implements the model/view pattern used by the Qt framework.\r\nSo this class can be used as a model for QTableView or QListView.",
        "url": "http://pypi.python.org/pypi/alarmserver",
        "summary": "Alarmhandling for HMI software",
        "command": "pip install 'alarmserver'"
      },
      "alart": {
        "name": "alart",
        "description": "=====\nalart\n=====\n\nalart is a pseudo-random art generator.\n\nExample art can be found at http://metanohi.name/projects/alart/images/\n\n\nLicense\n=======\n\nalart is free software under the terms of the GNU General Public License\nversion 3 (or any later version). This is version 0.1.1 (codename: \"Fox\") of\nthe program.\n\n\nInstallation\n============\n\nWay #1\n------\n\nGet the newest version of alart at http://metanohi.name/projects/alart/ or at\nhttp://pypi.python.org/pypi/alart\n\nExtract the downloaded file and run this in a terminal::\n\n  # python setup.py install\n\nExamples can then be found in the ``examples`` directory.\n\n\nWay #1\n------\n\nJust run this::\n\n  # pip install alart\n\nor::\n\n  # easy_install alart\n\nNote that this will not make the examples available.\n\n  \nDependencies\n------------\n\nPython 2.5 is required, though newer versions might be needed for Encapsulated\nPostScript support.\n\nalart depends on cairo and cairo's Python bindings for generating\nimages. Version 1.6 is needed for best output support, but earlier versions\n(e.g. 1.4) works ok. To install it, do one of these things:\n\n* For DEB-based distros (Debian etc.): type ``apt-get install python-cairo``\n* For RPM-based distros (Fedora etc.): type ``yum install pycairo``\n* For other distros: do something similar or get it at\n  http://cairographics.org/download/\n\nalart depends on PyGame 1.8.0+ (perhaps earlier versions are also supported)\nfor showing generated images. If you only want to generate images and not show\nthem in an interactive window, you do not need PyGame graphics and sound. To\ninstall it, do one of these things:\n\n* For DEB-based distros (Debian etc.): type ``apt-get install python-pygame``\n* For RPM-based distros (Fedora etc.): type ``yum install pygame``\n* For other distros: do something similar or get it at\n  http://pygame.org/download.shtml\n\n\nUse\n===\n\nTo use alart, just run ``alart``. This will display a generated image with\ndefault options. To generate a new image while in the window, press R.\n\nTo see a list of alart's command-line options with explanations, run ``alart\n--help``. To see alart's module help, run ``pydoc alart``.\n\n\nDevelopment\n===========\n\nalart uses Git for code management. To get the newest code, run::\n\n  $ git clone git://gitorious.org/alart/alart.git\n\nBugs can be reported to ns@metanohi.name (address of sole developer).\n\n\nThis document\n=============\n\nCopyright (C) 2010, 2011  Niels Serup\n\nCopying and distribution of this file, with or without modification,\nare permitted in any medium without royalty provided the copyright\nnotice and this notice are preserved.  This file is offered as-is,\nwithout any warranty.",
        "url": "http://pypi.python.org/pypi/alart",
        "summary": "Generate pseudo-random art",
        "command": "pip install 'alart'"
      },
      "alation": {
        "name": "alation",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alation",
        "summary": "UNKNOWN",
        "command": "pip install 'alation'"
      },
      "alation-api": {
        "name": "alation-api",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alation-api",
        "summary": "UNKNOWN",
        "command": "pip install 'alation-api'"
      },
      "alauda": {
        "name": "alauda",
        "description": "Alauda CLI\n=======================\n\nThis is the description file for the project.\n\nhttps://www.alauda.io\nhttps://www.alauda.cn",
        "url": "http://pypi.python.org/pypi/alauda",
        "summary": "Alauda CLI",
        "command": "pip install 'alauda'"
      },
      "alauda_test": {
        "name": "alauda_test",
        "description": "Alauda CLI\n=======================\n\nThis is the description file for the project.\n\nhttps://www.alauda.io\nhttps://www.alauda.cn",
        "url": "http://pypi.python.org/pypi/alauda_test",
        "summary": "Alauda CLI",
        "command": "pip install 'alauda_test'"
      },
      "alba-client-python": {
        "name": "alba-client-python",
        "description": "Библиотека для работы c Alba\n=============\n\nБиблиотека содержит два базовых класса AlbaService и AlbaCallback предназначенных для наследования.\n\nAlbaService - сервис в Alba. Позволяет получить список доступных способов оплаты, инициировать транзакцию, получать информацию о ней. Необходимо создать по экземпляру на каждый существующий сервис.\n\nAlbaCallback - обработчик для обратного вызова от Alba. Проверяет подпись и вызывает соответствующий параметру \"command\" метод.\n\nВ процессе работы может сработать исключение AlbaException.\n\nПример использования для инициации транзакции:\n\n       from alba_client import AlbaService, AlbaException\n\n       service = AlbaService(<service-id>, '<service-secret>')\n       try:\n           service.init_payment('mc', 10, 'Test', 'test@example.com', '71111111111')\n       except AlbaException, e:\n           print e\n\nПример использования для обратного вызова:\n\n       from alba_client import AlbaCallback\n\n       class MyAlbaCallback(AlbaCallback):\n           def callback_success(self, data):\n               # фиксирование успешной транзакции\n\n       service1 = AlbaService(<service1-id>, '<service1-secret>')\n       service2 = AlbaService(<service2-id>, '<service2-secret>')\n       callback = MyAlbaCallback([service1, service2])\n       callback.handle(<словарь-c-POST-данными>)",
        "url": "http://pypi.python.org/pypi/alba-client-python",
        "summary": "API client for Alba.",
        "command": "pip install 'alba-client-python'"
      },
      "albatross": {
        "name": "albatross",
        "description": "Albatross is a small and flexible  Python toolkit for developing highly stateful\r\nweb applications. The toolkit has been designed to take a lot of the pain out of\r\nconstructing intranet applications although you can also use Albatross for\r\ndeploying publicly accessed web applications.",
        "url": "http://pypi.python.org/pypi/albatross",
        "summary": "Albatross is a toolkit for developing highly stateful web applications.",
        "command": "pip install 'albatross'"
      },
      "Albertson": {
        "name": "albertson",
        "description": "Albertson\n=========\n\nA library for super easy to use, reliable, and scalable counters.\n\nHomepage: [https://github.com/FocusLab/Albertson][3]\n\n**Albertson is in an alpha state and probably shouldn't be used in\nproduction by anybody just yet.**\n\n![](http://upload.wikimedia.org/wikipedia/en/7/79/The_Simpsons-Jeff_Albertson.png)\n\n*\"Worst library ever!\"*\n\n\n\n\nWhy\n---\nCreating counters that handle incrementing at high levels of concurrency while\nalso being highly available and fault tolerant is *really* hard.  Thankfully,\nAmazon has solved these really hard bits with their [DynamoDB][2] service.\n\nAlbertson provides a simple, clean, and easy to use, Python interface to\nDynamoDb for this specific use case.\n\n\nWho\n---\nAlbertson was created by the dev team at [FocusLab][1].\n\n\nWhat's with the name?\n---------------------\nInternally at FocusLab Albertson is used for real-time, authoritative, counts\nthat are often used to correct less frequently updated counts throughout our\nsystem.  Accordingly, we've named the library after our favorite fictional\npedant, Comic Book Guy a.k.a. Jeff Albertson.\n\n\n[1]:    https://www.focuslab.io\n[2]:    http://aws.amazon.com/dynamodb/\n[3]:    https://github.com/FocusLab/Albertson",
        "url": "http://pypi.python.org/pypi/Albertson",
        "summary": "Easy to use, scalable, counters powered by Amazon's DynamoDB",
        "command": "pip install 'Albertson'"
      },
      "albuminer": {
        "name": "albuminer",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/albuminer",
        "summary": "Tool that, given an audio file or a path with audio files, gets a cover for all of them.",
        "command": "pip install 'albuminer'"
      },
      "albumr": {
        "name": "albumr",
        "description": "# albumr\n\nImgur album downloader.\n\n## Installation\n\n    pip install albumr\n\n## Usage\n\n    usage: albumr [-h] [-n] [-t] album [album ...]\n\n    Imgur album downloader\n\n    positional arguments:\n      album          an album hash or URL\n\n    optional arguments:\n      -h, --help     show this help message and exit\n      -n, --numbers  prepend numbers to filenames\n      -t, --titles   append album titles to directory names\n\n## Examples\n\n>From album URL:\n\n    albumr http://imgur.com/a/adkET\n\n>From album hash, with numbers in filenames and album title in directory name:\n\n    albumr -nt adkET\n\n## License\n\nLicensed under the [MIT License](http://www.opensource.org/licenses/MIT).",
        "url": "http://pypi.python.org/pypi/albumr",
        "summary": "Imgur album downloader",
        "command": "pip install 'albumr'"
      },
      "albumthief": {
        "name": "albumthief",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/albumthief",
        "summary": "Very fast album downloader made using gevent.",
        "command": "pip install 'albumthief'"
      },
      "alburnum-maas-client": {
        "name": "alburnum-maas-client",
        "description": "alburnum-maas-client\n====================\n\nPython client API library made especially for\n`MAAS <https://maas.ubuntu.com/>`__.\n\nThis was created by a core MAAS developer (Gavin Panella) so ought to\njust about work. It was written in his own time, and it's licensed under\nthe GNU Affero GPLv3 too, the same as MAAS itself.\n\nDependencies\n------------\n\nYou'll need the ``maascli`` package. It's not on PyPI unfortunately. On\nUbuntu, install the ``maas-cli`` system package:\n\n::\n\n    $ sudo apt-get install maas-cli\n\nAll the other dependencies are declared already in ``setup.py``.\n\nExample code\n------------\n\nFirst you need to create a *profile* with the ``maas`` command-line\ntool. There is `documentation for\nthat <https://maas.ubuntu.com/docs1.8/maascli.html#logging-in>`__ on the\nMAAS website.\n\nHere's a snippet that creates a tag and associates it with every node in\nthe MAAS:\n\n.. code:: python\n\n    import httplib\n    from pprint import pprint\n\n    from alburnum.maas.client import (\n        CallError,\n        SessionAPI,\n    )\n\n    # Load a MAAS CLI profile. The name below (here \"madagascar\") should be the\n    # name of a profile created when using `maas login` at the command-line.\n    papi = SessionAPI.fromProfileName(\"madagascar\")\n\n    # Create a tag if it doesn't exist.\n    tag_name = \"foo\"\n    try:\n        tag = papi.Tag.read(name=tag_name)\n    except CallError as error:\n        if error.status == httplib.NOT_FOUND:\n            tag = papi.Tags.new(\n                name=tag_name, comment=\"%s's Stuff\" % tag_name.capitalize())\n        else:\n            raise\n\n    # List all the MAAS's tags.\n    print(\" Tags.list() \".center(50, \"=\"))\n    pprint(papi.Tags.list())\n\n    # Associate the tag with all nodes.\n    print(\" Tag.update_nodes() \".center(50, \"=\"))\n    pprint(papi.Tag.update_nodes(\n        name=tag[\"name\"], add=[\n            node[\"system_id\"] for node in papi.Nodes.list()\n        ]))\n\n",
        "url": "http://pypi.python.org/pypi/alburnum-maas-client",
        "summary": "A client API library specially for MAAS.",
        "command": "pip install 'alburnum-maas-client'"
      },
      "alchemist": {
        "name": "alchemist",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alchemist",
        "summary": "A server architecture built on top of a solid foundation provided by flask, sqlalchemy, and various extensions.",
        "command": "pip install 'alchemist'"
      },
      "alchemist-armet": {
        "name": "alchemist-armet",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alchemist-armet",
        "summary": "Tight integration of armet with alchemist.",
        "command": "pip install 'alchemist-armet'"
      },
      "alchemist.audit": {
        "name": "alchemist.audit",
        "description": "Alchemist Auditing\n------------------\n\nAlchemist auditing provides a facility for auditing changes to an\nobject to a relational database. It automatically captures and records\nevents for object added, modified, deleted.  in addition if the\nrespective packages are present it also records worklow events (\nore.workflow ) and versioning ( alchemist.versioning ).\n\nAll events record time, action, active user, in addition modification\nevents capture field change descriptions, to allow for listing\nattributes changed.\n\nAuditing can be done on either a per table or \n\n\n0.3.4 - December 23rd, 2008\n\n - packaging fixes ( template not included in package data )\n\n0.3.2 - December 17th, 2008\n\n - update package metadata / classifiers\n - don't require active user for auditing functionality\n - automation api for adapter registration and recorder generation ( provideRecorder )\n\n0.3.0 - June 1st, 2008\n\n- First public release",
        "url": "http://pypi.python.org/pypi/alchemist.audit",
        "summary": "Alchemist Auditing Components ( Event Subscribers, Change Recorders, UI ) for Relational Applications",
        "command": "pip install 'alchemist.audit'"
      },
      "alchemist.security": {
        "name": "alchemist.security",
        "description": "A relational implementation of zope security components, including\n    authentication, principal role mappings (global and local),\n    permission role mappings ( global and local ).",
        "url": "http://pypi.python.org/pypi/alchemist.security",
        "summary": "Relational Implementation of Zope Security components",
        "command": "pip install 'alchemist.security'"
      },
      "alchemist.traversal": {
        "name": "alchemist.traversal",
        "description": "Traversal of objects by foreign keys for relational applications\n\nChanges\n-------\n \n0.4.0 - December 17th, 2008\n\n - switch to buildout based testing environment \n - fix, only set parent on domain container if we have an instance\n - fix, if parent not specified, don't set constraint\n\n0.3.1 - June 1st, 2008\n\n - fix an initialization exception during sqlalchemy introspection of variables,\n   inspection of managed container properties on a class/ie no instance is passed, \n   returns a container without query modifiers.",
        "url": "http://pypi.python.org/pypi/alchemist.traversal",
        "summary": "Foreign Key Traversal mechanisms for alchemist containers and domain objects.",
        "command": "pip install 'alchemist.traversal'"
      },
      "alchemist.ui": {
        "name": "alchemist.ui",
        "description": "-------\nChanges\n-------\n\n0.4.2 - December 23rd, 2008\n\n - fix packaging issue with binary egg \n\n0.4.1 - December 17th, 2008\n\n - fix, unique validator short circuits on form field validation and invariants\n - removed browser menu registrations\n - disallow field fields as container columns\n - redo unique validation in the presence of property/column aliases\n - server side sort, batching, paging json container views ( extjs / yui compatible )\n - traversable viewlet",
        "url": "http://pypi.python.org/pypi/alchemist.ui",
        "summary": "user interface components for use with zope3 relational database applications, crud, listing and relation views",
        "command": "pip install 'alchemist.ui'"
      },
      "alchemize": {
        "name": "alchemize",
        "description": "Alchemize - Simple de/serialization for Python\r\n===============================================\r\n\r\nAlchemize is designed to be a simple serialization and deserialization\r\nlibrary for Python. The primary use-case for Alchemize is to allow for\r\nusers to quickly build ReST clients using simple model mappings to\r\ntransform data from Python objects to a serializable form and vice-versa.\r\n\r\nThe power of Alchemize is that you can use it to augment existing\r\nmodel structures from other libraries. For example, you can use Alchemize\r\nto easily serialize your ORM models.\r\n\r\n* Documentation: `ReadTheDocs <http://alchemize.readthedocs.org>`_\r\n* Travis CI: |travis|\r\n* Coverage: |coveralls|\r\n\r\n.. |travis| image:: https://travis-ci.org/jmvrbanac/alchemize.svg\r\n    :target: https://travis-ci.org/jmvrbanac/alchemize\r\n\r\n.. |coveralls| image:: https://img.shields.io/coveralls/jmvrbanac/alchemize.svg\r\n  :target: https://coveralls.io/r/jmvrbanac/alchemize",
        "url": "http://pypi.python.org/pypi/alchemize",
        "summary": "A simple library that allows for serialization and deserialization of models via mapping definitions",
        "command": "pip install 'alchemize'"
      },
      "alchemy": {
        "name": "alchemy",
        "description": "Alchemy\n=======\n\nAlchemy is a tool that eases running jobs like scientific experiments that \ndiffer minimally in configuration. Features include:\n\n - Multiprocessor support, \n - nice handling of standard output and standard error of your job,\n - nice handling of directory structure so that you don't have to take\n   care of that in your job functions.\n\nAlchemy requires two things to get started. First, you need to define a function\nthat actually does what you want. Then you will need a configuration file (we\nuse yaml for this) where you put the parametrizations of your experiments. You\ncan then fire off your experiments with\n\n    $ python alchemy.py -c config.yaml\n\nExperiments will typically only differ slightly. For example, you might want to\nrun a simulation on the moon with a gravitation value of 1.63 and on the earth \nwith a gravitation value of 9.81.\n\nSay you have a function \"rocket\" in your module \"vehicles\" of package \n\"machines\". You want to run two experiments, one letting it start from earth and\none where it goes off from the moon. Your rocket has the name \"rockstar\" and you\nwant it to be exactly 3 meters long. You would then define the following yaml \ndocument.\n\n---\nfunction:     machines.vehicles.rocket\nname:         rockstar\nlength:       3.0\n?:            [{gravity: 9.81}.\n               {gravity: 1.63}]\n...\n\nThis resembles exactly two experiments. The question mark symbol tells alchemy\nthat you want to run one experiment for each of the values of the list. Thus, it\nwill result in the following dictionaries.\n\nThe first one will be for earth:\n\n    {'function': 'machines.vehicles.rocket', \n     'name': 'rockstar', \n     'length': 3.0, \n     'gravity': 9.81}\n\nwhile the second one will be for the moon:\n\n    {'function': 'machines.vehicles.rocket', \n     'name': 'rockstar', \n     'length': 3.0, \n     'gravity': 1.63}\n\nAlchemy will generate the crossproduct of all varying values. So if you have \nmultiple ?'s in your yaml file, all possible values for all ?'s will be \ncombined.\n\nBut how exactly is your function called? Alchemy retrieves the value of the \nfield 'function' and looks that object up on the PYTHONPATH. It the removes\nthe 'function' field, and feeds the resulting dictionary as keyword arguments\ninto your function. The code would be roughly something like this:\n\n    from machines.vehicles import rocket\n    rocket(name='rockstar', length=3.0, gravity=1.63)\n\nIf you are interested in creating more sophisticated configuration files,\nyou can use all stuff that PyYaml can process. Check out http://pyyaml.org/.\n\n\nOutputs of experiments\n----------------------\n\nAlchemy uses Python's very own `uuid` module to generate a unique identifier\nfor your experiment. It will then make a directory of that identifier and\nfor each job of your experiment (if you have no varying values, that will be 1)\na separate subdirectory with an increasing number is generated. \n\nThe id will be printed out when you start alchemy.\n\nBefore your function is executed, the Python interpreter will switch into that\ndirectory. Thus, if you use relative paths in your function, you can make sure\nthat all your output files fall into that directory.\n\nFurthermore, a file `stdout` and a file `stderr` will be created into which the\ncorresponding streams will be redirected. Also, the actual configuration used\nwill be saved into `config.yaml` for future reference.\n\n\nUsing multiple processors\n-------------------------\n\nPython's `multiprocessing` package is used to make use of multi processor \nsystems. You can specify the number of processes used with the `-p` option. It\ndefaults to one processor.\n\n\nLimitations\n-----------\n\n- No supports for cluster\n- Using combinations of varying values other than the cross product",
        "url": "http://pypi.python.org/pypi/alchemy",
        "summary": "job processing",
        "command": "pip install 'alchemy'"
      },
      "AlchemyAPI": {
        "name": "alchemyapi",
        "description": "==================================\nAlchemyAPI Python SDK: version 1.0\n==================================\n\nThis is a Python implementation of the AlchemyAPI SDK.\n\n\nINSTALLATION\n\nTo install this module, copy the alchemyapi.py file into your desired\nPython import directory.  Three AlchemyAPI Python modules are supplied: \n1. Version for Python 2.4.x (requires lxml)\n2. Version for Python 2.5.x+ (supports all later 2.x versions, including 2.7.x)\n3. Version for Python 3.x.x\n\n\nRUNNING EXAMPLES\n\nSeveral code examples are included to illustrate using the AlchemyAPI\nfor named entity extraction, text classification, language identification,\nand other tasks.\n\nAll code samples are within the \"example\" directory.\n\nTo run these code samples you must first edit the (example/api_key.txt) file, \nadding your assigned Orchestr8 API key.\n\nCode Samples:\n\n   1. Entity Extraction: python entities.py\n\n   2. Concept Tagging: python concepts.py\n\n   3. Keyword Extraction: python keywords.py\n\n   4. Text Categorization: python categories.py\n\n   5. Language Identification: python language.py\n\n   6. HTML Text Extraction: python text_extract.py\n\n   7. HTML Structured Content Scraping: python constraint_queries.py\n\n   8. Microformats Extraction: python microformats.py\n\n   9. RSS / ATOM Feed Links Extraction: python feed_links.py\n\n  10. Sentiment analysis example: python sentiment.py\n  \n  11. Relations extraction example: python relations.py\n\n  12. Parameters Object example: python params_object.py\n\n  13. Author extraction example: python author.py\n\n  14. Targeted sentiment example: python targeted_sentiment.py\n  \n\nDEPENDENCIES\n\nPython 2.4.x requires lxml:\n\n   lxml (available at: http://pypi.python.org/pypi/lxml )\n\n\nCOPYRIGHT AND LICENCE\n\nCopyright (C) 2009-2013 Orchestr8, LLC.\n\nThis library is free software; you can redistribute it and/or modify\nit under the same terms as Python itself, either Python version 2.5 or,\nat your option, any later version of Python 2.5 you may have available.",
        "url": "http://pypi.python.org/pypi/AlchemyAPI",
        "summary": "Python access to AlchemyAPI for unstructured text analysis and natural language processing.",
        "command": "pip install 'AlchemyAPI'"
      },
      "alchemyapi_python": {
        "name": "alchemyapi_python",
        "description": "# alchemyapi_python #\n\nA sdk for AlchemyAPI using Python\n\n\n## AlchemyAPI ##\n\nAlchemyAPI offers artificial intelligence as a service. We teach computers to learn how to read and see, and apply our technology to text analysis and image recognition through a cloud-based API. Our customers use AlchemyAPI to transform their unstructured content such as blog posts, news articles, social media posts and images into much more useful structured data. \n\nAlchemyAPI is a tech startup located in downtown Denver, Colorado. As the world’s most popular text analysis service, AlchemyAPI serves over 3.5 billion monthly API requests to over 35,000 developers. To enable our services, we use artificial intelligence, machine learning, neural networks, natural language processing and massive-scale web crawling. Our technology powers use cases in a variety of industry verticals, including social media monitoring, business intelligence, content recommendations, financial trading and targeted advertising.\n\nMore information at: http://www.alchemyapi.com\n\n\n\n## API Key ##\n\nTo use AlchemyAPI, you'll need to obtain an API key and attach that key to all requests. If you do not already have a key, please visit: http://www.alchemyapi.com/api/register.html\n\n\n\n## Requirements ##\n\nThe Python SDK requires that you install the [Requests Python module](http://docs.python-requests.org/en/latest/user/install/#install).",
        "url": "http://pypi.python.org/pypi/alchemyapi_python",
        "summary": "Enhanced version of AlchemyAPI Python SDK",
        "command": "pip install 'alchemyapi_python'"
      },
      "alchemyjsonschema": {
        "name": "alchemyjsonschema",
        "description": "alchemyjsonschema\n=================\n\n.. code:: python\n\n   # -*- coding:utf-8 -*-\n   import sqlalchemy as sa\n   import sqlalchemy.orm as orm\n   from sqlalchemy.ext.declarative import declarative_base\n\n   Base = declarative_base()\n\n\n   class Group(Base):\n       \"\"\"model for test\"\"\"\n       __tablename__ = \"Group\"\n\n       pk = sa.Column(sa.Integer, primary_key=True, doc=\"primary key\")\n       name = sa.Column(sa.String(255), default=\"\", nullable=False)\n\n\n   class User(Base):\n       __tablename__ = \"User\"\n\n       pk = sa.Column(sa.Integer, primary_key=True, doc=\"primary key\")\n       name = sa.Column(sa.String(255), default=\"\", nullable=True)\n       group_id = sa.Column(sa.Integer, sa.ForeignKey(Group.pk), nullable=False)\n       group = orm.relationship(Group, uselist=False, backref=\"users\")\n\n\n   ## ------SingleModelWalker--------\n   import pprint as pp\n   from alchemyjsonschema import SchemaFactory\n   from alchemyjsonschema import SingleModelWalker\n\n   factory = SchemaFactory(SingleModelWalker)\n   pp.pprint(factory.create(User))\n\n   \"\"\"\n   {'properties': {'group_id': {'type': 'integer'},\n                   'name': {'maxLength': 255, 'type': 'string'},\n                   'pk': {'description': 'primary key', 'type': 'integer'}},\n    'required': ['pk', 'group_id'],\n    'title': 'User',\n    'type': 'object'}\n   \"\"\"\n\n\n   ## ------OneModelOnlyWalker--------\n   import pprint as pp\n   from alchemyjsonschema import SchemaFactory\n   from alchemyjsonschema import OneModelOnlyWalker\n\n   factory = SchemaFactory(OneModelOnlyWalker)\n   pp.pprint(factory.create(User))\n\n   \"\"\"\n   {'properties': {'name': {'maxLength': 255, 'type': 'string'},\n                   'pk': {'description': 'primary key', 'type': 'integer'}},\n    'required': ['pk'],\n    'title': 'User',\n    'type': 'object'}\n   \"\"\"\n\n\n   ## ------AlsoChildrenWalker--------\n   import pprint as pp\n   from alchemyjsonschema import SchemaFactory\n   from alchemyjsonschema import AlsoChildrenWalker\n\n   factory = SchemaFactory(AlsoChildrenWalker)\n   pp.pprint(factory.create(User))\n\n   \"\"\"\n   {'definitions': {'Group': {'properties': {'pk': {'description': 'primary key',\n                                                    'type': 'integer'},\n                                             'name': {'maxLength': 255,\n                                                      'type': 'string'}},\n                              'type': 'object'}},\n    'properties': {'pk': {'description': 'primary key', 'type': 'integer'},\n                   'name': {'maxLength': 255, 'type': 'string'},\n                   'group': {'$ref': '#/definitions/Group'}},\n    'required': ['pk'],\n    'title': 'User',\n    'type': 'object'}\n   \"\"\"\n\n   pp.pprint(factory.create(Group))\n\n   \"\"\"\n   {'definitions': {'User': {'properties': {'pk': {'description': 'primary key',\n                                                   'type': 'integer'},\n                                            'name': {'maxLength': 255,\n                                                     'type': 'string'}},\n                             'type': 'object'}},\n    'description': 'model for test',\n    'properties': {'pk': {'description': 'primary key', 'type': 'integer'},\n                   'name': {'maxLength': 255, 'type': 'string'},\n                   'users': {'items': {'$ref': '#/definitions/User'},\n                             'type': 'array'}},\n    'required': ['pk', 'name'],\n    'title': 'Group',\n    'type': 'object'}\n   \"\"\"\n\n\nhas alchemyjsonschema command\n----------------------------------------\n\nhelp\n\n.. code:: bash\n\n    $ alchemyjsonschema -h\n    usage: alchemyjsonschema [-h]\n                             [--walker {noforeignkey,foreignkey,structual,control}]\n                             [--depth DEPTH]\n                             [--decision-relationship DECISION_RELATIONSHIP]\n                             [--decision-foreignkey DECISION_FOREIGNKEY]\n                             model\n\n    positional arguments:\n      model\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      --walker {noforeignkey,foreignkey,structual,control}\n      --depth DEPTH\n      --decision-relationship DECISION_RELATIONSHIP\n      --decision-foreignkey DECISION_FOREIGNKEY\n\ntarget models\n\n.. code:: python\n\n    class Group(Base):\n        __tablename__ = \"Group\"\n        query = Session.query_property()\n\n        pk = sa.Column(sa.Integer, primary_key=True, doc=\"primary key\")\n        name = sa.Column(sa.String(255), default=\"\", nullable=False)\n        color = sa.Column(sa.Enum(\"red\", \"green\", \"yellow\", \"blue\"))\n        created_at = sa.Column(sa.DateTime, nullable=True)\n\n\n    class User(Base):\n        __tablename__ = \"User\"\n        query = Session.query_property()\n\n        pk = sa.Column(sa.Integer, primary_key=True, doc=\"primary key\")\n        name = sa.Column(sa.String(255), default=\"\", nullable=False)\n        group_id = sa.Column(sa.Integer, sa.ForeignKey(Group.pk), nullable=False)\n        group = orm.relationship(Group, uselist=False, backref=\"users\")\n        created_at = sa.Column(sa.DateTime, nullable=True)\n\n\ndump schema (commandline)\n\n.. code:: bash\n\n    $ alchemyjsonschema alchemyjsonschema.tests.models:Group --walker structual\n\n    {\n      \"required\": [\n        \"pk\",\n        \"name\"\n      ],\n      \"definitions\": {\n        \"User\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"pk\": {\n              \"type\": \"integer\",\n              \"description\": \"primary key\"\n            },\n            \"name\": {\n              \"maxLength\": 255,\n              \"type\": \"string\"\n            },\n            \"created_at\": {\n              \"format\": \"date-time\",\n              \"type\": \"string\"\n            }\n          }\n        }\n      },\n      \"title\": \"Group\",\n      \"type\": \"object\",\n      \"properties\": {\n        \"pk\": {\n          \"type\": \"integer\",\n          \"description\": \"primary key\"\n        },\n        \"name\": {\n          \"maxLength\": 255,\n          \"type\": \"string\"\n        },\n        \"color\": {\n          \"enum\": [\n            \"red\",\n            \"green\",\n            \"yellow\",\n            \"blue\"\n          ],\n          \"maxLength\": 6,\n          \"type\": \"string\"\n        },\n        \"created_at\": {\n          \"format\": \"date-time\",\n          \"type\": \"string\"\n        },\n        \"users\": {\n          \"items\": {\n            \"$ref\": \"#/definitions/User\"\n          },\n          \"type\": \"array\"\n        }\n      }\n    }",
        "url": "http://pypi.python.org/pypi/alchemyjsonschema",
        "summary": "mappeing jsonschema for sqlalchemy models",
        "command": "pip install 'alchemyjsonschema'"
      },
      "Alchemytools": {
        "name": "alchemytools",
        "description": "Alchemytools\n------------\n\nThis project brings a set of useful tools to be used in any SQLAchemly project.\n\nThe idea is to save common problems, for example: Opening/Closing sessions, commiting the sesssin only at the end of the transaction, etc.\n\n\nAvailable Tools\n###############\n\nHere are all tools available in alchemytools.\n\nContext Managers\n****************\n\nmanaged\n=======\n\nThis is the basic context manager and it will commit and close your session automatically, at the end of the ``with`` block.\n\n      ::\n\n            with managed(MySessionClass) as session:\n                # Do what you need with your session\n            # Here the session is already closed and commited\n            \nIf you raise any exception inside the ``with`` block, the session will be rolled back and the exception re-raised.\n\nTo avoid having all of the function body inside the ``with`` block, ``managed`` functions as a context manager as well.\n\n      ::\n\n            @managed(MySessionClass)\n            def foo(session, *args, **kwargs):\n                # Do what you need with your session\n                pass\n\n\n            # call as if the session didn't exist:\n            foo(2, a='b')\n\nThe session is opened every time the function is called and closed whenever it returns or raises an exception. Autommit and rollback rules work as normal.\n\nAdditional options\n^^^^^^^^^^^^^^^^^^\n   \n * ``auto_flush``: Sets the autoflush option on the SQLAlchemy session, defaults fo ``False``",
        "url": "http://pypi.python.org/pypi/Alchemytools",
        "summary": "Alchemytools is a set of helpers to be used in any SQLAlchemy project",
        "command": "pip install 'Alchemytools'"
      },
      "alchimia": {
        "name": "alchimia",
        "description": "alchimia\n========\n\n``alchimia`` lets you use most of the SQLAlchemy-core API with Twisted, it does\nnot allow you to use the ORM.\n\nGetting started\n---------------\n\n.. code:: python\n\n    from alchimia import TWISTED_STRATEGY\n\n    from sqlalchemy import (\n        create_engine, MetaData, Table, Column, Integer, String\n    )\n    from sqlalchemy.schema import CreateTable\n\n    from twisted.internet.defer import inlineCallbacks\n    from twisted.internet.task import react\n\n\n    @inlineCallbacks\n    def main(reactor):\n        engine = create_engine(\n            \"sqlite://\", reactor=reactor, strategy=TWISTED_STRATEGY\n        )\n\n        metadata = MetaData()\n        users = Table(\"users\", metadata,\n            Column(\"id\", Integer(), primary_key=True),\n            Column(\"name\", String()),\n        )\n\n        # Create the table\n        yield engine.execute(CreateTable(users))\n\n        # Insert some users\n        yield engine.execute(users.insert().values(name=\"Jeremy Goodwin\"))\n        yield engine.execute(users.insert().values(name=\"Natalie Hurley\"))\n        yield engine.execute(users.insert().values(name=\"Dan Rydell\"))\n        yield engine.execute(users.insert().values(name=\"Casey McCall\"))\n        yield engine.execute(users.insert().values(name=\"Dana Whitaker\"))\n\n        result = yield engine.execute(users.select(users.c.name.startswith(\"D\")))\n        d_users = yield result.fetchall()\n        # Print out the users\n        for user in d_users:\n            print \"Username: %s\" % user[users.c.name]\n\n    if __name__ == \"__main__\":\n        react(main, [])\n\nDocumentation\n-------------\n\nThe documentation is all on `Read the Docs`_.\n\n.. _`Read the Docs`: https://alchimia.readthedocs.org/\n\nLimitations\n-----------\n\nThere are some limitations to ``alchimia's`` ability to expose the SQLAlchemy\nAPI.\n\n* Some methods simply haven't been implemented yet. If you file a bug, we'll\n  implement them! See ``CONTRIBUTING.rst`` for more info.\n* Some methods in SQLAlchemy either have no return value, or don't have a\n  return value we can control. Since most of the ``alchimia`` API is predicated\n  on returning ``Deferred`` instances which fire with the underlying SQLAlchemy\n  instances, it is impossible for us to wrap these methods in a useful way.\n  Luckily, many of these methods have alternate spelling. `The docs`_ call these\n  out in more detail.\n\n.. _`The docs`: https://alchimia.readthedocs.org/en/latest/limitations/",
        "url": "http://pypi.python.org/pypi/alchimia",
        "summary": "(SQLAlchemy - ORM) + Twisted = win",
        "command": "pip install 'alchimia'"
      },
      "alchy": {
        "name": "alchy",
        "description": "alchy\n*****\n\n|version| |travis| |coveralls| |license|\n\nA SQLAlchemy extension for its declarative ORM that provides enhancements for model classes, queries, and sessions.\n\nLinks\n=====\n\n- Project: https://github.com/dgilland/alchy\n- Documentation: http://alchy.readthedocs.org\n- PyPi: https://pypi.python.org/pypi/alchy/\n- TravisCI: https://travis-ci.org/dgilland/alchy\n\n\n.. |version| image:: http://img.shields.io/pypi/v/alchy.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/alchy/\n\n.. |travis| image:: http://img.shields.io/travis/dgilland/alchy/master.svg?style=flat-square\n    :target: https://travis-ci.org/dgilland/alchy\n\n.. |coveralls| image:: http://img.shields.io/coveralls/dgilland/alchy/master.svg?style=flat-square\n    :target: https://coveralls.io/r/dgilland/alchy\n\n.. |license| image:: http://img.shields.io/pypi/l/alchy.svg?style=flat-square\n    :target: https://pypi.python.org/pypi/alchy/",
        "url": "http://pypi.python.org/pypi/alchy",
        "summary": "A SQLAlchemy extension for its declarative ORM that provides enhancements for model classes, queries, and sessions.",
        "command": "pip install 'alchy'"
      },
      "al-cloudinsight": {
        "name": "al-cloudinsight",
        "description": "Cloud Insight API\n=======================\n\nThis is an example project which shows how to access the Cloud Insight API using Python.\nOverview\n\nThe Cloud Insight API is a REST API which provides many services related to the Cloud Insight system. The data transmission protocol is JSON objects. The API receives and sends answers as JSON objects and HTTP errors or confirmation as HTTP status code. The CloudInsightAPI class provides an interface and some example methods to access the Cloud Insight API. All the objects accessed by the CloudInsightAPI class will have the JSON response converted to generic Python objects (Bunch) which can have their properties accessed by obj.property syntax instead of dictionary syntax. The print of the objects will return a JSON formatted string to facilitate the visualization of the object data. The requests are made using the Requests library and will raise requests.exceptions.RequestException when some request fail according to the status code error.\n\nThe program.py provide an example of a command line script implementation of the CloudInsightAPI class",
        "url": "http://pypi.python.org/pypi/al-cloudinsight",
        "summary": "This is an example project which shows how to access the Cloud Insight API using Python.",
        "command": "pip install 'al-cloudinsight'"
      },
      "alco": {
        "name": "alco",
        "description": "ALCO - Autonomous Log Collector and Observer\n============================================\n\n|PyPI version|\n\nWhat's the problem\n------------------\n\nThere is a widely used stack of technologies for parsing, collecting and\nanalysing logs - `ELK Stack <https://www.elastic.co/products>`__. It has\nvery functional web interface, search cluster and a log transformation\ntool. Very cool, but:\n\n-  It's Java with well-known requirements for memory and CPUs\n-  It's ElasticSearch with it's requirements for disk space\n-  It's nodejs-based Logstash witch suddenly stops processing logs in\n   some conditions.\n-  It's Kibana with very cool RICH interface which looses on all counts\n   to ``grep`` and ``less`` in a task of log reading and searching.\n\nIntroducing ALCO\n----------------\n\nALCO is a simple ELK analog which primary aim is to provide a online\nreplacement for ``grep`` and ``less``. Main features are:\n\n-  Django application for incident analysis in distributed systems\n-  schemeless full-text index with filtering and searching\n-  configurable log collection and rotation from RabbitMQ messaging\n   server\n-  not a all-purpose monster\n\nTechnology stack\n----------------\n\nLet's trace log message path from some distributed system to ALCO web\ninterface.\n\n1. Python-based project calls ``logger.debug()`` method with text 'hello\n   world'\n2. At startup time\n   `Logcollect <https://github.com/tumb1er/logcollect/>`__ library\n   automatically configures python logging (or even\n   `Django <https://github.com/django/django/>`__ and\n   `Celery <https://github.com/celery/celery>`__ one's) to send log\n   messages to RabbitMQ server in JSON format readable both with ELK and\n   ALCO projects.\n3. ALCO log collector binds a queue to RabbitMQ exchange and processes\n   messages in a batch.\n4. It uses Redis to collect unique values for filterable fields and\n   SphinxSearch to store messages in a realtime index.\n5. When a message is inserted to sphinxsearch, it contains indexed\n   ``message`` field, timestamp information and schemeless JSON field\n   named ``js`` with all log record attributes sent by python log.\n6. Django-based web interface provides API and client-side app for\n   searching collected logs online.\n\nRequirements\n------------\n\n-  Python 2.7 or 3.3+\n-  `Logcollect <https://github.com/tumb1er/logcollect/>`__ for python\n   projects which logs are collected\n-  `RabbitMQ <https://www.rabbitmq.com/>`__ server for distributed log\n   collection\n-  `SphinxSearch <http://sphinxsearch.com/>`__ server 2.3 or later for\n   log storage\n-  `Redis <http://redis.io/>`__ for SphinxSearch docid management and\n   field values storage\n-  `django-sphinxsearch <https://github.com/tumb1er/django_sphinxsearch>`__\n   as a database backend for ``Django>=1.8`` (will be available from\n   PyPI)\n\nSetup\n-----\n\n1.  You need to configure logcollect in analyzed projects (see\n    `README <https://github.com/tumb1er/logcollect#tips-for-configuration>`__).\n    If RabbitMQ admin interface shows non-zero message flow in\n    ``logstash`` exchange - \"It works\" :-)\n\n2.  Install alco and it's requirements from PyPi\n\n    .. code:: sh\n\n        pip install alco\n\n3.  Next, create django project, add ``sphinxsearch`` database\n    connection and configure ``settings.py`` to enable alco applications\n\n    .. code:: python\n\n        # For SphinxRouter\n        SPHINX_DATABASE_NAME = 'sphinx'\n\n        DATABASES[SPHINX_DATABASE_NAME] = {\n              'ENGINE': 'sphinxsearch.backend.sphinx',\n              'HOST': '127.0.0.1',\n              'PORT': 9306,\n          }\n        }\n\n        # Auto routing log models to SphinxSearch database\n        DATABASE_ROUTERS = (\n          'sphinxsearch.routers.SphinxRouter',\n        )\n\n        INSTALLED_APPS += [\n        'rest_framework', # for API to work\n        'alco.collector',\n        'alco.grep'\n        ]\n\n        ROOT_URLCONF = 'alco.urls'\n\n4.  Configure ALCO resources in ``settings.py``:\n\n    .. code:: python\n\n        ALCO_SETTINGS = {\n          # log messaging server\n          'RABBITMQ': {\n              'host': '127.0.0.1',\n              'userid': 'guest',\n              'password': 'guest',\n              'virtual_host': '/'\n          },\n\n          # redis server\n          'REDIS': {\n              'host': '127.0.0.1',\n              'db': 0\n          },\n          # url for fetching sphinx.conf dynamically\n          'SPHINX_CONF_URL': 'http://127.0.0.1:8000/collector/sphinx.conf',\n          # name of django.db.connection for SphinxSearch\n          'SPHINX_DATABASE_NAME': 'sphinx',\n          # number of results in log view API\n          'LOG_PAGE_SIZE': 100\n        }\n\n        # override defaults for sphinx.conf template\n        ALCO_SPHINX_CONF = {\n          # local index definition defaults override \n          'index': {\n            'min_word_len': 8\n          },\n          # searchd section defaults override\n          'searchd': {\n            'dist_threads': 8\n          }\n        }\n\n5.  Run ``syncdb`` or better ``migrate`` management command to create\n    database tables.\n\n6.  Run webserver and create a LoggerIndex from `django\n    admin <http://127.0.0.1:8000/admin/collector/loggerindex/>`__.\n\n7.  Created directories for sphinxsearch:\n\n    ::\n\n        /var/log/sphinx/\n        /var/run/sphinx/\n        /data/sphinx/\n\n8.  Next, configure sphinxsearch to use generated config:\n\n    .. code:: sh\n\n\n        searchd -c sphinx_conf.py\n\n    ``sphinx_conf.py`` is a simple script that imports\n    ``alco.sphinx_conf`` module which fetches generated ``sphinx.conf``\n    from alco http api and created directories for SphinxSearch indices:\n\n    .. code:: python\n\n        #!/data/alco/virtualenv/bin/python\n\n        # coding: utf-8\n        import os\n        os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'settings')\n\n        from alco import sphinx_conf\n\n9.  Run log collectors:\n\n    .. code:: sh\n\n        python manage.py start_collectors --no-daemon\n\n    If it shows number of collected messages periodically - then log\n    collecting is set up correctly.\n\n10. Configure system services to start subsystems automatically:\n\n    -  nginx or apache http server\n    -  django uwsgi backend\n    -  alco collectors (``start_collectors`` management command)\n    -  sphinxsearch, redis, default database for Django\n\n11. Open ``http://127.0.0.1:8000/grep/<logger_name>/`` to read and\n    search logs online.\n\nVirtualenv\n----------\n\nWe successfully configured SphinxSearch to use python from\n``virtualenv``, adding some environment variables to start script (i.e.\nFreeBSD rc.d script):\n\n.. code:: sh\n\n\n    sphinxsearch_prestart ()\n    {\n        # nobody user has no HOME\n        export PYTHON_EGG_CACHE=/tmp/.python-eggs\n        # python path for virtualenv interpreter should be redeclared\n        export PYTHONPATH=${venv_path}/lib/python3.4/:${venv_path}/lib/python3.4/site-packages/\n        . \"${virtualenv_path}/bin/activate\" || err 1 \"Virtualenv is not found\"\n        echo \"Virtualenv ${virtualenv_path} activated: `which python`\"\n\n    }\n\nIn this case *shebang* for ``sphinx_conf.py`` must point virtualenv's\npython interpreter.\n\nProduction usage\n----------------\n\nFor now ALCO stack is tested in preproduction environment in our company\nand is actively developed. There are no reasons to say that it's not\nready for production usage.\n\n.. |PyPI version| image:: https://badge.fury.io/py/alco.svg\n   :target: http://badge.fury.io/py/alco",
        "url": "http://pypi.python.org/pypi/alco",
        "summary": "Autonomous Log Collector and Observer",
        "command": "pip install 'alco'"
      },
      "alcohol": {
        "name": "alcohol",
        "description": ".. image:: https://travis-ci.org/mbr/alcohol.svg?branch=master\n           :target: https://travis-ci.org/mbr/alcohol\n\n.. code::\n\n  from alcohol.mixins.sqlalchemy import SQLAlchemyUserMixin\n\n  class User(Base, SQLAlchemyUserMixin):\n      id = Column(Integer, primary_key=True)\n\n  bob = User()\n\n  # stores a hash of bobs password (using passlib)\n  bob.password = 'bobs_very_secret_password'\n\n  if bob.check_password(some_password):\n      print 'hello, bob!'\n\n  # creates a password-reset token that will work once to change his password\n  # after he forgot it, signed with the servers secret key\n  token = bob.create_password_reset_token(SECRET_KEY)\n\n\nalcohol is a framework for handling user :doc:`authentication` and\n:doc:`authorization`. Both of these parts can be used independently and support\nSQLAlchemy_ and in-memory backends.\n\nAuthorization is handled using *Role Based Access Controls* (a\n`NIST <https://en.wikipedia.org/wiki/NIST>`_-standard) as the underlying\nmodel::\n\n  from alcohol.rbac import DictRBAC\n\n  acl = DictRBAC()\n  acl.assign('bob', 'programmer')\n  acl.assign('alice', 'ceo')\n\n  acl.permit('programmer', 'run_unittests')\n  acl.permit('ceo', 'hire_and_fire')\n\n  acl.allowed('bob', 'run_unittests')    # True\n  acl.allowed('bob', 'hire_and_fire')    # False\n  acl.allowed('alice', 'hire_and_fire')  # True\n\n.. this should be put back in once flask-alcohol is stable/in better shape\n.. While suitable for use in stand-alone, non-web applications it is also a core\n.. ingredient to `Flask-Alcohol <http://pypi.python .org/pypi/flask-alcohol/>`_, a\n.. `Flask <http://flask.pocoo.org/>`_ library that takes this concept even\n.. further.\n\n\nUtilities\n---------\n\nalcohol also ships with a few SQLAlchemy_ mixins for handling updated/modified\ntimestamps, email fields, password-hashes and generating activation/reset\ntokens for the latter two. See :doc:`mixins` for details.\n\n\n.. [1] http://csrc.nist.gov/rbac/sandhu-ferraiolo-kuhn-00.pdf\n.. _SQLAlchemy: http://www.sqlalchemy.org/",
        "url": "http://pypi.python.org/pypi/alcohol",
        "summary": "Handles user authentication, in a way.",
        "command": "pip install 'alcohol'"
      },
      "alder": {
        "name": "alder",
        "description": "Consensus DHT database. Nested key value store.",
        "url": "http://pypi.python.org/pypi/alder",
        "summary": "Asynchrounous Lexical Distributed Event Roster",
        "command": "pip install 'alder'"
      },
      "aldjemy": {
        "name": "aldjemy",
        "description": "=======\nAldjemy\n=======\n\nBase\n----\n\nSmall package for integration SQLAlchemy into an existent Django project.\nThe primary use case of this package is building complex queries that are\nnot possible with the Django ORM.\n\nYou need to include aldjemy at the end of `INSTALLED_APPS`. When models are\nimported, aldjemy will read all models and contribute `sa` attribute to them.\n`sa` attribute is a class, mapped to Table class.\n\nInternally, aldjemy generates tables from Django models. This is an important\ndistinction from the standard decision of using SQLAlchemy reflection.\n\nCode example::\n\n    User.sa.query().filter(User.sa.username=='Brubeck')\n\nM2M sample::\n\n    User.sa.query().join(User.sa.groups).filter(Group.sa.name==\"GROUP_NAME\")\n\nExplicit joins is part of SQLAlchemy philosophy, so aldjemy can't get you exactly\nthe same experience as Django.\nBut aldjemy is not positioned as Django ORM drop-in replacement. It's a helper for special situations.\n\nWe have some stuff in the aldjemy cache too::\n\n    from aldjemy import core\n    core.Cache.models # All generated models\n    core.get_tables() # All tables, and M2M tables too\n\nYou can use this stuff if you need - maybe you want to build queries with tables, or something like this.\n\n\nSettings\n--------\n\nYou can add your own field types to map django types to sqlalchemy ones with\n``ALDJEMY_DATA_TYPES`` settings parameter.  \nParameter must be a ``dict``, key is result of ``field.get_internal_type()``,\nvalue must be a one arg function. You can get idea from ``aldjemy.types``.\n  \nAlso it is possible to extend/override list of supported SQLALCHEMY engines\nusing ``ALDJEMY_ENGINES`` settings parameter.  \nParameter should be a ``dict``, key is substring after last dot from \nDjango database engine setting (e.g. ``sqlite3`` from ``django.db.backends.sqlite3``),\nvalue is SQLAlchemy driver which will be used for connection (e.g. ``sqlite``, ``sqlite+pysqlite``).\nIt could be helpful if you want to use ``django-postgrespool``.\n\n\nMixins\n------\n\nOften django models have helper function and properties that helps to\nrepresent the model's data (`__unicode__`), or represent some model based logic.\n\nTo integrate it with aldjemy models you can put these methods into a separate mixin::\n\n    class TaskMixin(object):\n        def __unicode__(self):\n            return self.code\n\n    class Task(TaskMixin, models.Model):\n        aldjemy_mixin = TaskMixin\n        code = models.CharField(_('code'), max_length=32, unique=True)\n\nVoilà! You can use `unicode` on aldjemy classes, because this mixin will be\nmixed into generated aldjemy model.\n\nIf you want to expose all methods and properties without creating a\nseparate mixin class, you can use the `aldjemy.meta.AldjemyMeta`\nmetaclass::\n\n    from aldjemy.meta import AldjemyMeta\n\n    class Task(models.Model):\n        code = models.CharField(_('code'), max_length=32, unique=True)\n\n        def __unicode__(self):\n            return self.code\n\n        __metaclass__ = AldjemyMeta\n\nThe result is same as with the example above, only you didn't need to\ncreate the mixin class at all.\n\nAlso note that with Python 3, the syntax is a bit different::\n\n    class Task(models.Model, metaclass=AldjemyMeta):\n        code = models.CharField(_('code'), max_length=32, unique=True)\n\n        def __str__(self):\n            return self.code",
        "url": "http://pypi.python.org/pypi/aldjemy",
        "summary": "SQLAlchemy to Django integration library",
        "command": "pip install 'aldjemy'"
      },
      "aldream_test": {
        "name": "aldream_test",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aldream_test",
        "summary": "i don't care",
        "command": "pip install 'aldream_test'"
      },
      "aldryn-addons": {
        "name": "aldryn-addons",
        "description": "#######################\nAldryn Addons Framework\n#######################\n\n\n|PyPI Version|\n\n`Aldryn addons`_ are re-usable django apps that follow certain conventions to\nabstract out complicated configuration from the individual django website\nproject into upgradable packages. With this approach it is possible\nto avoid repetitive \"add this to ``INSTALLED_APPS`` and that to\n``MIDDLEWARE_CLASSES`` and add these to ``urls.py``\" work. The settings logic\nis bundled with the Addon and only interesting \"meta\" settings are exposed.\n\n``aldryn-addons`` is a framework to utilise such Addons in django projects.\n\nThe goal is to keep the footprint inside the django website project as small\nas possible, so updating things usually just mean bumping a version in\n``requirements.txt`` and no other changes in the project.\n\n\n======================\nInstallation & Updates\n======================\n\n*********************\nAldryn Platform Users\n*********************\n\nNothing to do. ``aldryn-addons`` is part of the Aldryn Platform.\n\n*******************\nManual Installation\n*******************\n\nAdd ``aldryn-addons`` to your projects ``requirements.txt`` or pip install it.\nIt is also highly recommended to install ``aldryn-django``. This is django\nitself bundled as an Addon.\n::\n\n    pip install aldryn-addons aldryn-django==1.6.11\n\n\nsettings.py\n===========\n\nAt the top if the settings the following code snippet::\n\n    INSTALLED_ADDONS = [\n        'aldryn-django',\n    ]\n\n    # add your own settings here that are needed by the installed Addons\n\n    import aldryn_addons.settings\n    aldryn_addons.settings.load(locals())\n\n    # add any other custom settings here\n\n\nurls.py\n=======\n\nAddons can automatically add stuff to the root ``urls.py`` so it's necessary\nto add ``aldryn_addons.urls.patterns()`` and\n``aldryn_addons.urls.i18n_patterns()``.\nThe code below is for Django 1.8 and above. For older versions of Django,\nplease add the prefix parameter to ``i18n_patterns``: ``i18n_patterns('', ...``\n::\n\n    from django.conf.urls import url, include\n    from django.conf.urls.i18n import i18n_patterns\n    import aldryn_addons.urls\n\n\n    urlpatterns = [\n        # add your own patterns here\n    ] + aldryn_addons.urls.patterns() + i18n_patterns(\n        # add your own i18n patterns here\n        url(r'^myapp/', include('myapp.urls')),\n        *aldryn_addons.urls.i18n_patterns()  # MUST be the last entry!\n    )\n\n\nPlease follow the installation instructions for aldryn-django for complete\nintegration.\nThen follow the setup instructions for aldryn-cms for the examples below.\n\n\nAdding Addons\n=============\n\nIn this example we're going to install `Aldryn Newsblog`_, which requires\n`django CMS`_.\n\npip install the Addon::\n\n    pip install aldryn-newsblog\n\nAdd it to ``INSTALLED_ADDONS`` in ``settings.py``::\n\n    INSTALLED_ADDONS = [\n        'aldryn-django',\n        'aldryn-cms',\n        'aldryn-newsblog',\n    ]\n\nCopy ``aldryn_config.py`` and ``addon.json`` from the Addon into the ``addons``\ndirectory within your project (``addons/aldryn-newsblog/aldryn_config.py`` and\n``addons/aldryn-newsblog/addon.json``). If ``aldryn_config.py`` defines any\nsettings on the settings Form, put them in\n``addons/aldryn-newsblog/settings.json``, if not put ``{}`` into it.\n\n.. Note:: The need to manually copy ``aldryn_config.py`` and ``addon.json`` is\n          due to legacy compatibility with the Aldryn Platform and will no\n          longer be necessary in a later release.\n\n.. Note:: Future versions will include a little webserver with a graphical UI\n          to edit the settings in ``settings.json``, much like it is provided\n          on the Aldryn Platform.\n\n\nYou are all set. The code in ``aldryn_config.py`` will take care of configuring\nthe Addon.\n\n\n============\nContributing\n============\n\nThis is a community project. We love to get any feedback in the form of\n`issues`_ and `pull requests`_. Before submitting your pull request, please\nreview our guidelines for `Aldryn addons`_.\n\n.. _issues: https://github.com/aldryn/aldryn-addons/issues\n.. _pull requests: https://github.com/aldryn/aldryn-addons/pulls\n.. _Aldryn addons: http://docs.aldryn.com/en/latest/reference/addons/index.html\n.. _Aldryn Newsblog: https://github.com/aldryn/aldryn-newsblog\n.. _django CMS: https://github.com/aldryn/aldryn-cms\n\n.. |PyPI Version| image:: http://img.shields.io/pypi/v/aldryn-addons.svg\n   :target: https://pypi.python.org/pypi/aldryn-addons\n",
        "url": "http://pypi.python.org/pypi/aldryn-addons",
        "summary": "Aldryn Addons Framework",
        "command": "pip install 'aldryn-addons'"
      },
      "aldryn-apphook-reload": {
        "name": "aldryn-apphook-reload",
        "description": "aldryn-apphook-reload\n=====================\n\n.. image:: https://travis-ci.org/aldryn/aldryn-apphook-reload.svg?branch=develop\n    :target: https://travis-ci.org/aldryn/aldryn-apphook-reload\n\n.. image:: https://img.shields.io/coveralls/aldryn/aldryn-apphook-reload.svg\n  :target: https://coveralls.io/r/aldryn/aldryn-apphook-reload\n\nReload urls of django CMS Apphooks without a restart\n\n\n.. warning:: This is a Prototype.\n\n\nIntroduction\n------------\n\nDjango CMS allows `extending cms pages with Apphooks\n<http://django-cms.readthedocs.org/en/support-3.0.x/introduction/apphooks.html>`_.\nApphooks are saved in the Database, which means urls depend on the database contents. For changes\nto Apphooks to be reflected in ``reverse()`` and ``{% url ... %}`` calls, a webserver restart\nis usually necessary.\n\naldryn-apphook-reload will automatically reload urls from Django CMS apphooks, without the need\nof a webserver restart. It listens to ``cms.signals.urls_need_reloading`` and causes a reload.\n\nThe signal is only available in the process where the change to the database was made. In order\nfor other processes to know when to reload (be it a gunicorn worker or a process on a other server)\na token is saved in the database. This implies a performance hit: 1 database query per request.\n\n\nInstallation\n------------\n\n* add ``aldryn_apphook_reload`` to ``INSTALLED_APPS``.\n\n* add ``aldryn_apphook_reload.middleware.ApphookReloadMiddleware`` to ``MIDDLEWARE_CLASSES``\n  (place it as close to the top as possible)\n\n* run migrations: ``python manage.py migrate aldryn_apphook_reload``\n\n\nAdvanced\n--------\n\nIf the process that triggers ``cms.signals.urls_need_reloading`` is a simple ``runserver`` under\nload ( ~2 requests per second), the reload sometimes fails on the other processes. This might be\ndue to an unknown race condition, where the token in the database is refreshed already, but the\nnew apphooks are not in the database yet. The other processes would try to reload right away\nand would reload the old apphooks.\nTests with gunicorn in the default mode and in the gevent mode worked fine though.\n\nWhy not save the token in the cache backend for better performance? - Because altering the cache\nwould happen right away, before the database transaction is committed at the end of the request.\nThus other process would reload their urls prematurely.",
        "url": "http://pypi.python.org/pypi/aldryn-apphook-reload",
        "summary": "Reload urls of django CMS Apphooks without a restart",
        "command": "pip install 'aldryn-apphook-reload'"
      },
      "aldryn-apphooks-config": {
        "name": "aldryn-apphooks-config",
        "description": "|PyPI Version| |Build Status| |Coverage Status|\n\n======================\naldryn-apphooks-config\n======================\n\nNamespaces based configuration for Apphooks\n\nBasic concepts\n==============\n\nThe concept of apphooks-config is to store all the configuration\nin an applications-specific model, and let the developer\nspecify the desired option in a form.\nIn the views the model instance specific for the current\napplication namespace is loaded (through a mixin) and it's\nthus available in the view to provide the configuration for\nthe current namespace.\n\nNamespaces can be created on the fly in the ``Page`` admin\n**Advanced settings** by following the steps above.\nWhen creating an application configuration, you are in fact defining a\nnamespace, which is saved in the same field in the ``Page`` model as the\nplain namespaces.\n\n\nImplementation step-guide\n=========================\n\n* Define a AppHookConfig model::\n\n    from aldryn_apphooks_config.models import AppHookConfig\n\n    class NewsBlogConfig(AppHookConfig):\n        pass\n\n  Implementation can be completely empty as the schema is defined in the\n  parent (abstract) model\n\n* Use apphooks managers in your model::\n\n    from aldryn_apphooks_config.managers import AppHookConfigManager\n\n    class Article(models.Model):\n        title = models.CharField()\n\n        objects = AppHookConfigManager()\n\n``AppHookConfigManager`` adds ``namespace`` method to manager and queryset::\n\n    Article.objects.namespace('foobar')\n\nThere is also a proper queryset, the ``ApphooksConfigQueryset``. Parler\nintegrated variants can be found in ``aldryn_apphooks_config.managers.parler``.\nNames are ``AppHookConfigTranslatableManager`` and\n``AppHookConfigTranslatableQueryset``.\n\n* Define a ConfigForm::\n\n    from app_data import AppDataForm\n    from django import forms\n    from aldryn_newsblog.models import NewsBlogConfig\n    from aldryn_apphooks_config.utils import setup_config\n\n    class BlogOptionForm(AppDataForm):\n        # fields are totally arbitrary: any form field supported by\n        # django-appdata is supported\n        show_authors = forms.BooleanField(required=False)\n        ...\n\n    # this function will register the provided form with the model created\n    # at the above step\n    setup_config(BlogOptionForm, NewsBlogConfig)\n\n* Define an admin class for the AppHookConfig model::\n\n    from django.contrib import admin\n    from aldryn_apphooks_config.admin import BaseAppHookConfig\n\n    class BlogConfigAdmin(BaseAppHookConfig):\n\n        def get_config_fields(self):\n            # this method **must** be implemented and **must** return the\n            # fields defined in the above form, with the ``config`` prefix\n            # This is dependent on the django-appdata API\n            return ('config.show_authors', ...)\n\n* Define a CMSApp derived from CMSConfigApp provided by this application::\n\n    from aldryn_apphooks_config.app_base import CMSConfigApp\n    from cms.apphook_pool import apphook_pool\n    from django.utils.translation import ugettext_lazy as _\n    from .models import NewsBlogConfig\n\n\n    class NewsBlogApp(CMSConfigApp):\n        name = _('NewsBlogApp')\n        urls = ['aldryn_newsblog.urls']\n        app_name = 'aldryn_newsblog'\n        # this option is specific of CMSConfigApp, and links the\n        # CMSApp to a specific AppHookConfig model\n        app_config = NewsBlogConfig\n\n    apphook_pool.register(NewsBlogApp)\n\n* Implements your views inheriting the ``AppConfigMixin``::\n\n    from django.views.generic.detail import DetailView\n    from aldryn_apphooks_config.mixins import AppConfigMixin\n\n    class ArticleDetail(AppConfigMixin, DetailView):\n        def get_queryset(self):\n            return Article.objects.namespace(self.namespace)\n\n  ``AppConfigMixin`` provides a complete support to namespaces, so the view\n  is not required to set anything specific to support them; the following\n  attributes are set for the view class instance:\n\n  * current namespace in ``self.namespace``\n  * namespace configuration (the instance of NewsBlogConfig) in ``self.config``\n  * current application in the ``current_app`` parameter passed to the\n    Response class\n\nTest setup\n==========\n\nTo properly setup the data for tests to run for a apphook-config enabled application,\nmake sure you add the following code to your TestCase::\n\n    MyTestCase():\n\n        def setUp(self):\n            # This is the namespace represented by the AppHookConfig model instance\n            self.ns_newsblog = NewsBlogConfig.objects.create(namespace='NBNS')\n            self.page = api.create_page(\n                'page', self.template, self.language, published=True,\n                # this is the name of the apphook defined in the CMSApp class\n                apphook='NewsBlogApp',\n                # The namespace is the namespace field of the AppHookConfig instance created above\n                apphook_namespace=self.ns_newsblog.namespace)\n            # publish the page to make the apphook available\n            self.page.publish(self.language)\n\n\n.. |PyPI Version| image:: http://img.shields.io/pypi/v/aldryn-apphooks-config.svg\n   :target: https://pypi.python.org/pypi/aldryn-apphooks-config\n.. |Build Status| image:: http://img.shields.io/travis/aldryn/aldryn-apphooks-config/master.svg\n   :target: https://travis-ci.org/aldryn/aldryn-apphooks-config\n.. |Coverage Status| image:: http://img.shields.io/coveralls/aldryn/aldryn-apphooks-config/master.svg\n   :target: https://coveralls.io/r/aldryn/aldryn-apphooks-config?branch=master\n\n\n\n\nHistory\n-------\n\n0.2.6 (2015-10-05)\n++++++++++++++++++\n\n* Add support for Python 3.5\n* Add support for Django 1.9a1\n* Code style cleanup and tests\n\n\n0.2.5 (2015-09-25)\n++++++++++++++++++\n\n* Add support for Django 1.8, django CMS 3.2\n* AppHookConfigTranslatableManager.get_queryset should use queryset_class\n* Skip overriding admin form if app_config field not present\n\n\n0.2.4 (2015-04-20)\n++++++++++++++++++\n\n* Fixes issue where an apphook could not be changed, once set.\n* Addes optional 'default' kwarg to namespace_url templatetag\n\n\n0.1.0 (2014-01-01)\n++++++++++++++++++\n\n* First release on PyPI.",
        "url": "http://pypi.python.org/pypi/aldryn-apphooks-config",
        "summary": "Namespaces based configuration for Apphooks",
        "command": "pip install 'aldryn-apphooks-config'"
      },
      "aldryn-blog": {
        "name": "aldryn-blog",
        "description": "===============\nAldryn Blog App\n===============\n\n.. image:: https://travis-ci.org/aldryn/aldryn-blog.svg?branch=master\n    :target: https://travis-ci.org/aldryn/aldryn-blog\n\n.. image:: https://img.shields.io/coveralls/aldryn/aldryn-blog.svg\n  :target: https://coveralls.io/r/aldryn/aldryn-blog\n\n\nSimple blogging application. It allows you to:\n\n- write a tagable post message\n- plug in latest post messages (optionally filtered by tags)\n- attach post message archive view\n\nInstallation\n============\n\nAldryn Platform Users\n---------------------\n\nChoose a site you want to install the add-on to from the dashboard. Then go to ``Apps -> Install app`` and click ``Install`` next to ``Blog`` app.\n\nRedeploy the site.\n\nManual Installation\n-------------------\n\n**NOTE**: If you are using a database other than PostgresSQL, check out the table below.\n\nDatabase support:\n\n+---------------+----------------------------+-----------------+\n| SQLite3       | MySQL                      | PostgresSQL     |\n+===============+============================+=================+\n| Not supported | Requires Time zone support | Fully supported |\n+---------------+----------------------------+-----------------+\n\n\nRun ``pip install aldryn-blog``.\n\nAdd below apps to ``INSTALLED_APPS``: ::\n\n    INSTALLED_APPS = [\n        …\n        \n        'aldryn_blog',\n        'aldryn_common',\n        'django_select2',\n        'djangocms_text_ckeditor',\n        'easy_thumbnails',\n        'filer',\n        'hvad',\n        'taggit',\n        # for search\n        'aldryn_search',\n        'haystack',\n        …\n    ]\n\nPosting\n=======\n\nYou can add post messages in the admin interface now. Search for the label ``Aldryn_Blog``.\n\nIn order to display them, create a CMS page and install the app there (choose ``Blog`` from the ``Advanced Settings -> Application`` dropdown).\n\nNow redeploy/restart the site again.\n\nThe above CMS site has become a blog post archive view.\n\nAbout the Content of a Post\n---------------------------\n\nIn Aldryn Blog, there are two content fields in each Post which may be confusing:\n\n1. Lead-In and\n2. Body\n\nThe Lead-In is text/html only and is intended to be a brief \"teaser\" or introduction into the blog post. The lead-in is shown in the blog list-views and is presented as the first paragraph (or so) of the blog post itself. **It is not intended to be the whole blog post.**\n\nTo add the body of the blog post, the CMS operator will:\n\n1. Navigate to the blog post view (*not* the list view);\n2. Click the \"Live\" button in the CMS toolbar to go into edit-mode;\n3. Click the \"Structure\" button to enter the structure sub-mode;\n4. Here the operator will see the placeholder \"ALDRYN_BLOG_POST_CONTENT\", use the menu on the far right of the placeholder to add whatever CMS plugin the operator wishes –– this will often be the Text plugin;\n5. Double-click the new Text plugin (or whatever was selected) to add the desired content;\n6. Save changes on the plugin's UI;\n7. Press the \"Publish\" button in the CMS Toolbar.\n\n\nAvailable CMS Plug-ins\n======================\n\n* ``Latest Blog Entries`` plugin lets you list **n** most frequent blog entries filtered by tags.\n* ``Blog Authors`` plugin lists blog authors and the number of posts they have authored.\n* ``Tags`` plugin lists the tags applied to all posts and allows filtering by these tags.\n\n\nSearch\n======\n\nIf you want the blog posts to be searchable, be sure to install ``aldryn-search`` and its dependencies.\nYour posts will be searchable using ``django-haystack``.\n\nYou can turn it this behavior off by setting ``ALDRYN_BLOG_SEARCH = False`` in your django settings.\n\n\nAdditional Settings\n===================\n\n* ``ALDRYN_BLOG_SHOW_ALL_LANGUAGES``: By default, only the blog posts in the current language will be displayed. By setting the value of this option to ``True``, you can change the behaviour to display all posts from all languages instead.\n* ``ALDRYN_BLOG_USE_RAW_ID_FIELDS``: Enable raw ID fields in admin (default = False)\n",
        "url": "http://pypi.python.org/pypi/aldryn-blog",
        "summary": "Adds blogging abilities to django CMS",
        "command": "pip install 'aldryn-blog'"
      },
      "aldryn-boilerplates": {
        "name": "aldryn-boilerplates",
        "description": "###################\naldryn-boilerplates\n###################\n\n.. image:: https://travis-ci.org/aldryn/aldryn-boilerplates.svg?branch=develop\n    :target: https://travis-ci.org/aldryn/aldryn-boilerplates\n\n.. image:: https://img.shields.io/coveralls/aldryn/aldryn-boilerplates.svg\n  :target: https://coveralls.io/r/aldryn/aldryn-boilerplates\n\n\n***********\nThe concept\n***********\n\nAldryn Boilerplates aims to solve a familiar Django problem. Sometimes re-usable applications need\nto provide their own templates and staticfiles, but in order to be useful, these need to commit\nthemselves to particular frontend expectations - thereby obliging the adopter to override these\nfiles in order to adapt the application to other frontends, or create a new fork of the project\naimed at a different frontend setup.\n\nIt's especially difficult to provide a rich and complete frontend for a re-usable application,\nbecause there's a conflict between creating a *useful* frontend and creating an *agnostic* one.\n\nThe solution is to build in provision for different, switchable, frontend expectations into the\nre-usable application, and this is what Aldryn Boilerplates does.\n\nOn the `Aldryn <http://aldryn.com>`_ platform, a *Boilerplate* is a complete set of frontend\nexpectations, assumptions, opinions, conventions, frameworks, templates, static files and more - a\nstandard way of working for frontend development.\n\nMany developers do in fact work with their own preferred standard sets of frontend tools and code\nfor all their projects; in effect, with their own Boilerplates, even if they don't use that name.\nAldryn Boilerplates is intended to make it easier to provide support for multiple Boilerplates in\nres-usable applications, and to switch between them.\n\nIf users of a particular frontend framework or system would like to use it with a certain re-usable\napplication, they now no longer need to rip out and replace the existing one, or override it at the\nproject level every single time. Instead with Aldryn Boilerplates they can simply *add* the\nfrontend files to the application, alongside the ones for existing supported Boilerplates.\n\nA simple setting in the project tells applications that support Aldryn Boilerplates which one to\nuse.\n\n\n*************************\nUsing Aldryn Boilerplates\n*************************\n\nAldryn Boilerplates doesn't change the way regular files in ``templates`` and ``static`` are\ndiscovered - a re-usable application that supports Aldryn Boilerplates can also work perfectly well\nin a project that doesn't have it installed.\n\nHowever, to support Aldryn Boilerplates, your application should place Boilerplate-specific\nfrontend files in ``boilerplates/my-boilerplate-name/templates/`` and\n``boilerplates/my-boilerplate-name/static/``.\n\nFor example, to add support for the Standard Aldryn Boilerplate (`aldryn-boilerplate-bootstrap3`_)\nto your application, place the files in ``boilerplates/bootstrap3/templates/`` and\n``boilerplates/bootstrap3/static/``.\n\n.. hint::\n    don't forget to add ``boilerplates`` to ``Manifest.in``, alongside ``static`` and ``templates``\n    when creating Python packages.\n\n.. note::\n    The convention is to prefix the github repository name with ``aldryn-boilerplate-``. Your\n    Boilerplate could be called something like ``aldryn-boilerplate-mycompany-awesome``. To use it\n    in a project, you'd set ``ALDRYN_BOILERPLATE_NAME = 'mycompany-awesome'`` and put templates\n    and static files into ``boilerplates/mycompany-awesome/`` in Addons.\n    ``ALDRYN_BOILERPLATE_NAME`` is set automatically on Aldryn based on\n    ``\"identifier\": \"mycompany-awesome\"`` in ``boilerplate.json`` when submitting a boilerplate to\n    Aldryn.\n\n\n************\nInstallation\n************\n\n.. note::\n    aldryn-boilerplates comes pre-installed on the Aldryn Platform and\n    ``ALDRYN_BOILERPLATE_NAME`` is set automatically.\n\n::\n\n    pip install aldryn-boilerplates\n\n\n*************\nConfiguration\n*************\n\n::\n\n    INSTALLED_APPS = [\n        ...\n        'aldryn_boilerplates',\n        ...\n    ]\n\n    TEMPLATE_CONTEXT_PROCESSORS = [\n        ...\n        'aldryn_boilerplates.context_processors.boilerplate',\n    ]\n\n    STATICFILES_FINDERS = [\n        'django.contrib.staticfiles.finders.FileSystemFinder',\n        # important! place right before django.contrib.staticfiles.finders.AppDirectoriesFinder\n        'aldryn_boilerplates.staticfile_finders.AppDirectoriesFinder',\n        'django.contrib.staticfiles.finders.AppDirectoriesFinder',\n    ]\n\n    TEMPLATE_LOADERS = [\n        'django.template.loaders.filesystem.Loader',\n        # important! place right before django.template.loaders.app_directories.Loader\n        'aldryn_boilerplates.template_loaders.AppDirectoriesLoader',\n        'django.template.loaders.app_directories.Loader',\n    ]\n\nNow set the name of the Boilerplate you want to use in your project::\n\n    ALDRYN_BOILERPLATE_NAME = 'bootstrap3'\n\n\n******************************************************\nAdding aldryn-boilerplate support to existing packages\n******************************************************\n\nThe recommended approach is to add a dependency to aldryn-boilerplates and to move existing\n``static`` and ``template`` files to a boilerplate folder (completely remove ``static`` and\n``templates``). If you're in the process of re-factoring your existing templates with something\nnew, put them into the ``legacy`` boilerplate folder and set ``ALDRYN_BOILERPLATE_NAME='legacy'``\non projects that are still using the old templates.\nThe new and shiny project can then use ``ALDRYN_BOILERPLATE_NAME='bootstrap3'`` to use the new\nAldryn Bootstrap Boilerplate (`aldryn-boilerplate-bootstrap3`_). Or any other\nboilerplate for that matter.\n\nRemoving ``static`` and ``templates`` has the benefit of removing likely deprecated templates\nfrom the very prominent location, that will confuse newcomers. It also prevents having not-relevant\ntemplates and static files messing up your setup.\n\n\n.. _aldryn-boilerplate-bootstrap3: https://github.com/aldryn/aldryn-boilerplate-standard",
        "url": "http://pypi.python.org/pypi/aldryn-boilerplates",
        "summary": "An extension that allows re-usable apps to provide sets of templates and staticfiles for different boilerplates.",
        "command": "pip install 'aldryn-boilerplates'"
      },
      "aldryn-bootstrap3": {
        "name": "aldryn-bootstrap3",
        "description": "###########################\nAldryn Bootstrap3\n###########################\n\n|PyPI Version| |Build Status| |Coverage Status|\n\naldryn-bootstrap3 is a plugin bundle provided for django CMS. This package extends the most used components of the `Bootstrap <http://getbootstrap.com/>`_ framework. It uses a variety of components for rapid frontend development and implements various best practices from within the front-end community.\n\nfollowing plugins are available:\n\n* `Grid (Row and Column) <http://getbootstrap.com/css/#grid/>`_\n* `Button and Link <http://getbootstrap.com/css/#buttons>`_\n* `Image <http://getbootstrap.com/css/#images>`_\n* Icon (`Fontawesome <http://fortawesome.github.io/Font-Awesome/>`_ and `Glyphicons <http://getbootstrap.com/components/#glyphicons>`_)\n* `Blockquote <http://getbootstrap.com/css/#type-blockquotes>`_\n* `Label <http://getbootstrap.com/components/#labels>`_\n* `Well <http://getbootstrap.com/components/#wells>`_\n* `Alert <http://getbootstrap.com/components/#alerts>`_\n* `Panel (Heading, Body and Footer) <http://getbootstrap.com/components/#panels>`_\n* `Accordion <http://getbootstrap.com/javascript/#collapse-example-accordion>`_\n* `ListGroup <http://getbootstrap.com/components/#list-group>`_\n* `Carousel <http://getbootstrap.com/javascript/#carousel>`_\n* `Spacer <https://github.com/aldryn/aldryn-bootstrap3/wiki/13-spacer>`_\n* `File <https://github.com/aldryn/aldryn-bootstrap3/wiki/14-file>`_\n\n*************\nDocumentation\n*************\n\nFor further information about usage `read the docs <https://github.com/aldryn/aldryn-bootstrap3/wiki>`_.\n\n************\nContribution\n************\n\nYou are very welcome improving this addon for Aldryn and your everyday use, especially the documentation always\nneeds love. Feel free to fork and send us pull requests and checkout the\n`contribution guide <http://aldryn-boilerplate-bootstrap3.readthedocs.org/en/latest/contribution/index.html>`_ within our documentation.\n\n.. |PyPI Version| image:: http://img.shields.io/pypi/v/aldryn-bootstrap3.svg\n   :target: https://pypi.python.org/pypi/aldryn-bootstrap3\n.. |Build Status| image:: http://img.shields.io/travis/aldryn/aldryn-bootstrap3/master.svg\n   :target: https://travis-ci.org/aldryn/aldryn-bootstrap3\n.. |Coverage Status| image:: http://img.shields.io/coveralls/aldryn/aldryn-bootstrap3/master.svg\n   :target: https://coveralls.io/r/aldryn/aldryn-bootstrap3?branch=master\n",
        "url": "http://pypi.python.org/pypi/aldryn-bootstrap3",
        "summary": "cms plugins and helpers for bootstrap3 based sites",
        "command": "pip install 'aldryn-bootstrap3'"
      },
      "aldryn-categories": {
        "name": "aldryn-categories",
        "description": "#################\nAldryn Categories\n#################\n\n|pypi_version| |build_status| |coverage_status| |codeclimate|\n\nAldryn Categories is a simple, Aldryn-compatible project that provides\nhierarchical *categories* as an independent model in your project. Categories\nare similar to *tags*, but are structured into a taxonomy. The project is\nsuitable for I18N projects as Categories are fully translatable.\n\nPlease see the official `Aldryn Categories documentation <http://aldryn-categories.readthedocs.org>`_,\nwhich includes information on installation.\n\nDevelopers should also note that the project maintains\n`UML diagrams <https://github.com/aldryn/aldryn-categories/blob/master/diagrams/aldryn_categories.pdf>`_\nfor this project.\n\n\n************\nContributing\n************\n\nAldryn Categories is a an open-source project. We'll be delighted to receive your\nfeedback in the form of issues and pull requests. Before submitting your pull\nrequest, please review our `guidelines for Aldryn addons <http://docs.aldryn.com/en/latest/reference/addons/index.html>`_.\n\n\n************\nRequirements\n************\n\n1. Python v2.6+\n2. Django v1.6.x + South v1.0.2+ (see note below) or Django v1.7+\n3. django-treebeard v2.0+\n4. django-parler v1.2.1+\n\n\n.. |pypi_version| image:: http://img.shields.io/pypi/v/aldryn-categories.svg\n   :target: https://pypi.python.org/pypi/aldryn-categories\n   :alt: PyPI Version\n.. |build_status| image:: https://travis-ci.org/aldryn/aldryn-categories.svg?branch=master\n   :target: https://travis-ci.org/aldryn/aldryn-categories/\n   :alt: Build Status\n.. |coverage_status| image:: http://img.shields.io/coveralls/aldryn/aldryn-categories/master.svg\n   :target: https://coveralls.io/r/aldryn/aldryn-categories?branch=master\n   :alt: Coverage Status\n.. |codeclimate| image:: https://codeclimate.com/github/aldryn/aldryn-categories/badges/gpa.svg\n   :target: https://codeclimate.com/github/aldryn/aldryn-categories\n   :alt: Code Climate\n",
        "url": "http://pypi.python.org/pypi/aldryn-categories",
        "summary": "Hierarchical categories/taxonomies for your Django project",
        "command": "pip install 'aldryn-categories'"
      },
      "aldryn-client": {
        "name": "aldryn-client",
        "description": "#########################\nAldryn Commandline Client\n#########################\n\n\n**********\nInstalling\n**********\n\n``pip install aldryn-client``\n\n\n****************\nUsing the client\n****************\n\nfor more information see http://docs.aldryn.com/en/latest/client/index.html\n",
        "url": "http://pypi.python.org/pypi/aldryn-client",
        "summary": "The command-line client for the Aldryn Cloud",
        "command": "pip install 'aldryn-client'"
      },
      "aldryn-cms": {
        "name": "aldryn-cms",
        "description": "##########\nAldryn CMS\n##########\n\n\n|PyPI Version|\n\nAn opinionated django CMS setup bundled as an Aldryn Addon.\n\nThis package will auto configure django CMS including some extra tools.\nIt includes django-filer, a default set of plugins, django-hvad and\ndjango-parler, aldryn-boilerplates and some more.\nA future goal is to split some of those other tools into separate Addons.\n\n======================\nInstallation & Updates\n======================\n\n*********************\nAldryn Platform Users\n*********************\n\nNothing to do. ``aldryn-cms`` is part of the Aldryn Platform.\n\n*******************\nManual Installation\n*******************\n\n.. important:: Please follow the setup instructions for installing\n               ``aldryn-addons`` and ``aldryn-django`` first!\n\n\nAdd ``aldryn-cms`` to your projects ``requirements.txt`` or pip install it.\n::\n\n    pip install aldryn-cms==3.1.2.0\n\n\nThe version is made up of the django CMS release with an added digit for the\nrelease version of this package itself.\n\nIf you followed the ``aldryn-addons`` and ``aldryn-django`` installation\ninstructions, you should already have a ``ALDRYN_ADDONS`` setting. Add\n``aldryn-cms`` to it.::\n\n    INSTALLED_ADDONS = [\n        'aldryn-django',\n        'aldryn-cms',\n    ]\n\nCreate the ``addons/aldryn-cms`` directory at the same level as your\n``manage.py``. Then copy ``addon.json``, ``aldryn_config.py`` from\nthe matching sourcecode into it.\nAlso create a ``settings.json`` file in the same directory with the follwing\ncontent::\n\n    {\n      \"cms_templates\": \"[[\\\"default.html\\\", \\\"Default\\\"]]\"\n    }\n\n.. important:: The above ``settings.json`` assume you have a ``default.html``\n               cms template installed.\n\n.. note:: The need to manually copy ``aldryn_config.py`` and ``addon.json`` is\n          due to legacy compatibility with the Aldryn Platform and will no\n          longer be necessary in a later release of aldryn-addons.\n\n\n============\nContributing\n============\n\nThis is a community project. We love to get any feedback in the form of\n`issues`_ and `pull requests`_. Before submitting your pull request, please\nreview our guidelines for `Aldryn addons`_.\n\n.. _issues: https://github.com/aldryn/aldryn-cms/issues\n.. _pull requests: https://github.com/aldryn/aldryn-cms/pulls\n.. _Aldryn addons: http://docs.aldryn.com/en/latest/reference/addons/index.html\n.. _aldryn-cms: https://github.com/aldryn/aldryn-cms\n\n.. |PyPI Version| image:: http://img.shields.io/pypi/v/aldryn-cms.svg\n   :target: https://pypi.python.org/pypi/aldryn-cms\n",
        "url": "http://pypi.python.org/pypi/aldryn-cms",
        "summary": "An opinionated django CMS setup bundled as an Aldryn Addon",
        "command": "pip install 'aldryn-cms'"
      },
      "aldryn-common": {
        "name": "aldryn-common",
        "description": "# Aldryn Common\n\nAldryn Common is a library of helpful utilities for packages in the [Aldryn](http://aldryn.com) ecosystem, and is\nalso aimed at developers of [django CMS](http://django-cms.org) projects.\n\nIt's installed by default in your Aldryn project - you don't need to do anything to install it - and numerous other\nAddons will make use of the tools it provides. Feel free to make use of them in your own projects.\n\nThey include tools for:\n\n* pagination\n* handling slugs (cleaning, ensuring uniqueness)\n* managing times and dates\n\nas well as a variety of helpful templatetags and more.\n\n## Settings:\n* ``ALDRYN_COMMON_PAGINATION_SOFTLIMIT``: Soft-limiting search results. If True, querying a page number larger than max.\n will not fail, but instead return the last available page. Default is True.\n\nRequires [Aldryn Boilerplates](https://github.com/aldryn/aldryn-boilerplates)\n",
        "url": "http://pypi.python.org/pypi/aldryn-common",
        "summary": "Common utitilities",
        "command": "pip install 'aldryn-common'"
      },
      "aldryn-dashboard": {
        "name": "aldryn-dashboard",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aldryn-dashboard",
        "summary": "Dashboard for django CMS",
        "command": "pip install 'aldryn-dashboard'"
      },
      "aldryn-django": {
        "name": "aldryn-django",
        "description": "#############\nAldryn Django\n#############\n\n\n|PyPI Version|\n\nAn opinionated Django setup bundled as an Aldryn Addon.\n\nThis package will auto configure Django, including admin and some other basic\npackages. It also handles sane configuration of the database connection and\nstatic and media files.\n\nThe goal is to keep the footprint inside the django website project as small\nas possible, so updating things usually just means bumping a version in\n``requirements.txt`` and no other changes in the project.\n\n======================\nInstallation & Updates\n======================\n\n*********************\nAldryn Platform Users\n*********************\n\nNothing to do. ``aldryn-django`` is part of the Aldryn Platform.\n\n*******************\nManual Installation\n*******************\n\n.. important:: Please follow the setup instructions for installing\n               ``aldryn-addons`` first!\n\n\nAdd ``aldryn-django`` to your projects ``requirements.txt`` or pip install it.\n::\n\n    pip install aldryn-django==1.6.11.1\n\n\nThe version is made up of the Django release with an added digit for the\nrelease version of this package itself.\n\nIf you followed the ``aldryn-addons`` installation instructions, you should\nalready have a ``ALDRYN_ADDONS`` setting. Add ``aldryn-django`` to it.::\n\n    INSTALLED_ADDONS = [\n        'aldryn-django',\n    ]\n\nCreate the ``addons/aldryn-django`` directory at the same level as your\n``manage.py``. Then copy ``addon.json``, ``aldryn_config.py`` from\nthe matching sourcecode into it.\nAlso create a ``settings.json`` file in the same directory with the follwing\ncontent::\n\n    {\n        \"languages\": \"[\\\"en\\\", \\\"de\\\"]\"\n    }\n\n.. Note:: The need to manually copy ``aldryn_config.py`` and ``addon.json`` is\n          due to legacy compatibility with the Aldryn Platform and will no\n          longer be necessary in a later release of aldryn-addons.\n\n\nmanage.py and wsgi.py\n=====================\n\nAldryn django comes with entrypoints for ``manage.py`` and ``wsgi.py``. This\nmakes it possible to just have a small snippet of code in the website project\nthat should never change inside those files. The details of local project\nsetup (e.g reading environment variables from a ``.env`` file) are then up to\nthe currently installed version of ``aldryn-django``. Also other opinionated\nthings can be done, like using a production-grade wsgi middleware to serve\nstatic and media files.\n\n\nput this in manage.py::\n\n    #!/usr/bin/env python\n    import os\n    from aldryn_django import startup\n\n\n    if __name__ == \"__main__\":\n        startup.manage(path=os.path.dirname(os.path.abspath(__file__)))\n\n\nput this in wsgi.py::\n\n    import os\n    from aldryn_django import startup\n\n\n    application = startup.wsgi(path=os.path.dirname(__file__))\n\n\n====\nAPIs\n====\n\n**********\nMigrations\n**********\n\nTo run migrations, call the command ``aldryn-django migrate``. This will run\na series of commands for the migration stage of a project.\n``aldryn-django`` will run ``python manage.py syncdb`` and\n``python manage.py migrate`` (and on Django>=1.7 just\n``python manage.py migrate``). But any Addon can add stuff to this migration\nstep by appending commands to the ``MIGRATION_COMMANDS`` setting. For example\n``aldryn-cms`` (django-cms as an Addon) will run\n``python manage.py cms fix-tree`` at the migration stage.\n\n\n*****************\nProduction Server\n*****************\n\nCalling ``aldryn-django web`` will start an opinionated Django setup for\nproduction (currently uwsgi based).\n\n\n============\nContributing\n============\n\nThis is a community project. We love to get any feedback in the form of\n`issues`_ and `pull requests`_. Before submitting your pull request, please\nreview our guidelines for `Aldryn addons`_.\n\n.. _issues: https://github.com/aldryn/aldryn-django/issues\n.. _pull requests: https://github.com/aldryn/aldryn-django/pulls\n.. _Aldryn addons: http://docs.aldryn.com/en/latest/reference/addons/index.html\n.. _aldryn-django: https://github.com/aldryn/aldryn-django\n\n.. |PyPI Version| image:: http://img.shields.io/pypi/v/aldryn-django.svg\n   :target: https://pypi.python.org/pypi/aldryn-django\n",
        "url": "http://pypi.python.org/pypi/aldryn-django",
        "summary": "An opinionated Django setup bundled as an Aldryn Addon",
        "command": "pip install 'aldryn-django'"
      },
      "aldryn-events": {
        "name": "aldryn-events",
        "description": "#############\nAldryn-Events\n#############\n\n|PyPI Version| |Build Status| |Coverage Status| |codeclimate| |requires_io|\n\n|Browser Matrix|\n\nAldryn Events is an Aldryn-compatible application for publishing information\nabout events in django CMS.\n\nPlease see the official `Aldryn Events documentation <http://aldryn-events.readthedocs.org>`_,\nwhich includes information on installation and getting started.\n\nIt also contains `documentation for content editors and end-users\n<http://aldryn-events.readthedocs.org/en/latest/user/index.html>`_.\n\n\n************\nContributing\n************\n\nAldryn Events is a an open-source project. We'll be delighted to receive your\nfeedback in the form of issues and pull requests. Before submitting your pull\nrequest, please review our `guidelines for Aldryn addons <http://docs.aldryn.com/en/latest/reference/addons/index.html>`_.\n\n\n************\nRequirements\n************\n\n* Python 2.6 or 2.7\n* django CMS 3.0.12 or later\n* Django 1.6 or 1.7\n\n\nOptional requirements\n=====================\n\n* django-tablib\n\nPackage should be installed manually. Also take in account ``django-tablib``\nlimitations which are listed below.\n\nPython 2.6\n----------\n\nIf you are planning to use ``aldryn-events`` with ``Python 2.6``\nbe aware that event registrations export functions will not work because\n``django-tablib`` package has ``Python 2.6``/``Django 1.6+`` compatibility issues.\n\nDjango 1.8\n----------\n\nUnfortunately ``django-tablib`` does not supports ``Django 1.8`` which means\nthat event registrations export functions will not work.\n\n\n.. |PyPI Version| image:: http://img.shields.io/pypi/v/aldryn-events.svg\n   :target: https://pypi.python.org/pypi/aldryn-events\n.. |Build Status| image:: http://img.shields.io/travis/aldryn/aldryn-events/master.svg\n   :target: https://travis-ci.org/aldryn/aldryn-events\n.. |Coverage Status| image:: http://img.shields.io/coveralls/aldryn/aldryn-events/master.svg\n   :target: https://coveralls.io/r/aldryn/aldryn-events?branch=master\n.. |codeclimate| image:: https://codeclimate.com/github/aldryn/aldryn-events/badges/gpa.svg\n   :target: https://codeclimate.com/github/aldryn/aldryn-events\n   :alt: Code Climate\n.. |requires_io| image:: https://requires.io/github/aldryn/aldryn-events/requirements.svg?branch=master\n   :target: https://requires.io/github/aldryn/aldryn-events/requirements/?branch=master\n   :alt: Requirements Status\n.. |Browser Matrix| image:: https://saucelabs.com/browser-matrix/aldryn-events.svg\n   :target: https://saucelabs.com/u/aldryn-events",
        "url": "http://pypi.python.org/pypi/aldryn-events",
        "summary": "An events app for Aldryn",
        "command": "pip install 'aldryn-events'"
      },
      "aldryn-faq": {
        "name": "aldryn-faq",
        "description": "##########\nAldryn FAQ\n##########\n\n|PyPI Version| |Build Status| |Coverage Status| |codeclimate| |requires_io|\n\n|Browser Matrix|\n\nAldryn FAQ is an `Aldryn <http://aldryn.com>`_-compatible simple Frequently\nAsked Questions (FAQ) application for `django CMS <http://django-cms.org>`_.\n\nIt allows you to present categorized lists of frequently asked questions and\ntheir answers.\n\n**Content editors** looking for documentation on how to use the editing\ninterface should refer to our `user manual`_ section.\n\n**Django developers** who want to learn more about django CMS, as well as\nhow to install, configure and customize it for their own projects should\nrefer to the `documentation`_ sections.\n\n.. _user manual: http://aldryn-faq.readthedocs.org/en/latest/user/index.html\n\n\n======================\nInstallation & Updates\n======================\n\nPlease head over to our `documentation`_ for all the details on how to install,\nconfigure and use Aldryn FAQ.\n\nYou can also find instructions on `how to upgrade`_ from earlier versions.\n\n.. _documentation: http://aldryn-faq.readthedocs.org/en/latest/how_to/index.html\n.. _how to upgrade: http://aldryn-faq.readthedocs.org/en/latest/how_to/upgrade.html\n\n\n============\nContributing\n============\n\nThis is a community project. We love to get any feedback in the form of\n`issues`_ and `pull requests`_. Before submitting your pull request, please\nreview our guidelines for `Aldryn addons`_.\n\n.. _issues: https://github.com/aldryn/aldryn-faq/issues\n.. _pull requests: https://github.com/aldryn/aldryn-faq/pulls\n.. _Aldryn addons: http://docs.aldryn.com/en/latest/reference/addons/index.html\n\n\n.. |PyPI Version| image:: http://img.shields.io/pypi/v/aldryn-faq.svg\n   :target: https://pypi.python.org/pypi/aldryn-faq\n.. |Build Status| image:: http://img.shields.io/travis/aldryn/aldryn-faq/master.svg\n   :target: https://travis-ci.org/aldryn/aldryn-faq\n.. |Coverage Status| image:: http://img.shields.io/coveralls/aldryn/aldryn-faq/master.svg\n   :target: https://coveralls.io/r/aldryn/aldryn-faq?branch=master\n.. |codeclimate| image:: https://codeclimate.com/github/aldryn/aldryn-faq/badges/gpa.svg\n   :target: https://codeclimate.com/github/aldryn/aldryn-faq\n   :alt: Code Climate\n.. |requires_io| image:: https://requires.io/github/aldryn/aldryn-faq/requirements.svg?branch=master\n   :target: https://requires.io/github/aldryn/aldryn-faq/requirements/?branch=master\n   :alt: Requirements Status\n.. |Browser Matrix| image:: https://saucelabs.com/browser-matrix/aldryn-faq.svg\n   :target: https://saucelabs.com/u/aldryn-faq",
        "url": "http://pypi.python.org/pypi/aldryn-faq",
        "summary": "FAQ addon for django CMS",
        "command": "pip install 'aldryn-faq'"
      },
      "aldryn-forms": {
        "name": "aldryn-forms",
        "description": "================\nAldryn Forms App\n================\n\nAldryn Forms allows you to build flexible HTML forms for your `Aldryn <http://aldryn.com>`_ and `django CMS \n<http://django-cms>`_ projects, and to integrate them directly in your pages.\n\nForms can be assembled using the form builder, with the familiar simple drag-and-drop interface of the django CMS\nplugin system.\n\nSubmitted data is stored in the Django database, and can be explored and exported using the admin, while forms can \nbe configured to send a confirmation message to users.\n\nInstallation\n============\n\nAldryn Platform Users\n---------------------\n\nChoose a site you want to install the add-on to from the dashboard. Then go to ``Apps -> Install app`` and click ``Install`` next to ``Forms`` app.\n\nRedeploy the site.\n\nManuall Installation\n--------------------\n\nRun ``pip install aldryn-forms``.\n\nUpdate ``INSTALLED_APPS`` with ::\n\n    INSTALLED_APPS = [\n        …\n        'absolute',\n        'aldryn_forms',\n        'aldryn_forms.contrib.email_notifications',\n        'captcha',\n        'emailit',\n        'filer',\n        …\n    ]\n\nConfigure ``aldryn-boilerplates`` (https://pypi.python.org/pypi/aldryn-boilerplates/).\n\nTo use the old templates, set ``ALDRYN_BOILERPLATE_NAME='legacy'``.\nTo use https://github.com/aldryn/aldryn-boilerplate-standard (recommended, will be renamed to\n``aldryn-boilerplate-bootstrap3``) set ``ALDRYN_BOILERPLATE_NAME='bootstrap3'``.\n\nAlso ensure you define an `e-mail backend <https://docs.djangoproject.com/en/dev/topics/email/#dummy-backend>`_ for your app.\n\n\nCreating a Form\n===============\n\nYou can create forms in the admin interface now. Search for the label ``Aldryn_Forms``.\n\nCreate a CMS page and install the ``Forms`` app there (choose ``Forms`` from the ``Advanced Settings -> Application`` dropdown).\n\nNow redeploy/restart the site again.\n\nThe above CMS site has become a forms POST landing page – a place where submission errors get displayed if there are any.\n\n\nAvailable Plug-ins\n==================\n\n``Form`` plugin lets you embed certain forms on a CMS page.\n\n``Fieldset`` groups fields.\n\n``Text Field`` renders text input.\n\n``Text Area Field`` renders text input.\n\n``Yes/No Field`` renders checkbox.\n\n``Select Field`` renders single select input.\n\n``Multiple Select Field`` renders multiple checkboxes.\n\n``File field`` renders a file upload input.\n\n``Image field`` same as ``file field`` but validates that the uploaded file is an image.\n",
        "url": "http://pypi.python.org/pypi/aldryn-forms",
        "summary": "Create forms and embed them on CMS pages",
        "command": "pip install 'aldryn-forms'"
      },
      "aldryn-gallery": {
        "name": "aldryn-gallery",
        "description": "==============\nAldryn Gallery\n==============\n\n.. image:: https://travis-ci.org/aldryn/aldryn-gallery.svg?branch=master\n    :target: https://travis-ci.org/aldryn/aldryn-gallery\n\n.. image:: https://img.shields.io/coveralls/aldryn/aldryn-gallery.svg\n  :target: https://coveralls.io/r/aldryn/aldryn-gallery\n\n\nAldryn Gallery is build on the principle of plugin-in-plugin provided by django-cms \nsince version 3.0.\n\nThe gallery requires **jQuery** and `classjs <https://github.com/finalangel/classjs-plugins>`_ cl.gallery.\n",
        "url": "http://pypi.python.org/pypi/aldryn-gallery",
        "summary": "Gallery",
        "command": "pip install 'aldryn-gallery'"
      },
      "aldryn-gallery-timed": {
        "name": "aldryn-gallery-timed",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aldryn-gallery-timed",
        "summary": "Aldryn Gallery Slides that can be timed",
        "command": "pip install 'aldryn-gallery-timed'"
      },
      "aldryn-installer": {
        "name": "aldryn-installer",
        "description": "===============================\nAldryn Installer\n===============================\n\n.. image:: https://badge.fury.io/py/aldryn-installer.png\n    :target: http://badge.fury.io/py/aldryn-installer\n    \n.. image:: https://travis-ci.org/nephila/aldryn-installer.png?branch=master\n        :target: https://travis-ci.org/nephila/aldryn-installer\n\n.. image:: https://pypip.in/d/aldryn-installer/badge.png\n        :target: https://crate.io/packages/aldryn-installer?version=latest\n\n.. image:: https://coveralls.io/repos/nephila/aldryn-installer/badge.png?branch=master\n        :target: https://coveralls.io/r/nephila/aldryn-installer?branch=master\n\nCommand to easily bootstrap django CMS projects\n\n* Free software: BSD license\n\nFeatures\n--------\n\n``aldryn-installer`` is a console wizard to help bootstrapping a django CMS\nproject.\n\nRefer to `django CMS Tutorial <http://slid.es/chive/djangocms/fullscreen>`_ on\nhow to properly setup your first django CMS project.\n\nInstallation\n------------\n\n#. Create an empty virtualenv::\n\n    virtualenv /virtualenv/path/my_project\n\n#. Install `aldryn-installer`::\n\n    pip install aldryn-installer\n\n   or::\n\n    pip install -e git+https://github.com/nephila/aldryn-installer#egg=aldryn-installer\n\nDocumentation\n-------------\n\nSee http://aldryn-installer.readthedocs.org\n\nCaveats\n-------\n\nWhile this wizard try to handle most of the things for you, it doesn't check for\nall the proper native (non python) libraries to be installed.\nBefore running this, please check you have the proper header and libraries\ninstalled and available for packages to be installed.\n\nLibraries you would want to check:\n\n* libjpeg (for JPEG support in ``Pillow``)\n* zlib (for PNG support in ``Pillow``)\n* postgresql (for ``psycopg``)\n* libmysqlclient (for ``Mysql-Python``)\n\n\n\n\nHistory\n-------\n\n0.1.0 (2013-10-19)\n++++++++++++++++++\n\n* First public release.\n\n0.1.1 (2013-10-20)\n++++++++++++++++++\n\n* Improved documentation on how to fix installation in case of missing libraries.",
        "url": "http://pypi.python.org/pypi/aldryn-installer",
        "summary": "Command to easily bootstrap django CMS projects",
        "command": "pip install 'aldryn-installer'"
      },
      "aldryn-jobs": {
        "name": "aldryn-jobs",
        "description": "###########\nAldryn Jobs\n###########\n\n|PyPI Version| |Build Status| |Coverage Status| |codeclimate| |requires_io|\n\n|Browser Matrix|\n\n.. |PyPI Version| image:: http://img.shields.io/pypi/v/aldryn-jobs.svg\n   :target: https://pypi.python.org/pypi/aldryn-jobs\n.. |Build Status| image:: http://img.shields.io/travis/aldryn/aldryn-jobs/master.svg\n   :target: https://travis-ci.org/aldryn/aldryn-jobs\n.. |Coverage Status| image:: http://img.shields.io/coveralls/aldryn/aldryn-jobs/master.svg\n   :target: https://coveralls.io/r/aldryn/aldryn-jobs?branch=master\n.. |codeclimate| image:: https://codeclimate.com/github/aldryn/aldryn-jobs/badges/gpa.svg\n   :target: https://codeclimate.com/github/aldryn/aldryn-jobs\n   :alt: Code Climate\n.. |requires_io| image:: https://requires.io/github/aldryn/aldryn-jobs/requirements.svg?branch=master\n   :target: https://requires.io/github/aldryn/aldryn-jobs/requirements/?branch=master\n   :alt: Requirements Status\n.. |Browser Matrix| image:: https://saucelabs.com/browser-matrix/aldryn-jobs.svg\n   :target: https://saucelabs.com/u/aldryn-jobs\n\nAldryn Jobs is an Aldryn-compatible django CMS application for publishing\njob openings and receiving applications.\n\nPlease see the `Aldryn Jobs documentation <http://aldryn-jobs.readthedocs.org>`_,\nwhich includes information on installation and getting started.\n\nIt also contains `documentation for content editors and end-users\n<http://aldryn-jobs.readthedocs.org/en/latest/user/index.html>`_.\n\n************\nContributing\n************\n\nAldryn Jobs is a an open-source project. We'll be delighted to receive your\nfeedback in the form of issues and pull requests. Before submitting your pull\nrequest, please review our\n`guidelines for Aldryn Addons <http://docs.aldryn.com/en/latest/reference/addons/index.html>`_.\n\n\n************\nRequirements\n************\n\n* django CMS 3.0.12 or later\n* Django 1.6.9 or 1.7.x",
        "url": "http://pypi.python.org/pypi/aldryn-jobs",
        "summary": "Publish job openings on your site",
        "command": "pip install 'aldryn-jobs'"
      },
      "aldryn-mailchimp": {
        "name": "aldryn-mailchimp",
        "description": "################\nAldryn MailChimp\n################\n\nAldryn MailChimp is the easiest way to integrate MailChimp into\n`Aldryn <http://aldryn.com>`_ and `django CMS <http://django-cms.org/>`_ sites.\n\nWith Aldryn MailChimp you can:\n\n- Allow users to subscribe to mailing lists\n- Displays existing campaigns\n\nTo activate MailChimp integration:\n\n- provide an ``API Key`` while installing an app\n- create an CMS page for hooking the app (navigate to\n  ``Advanced Settings -> Application`` on CMS edit page)\n\nWhen all above is done, you can add MailChimp integration plugins to\nplaceholders.\n\n===============================\nCategories + Automatic Matching\n===============================\n\nVersion 0.2.4 introduced categories with automatic matching. You can define\ncategories and add keywords to those categories to automatically sort synced\ncampaigns into categories. You can define priorities for both campaigns and\ntheir keywords.\n\n++++++++\nMatching\n++++++++\n\nOnce the campaigns have been fetched, the automatic matcher will go through all\ncategories (starting from the top as defined in\n``/admin/aldryn_mailchimp/category/``) and scan each campaign for the defined\nkeywords. You can specify keywords to be searched in any or multiple of the\nfollowing three:\n\n- campaign title\n- campaign subject\n- campaign content\n\nOnce a match is found, the search for the current campaign will be stopped, the\nfound category will be assigned to the campaign and the matcher will then\ncontinue with the next campaign.\n",
        "url": "http://pypi.python.org/pypi/aldryn-mailchimp",
        "summary": "Plugins for MailChimp integration.",
        "command": "pip install 'aldryn-mailchimp'"
      },
      "aldryn-news": {
        "name": "aldryn-news",
        "description": "===============\nAldryn News App\n===============\n\nSimple news application. It allows you to:\n\n- write a tagable news\n- plug in latest new messages (optionally filtered by tags)\n- attach news archive view\n\nInstallation\n============\n\nAldryn Platrofm Users\n---------------------\n\nChoose a site you want to install the add-on to from the dashboard. Then go to ``Apps -> Install app`` and click ``Install`` next to ``News`` app.\n\nRedeploy the site.\n\nManuall Installation\n--------------------\n\nRun ``pip install aldryn-news``.\n\nAdd below apps to ``INSTALLED_APPS``: ::\n\n    INSTALLED_APPS = [\n        …\n        'taggit',\n        'aldryn_news',\n        'aldryn_search',\n        'django_select2',\n        'djangocms_text_ckeditor',\n        'easy_thumbnails',\n        'filer',\n        'hvad',\n        'haystack', # for search\n        …\n    ]\n\nPosting news\n============\n\nYou can add news in the admin interface now. Search for the label ``Aldryn_News``.\n\nIn order to display them, create a CMS page and install the app there (choose ``News`` from the ``Advanced Settings -> Application`` dropdown).\n\nNow redeploy the site again.\n\nThe above CMS site has become a news archive view.\n\n\nAvailable Plug-ins\n==================\n\n``Latest News Entries`` plugin lets you list **n** most frequent news filtered by tags.\n\n\nSearch\n==================\n\nIf you want the news entries to be searchable, be sure to install ``aldryn-search`` and its dependencies.\nYour entries will be searchable using ``django-haystack``.\n\nYou can turn it this behavior off by setting ``ALDRYN_NEWS_SEARCH = False`` in your django settings.\n",
        "url": "http://pypi.python.org/pypi/aldryn-news",
        "summary": "Publish news in django CMS",
        "command": "pip install 'aldryn-news'"
      },
      "aldryn-newsblog": {
        "name": "aldryn-newsblog",
        "description": "##################\nAldryn News & Blog\n##################\n\n|PyPI Version| |Build Status| |Coverage Status| |codeclimate| |requires_io|\n\n|Browser Matrix|\n\nAldryn News & Blog is an `Aldryn <http://aldryn.com>`_-compatible news and\nweblog application for `django CMS <http://django-cms.org>`_.\n\n**Content editors** looking for documentation on how to use the editing\ninterface should refer to our `user manual`_ section.\n\n**Django developers** who want to learn more about django CMS, as well as\nhow to install, configure and customize it for their own projects should\nrefer to the `documentation`_ sections.\n\nAldryn News & Blog is intended to serve as a model of good practice for\ndevelopment of django CMS and Aldryn applications.\n\n.. _user manual: http://aldryn-newsblog.readthedocs.org/en/latest/user/index.html\n\n\n======================\nInstallation & Updates\n======================\n\nPlease head over to our `documentation`_ for all the details on how to install,\nconfigure and use Aldryn News & Blog.\n\nYou can also find instructions on `how to upgrade`_ from earlier versions.\n\n.. _documentation: http://aldryn-newsblog.readthedocs.org/en/latest/how_to/index.html\n.. _how to upgrade: http://aldryn-newsblog.readthedocs.org/en/latest/how_to/upgrade.html\n\n\n============\nContributing\n============\n\nThis is a community project. We love to get any feedback in the form of\n`issues`_ and `pull requests`_. Before submitting your pull request, please\nreview our guidelines for `Aldryn addons`_.\n\n.. _issues: https://github.com/aldryn/aldryn-newsblog/issues\n.. _pull requests: https://github.com/aldryn/aldryn-newsblog/pulls\n.. _Aldryn addons: http://docs.aldryn.com/en/latest/reference/addons/index.html\n\n\n.. |PyPI Version| image:: http://img.shields.io/pypi/v/aldryn-newsblog.svg\n   :target: https://pypi.python.org/pypi/aldryn-newsblog\n.. |Build Status| image:: http://img.shields.io/travis/aldryn/aldryn-newsblog/master.svg\n   :target: https://travis-ci.org/aldryn/aldryn-newsblog\n.. |Coverage Status| image:: http://img.shields.io/coveralls/aldryn/aldryn-newsblog/master.svg\n   :target: https://coveralls.io/r/aldryn/aldryn-newsblog?branch=master\n.. |codeclimate| image:: https://codeclimate.com/github/aldryn/aldryn-newsblog/badges/gpa.svg\n   :target: https://codeclimate.com/github/aldryn/aldryn-newsblog\n   :alt: Code Climate\n.. |requires_io| image:: https://requires.io/github/aldryn/aldryn-newsblog/requirements.svg?branch=master\n   :target: https://requires.io/github/aldryn/aldryn-newsblog/requirements/?branch=master\n   :alt: Requirements Status\n.. |Browser Matrix| image:: https://saucelabs.com/browser-matrix/aldryn-newsblog.svg\n   :target: https://saucelabs.com/u/aldryn-newsblog",
        "url": "http://pypi.python.org/pypi/aldryn-newsblog",
        "summary": "Adds blogging and newsing capabilities to django CMS",
        "command": "pip install 'aldryn-newsblog'"
      },
      "aldryn-people": {
        "name": "aldryn-people",
        "description": "#############\nAldryn People\n#############\n\n|PyPI Version| |Build Status| |Coverage Status| |codeclimate| |requires_io|\n\n|Browser Matrix|\n\nAldryn People allows you to:\n\n- add people and groups of people to your website\n- display them on CMS pages\n- download vCards\n\nPlease see the `Aldryn People documentation <http://aldryn-people.readthedocs.org>`_,\nwhich includes information on installation and getting started.\n\nIt also contains `documentation for content editors and end-users\n<http://aldryn-people.readthedocs.org/en/latest/user/index.html>`_.\n\n************\nContributing\n************\n\nAldryn People is a an open-source project. We'll be delighted to receive your\nfeedback in the form of issues and pull requests. Before submitting your pull\nrequest, please review our\n`guidelines for Aldryn Addons <http://docs.aldryn.com/en/latest/reference/addons/index.html>`_.\n\n\n************\nRequirements\n************\n\n* django CMS 3.0.12 or later\n* Django 1.6.9 or later (currently tested with 1.6.x, 1.7.x and 1.8.x)\n* Python 2.6 or 2.7 (at present we are held back with a dependency that is incompatible with Python 3)\n\n\n.. |PyPI Version| image:: https://badge.fury.io/py/aldryn_people.svg\n    :target: http://badge.fury.io/py/aldryn_people\n.. |Build Status| image:: https://travis-ci.org/divio/django-cms.svg?branch=develop\n    :target: https://travis-ci.org/divio/django-cms\n.. |Coverage Status| image:: https://img.shields.io/coveralls/aldryn/aldryn-people.svg\n    :target: https://coveralls.io/r/aldryn/aldryn-people\n.. |codeclimate| image:: https://codeclimate.com/github/aldryn/aldryn-people/badges/gpa.svg\n   :target: https://codeclimate.com/github/aldryn/aldryn-people\n   :alt: Code Climate\n.. |Browser Matrix| image:: https://saucelabs.com/browser-matrix/aldryn-jobs.svg\n   :target: https://saucelabs.com/u/aldryn-jobs\n.. |requires_io| image:: https://requires.io/github/aldryn/aldryn-people/requirements.svg?branch=master\n   :target: https://requires.io/github/aldryn/aldryn-people/requirements/?branch=master\n   :alt: Requirements Status",
        "url": "http://pypi.python.org/pypi/aldryn-people",
        "summary": "Aldryn People publishes profile pages for people in your organisation including team members, collaborators, partners, clients, and so on, including photographs and address information.",
        "command": "pip install 'aldryn-people'"
      },
      "aldryn-pypi-stats": {
        "name": "aldryn-pypi-stats",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aldryn-pypi-stats",
        "summary": "Simple plugin to add dynamic stats from PyPI packages.",
        "command": "pip install 'aldryn-pypi-stats'"
      },
      "aldryn-quote": {
        "name": "aldryn-quote",
        "command": "pip install 'aldryn-quote'"
      },
      "aldryn-reversion": {
        "name": "aldryn-reversion",
        "description": "################\nAldryn Reversion\n################\n\n|PyPI Version| |Build Status| |Coverage Status| |codeclimate| |requires_io|\n\n***********\nDescription\n***********\n\nA collection of shared helpers and mixins to provide support for\ndjango-reversion on models with translatable (using django-parler)\nfields and/or django-cms placeholder fields.\n\nNote: ::\n\n    django-parler is optional and is not required. However, if your model is\n    translated with Parler, aldryn-reversion will take translations and the\n    resulting internal Parler translation cache into consideration when making\n    revisions.\n\n\n*****\nUsage\n*****\n\nPlease refer to  `documentation\n<http://aldryn-reversions.readthedocs.org/en/latest/how_to/usage.html>`_. Or\n`Aldryn Reversion documentation index\n<http://aldryn-reversions.readthedocs.org>`_,\n\n\n************\nRequirements\n************\n\n* Python 2.6 or 2.7\n* Django 1.6, 1.7 or 1.8\n* django-reversion\n\nOptional\n========\n\n* django CMS 3.0.12 or later\n* django-parler\n\n\n************\nInstallation\n************\n\nMost likely you don't need to install this addon by yourself, and it is\ninstalled as a dependency for another addon.\nIf you do need to install this addon manually, just follow those steps:\n\n\n1) Run `pip install aldryn-reversion`.\n\n2) Add below apps to ``INSTALLED_APPS``: ::\n\n    INSTALLED_APPS = [\n        …\n        'reversion',\n        'aldryn_reversion',\n        …\n    ]\n\n3) (Re-)Start your application server.\n\n\n.. |PyPI Version| image:: http://img.shields.io/pypi/v/aldryn-reversion.svg\n   :target: https://pypi.python.org/pypi/aldryn-reversion\n.. |Build Status| image:: http://img.shields.io/travis/aldryn/aldryn-reversion/master.svg\n   :target: https://travis-ci.org/aldryn/aldryn-reversion\n.. |Coverage Status| image:: http://img.shields.io/coveralls/aldryn/aldryn-reversion/master.svg\n   :target: https://coveralls.io/r/aldryn/aldryn-reversion?branch=master\n.. |codeclimate| image:: https://codeclimate.com/github/aldryn/aldryn-reversion/badges/gpa.svg\n   :target: https://codeclimate.com/github/aldryn/aldryn-reversion\n   :alt: Code Climate\n.. |requires_io| image:: https://requires.io/github/aldryn/aldryn-reversion/requirements.svg?branch=master\n   :target: https://requires.io/github/aldryn/aldryn-reversion/requirements/?branch=master\n   :alt: Requirements Status\n",
        "url": "http://pypi.python.org/pypi/aldryn-reversion",
        "summary": "Support for django-reversion on models with translatable fields and django-cms placeholder fields.",
        "command": "pip install 'aldryn-reversion'"
      },
      "aldryn-search": {
        "name": "aldryn-search",
        "description": "=================\naldryn-search\n=================\n\nThis package provides a search indexes for easy Haystack 2 integration with django CMS.\nThe package is compatible with `Aldryn <http://www.aldryn.com>`_.\n\nUsage\n=====\n\nAfter installing aldryn-search through your package manager of choice, add ``aldryn_search`` to your\n``INSTALLED_APPS``. If you run a multilingual CMS setup, you have to define a haystack backend for every language\nin use::\n\n    HAYSTACK_CONNECTIONS = {\n        'en': {\n            'ENGINE': 'haystack.backends.solr_backend.SolrEngine',\n            'URL': 'http://my-solr-server/solr/my-site-en/',\n            'TIMEOUT': 60 * 5,\n            'INCLUDE_SPELLING': True,\n            'BATCH_SIZE': 100,\n        },\n        'fr': {\n            'ENGINE': 'haystack.backends.solr_backend.SolrEngine',\n            'URL': 'http://my-solr-server/solr/my-site-fr/',\n            'TIMEOUT': 60 * 5,\n            'INCLUDE_SPELLING': True,\n            'BATCH_SIZE': 100,\n        },\n    }\n\nTo make sure the correct backend is used during search, add ``aldryn_search.router.LanguageRouter`` to your\n``HAYSTACK_ROUTERS`` setting::\n\n    HAYSTACK_ROUTERS = ['aldryn_search.router.LanguageRouter',]\n\n\n\nWhen using multiple languages, usually there's one search backend per language, when indexing it's important to know\nwhich language is currently being used, this can be facilitated by the ``ALDRYN_SEARCH_LANGUAGE_FROM_ALIAS`` setting,\nthis setting could be a callable or a string path that resolves to one.\n\nPlease keep in mind that it's usually not a good idea to import things in your settings, however there are cases where\nit seems overkill to create a function to handle the alias, for example::\n\n    ALDRYN_SEARCH_LANGUAGE_FROM_ALIAS = lambda alias: alias.split('-')[-1]\n\n\nthe example above could be used when using multiple languages and sites, all backends could have a language suffix.\n\nThe same could be achieved using a function defined somewhere else in your code like so::\n\n    ALDRYN_SEARCH_LANGUAGE_FROM_ALIAS = \"my_app.helpers.language_from_alias\"\n\n\n\nIf any of the above return None then ``settings.LANGUAGE_CODE`` will be used.\n\nBy default this setting evaluates to a function that checks if the alias is in ``settings.LANGUAGES`` and if so it\nuses the alias as a language.\n\n\nFor a complete Haystack setup, please refer to their `documentation <http://docs.haystacksearch.org/dev/>`_.\n\nFor more docs, see the ``docs`` folder or the\n`online documentation <http://django-cms-search.readthedocs.org/en/latest/>`_.\n\nIntegration with django CMS\n===========================\n\naldryn-search comes with an App Hook for django CMS, and a search view using Django's class based views. If you\nwant to use this app hook, you can either subclass it and register it yourself, or set\n``ALDRYN_SEARCH_REGISTER_APPHOOK`` to ``True``.\n\nFor pagination, aldryn-search uses ``aldryn_common.paginator.DiggPaginator``. If you want to use this built-in\npagination, make sure to install`django-spurl <https://github.com/j4mie/django-spurl>`_, and add then add ``spurl``\nto ``INSTALLED_APPS``.\n\nPagination\n==========\n\nResults are paginated according to the ``ALDRYN_SEARCH_PAGINATION`` setting (default: 10).\nIf set to ``None`` pagination is disabled.\n",
        "url": "http://pypi.python.org/pypi/aldryn-search",
        "summary": "An extension to django CMS to provide multilingual Haystack indexes",
        "command": "pip install 'aldryn-search'"
      },
      "aldryn-sites": {
        "name": "aldryn-sites",
        "description": "aldryn-sites\n============\n\n.. image:: https://travis-ci.org/aldryn/aldryn-sites.svg?branch=develop\n    :target: https://travis-ci.org/aldryn/aldryn-sites\n\n.. image:: https://img.shields.io/coveralls/aldryn/aldryn-sites.svg\n  :target: https://coveralls.io/r/aldryn/aldryn-sites\n\nExtensions to django.contrib.sites.\n\nFeatures\n--------\n\n* **Domain redirects**: handles smart redirecting to a main domain from alias domains.\n  Taking http/https into consideration.\n\n* **Site auto-population**: automatically populates the Domain name in ``django.contrib.sites.Site.domain`` based\n  on the ``ALDRYN_SITES_DOMAINS`` setting.\n\n\nInstallation\n------------\n\n\n* add ``aldryn_sites`` to ``INSTALLED_APPS``.\n\n* add ``aldryn_sites.middleware.SiteMiddleware`` to ``MIDDLEWARE_CLASSES``\n  (place it **before** ``djangosecure.middleware.SecurityMiddleware`` if redirects should be smart about alias domains\n  possibly not having a valid certificate of their own. The middleware will pick up on ``SECURE_SSL_REDIRECT`` from\n  ``django-secure``.)\n  \nconfigure ``ALDRYN_SITES_DOMAINS``::\n\n    ALDRYN_SITES_DOMAINS = {\n        1: {  # matches SITE_ID\n            'domain': 'www.example.com',  # main domain that all domains in redirects will redirect to.\n                                          # Auto populates ``django.contrib.sites.Site.domain``\n            'aliases': [                  # these domains will be accessible like the main domain (no redirect).\n                'an.other.domain.com',\n                r'^[a-z0-9-]+\\.anysub\\.com$',  # regexes are supported\n            ],\n            'redirects': [                # these domains will be redirected to the main domain.\n                'example.com',            # add ``'*'`` to redirect all non-main domains to the main one.\n                'example.ch',\n                'www.example.ch',\n                r'^[a-z0-9-]+\\.my-redirect-domain\\.com$',  # regexes are supported\n                r'.*',  # matches any domain (Makes the above rules useless. It's just an example)\n            ],\n        }\n    }\n\nWhen using regexes:\n\n* exact matches win over pattern matches\n* pattern redirect matches win over pattern alias matches\n\n\nFurther Settings\n----------------\n\nset ``ALDRYN_SITES_SET_DOMAIN_NAME`` to ``False`` if you don't want ``django.contrib.sites.Site.domain`` to be\nauto-populated (default: ``True``).\n\n\nTODOS\n-----\n\n* validate settings\n* test settings validators\n* log warning if there are Sites in the database that are not in the settings\n* pretty display of how redirects will work (in admin and as a simple util)\n* regex support for aliases\n* form to test redirect logic\n* pre-compile and cache regexes",
        "url": "http://pypi.python.org/pypi/aldryn-sites",
        "summary": "An extension for django.contrib.sites, featuring domain redirects and automatic population of the django.contrib.sites.Site table based on settings.",
        "command": "pip install 'aldryn-sites'"
      },
      "aldryn-snake": {
        "name": "aldryn-snake",
        "description": "aldryn-snake\n============\n\nAdds tail and head context processors for Addons.\n\nInstallation\n------------\n\nAdd ``aldryn_snake.template_api.template_processor`` to your ``TEMPLATE_CONTEXT_PROCESSORS``\nsettings.\n\nSomewhere in your app that will be imported on startup (recommended in ``models.py``) add\nsomething to the api::\n\n    # -*- coding: utf-8 -*-\n    from aldryn_snake.template_api import registry\n    from django.conf import settings\n\n    OPTIMIZELY_SCRIPT = \"\"\"<script src=\"//cdn.optimizely.com/js/%(account_number)s.js\"></script>\"\"\"\n\n\n    def get_crazyegg_script():\n        optimizely_number = getattr(settings, 'OPTIMIZELY_ACCOUNT_NUMBER', None)\n        if optimizely_number:\n            return OPTIMIZELY_SCRIPT % {'account_number': optimizely_number}\n        else:\n            return ''\n\n    registry.add_to_tail(get_crazyegg_script())\n\n\nIf ``add_to_tail`` or ``add_to_head`` receive a callable, it will be called with the ``request``\nkeyword argument.\n\n\nAdd the following in your base template to the ``<head>``::\n\n    {{ ALDRYN_SNAKE.render_head }}\n\nAdd the following in your base template right above ``</body>``::\n\n    {{ ALDRYN_SNAKE.render_tail }}\n",
        "url": "http://pypi.python.org/pypi/aldryn-snake",
        "summary": "Adds header and tail scripts from addons",
        "command": "pip install 'aldryn-snake'"
      },
      "aldryn-snippet": {
        "name": "aldryn-snippet",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aldryn-snippet",
        "summary": "Snippets",
        "command": "pip install 'aldryn-snippet'"
      },
      "aldryn-style": {
        "name": "aldryn-style",
        "description": "============\nAldryn Style\n============\n\nA Plugin for django CMS to add CSS classes to other plugins.\n\n------------\nInstallation\n------------\n\nThis plugin requires `django CMS` 2.4 or higher to be properly installed.\n\n* Within your ``virtualenv`` run ``pip install aldryn-style``\n* Add ``'aldryn_style'`` to your ``INSTALLED_APPS`` setting.\n* Run ``manage.py migrate aldryn_style``.\n\n-----\nUsage\n-----\n\nYou can define styles in your settings.py::\n\n    _ = lambda s: s\n    ALDRYN_STYLE_CLASS_NAMES = (\n        ('info', _('info')),\n        ('new', _('new')),\n        ('hint', _('hint')),\n    )\n\nAfter that you can place other plugins inside this style plugin.\nIt will create a div with a class that was prior selected around this plugin.\n\n------------\nTranslations\n------------\n\nIf you want to help translate the plugin please do it on transifex:\n\nhttps://www.transifex.com/projects/p/django-cms/resource/aldryn-style/",
        "url": "http://pypi.python.org/pypi/aldryn-style",
        "summary": "Style Plugin for django CMS",
        "command": "pip install 'aldryn-style'"
      },
      "aldryn-tours": {
        "name": "aldryn-tours",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aldryn-tours",
        "summary": "Let users take part in your tours",
        "command": "pip install 'aldryn-tours'"
      },
      "aldryn-translation-tools": {
        "name": "aldryn-translation-tools",
        "description": "Aldryn Translation Tools\n========================\n\n|PyPI Version| |Build Status| |Coverage Status|\n\nA collection of shared helpers and mixins for translated django-CMS projects.\n\nTo use, install it into your project using pip::\n\n    pip install aldryn-translation-tools\n\n\nadmin.AllTranslationsMixin\n--------------------------\n\nAutomatically adds a list of language \"tags\" in the changelist. Tag color\nindicates the state of translation for that object. Grey meaning untranslated,\nblue meaning translated. Darker versions of each are used to indicate the\ncurrent language.\n\nEach tag is linked to the specific language tag on the change form of the\nobject.\n\nA similar capability is in HVAD, and now there is this for Parler-based\nprojects.\n\nPreview:\n\n.. image:: https://cloud.githubusercontent.com/assets/615759/7727430/5889f0e0-ff11-11e4-930a-2bfc80bef426.jpg\n\nTo use this, merely import and add the mixin to your Model Admin class: ::\n\n    from parler.admin import TranslatableAdmin\n    from aldryn_translation_tools.admin import AllTranslationsMixin\n\n    class GroupAdmin(AllTranslationsMixin, TranslatableAdmin):\n       # ....\n\nIf you wish to put the tags into a different column, you can add\n`all_translations` to the list_display list wherever you'd like, otherwise the\n\"Languages\" column will automatically be placed on the far right.\n\n\nadmin.LinkedRelatedInlineMixin\n------------------------------\n\nThis admin inline mixin links the first field to the row object's own admin\nchange form.\n\nIf the first field is editable, results are undefined but probably won't work\nas expected. For best results, consider making all fields readonly (since they\ncan be edited with ease by following the link), and disabling the ability to\nadd new objects by overriding has_add_permission() on the inline to always\nreturn ``False``.\n\n\nmodels.TranslatedAutoSlugMixin\n------------------------------\n\nThis is a TranslatableModel mixin that automatically generates a suitable\nslug for the object on ``save()``.\n\nIf ``slug_globally_unique`` is ``True``, then slugs will be required to be\nunique across all languages.\n\nIf ``slug_globally_unique`` is ``False`` (default), then the strategy used here\nis that it is OK for two objects to use the same slug if the slugs are for\ndifferent languages. So if this were used on a translated Article model, these\nURLs would be valid:\n\n``/en/pain`` - An article in EN about physical discomfort\n\n``/fr/pain`` - An article in FR about bread\n\nOf course, this means that when resolving an object from its URL, care must\nbe taken to factor in the language segment of the URL too.\n\nWhen using this mixin, it is important to also set the\n``slug_source_field_name`` property on the implementing model to the name of\nthe translated field which the slug is to be derived from. If you require more\nslugs to be derived from multiple fields (translated or otherwise), simply\noverride the method ``get_slug_source`` to provide the source string for the\nslug.\n\nConfiguration properties\n************************\n\nslug_default\n~~~~~~~~~~~~\nProvide a lazy translated string to use for the default slug should an object\nnot have a source string to derive a slug from.\n\nslug_field_name\n~~~~~~~~~~~~~~~\nProvide the name of the translated field in which generated slug shall\nbe stored.\n\nslug_globally_unique\n~~~~~~~~~~~~~~~~~~~~\nA boolean flag controlling whether slugs are globally unique, or only unique\nwith each language. Default value is False.\n\nslug_max_length\n~~~~~~~~~~~~~~~\nDeclares the max_length of slugs. This defaults to the ``max_length`` of the\nslug_field and is determined via introspection.\n\nslug_separator\n~~~~~~~~~~~~~~\nThis determines the separator used before any index added to the slug. It does\n**not** determine the separator used in the slug itself, which is always ``-``.\nThis is only provided for compatibility with the slugify()`` method in\naldryn_common, but it is not recommended to be used. Defaults to ``-``.\n\nslug_source_field_name\n~~~~~~~~~~~~~~~~~~~~~~\nProvide the name of the translated field to be used for deriving the slug.\nIf more than one field, or other complex sources are required, override the\nmethod ``get_slug_source()`` instead. Note that if ``get_slug_source()`` is\noverriden, it is recommended to also override ``get_slug_default()``.\n\n\nPublic methods\n**************\n\nget_slug_default\n~~~~~~~~~~~~~~~~\n\nNaively constructs a translated default slug from the object. For better\nresults, just set the `slug_default` property on the class to a lazy\ntranslated string. Alternatively, override this method if you need to more\nprogrammtically determine the default slug.\n\nExample: If your model is \"news article\" and your source field is \"title\" this\nwill return \"news-article-without-title\".\n\n\nget_slug_max_length\n~~~~~~~~~~~~~~~~~~~\nAccepts an optional parameter ``idx_len``.\n\nIntrospects the slug field to determine the maximum length, taking into account\na possible separator and up to a [idx_len]-digit number.\n\n\nget_slug_source\n~~~~~~~~~~~~~~~\nSimply returns the value of the slug source field. Override for more complex\nsituations such as using multiple fields (translated or not) as the source.\n\n\nmodels.TranslationHelperMixin\n-----------------------------\n\nPublic Methods\n**************\n\n\nknown_translation_getter()\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSignature::\n\n    (value, language) = obj.known_translation_getter(field, default=None, language_code=None, any_language=False)\n\nActs like Parler's safe_translation_getter(), but respects the fallback\npreferences as defined in `settings.CMS_LANGUAGES` and provides both the\ntranslated value and the language it represents as a tuple.\n\nThis is especially helpful when resolving an object's absolute url for a given\nlanguage. If a fallback is used (respecting preference), then the returned\nlanguage_code can then be used to set the correct context for a reverse() to get\na URL consistent to the resulting language.\n\nFor example::\n\n    from django.utils.translation import override\n\n    from aldryn_translation_tools.models import TranslationHelperMixin\n    from cms.utils.i18n import get_current_language\n    from parler.models import TranslatableModel, TranslatedFields\n\n    class Fruit(TranslationHelperMixin, TranslatableModel):\n        translations = TranslatableFields(\n            name=models.CharField(...),\n            slug=models.CharField(...)\n        )\n\n        def get_absolute_url(self, language=None):\n            language = language or get_current_language()\n            (slug, language) = self.known_translation_getter('slug',\n                default=None, language_code=language, any_language=False)\n            with override(language):\n                return reverse('fruit-detail', kwargs={'slug': slug})\n\nIn contrast, if we had only done something like this::\n\n    ...\n\n        def get_absolute_url(self, language=None)\n            language = language or get_current_language()\n            slug = self.safe_translation_getter('slug', default=None,\n                language_code=language, any_language=False)\n            with override(language):\n                return reverse('fruit-detail', kwargs={'slug': slug})\n\nThen, if the fruit `apple` has not yet been translated to FR it is possible that\nyou'll end up with the slug in a fallback langauge, and the rest of the URL in\nthe requested language, so instead of getting a language-consistent fallback\nurl::\n\n    /en/apple/\n\nYou might get::\n\n    /fr/apple/\n\nWhich, at best, would be confusing for site visitors but more likely won't exist\nresulting in a NoReverseFound exception or 404 and which clearly is not\nrespecting the fallback preferences set by the developer.\n\n\n.. |PyPI Version| image:: https://badge.fury.io/py/aldryn-translation-tools.svg\n   :target: https://pypi.python.org/pypi/aldryn-translation-tools\n.. |Build Status| image:: https://travis-ci.org/aldryn/aldryn-translation-tools.svg\n   :target: https://travis-ci.org/aldryn/aldryn-translation-tools\n.. |Coverage status| image:: https://coveralls.io/repos/aldryn/aldryn-translation-tools/badge.svg?branch=master&service=github\n   :target: https://coveralls.io/github/aldryn/aldryn-translation-tools?branch=master\n\n",
        "url": "http://pypi.python.org/pypi/aldryn-translation-tools",
        "summary": "Collection of helpers and mixins for translated projects",
        "command": "pip install 'aldryn-translation-tools'"
      },
      "aldryn-wordpress-import": {
        "name": "aldryn-wordpress-import",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aldryn-wordpress-import",
        "summary": "Wordpress import for aldryn-blog",
        "command": "pip install 'aldryn-wordpress-import'"
      },
      "aldryn-wow": {
        "name": "aldryn-wow",
        "description": "=============\naldryn-wow\n=============\n\n.. image:: https://badge.fury.io/py/aldryn-wow.svg\n    :target: http://badge.fury.io/py/aldryn-wow\n.. image:: https://travis-ci.org/narayanaditya95/aldryn-wow.svg?branch=master\n    :target: https://travis-ci.org/narayanaditya95/aldryn-wow\n.. image:: https://coveralls.io/repos/narayanaditya95/aldryn-wow/badge.svg?branch=master\n    :target: https://coveralls.io/r/narayanaditya95/aldryn-wow?branch=master\n.. image:: https://landscape.io/github/narayanaditya95/aldryn-wow/master/landscape.svg?style=flat\n    :target: https://landscape.io/github/narayanaditya95/aldryn-wow/master\n    :alt: Code Health\n\n------------\n\nPlugin for django-cms to include awesome animations from `WOW <http://mynameismatthieu.com/WOW/>`_.js and `Animate <http://daneden.github.io/animate.css/>`_.css\n\nInstallation\n------------\n\nThis plugin requires `django CMS` 3.0 or higher to be properly installed.\n\n* In your projects `virtualenv`, run ``pip install aldryn-wow``\n* If using Django 1.6 add ``'aldryn_wow': 'aldryn_wow.south_migrations',``\n  to ``SOUTH_MIGRATION_MODULES``  (or define ``SOUTH_MIGRATION_MODULES`` if it does not exists);\n* Run ``manage.py migrate aldryn_wow``\n\n\nUsage\n-----\n\nDefault content in Placeholder\n******************************\n\nIf you use Django-CMS >= 3.0, you can use ``Animation`` and ``Wow Animation`` in \"default_plugins\"\n(see docs about the CMS_PLACEHOLDER_CONF setting in Django CMS 3.0).\n\nChangelog\n---------\n\nVersion 1.0.0\n*************\n* Drop backward compatibilty.\n* Tested and status upgraded to Production/Stable.\n\nVersion 0.0.3\n*************\n* Make parameter fields in WOW animations optional.\n\nVersion 0.0.2\n*************\n* Fixed packaging issues.\n* Added tests to cover all plugins.\n* Add south and django migrations.\n* Drop support for Python 2.6.\n\nVersion 0.0.1\n*************\n* Initial Release.",
        "url": "http://pypi.python.org/pypi/aldryn-wow",
        "summary": "Plugin for aldryn to include awesome animations from WOW.js and Animate.css",
        "command": "pip install 'aldryn-wow'"
      },
      "alea": {
        "name": "alea",
        "description": null,
        "url": "http://pypi.python.org/pypi/alea",
        "summary": null,
        "command": "pip install 'alea'"
      },
      "alebot": {
        "name": "alebot",
        "description": "alebot\n    ------\n\n    alebot is a super lean and highly modularized irc bot that lets you\n    extend it in a python way, using classes and decorators. It supports\n    both hooks and background tasks in an easy and fail-safe way.\n\n    Links\n    `````\n\n    * `source code <https://github.com/alexex/alebot>`_\n    * `docs <https://alebot.readthedocs.org/`_",
        "url": "http://pypi.python.org/pypi/alebot",
        "summary": "A super lean and highly modularized irc bot",
        "command": "pip install 'alebot'"
      },
      "alembic": {
        "name": "alembic",
        "description": "Alembic is a database migrations tool written by the author\nof `SQLAlchemy <http://www.sqlalchemy.org>`_.  A migrations tool\noffers the following functionality:\n\n* Can emit ALTER statements to a database in order to change\n  the structure of tables and other constructs\n* Provides a system whereby \"migration scripts\" may be constructed;\n  each script indicates a particular series of steps that can \"upgrade\" a\n  target database to a new version, and optionally a series of steps that can\n  \"downgrade\" similarly, doing the same steps in reverse.\n* Allows the scripts to execute in some sequential manner.\n\nThe goals of Alembic are:\n\n* Very open ended and transparent configuration and operation.   A new\n  Alembic environment is generated from a set of templates which is selected\n  among a set of options when setup first occurs. The templates then deposit a\n  series of scripts that define fully how database connectivity is established\n  and how migration scripts are invoked; the migration scripts themselves are\n  generated from a template within that series of scripts. The scripts can\n  then be further customized to define exactly how databases will be\n  interacted with and what structure new migration files should take.\n* Full support for transactional DDL.   The default scripts ensure that all\n  migrations occur within a transaction - for those databases which support\n  this (Postgresql, Microsoft SQL Server), migrations can be tested with no\n  need to manually undo changes upon failure.\n* Minimalist script construction.  Basic operations like renaming\n  tables/columns, adding/removing columns, changing column attributes can be\n  performed through one line commands like alter_column(), rename_table(),\n  add_constraint(). There is no need to recreate full SQLAlchemy Table\n  structures for simple operations like these - the functions themselves\n  generate minimalist schema structures behind the scenes to achieve the given\n  DDL sequence.\n* \"auto generation\" of migrations. While real world migrations are far more\n  complex than what can be automatically determined, Alembic can still\n  eliminate the initial grunt work in generating new migration directives\n  from an altered schema.  The ``--autogenerate`` feature will inspect the\n  current status of a database using SQLAlchemy's schema inspection\n  capabilities, compare it to the current state of the database model as\n  specified in Python, and generate a series of \"candidate\" migrations,\n  rendering them into a new migration script as Python directives. The\n  developer then edits the new file, adding additional directives and data\n  migrations as needed, to produce a finished migration. Table and column\n  level changes can be detected, with constraints and indexes to follow as\n  well.\n* Full support for migrations generated as SQL scripts.   Those of us who\n  work in corporate environments know that direct access to DDL commands on a\n  production database is a rare privilege, and DBAs want textual SQL scripts.\n  Alembic's usage model and commands are oriented towards being able to run a\n  series of migrations into a textual output file as easily as it runs them\n  directly to a database. Care must be taken in this mode to not invoke other\n  operations that rely upon in-memory SELECTs of rows - Alembic tries to\n  provide helper constructs like bulk_insert() to help with data-oriented\n  operations that are compatible with script-based DDL.\n* Non-linear, dependency-graph versioning.   Scripts are given UUID\n  identifiers similarly to a DVCS, and the linkage of one script to the next\n  is achieved via human-editable markers within the scripts themselves.\n  The structure of a set of migration files is considered as a\n  directed-acyclic graph, meaning any migration file can be dependent\n  on any other arbitrary set of migration files, or none at\n  all.  Through this open-ended system, migration files can be organized\n  into branches, multiple roots, and mergepoints, without restriction.\n  Commands are provided to produce new branches, roots, and merges of\n  branches automatically.\n* Provide a library of ALTER constructs that can be used by any SQLAlchemy\n  application. The DDL constructs build upon SQLAlchemy's own DDLElement base\n  and can be used standalone by any application or script.\n* At long last, bring SQLite and its inablity to ALTER things into the fold,\n  but in such a way that SQLite's very special workflow needs are accommodated\n  in an explicit way that makes the most of a bad situation, through the\n  concept of a \"batch\" migration, where multiple changes to a table can\n  be batched together to form a series of instructions for a single, subsequent\n  \"move-and-copy\" workflow.   You can even use \"move-and-copy\" workflow for\n  other databases, if you want to recreate a table in the background\n  on a busy system.\n\nDocumentation and status of Alembic is at http://alembic.readthedocs.org/",
        "url": "http://pypi.python.org/pypi/alembic",
        "summary": "A database migration tool for SQLAlchemy.",
        "command": "pip install 'alembic'"
      },
      "alembic-offline": {
        "name": "alembic-offline",
        "description": "alembic-offline\n===============\n\n.. image:: https://api.travis-ci.org/paylogic/alembic-offline.png\n   :target: https://travis-ci.org/paylogic/alembic-offline\n\n.. image:: https://pypip.in/v/alembic-offline/badge.png\n   :target: https://crate.io/packages/alembic-offline/\n\n.. image:: https://coveralls.io/repos/paylogic/alembic-offline/badge.svg?branch=master\n    :target: https://coveralls.io/r/paylogic/alembic-offline?branch=master\n\n.. image:: https://readthedocs.org/projects/alembic-offline/badge/?version=latest\n    :alt: Documentation Status\n    :scale: 100%\n    :target: https://readthedocs.org/projects/alembic-offline/\n\nalembic-offline is an extension for alemic to enrich offline functionality of the migrations\n\n.. contents::\n\nUsage\n-----\n\nPhased migrations\n^^^^^^^^^^^^^^^^^\n\nalembic-offline introduces a helper which allows to implement phased migrations, e.g. those which steps\nare divided into logical phases. For example, you can have steps to be executed before code deploy and\nthose after.\n\nIn your alembic config file (main section):\n\n::\n\n    phases = before-deploy after-deploy final\n    default-phase = after-deploy\n\nIn your version file:\n\n.. code-block:: python\n\n    from sqlalchemy import INTEGER, VARCHAR, NVARCHAR, TIMESTAMP, Column, func\n    from alembic import op\n\n    from alembic_offline import phased, execute_script\n\n    from tests.migrations.scripts import script\n\n    revision = '1'\n    down_revision = None\n\n\n    @phased\n    def upgrade():\n\n        op.create_table(\n            'account',\n            Column('id', INTEGER, primary_key=True),\n            Column('name', VARCHAR(50), nullable=False),\n            Column('description', NVARCHAR(200)),\n            Column('timestamp', TIMESTAMP, server_default=func.now())\n        )\n        yield\n        op.execute(\"update account set name='some'\")\n        yield\n        execute_script(script.__file__)\n\n\n    def downgrade():\n        pass\n\nWill give the sql output (for sqlite):\n\n.. code-block:: sql\n\n    -- Running upgrade  -> 1\n\n    -- PHASE::before-deploy::;\n\n    CREATE TABLE account (\n        id INTEGER NOT NULL,\n        name VARCHAR(50) NOT NULL,\n        description NVARCHAR(200),\n        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n        PRIMARY KEY (id)\n    );\n\n    -- PHASE::after-deploy::;\n\n    update account set name='some';\n\n    -- PHASE::final::;\n\n    -- SCRIPT::scripts/script.py::;\n\n    INSERT INTO alembic_version (version_num) VALUES ('1');\n\nAs you see, phases are rendered as SQL comments to divide migration steps, so those who execute migration\ncan see which phase's step it is.\nHowever, if migration procedure is highly customized, you can use alembic-offline API described below.\n`get_migration_data` returns migration phases in special form so you can automate their execution.\n\nArbitrary script as operation\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFor complex migrations, it's not enough to execute sql, you might need some script to be executed instead.\nFor that, there's special operation:\n\n.. code-block:: python\n\n    from alembic_offline import execute_script\n\n    def upgrade():\n        execute_script('scripts/script.py')\n\nIf you'll get migration sql, it will be rendered as SQL comment:\n\n.. code-block:: sql\n\n    -- SCRIPT::scripts/script.py::;\n\nFor those who execute migrations it will be visible and they can execute the script manually.\nHowever, if migration procedure is highly customized, you can use alembic-offline API described below.\n`get_migration_data` returns script migration steps in special form so you can automate their execution.\nFor online mode, the script will be executed as subprocess via python `subprocess` module.\n\nGet migration data\n^^^^^^^^^^^^^^^^^^\n\nalembic-offline provides specialized API to get certain migration data as dictionary:\n\n.. code-block:: python\n\n    from alembic_offline import get_migration_data\n\n    from alemic.config import Config\n\n    config = Config('path to alemic.ini')\n\n    data = get_migration_data(config, 'your-revision')\n\n    assert data == {\n        'revision': 'your-revision',\n        'phases': {\n            'after-deploy': [\n                {\n                    'type': 'mysql',\n                    'script': 'alter table account add column name VARCHAR(255)'\n                },\n                {\n                    'type': 'python',\n                    'script': 'from app.models import Session, Account; Session.add(Account()); Session.commit()',\n                    'path': 'scripts/my_script.py'\n                },\n            ]\n        }\n    }\n\n`get_migration_data` requires both `phases` and `default-phase` configuration options to be set.\n`default-phase` is needed to be able to get migration data even for simple migrations without phases.\n\nGet migration data in batch\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nalembic-offline provides an API call to get migration data for all revisions:\n\n.. code-block:: python\n\n    from alembic_offline import get_migrations_data\n\n    from alemic.config import Config\n\n    config = Config('path to alemic.ini')\n\n    data = get_migrations_data(config)\n\n    assert data == [\n        {\n            'revision': 'your-revision',\n            'phases': {\n                'after-deploy': [\n                    {\n                        'type': 'mysql',\n                        'script': 'alter table account add column name VARCHAR(255)'\n                    },\n                    {\n                        'type': 'python',\n                        'script': 'from app.models import Session, Account; Session.add(Account()); Session.commit()',\n                        'path': 'scripts/my_script.py'\n                    },\n                ]\n            }\n        }\n    ]\n\nCommand line utilities\n^^^^^^^^^^^^^^^^^^^^^^\n\nBecause with alembic revisions it's sometimes hard to find which the correct down revision should be; especially\nwhen there are multiple heads we added the alembic-offline graph command.\n\nThe graph command will generate a `dot file <https://en.wikipedia.org/wiki/DOT_(graph_description_language)>`_ of\nthe revisions, this file can then be converted to an image for easy visualization.\n\nUsage:\n\n::\n\n    alembic-offline graph --filename revisions.dot --alembic-config path/to/alembic.ini\n\nThen if you have `graphviz <https://en.wikipedia.org/wiki/Graphviz>`_ installed you can run:\n\n::\n\n    dot -Tpng -o revisions.png revisions.dot\n\nTo generate a png image.\n\nContact\n-------\n\nIf you have questions, bug reports, suggestions, etc. please create an issue on\nthe `GitHub project page <http://github.com/paylogic/alembic-offline>`_.\n\nLicense\n-------\n\nThis software is licensed under the `MIT license <http://en.wikipedia.org/wiki/MIT_License>`_\n\nPlease refer to the `license file <https://github.com/paylogic/alembic-offline/blob/master/LICENSE.txt>`_\n\n© 2015 Anatoly Bubenkov, Paylogic International and others.\n\nChangelog\n=========\n\n1.2.0\n-----\n\n* add migration dependency tree generation command (hvdklauw)\n\n1.1.0\n-----\n\n* add down_revision to migration data (bubenkoff)\n* reverse migration order to simplify the application (bubenkoff)\n\n1.0.5\n-----\n\n* correctly handle multi-phased migration data extraction (bubenkoff)\n\n1.0.4\n-----\n\n* online script execution implemented (bubenkoff)\n* `get_migrations_data` API (bubenkoff)\n\n1.0.3\n-----\n\n* Added arbitrary script operation (bubenkoff)\n* Strict phases configuration assertions for phased migration decorator (bubenkoff)\n* `get_migration_data` API (bubenkoff)\n\n1.0.0\n-----\n\n* Initial public release (bubenkoff)",
        "url": "http://pypi.python.org/pypi/alembic-offline",
        "summary": "Offline extensions for alemic database migration framework",
        "command": "pip install 'alembic-offline'"
      },
      "alengen": {
        "name": "alengen",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alengen",
        "summary": "Automatic model code generator for SQLAlchemy",
        "command": "pip install 'alengen'"
      },
      "aleparser": {
        "name": "aleparser",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aleparser",
        "summary": "A simple python ALE (AvidLogExchange) parser.",
        "command": "pip install 'aleparser'"
      },
      "alerta": {
        "name": "alerta",
        "description": "Introduction\n============\n\nAlerta is a monitoring tool that allows alerts from many different systems to be consolidated into a single view.\n\nCurrently there are integrations for tools that support standard protocols such as ``SNMP``, ``syslog`` and ``HTTP``.\nThere are also specific integrations for popular monitoiring tools such as Nagios_, Zabbix_, Sensu_ and Riemann_.\n\n.. _`nagios`: https://github.com/alerta/nagios3-alerta\n.. _`zabbix`: https://github.com/alerta/zabbix-alerta\n.. _`sensu`: https://github.com/alerta/sensu-alerta\n.. _`riemann`: https://github.com/guardian/riemann-config/blob/master/alerta.clj\n\n\nInstallation\n============\n\nInstalling this package makes available a command-line tool that can be used to send alerts to the alerta system and\nto query the alert database::\n\n    $ pip install alerta-client\n\n\nConfiguration\n=============\n\nConfiguration supports profiles for different environments like `production` and `development` or `testing`.\n\nFor a basic configuration that can be used to test the client tools against a demo alerta server, use::\n\n    [DEFAULT]\n    timezone = Europe/London\n\n    [profile production]\n    endpoint = http://alerta.prod.com:8080\n    debug = no\n\n    [profile development]\n    endpoint = http://alerta.dev.com:8080\n    debug = yes\n\nCopy this configuration ``$HOME/.alerta.conf`` files::\n\n    $ mv /path/to/alerta.conf.sample $HOME/.alerta.conf\n\nor use the ``ALERTA_CONF`` environment variable::\n\n    $ export ALERTA_CONF=/path/to/alerta.conf\n\n\nUsage\n=====\n::\n\n    $ alert help\n    usage: alert [OPTIONS] COMMAND [FILTERS]\n\n    Alerta client unified command-line tool\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      --profile PROFILE     Select profile to apply from ~/.alerta.conf\n      --endpoint-url URL    API endpoint URL\n      --output OUTPUT       Output format of \"text\" or \"json\"\n      --json, -j            Output in JSON format. Shortcut for \"--output json\"\n      --color, --colour     Color-coded output based on severity\n      --debug               Print debug output\n\n    Commands:\n        send                Send alert to server\n        query               List alerts based on query filter\n        watch               Watch alerts based on query filter\n        raw                 Show alert raw data\n        history             Show alert history\n        tag                 Tag alerts\n        ack                 Acknowledge alerts\n        unack               Unacknowledge alerts\n        close               Close alerts\n        delete              Delete alerts\n        heartbeat           Send heartbeat to server\n        help                Show help\n        version             Show alerta version info\n\n    Filters:\n        Query parameters can be used to filter alerts by any valid alert attribute\n\n        resource=web01     Show alerts with resource equal to \"web01\"\n        resource!=web01    Show all alerts except those with resource of \"web01\"\n        event=~down        Show alerts that include \"down\" in event name\n        event!=~down       Show all alerts that don't have \"down\" in event name\n\n        Special query parameters include \"limit\", \"sort-by\", \"from-date\" and \"q\" (a\n        json-compliant mongo query).\n\n\nExamples\n========\n\n::",
        "url": "http://pypi.python.org/pypi/alerta",
        "summary": "Alerta unified command-line tool",
        "command": "pip install 'alerta'"
      },
      "alerta-server": {
        "name": "alerta-server",
        "description": "Introduction\n============\n\nAlerta is a monitoring tool that allows alerts from many different systems to be consolidated into a single view.\n\nCurrently there are integrations for tools that support standard protocols such as ``SNMP``, ``syslog`` and ``HTTP``.\nThere are also specific integrations for popular monitoiring tools such as Nagios_, Zabbix_ and Riemann_.\n\n.. _`nagios`: https://github.com/alerta/nagios3-alerta\n.. _`zabbix`: https://github.com/alerta/zabbix-alerta\n.. _`riemann`: https://github.com/guardian/riemann-config/blob/master/alerta.clj\n\n\nInstallation\n============\n\nInstalling this package makes available a ``alert-sender`` and ``alert-query`` tool that can be used to send alerts\nto the alerta system and to query the alert database::\n\n    $ pip install alerta\n\n\nConfiguration\n=============\n\nFor a basic configuration that can be used to test the client tools against a demo alerta server, use::\n\n    [DEFAULT]\n    timezone = Europe/London\n    api_host = api.alerta.io\n    api_port = 80\n\n    [alert-query]\n    colour = yes\n\nCopy this configuration to ``/etc/alerta/alerta.conf`` or ``$HOME/.alerta.conf`` files::\n\n    $ mv /path/to/alerta.conf.sample $HOME/.alerta.conf\n\nor use the ``ALERTA_CONF`` environment variable::\n\n    $ export ALERTA_CONF=/path/to/alerta.conf\n\n\nBasic Usage\n===========\n\nAbbreviated usage for both commands is shown below::\n\n    usage: alert-sender [-r RESOURCE] [-e EVENT] [-C CORRELATE] [-g GROUP]\n                        [-v VALUE] [--status STATUS] [-s SEVERITY] [-E ENV]\n                        [-S SERVICE] [-T TAGS] [-t TEXT] [--summary TEXT]\n                        [--more TEXT] [--graphs URLS] [-o TIMEOUT]\n                        [--type EVENT_TYPE] [-H] [-O ORIGIN] [-q] [-d]\n\n\n    usage: alert-query [-h] [-c FILE] [--minutes MINUTES] [--hours HOURS]\n                       [--days DAYS] [-i ALERTID] [-E ENV] [--not-environment ENV]\n                       [-S SERVICE] [--not-service SERVICE] [-r RESOURCE]\n                       [--not-resource RESOURCE] [-s SEVERITY]\n                       [--not-severity SEVERITY] [--status STATUS]\n                       [--not-status STATUS] [-e EVENT] [--not-event EVENT]\n                       [-g GROUP] [--not-group GROUP] [--origin ORIGIN]\n                       [--not-origin ORIGIN] [-v VALUE] [--not-value VALUE]\n                       [-T TAGS] [--not-tags TAGS] [-t TEXT] [--not-text TEXT]\n                       [--type EVENT_TYPE] [--not-type TYPE]\n                       [--repeat {true,false}] [--show SHOW] [--oneline]\n                       [--date DATE] [--format FORMAT] [-o SORTBY] [-w]\n                       [-n INTERVAL] [--count LIMIT] [-q QUERY] [--no-header]\n                       [--no-footer] [--color] [--output OUTPUT] [-j] [-X] [-d]\n                       [--version] [--debug] [--verbose] [--log-dir DIR]\n                       [--log-file FILE] [--pid-dir DIR] [--use-syslog]\n                       [--use-stderr] [--yaml-config FILE] [--show-settings]\n\n\nExamples\n========\n\nTo send a DiskFull warning alert for /tmp on myhost, use::\n\n    $ alert-sender --resource myhost:/tmp --event DiskFull --severity warning\n\nTo list all alerts for myhost, use::\n\n    $ alert-query --resource myhost\n\n\nTrouble-shooting\n================\n\nTo use ``curl`` to request the same URL for a query, use::\n\n    $ alert-query --dry-run | sh\n\nAnd for an alert send, use::\n\n    $ alert-sender -r myhost -e test --dry-run | sh\n\n\nPython API\n==========\n\nA python API can be used to generate alerts::\n\n    >>> from alerta.common.api import ApiClient\n    >>> from alerta.common.alert import Alert\n    >>>\n    >>> client = ApiClient(host='api.alerta.io', port=80)\n    >>> alert = Alert(resource=\"foo\", event=\"bar\")\n    >>>\n    >>> client.send(alert)\n    u'8e9c4736-c2a8-4b4d-8638-07dad6ed1d2b'\n    >>>\n\nThe python API can also be used to query for alerts::\n\n    >>> from alerta.common.api import ApiClient\n    >>>\n    >>> client = ApiClient(host='api.alerta.io', port=80)\n    >>> r = client.query()\n    >>> r['status']\n    u'ok'\n    >>> pp = pprint.PrettyPrinter(indent=4)\n    >>> pp.pprint(r['alerts']['severityCounts'])\n    {   u'cleared': 0,\n        u'critical': 1,\n        u'debug': 0,\n        u'indeterminate': 0,\n        u'informational': 0,\n        u'major': 2,\n        u'minor': 1,\n        u'normal': 4,\n        u'security': 0,\n        u'unknown': 0,\n        u'warning': 1}",
        "url": "http://pypi.python.org/pypi/alerta-server",
        "summary": "Alerta server WSGI application",
        "command": "pip install 'alerta-server'"
      },
      "alert-from-script": {
        "name": "alert-from-script",
        "description": "alert_from_script\n=================\n\nGenerate SNS alerts from any command.\n\nInstallation\n============\n\n::\n\n$ sudo python setup.py install\n\nUsage\n=====\n\n::\n\n  usage: alert-from-script [-h] sns_topic sns_subject script\n\n  Runs a script and sends the stdout and stderr to SNS in case exit != 0.\n\n  positional arguments:\n    sns_topic    ARN of SNS topic to publish to.\n    sns_subject  Subject used for SNS messages.\n    script       The script to run. Includes all args to run.\n\n  optional arguments:\n    -h, --help   show this help message and exit\n",
        "url": "http://pypi.python.org/pypi/alert-from-script",
        "summary": "Generate SNS alerts from any command.",
        "command": "pip install 'alert-from-script'"
      },
      "alert-grid": {
        "name": "alert-grid",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alert-grid",
        "summary": "Alert Grid utility",
        "command": "pip install 'alert-grid'"
      },
      "alertlogic": {
        "name": "alertlogic",
        "description": "Python interface to Alert Logic.",
        "url": "http://pypi.python.org/pypi/alertlogic",
        "summary": "Alert Logic Library",
        "command": "pip install 'alertlogic'"
      },
      "alex": {
        "name": "alex",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alex",
        "summary": "Natural language access to command line",
        "command": "pip install 'alex'"
      },
      "alexandria": {
        "name": "alexandria",
        "description": "Alexandria README\n==================\n\nAlexandria is a a DNS management solution that allows you to easily manage your\nzone files using a simple to use web interface.\n\nInstallation\n------------\n\n - Wait for this package to be available on PyPi...\n\nDeveloping\n----------\n\nGetting the application set up locally:\n\n 0. Change directory to this project\n 1. Create virtualenv for Project in $venv\n 2. $venv/bin/pip install -e .\n 3. $venv/bin/initialize_alexandria_db config/development.ini\n 4. $venv/bin/pserve config/development.ini\n\nFor submitting patches back to the project:\n\n 0. Create a new branch for the feature/topic from master\n 1. Hack away\n 2. Submit a pull request\n\n\n0.0\n---\n\n-  Initial version",
        "url": "http://pypi.python.org/pypi/alexandria",
        "summary": "alexandria",
        "command": "pip install 'alexandria'"
      },
      "Alexandria-Upload-Utils": {
        "name": "alexandria-upload-utils",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Alexandria-Upload-Utils",
        "summary": "Easy uploads to an Alexandria build archive",
        "command": "pip install 'Alexandria-Upload-Utils'"
      },
      "alexer": {
        "name": "alexer",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alexer",
        "summary": "dead simple lexer",
        "command": "pip install 'alexer'"
      },
      "alexis": {
        "name": "alexis",
        "description": "",
        "url": "http://pypi.python.org/pypi/alexis",
        "summary": "",
        "command": "pip install 'alexis'"
      },
      "alex_sayhi": {
        "name": "alex_sayhi",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alex_sayhi",
        "summary": "UNKNOWN",
        "command": "pip install 'alex_sayhi'"
      },
      "alf": {
        "name": "alf",
        "description": "alf\r\n===\r\n\r\n.. image:: https://travis-ci.org/globocom/alf.svg?branch=master\r\n    :target: https://travis-ci.org/globocom/alf\r\n    \r\nPython OAuth 2 Client\r\n---------------------\r\n\r\n`alf` is an OAuth 2 Client based on `requests.Session\r\n<http://docs.python-requests.org/en/latest/user/advanced/#session-objects>`_\r\nwith seamless support for the `Client Credentials Flow\r\n<http://tools.ietf.org/html/draft-ietf-oauth-v2-31#section-1.3.4>`_.\r\n\r\nFeatures\r\n--------\r\n\r\n* Automatic token retrieving and renewing\r\n* Token expiration control\r\n* Automatic token storage\r\n* Automatic retry on status 401 (UNAUTHORIZED)\r\n\r\nUsage\r\n-----\r\n\r\nInitialize the client and use it as a `requests.Session\r\n<http://docs.python-requests.org/en/latest/user/advanced/#session-objects>`_\r\nobject.\r\n\r\n.. code-block:: python\r\n\r\n    from alf.client import Client\r\n\r\n    alf = Client(\r\n        token_endpoint='http://example.com/token',\r\n        client_id='client-id',\r\n        client_secret='secret')\r\n\r\n    resource_uri = 'http://example.com/resource'\r\n\r\n    alf.put(\r\n        resource_uri, data='{\"name\": \"alf\"}',\r\n        headers={'Content-Type': 'application/json'})\r\n\r\n    alf.get(resource_uri)\r\n\r\n    alf.delete(resource_uri)\r\n\r\nUsing your custom token storage\r\n-------------------------------\r\n\r\nNow passing an object with get and set attributes you can store or retrieve a token.\r\n\r\nThis object can be a Redis, Memcache or your custom object.\r\n\r\n.. code-block:: python\r\n\r\n    from alf.client import Client\r\n    from redis import StrictRedis\r\n\r\n    redis = StrictRedis(host='localhost', port=6379, db=0)\r\n\r\n    alf = Client(\r\n        token_endpoint='http://example.com/token',\r\n        client_id='client-id',\r\n        client_secret='secret',\r\n        token_storage=redis)\r\n\r\n    resource_uri = 'http://example.com/resource'\r\n\r\n    alf.put(\r\n        resource_uri, data='{\"name\": \"alf\"}',\r\n        headers={'Content-Type': 'application/json'})\r\n\r\n    alf.get(resource_uri)\r\n\r\n    alf.delete(resource_uri)\r\n\r\n\r\nHow does it work?\r\n-----------------\r\n\r\nBefore any request the client tries to retrive a token on the endpoint,\r\nexpecting a JSON response with the ``access_token`` and ``expires_in`` keys.\r\n\r\nThe client keeps the token until it is expired, and according to the ``expires_in``\r\nvalue calculates an ``expires_on`` value to store and validate token from multiple clients.\r\n\r\nAfter getting the token, the request is issued with a `Bearer authorization\r\nheader <http://tools.ietf.org/html/draft-ietf-oauth-v2-31#section-7.1>`_:\r\n\r\n.. code-block::\r\n\r\n    GET /resource/1 HTTP/1.1\r\n    Host: example.com\r\n    Authorization: Bearer token\r\n\r\nIf the request fails with a 401 (UNAUTHORIZED) status, a new token is retrieved\r\nfrom the endpoint and the request is retried. This happens only once, if it\r\nfails again the error response is returned.\r\n\r\nWorkflow\r\n--------\r\n\r\n.. image:: https://raw.githubusercontent.com/globocom/alf/master/assets/workflow.png\r\n\r\nTroubleshooting\r\n---------------\r\n\r\nIn case of an error retrieving a token, the error response will be returned,\r\nthe real request won't happen.\r\n\r\n\r\nRelated projects\r\n----------------\r\n\r\n`djalf <https://github.com/viniciuschagas/djalf>`_\r\n''''''''''''''''''''''''''''''''''''''''''''''''''\r\n\r\nAn extended client that uses Django's cache backend to share tokens between\r\nserver instances.\r\n\r\n\r\n`tornado-alf <https://github.com/globocom/tornado-alf>`_\r\n''''''''''''''''''''''''''''''''''''''''''''''''''''''''\r\n\r\nA port of the `alf` client using tornado's `AsyncHTTPClient`.",
        "url": "http://pypi.python.org/pypi/alf",
        "summary": "OAuth Client",
        "command": "pip install 'alf'"
      },
      "alfa": {
        "name": "alfa",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alfa",
        "summary": "A simple printer for straightening lists",
        "command": "pip install 'alfa'"
      },
      "alfajor": {
        "name": "alfajor",
        "description": "Alfajor\r\n-------\r\n\r\nTasty functional testing.\r\n\r\nAlfajor provides a modern, object-oriented and browser-neutral interface to\r\nHTTP resources.  With Alfajor, your Python scripts and test code have a live,\r\nsynchronized mirror of the browser's X/HTML DOM, even with DOM changes made on\r\nthe client by JavaScript.\r\n\r\nAlfajor provides:\r\n\r\n - A straightforward 'browser' object, with an implementation that\r\n   communicates in real-time with live web browsers via Selenium and a fast,\r\n   no-javascript implementation via an integrated WSGI gateway\r\n\r\n - Use a specific browser, or, via integration with the 'nose' test runner,\r\n   switch out the browser backend via a command line option to your tests.\r\n   Firefox, Safari, WSGI- choose which you want on a run-by-run basis.\r\n\r\n - Synchronized access to the page DOM via a rich dialect of lxml, with great\r\n   time-saving shortcuts that make tests compact, readable and fun to write.\r\n\r\n - Optional management of server processes under test, allowing them to\r\n   transparently start and stop on demand as your tests run.\r\n\r\n - An 'apiclient' with native JSON response support, useful for testing REST\r\n   and web api implementations at a fine-grained level.\r\n\r\n - A friendly BSD license.",
        "url": "http://pypi.python.org/pypi/alfajor",
        "summary": "Tasty functional testing.",
        "command": "pip install 'alfajor'"
      },
      "alfanous": {
        "name": "alfanous",
        "description": "Alfanous is a Quranic search engine provides simple and advanced search services in the diverse information of the Holy Quran .\r\n\r\n-------\r\nInstall\r\n-------\r\n\r\n.. code-block:: sh\r\n\r\n    $ sudo pip install alfanous\r\n\r\n-----\r\nUsage\r\n-----\r\nYou can use it from console:\r\n\r\n.. code-block:: sh\r\n\r\n    $ alfanous-console -a search -q الله \r\n\r\nor from Python:\r\n\r\n.. code-block:: python\r\n\r\n    >>> import alfanous\r\n    >>> alfanous.search(u\"الله\")\r\n    >>> alfanous.search(u\"qwl\")     # Buckwalter transliteration\r\n\r\n\r\nMore about `API <https://github.com/Alfanous-team/alfanous/tree/master/src/alfanous>`_",
        "url": "http://pypi.python.org/pypi/alfanous",
        "summary": "Quranic search engine API",
        "command": "pip install 'alfanous'"
      },
      "alfanousDesktop": {
        "name": "alfanousdesktop",
        "description": "A desktop GUI interface for alfanous Quran search engine API",
        "url": "http://pypi.python.org/pypi/alfanousDesktop",
        "summary": "Desktop interface for alfanous Quranic search engine API",
        "command": "pip install 'alfanousDesktop'"
      },
      "alfred": {
        "name": "alfred",
        "description": "=============\r\npython-alfred\r\n=============\r\n\r\n:Authors:\r\n        Mike Spindel\r\n:Version: 0.2\r\n\r\n\r\n`AlfredApp <http://www.alfredapp.com>`_ is an application launcher and\r\ngeneral productivity tool for Mac OS X. It can be extended and\r\ncustomized with custom workflows and plugin scripts.\r\n\r\nPlugin scripts, called\r\n\"`script filters <http://www.alfredforum.com/topic/5-generating-feedback-in-workflows/>`_\"\r\nby AlfredApp, operate by printing an XML document to standard\r\noutput. ``python-alfred`` is a Python library for easily building these\r\nXML documents.\r\n\r\nInstallation\r\n============\r\n\r\n::\r\n\r\n  $ pip install alfred\r\n\r\n\r\nUsage\r\n=====\r\n\r\nAs an example, consider a filter that converts numeric input into\r\nbinary and hexadecimal.::\r\n\r\n    import sys\r\n    import alfred\r\n     \r\n     \r\n    if __name__ == \"__main__\":\r\n        try:\r\n            val = int(sys.argv[1])\r\n        except:\r\n            sys.exit(1)\r\n\r\n        # Use the icon associated with the Calculator app\r\n        icon = alfred.Icon(filepath=\"/Applications/Calculator.app\")\r\n\r\n        # Create an item for the hex conversion\r\n        hex_item = alfred.Item(\r\n            uid='hex',\r\n            arg=\"\",\r\n            title=hex(val),\r\n            subtitle=\"Hexadecimal\",\r\n            valid=False,\r\n            icon=icon)\r\n\r\n        # Create an item for the binary conversion\r\n        bin_item = alfred.Item(\r\n            uid='bin',\r\n            arg=\"\",\r\n            title=bin(val),\r\n            subtitle=\"Binary\",\r\n            valid=False,\r\n            icon=icon)\r\n\r\n        # Call alfred.render to generate the XML document\r\n        print alfred.render([hex_item, bin_item])\r\n\r\n\r\nRequirements\r\n============\r\n\r\n``python-alfred`` requires ``lxml``.\r\n\r\n\r\nChanges\r\n=======\r\n\r\n0.2 - June 8, 2013\r\n-----------------------\r\n\r\n* Added support for new ``<arg></arg>`` elements\r\n\r\n0.1 - June 4, 2013\r\n-----------------------\r\n\r\n* Initial release",
        "url": "http://pypi.python.org/pypi/alfred",
        "summary": "Utilities for Alfred script filters.",
        "command": "pip install 'alfred'"
      },
      "alfredo": {
        "name": "alfredo",
        "description": "Alfredo - Born to serve!\n************************\n\n\nAlfredo is a simple, extensible gtalk bot. It's capable of doing any kind of tasks, implemented as separated commands.\n\nHere is a typical session: ::\n\n    you: inv some text\n    alfredo: called inv some text -> txet emos\n    \n\nImplementing a new command\n**************************\n\nCommands are implemented as Plugins (more at plugnplay <https://github.com/daltonmatos/plugnplay>). Just create a new class:\n\n    from alfredo import Plugin, ICommand\n\n    class SomeCommand(Plugin):\n      implements = [ICommand]\n\n      def help(self):\n        return ('short help', 'long help')\n\n      def name(self):\n        return 'mycommand'\n\n      def match_name(self, command):\n        return 'mycommand' == command\n\n      def run(self, user, *args)\n        # process some logic\n        return result\n\n\nIn this case we create a new command named 'mycommand'. If we send this message to alfredo:\n\n   mycommand p1 p2 p3\n\n\nthe ``run()`` method would be called like this: ``run('user@domain.com', 'p1', 'p2', 'p3')``. This method must return a string, that will be sent back to the original user.\n\n\nHow to use it\n*************\n\nTo start talking to a running instance of alfredo just add ``alfredo@daltonmatos.com`` to your gtalk conacts list and you are done!\n\nOr try out your own commands from the example code.\n\n\nDependencies\n************\n\nAlfredo's core components only needs:\n\n* plugnplay - https://github.com/daltonmatos/plugnplay\n* xmpppy - http://xmpppy.sourceforge.net/\n\nThe included commands needs:\n\n* BeautifulSoup - http://www.crummy.com/software/BeautifulSoup/\n* requests - https://github.com/kennethreitz/requests\n* simplejson - http://code.google.com/p/simplejson/\n\nYou can even run the requirements file to get up your environment::\n\n    pip install -r requirements.txt\n\n--\n\nDalton barreto\n\ndaltonmatos@gmail.com",
        "url": "http://pypi.python.org/pypi/alfredo",
        "summary": "Alfredo is a gtalk bot born so serve you.",
        "command": "pip install 'alfredo'"
      },
      "Alfred-Workflow": {
        "name": "alfred-workflow",
        "description": "A Python helper library for writing `Alfred 2`_ workflows.\n\nAlfred workflows typically take user input, fetch data from the Web or\nelsewhere, filter them and display results to the user. Alfred-Workflow\ntakes care of a lot of the details for you, allowing you to concentrate your\nefforts on your workflow's functionality.\n\nFeatures\n========\n\n* Catches and logs workflow errors for easier development and support\n* \"Magic\" arguments to help development/debugging\n* Auto-saves settings\n* Super-simple data caching\n* Fuzzy, Alfred-like search/filtering with diacritic folding\n* Keychain support for secure storage (and syncing) of passwords, API keys etc.\n* Simple generation of Alfred feedback (XML output)\n* Input/output decoding for handling non-ASCII text\n* Lightweight web API with modelled on `requests`_\n* Pre-configured logging\n* Painlessly add directories to ``sys.path``\n* Easily launch background tasks (daemons) to keep your workflow responsive\n* Check for new versions and update workflows hosted on GitHub.\n\nQuick Example\n=============\n\nHere's how to show recent `Pinboard.in <https://pinboard.in/>`_ posts in Alfred.\n\nCreate a new workflow in Alfred's preferences. Add a **Script Filter** with\nLanguage ``/usr/bin/python`` and paste the following into the **Script** field\n(changing ``API_KEY``):\n\n.. code-block:: python\n\n    import sys\n    from workflow import Workflow, ICON_WEB, web\n\n    API_KEY = 'your-pinboard-api-key'\n\n    def main(wf):\n        url = 'https://api.pinboard.in/v1/posts/recent'\n        params = dict(auth_token=API_KEY, count=20, format='json')\n        r = web.get(url, params)\n        r.raise_for_status()\n        for post in r.json()['posts']:\n            wf.add_item(post['description'], post['href'], arg=post['href'],\n                        uid=post['hash'], valid=True, icon=ICON_WEB)\n        wf.send_feedback()\n\n\n    if __name__ == u\"__main__\":\n        wf = Workflow()\n        sys.exit(wf.run(main))\n\n\nAdd an **Open URL** action to your workflow with ``{query}`` as the **URL**,\nconnect your **Script Filter** to it, and you can now hit **ENTER** on a\nPinboard item in Alfred to open it in your browser.\n\nInstallation\n============\n\n**Note**: If you intend to distribute your workflow to other users, you should\ninclude Alfred-Workflow (and other Python libraries your workflow requires)\nwithin your workflow's directory as described below. **Do not** ask users to\ninstall anything into their system Python. Python installations cannot support\nmultiple versions of the same library, so if you rely on globally-installed\nlibraries, the chances are very good that your workflow will sooner or later\nbreak—or be broken by—some other software doing the same naughty thing.\n\nWith pip\n--------\n\nYou can install Alfred-Workflow directly into your workflow with::\n\n    pip install --target=/path/to/my/workflow Alfred-Workflow\n\nYou can install any other library available on the `Cheese Shop`_ the\nsame way. See the `pip documentation`_ for more information.\n\nFrom source\n-----------\n\nDownload the ``alfred-workflow-X.X.X.zip`` file from the `GitHub releases`_ page\nand either extract the ZIP to the root directory of your workflow (where\n``info.plist`` is) or place the ZIP in the root directory and add\n``sys.path.insert(0, 'alfred-workflow-X.X.X.zip')`` to the top of your\nPython scripts.\n\nAlternatively, you can download `the source code`_ from the `GitHub repository`_\nand copy the ``workflow`` subfolder to the root directory of your workflow.\n\nYour workflow directory should look something like this (where\n``yourscript.py`` contains your workflow code and ``info.plist`` is\nthe workflow information file generated by Alfred)::\n\n    Your Workflow/\n        info.plist\n        icon.png\n        workflow/\n            __init__.py\n            background.py\n            update.py\n            version\n            web.py\n            workflow.py\n        yourscript.py\n        etc.\n\n\nOr like this::\n\n    Your Workflow/\n        info.plist\n        icon.png\n        workflow-1.X.X.zip\n        yourscript.py\n        etc.\n\nDocumentation\n=============\n\nDetailed documentation, including a tutorial, is available at\nhttp://www.deanishe.net/alfred-workflow/.\n\n.. _requests: http://docs.python-requests.org/en/latest/\n.. _Alfred 2: http://www.alfredapp.com/\n.. _GitHub releases: https://github.com/deanishe/alfred-workflow/releases\n.. _the source code: https://github.com/deanishe/alfred-workflow/archive/master.zip\n.. _GitHub repository: https://github.com/deanishe/alfred-workflow\n.. _Cheese Shop: https://pypi.python.org/pypi\n.. _pip documentation: https://pip.pypa.io/en/latest/",
        "url": "http://pypi.python.org/pypi/Alfred-Workflow",
        "summary": "Full-featured helper library for writing Alfred 2 workflows",
        "command": "pip install 'Alfred-Workflow'"
      },
      "alfREST": {
        "name": "alfrest",
        "description": "A ligthweight python library based on the Alfresco RESTful web services.\r\n\r\nSample usage::\r\n\r\n  from alfREST import RESTHelper\r\n  path = \"/Sites/mysite/documentLibrary/test\"\r\n\r\n  # login\r\n  rh = RESTHelper()\r\n  rh.login(login, password, host, port)\r\n\r\n  # createDocument (sio could be a file object...)\r\n  from StringIO import StringIO\r\n  sio = StringIO()\r\n  sio.write(\"Well, that's all folks.\")\r\n  sio.seek(0)\r\n  sio.name = \"test.txt\"\r\n  tkns = path.split(\"/\")\r\n  siteId = tkns[2]\r\n  containerId = tkns[3]\r\n  uploadDirectory = \"/\".join(tkns[4:])\r\n  idObject = rh.fileUpload(sio, siteId, containerId, \"/%s\" % uploadDirectory)\r\n  sio.close()\r\n\r\n  # get properties\r\n  props = rh.getProperties(\"%s/test.txt\" % path)\r\n  assert props[\"cmis:createdBy\"] == login\r\n\r\n  # get content\r\n  content = rh.getContent(\"%s/test.txt\" % path)\r\n  assert content == \"Well, that's all folks.\"\r\n\r\n  # add a tag to the document\r\n  rh.addTag(\"workspace\", \"SpacesStore\", idObject, \"tag_test\")\r\n  assert \"tag_test\" in rh.getNodeTags(\"workspace\", \"SpacesStore\", idObject)\r\n\r\n  # list document in folder\r\n  children = rh.getChildren(path)\r\n  assert children[0][\"cmis:name\"] == \"test.txt\"\r\n\r\n  # create a group and apply a  policy to the test folder\r\n  rh.addRootGroup(u\"GROUP_TEST\")\r\n  acl = {}\r\n  acl[u'GROUP_TEST'] = [([u\"{http://www.alfresco.org/model/content/1.0}cmobject.Consumer\",], True),]\r\n  rh.applyACL(path, acl)\r\n\r\n  # create a new user, insert the user in the group \r\n  rh.addPerson(\"supermario\", \"mario\", \"super\", \"supermario@nintendo.com\", \"imsuper\")\r\n  rh.addGroupOrUserToGroup(u\"supermario\", u\"GROUP_TEST\")\r\n\r\n  # some check\r\n  users = rh.listChildAuthorities(u\"GROUP_TEST\")\r\n  assert len(users) == 1\r\n  assert users[0]['fullName'] == \"supermario\"\r\n\r\n  # restore initial status\r\n  rh.removeAuthorityFromGroup(u\"supermario\", u\"GROUP_TEST\")\r\n  rh.deletePerson(\"supermario\")\r\n  acl = {}\r\n  rh.applyACL(path, acl)\r\n  rh.deleteRootGroup(u\"GROUP_TEST\")\r\n\r\n  # remove tag from the file object\r\n  rh.deleteTag(\"workspace\", \"SpacesStore\", idObject, \"tag_test\")\r\n  assert \"tag_test\" not in rh.getNodeTags(\"workspace\", \"SpacesStore\", idObject)\r\n\r\n  # delete the file object\r\n  rh.deleteObject(idObject)\r\n\r\n  # logout\r\n  rh.logout()\r\n\r\n**Changelogs 0.9.3**\r\n\r\n- addTag\r\n- deleteTag\r\n\r\n**Changelogs 0.9.2c (bugfix: upload binary files works)**\r\n\r\n- createFolder\r\n- getNodeTags (get all the tags for a node)\r\n\r\n**Changelogs 0.9.1**\r\n\r\n- upload (upload file content and meta-data into repository)\r\n- delete file (delete the specified object)\r\n- getChildren (gets the list of child objects contained in the specified folder)\r\n- getContent (gets the content stream for the specified document)\r\n- getProperties (gets the properties for the object)\r\n\r\n**Road to 1.0**\r\n\r\n- Create / Move a Folder or Document (createDocument, createFolder, createPolicy, moveObject)\r\n- Write Content (setContent)\r\n- Delete Content (deleteContent)\r\n- Get Content (getContent)\r\n- Get Folder Children (getChildren)\r\n\r\n\r\n**Road to 1.1**\r\n\r\n- Get Checked Out Documents (getCheckedOutDocs)\r\n- Checkout Document (checkOut)\r\n- Cancel Checkout (cancelCheckout)\r\n- Checkin Private Working Copy (checkin)\r\n\r\n\r\n**Contacts**\r\n\r\nFor more info and requests: tiziano [at] axiastudio.it",
        "url": "http://pypi.python.org/pypi/alfREST",
        "summary": "Alfresco REST web services client library for python",
        "command": "pip install 'alfREST'"
      },
      "algae": {
        "name": "algae",
        "description": "python-algae\n============\n\nPython collections library.",
        "url": "http://pypi.python.org/pypi/algae",
        "summary": "Python advanced collections library",
        "command": "pip install 'algae'"
      },
      "algebraixlib": {
        "name": "algebraixlib",
        "description": ".. Algebraix Technology Core Library documentation.\n   $Id: README.rst 22838 2015-08-20 21:49:14Z gfiedler $\n   Copyright Algebraix Data Corporation 2015 - $Date: 2015-08-20 16:49:14 -0500 (Thu, 20 Aug 2015) $\n\n   This file is part of algebraixlib <http://github.com/AlgebraixData/algebraixlib>.\n\n   algebraixlib is free software: you can redistribute it and/or modify it under the terms of\n   version 3 of the GNU Lesser General Public License as published by the Free Software Foundation.\n\n   algebraixlib is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without\n   even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n   Lesser General Public License for more details.\n\n   You should have received a copy of the GNU Lesser General Public License along with algebraixlib.\n   If not, see <http://www.gnu.org/licenses/>.\n\n   This file is not included via toctree. Mark it as orphan to suppress the warning that it isn't\n   included in any toctree.\n\n:orphan:\n\n|logo|_\n\nalgebraixlib\n============\n\nWhat Is It?\n-----------\n\n``algebraixlib`` is a library that provides constructs and facilities to harness the fundamentals\nof data algebra. Data algebra consists of mathematical constructs that can represent all data, no\nmatter how it is structured, and the operations on that data. With this, all the advantages of a\nmathematically rigorous modeling can be unleashed. See also\n`A Beginner's Introduction to Data Algebra`_.\n\nGetting Started\n---------------\n\n#.  Make sure you have the right versions of Python and IPython Notebook installed (see\n    `Requirements`_ below).\n#.  Install the ``algebraixlib`` library (see `How to Install`_ below).\n#.  Download the `examples`_ from our `GitHub`_ repository.\n#.  Try the Hello_World.ipynb example first.\n\n(Alternatively, you can also look at a static version of the notebooks in `nbviewer`_; see the\nREADME file in our `examples`_ directory for direct links. For this you don't need to install or\ndownload anything. You can also start with the simpler hello_world.py. However, you'll lose out\non some math and need to read up on it in our documentation at `Read the Docs`_. )\n\nDocumentation and Support\n-------------------------\n\n*   Find documentation at `Read the Docs`_.\n*   Find the ``pip`` installer on `PyPI`_.\n*   Find the source code, the bugtracker and contribute on `GitHub`_.\n*   Find tutorials and example code in the `examples`_ directory on GitHub.\n*   Post questions about algebraixlib on `Stack Overflow`_ using the tag [algebraixlib].\n*   Post questions about the mathematics of data algebra on `math.stackexchange`_ using the tag\n    [data-algebra].\n*   Contact us at `email`_.\n\nSee also our `GitHub project page`_. In addition, there is a book forthcoming about data algebra.\n\n\nDetailed Instructions\n=====================\n\nRequirements\n------------\n\n*   `Python`_: Tested with 3.4.3. Likely to run with Python 3.4.x. It may run with earlier Python 3\n    versions, but you may run into issues. Does not run with any version of Python before Python 3.\n\n    *   For installing and using multiple versions of Python on the same machine, see\n        `Official multiple python versions on the same machine? (Stack Overflow)`_,\n        `How to install both Python 2.x and Python 3.x in Windows 7 (Stack Overflow)`_ and\n        `A Python Launcher For Windows (Python Insider)`_.\n\n*   `IPython Notebook`_: Tested with IPython 3.2 (used in the IPython notebook tutorials and\n    examples).\n\n    *   See `IPython Installation`_ for instructions how to install the IPython notebook\n        (``pip install \"ipython[notebook]\"``).\n    *   If you don't want IPython in your system environment, you can install it into a virtual\n        environment (see `Creation of virtual environments`_).\n\nHow to Install\n--------------\n\nIf you already have Python installed and are familiar with installing packages, you can install\n``algebraixlib`` with ``pip``::\n\n> pip install algebraixlib\n\nAdditional user permissions may be necessary to complete the installation. In such a situation,\nother options include installing the package for a single user (in the user's home directory)::\n\n> pip install algebraixlib --user <username> \n\nor in a virtual environment (see `Creation of virtual environments`_).\n\nYou can also manually download ``algebraixlib`` from `GitHub`_ or `PyPI`_. To install from a\ndownload, unpack it and run the following command from the top-level source directory (the\ndirectory that contains the file setup.py)::\n\n> python setup.py install\n\n(The same considerations about permissions apply.)\n\nUnit Tests\n----------\n\nThe unit tests require the following libraries to be installed:\n\n*   `nose`_\n*   `coverage`_\n\nTo execute the unit tests, use the following command in the algebraixlib directory (it contains the\nfile runtests.py)::\n\n> python runtests.py\n\nDocument Build\n--------------\nThe document build requires the following libraries be installed:\n\n*   `Sphinx`_ (1.3 or later)\n\nTo run a document build, use the following command in the algebraixlib/docs directory (it\ncontains the file build.py)::\n\n> python build.py\n\n\nLegalese\n========\n\nCopyright\n---------\n\nCopyright(c) 2015 Algebraix Data Corporation.\n\nLicense\n-------\n\n``algebraixlib`` is free software: you can redistribute it and/or modify it under the terms of\n`version 3 of the GNU Lesser General Public License`_ as published by the\n`Free Software Foundation`_. A copy of the GNU Lesser General Public License is published along\nwith ``algebraixlib`` on `GitHub`_. Otherwise, see `GNU licenses`_.\n\nWarranty\n--------\n\n``algebraixlib`` is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\nwithout even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\nGNU Lesser General Public License for more details.\n\n.. _Python:\n    http://python.org\n.. _Official multiple python versions on the same machine? (Stack Overflow):\n    http://stackoverflow.com/questions/2547554/official-multiple-python-versions-on-the-same-machine\n.. _How to install both Python 2.x and Python 3.x in Windows 7 (Stack Overflow):\n    http://stackoverflow.com/questions/3809314/how-to-install-both-python-2-x-and-python-3-x-in-windows-7\n.. _A Python Launcher For Windows (Python Insider):\n    http://blog.python.org/2011/07/python-launcher-for-windows_11.html\n.. _IPython Notebook:\n    http://ipython.org/notebook.html\n.. _IPython Installation:\n    http://ipython.org/install.html\n.. _nbviewer:\n    http://nbviewer.ipython.org/\n.. _email:\n    mailto:algebraixlib@algebraixdata.com\n.. _Read the Docs:\n    http://algebraixlib.rtfd.org/\n.. _A Beginner's Introduction to Data Algebra:\n    http://algebraixlib.readthedocs.org/en/latest/intro.html\n.. _Examples:\n    https://github.com/AlgebraixData/algebraixlib/tree/master/examples\n.. _Hello_World.ipynb:\n    https://github.com/AlgebraixData/algebraixlib/blob/master/examples/Hello_World.ipynb\n.. _PyPI:\n    http://pypi.python.org/pypi/algebraixlib\n.. _nose:\n    https://pypi.python.org/pypi/nose/\n.. _coverage:\n    https://pypi.python.org/pypi/coverage\n.. _Sphinx:\n    https://pypi.python.org/pypi/Sphinx\n.. _GitHub:\n    http://github.com/AlgebraixData/algebraixlib\n.. _Stack Overflow:\n    http://stackoverflow.com/\n.. _math.stackexchange:\n    http://math.stackexchange.com/\n.. _GitHub project page:\n    http://algebraixdata.github.io/algebraixlib/\n.. _Version 3 of the GNU Lesser General Public License:\n    http://www.gnu.org/licenses/lgpl-3.0-standalone.html\n.. _GNU Licenses:\n    http://www.gnu.org/licenses/\n.. _Free Software Foundation:\n    http://www.fsf.org/\n.. _Creation of virtual environments:\n    https://docs.python.org/3/library/venv.html\n\n.. |logo| image:: https://raw.githubusercontent.com/AlgebraixData/algebraixlib/gh-pages/ALGBX-Logo-Color-150DPI.png\n.. _logo: http://www.algebraixdata.com/technology/#algebraix-library",
        "url": "http://pypi.python.org/pypi/algebraixlib",
        "summary": "A data algebra library",
        "command": "pip install 'algebraixlib'"
      },
      "algobroker": {
        "name": "algobroker",
        "description": "Algobroker is an interface to trading and events",
        "url": "http://pypi.python.org/pypi/algobroker",
        "summary": "Algorithmic trading broker",
        "command": "pip install 'algobroker'"
      },
      "algogd": {
        "name": "algogd",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/algogd",
        "summary": "Algorithmic backtester for incorporating GDELT event data into finance analysis",
        "command": "pip install 'algogd'"
      },
      "algoliasearch": {
        "name": "algoliasearch",
        "description": "Algolia Search API Client for Python\n====================================\n\n`Algolia Search <http://www.algolia.com>`__ is a hosted full-text,\nnumerical, and faceted search engine capable of delivering realtime\nresults from the first keystroke.\n\nOur Python client lets you easily use the `Algolia Search\nAPI <https://www.algolia.com/doc/rest_api>`__ from your backend. It\nwraps the `Algolia Search REST\nAPI <http://www.algolia.com/doc/rest_api>`__.\n\n|Build Status| |PyPI version| |Coverage Status|\n\nTable of Contents\n=================\n\n**Getting Started**\n\n1. `Setup <#setup>`__\n2. `Quick Start <#quick-start>`__\n3. `Online documentation <#documentation>`__\n4. `Tutorials <#tutorials>`__\n\n**Commands Reference**\n\n1.  `Add a new object <#add-a-new-object-to-the-index>`__\n2.  `Update an object <#update-an-existing-object-in-the-index>`__\n3.  `Search <#search>`__\n4.  `Multiple queries <#multiple-queries>`__\n5.  `Get an object <#get-an-object>`__\n6.  `Delete an object <#delete-an-object>`__\n7.  `Delete by query <#delete-by-query>`__\n8.  `Index settings <#index-settings>`__\n9.  `List indices <#list-indices>`__\n10. `Delete an index <#delete-an-index>`__\n11. `Clear an index <#clear-an-index>`__\n12. `Wait indexing <#wait-indexing>`__\n13. `Batch writes <#batch-writes>`__\n14. `Security / User API Keys <#security--user-api-keys>`__\n15. `Copy or rename an index <#copy-or-rename-an-index>`__\n16. `Backup / Retrieve all index\n    content <#backup--retrieve-of-all-index-content>`__\n17. `Logs <#logs>`__\n\nSetup\n-----\n\nTo setup your project, follow these steps:\n\n1. Install AlgoliaSearch using pip:\n   ``pip install --upgrade algoliasearch``.\n2. Initialize the client with your ApplicationID and API-Key. You can\n   find all of them on `your Algolia\n   account <http://www.algolia.com/users/edit>`__.\n\n.. code:: python\n\n    from algoliasearch import algoliasearch\n\n    client = algoliasearch.Client(\"YourApplicationID\", 'YourAPIKey')\n\nQuick Start\n-----------\n\nIn 30 seconds, this quick start tutorial will show you how to index and\nsearch objects.\n\nWithout any prior configuration, you can start indexing `500\ncontacts <https://github.com/algolia/algoliasearch-client-csharp/blob/master/contacts.json>`__\nin the ``contacts`` index using the following code:\n\n.. code:: python\n\n    index = client.init_index(\"contact\")\n    batch = json.load(open('contacts.json'))\n    index.add_objects(batch)\n\nYou can now search for contacts using firstname, lastname, company, etc.\n(even with typos):\n\n.. code:: python\n\n    # search by firstname\n    print index.search(\"jimmie\")\n    # search a firstname with typo\n    print index.search(\"jimie\")\n    # search for a company\n    print index.search(\"california paint\")\n    # search for a firstname & company\n    print index.search(\"jimmie paint\")\n\nSettings can be customized to tune the search behavior. For example, you\ncan add a custom sort by number of followers to the already great\nbuilt-in relevance:\n\n.. code:: python\n\n    index.set_settings({\"customRanking\": [\"desc(followers)\"]})\n\nYou can also configure the list of attributes you want to index by order\nof importance (first = most important):\n\n.. code:: python\n\n    index.set_settings({\"attributesToIndex\": [\"lastname\", \"firstname\", \"company\", \n                                             \"email\", \"city\", \"address\"]})\n\nSince the engine is designed to suggest results as you type, you'll\ngenerally search by prefix. In this case the order of attributes is very\nimportant to decide which hit is the best:\n\n.. code:: python\n\n    print index.search(\"or\")\n    print index.search(\"jim\")\n\n**Notes:** If you are building a web application, you may be more\ninterested in using our `JavaScript\nclient <https://github.com/algolia/algoliasearch-client-js>`__ to\nperform queries. It brings two benefits: \\* Your users get a better\nresponse time by not going through your servers \\* It will offload\nunnecessary tasks from your servers\n\n.. code:: html\n\n    <script src=\"//cdn.jsdelivr.net/algoliasearch/3/algoliasearch.min.js\"></script>\n    <script>\n    var client = algoliasearch('ApplicationID', 'apiKey');\n    var index = client.initIndex('indexName');\n\n    // perform query \"jim\"\n    index.search('jim', searchCallback);\n\n    // the last optional argument can be used to add search parameters\n    index.search(\n      'jim', {\n        hitsPerPage: 5,\n        facets: '*',\n        maxValuesPerFacet: 10\n      },\n      searchCallback\n    );\n\n    function searchCallback(err, content) {\n      if (err) {\n        console.error(err);\n        return;\n      }\n\n      console.log(content);\n    }\n    </script>\n\nDocumentation\n=============\n\nCheck our `online\ndocumentation <http://www.algolia.com/doc/guides/python>`__: \\* `Initial\nImport <http://www.algolia.com/doc/guides/python#InitialImport>`__ \\*\n`Ranking &\nRelevance <http://www.algolia.com/doc/guides/python#RankingRelevance>`__\n\\* `Indexing <http://www.algolia.com/doc/guides/python#Indexing>`__ \\*\n`Search <http://www.algolia.com/doc/guides/python#Search>`__ \\*\n`Sorting <http://www.algolia.com/doc/guides/python#Sorting>`__ \\*\n`Filtering <http://www.algolia.com/doc/guides/python#Filtering>`__ \\*\n`Faceting <http://www.algolia.com/doc/guides/python#Faceting>`__ \\*\n`Geo-Search <http://www.algolia.com/doc/guides/python#Geo-Search>`__ \\*\n`Security <http://www.algolia.com/doc/guides/python#Security>`__ \\*\n`REST API <http://www.algolia.com/doc/rest>`__\n\nTutorials\n=========\n\nCheck out our `tutorials <http://www.algolia.com/doc/tutorials>`__: \\*\n`Search bar with autocomplete\nmenu <http://www.algolia.com/doc/tutorials/auto-complete>`__ \\* `Search\nbar with multi category autocomplete\nmenu <http://www.algolia.com/doc/tutorials/multi-auto-complete>`__ \\*\n`Instant search result\npages <http://www.algolia.com/doc/tutorials/instant-search>`__\n\nCommands Reference\n==================\n\nAdd a new object to the Index\n-----------------------------\n\nEach entry in an index has a unique identifier called ``objectID``.\nThere are two ways to add en entry to the index:\n\n1. Using automatic ``objectID`` assignment. You will be able to access\n   it in the answer.\n2. Supplying your own ``objectID``.\n\nYou don't need to explicitly create an index, it will be automatically\ncreated the first time you add an object. Objects are schema less so you\ndon't need any configuration to start indexing. If you wish to configure\nthings, the settings section provides details about advanced settings.\n\nExample with automatic ``objectID`` assignment:\n\n.. code:: python\n\n    res = index.add_object({\"firstname\": \"Jimmie\", \n                           \"lastname\": \"Barninger\"})\n    print \"ObjectID=%s\" % res[\"objectID\"]\n\nExample with manual ``objectID`` assignment:\n\n.. code:: python\n\n    res = index.add_object({\"firstname\": \"Jimmie\", \n                           \"lastname\": \"Barninger\"}, \"myID\")\n    print \"ObjectID=%s\" % res[\"objectID\"]\n\nUpdate an existing object in the Index\n--------------------------------------\n\nYou have three options when updating an existing object:\n\n1. Replace all its attributes.\n2. Replace only some attributes.\n3. Apply an operation to some attributes.\n\nExample on how to replace all attributes of an existing object:\n\n.. code:: python\n\n    index.save_object({\"firstname\": \"Jimmie\", \n                      \"lastname\": \"Barninger\", \n                      \"city\": \"New York\",\n                      \"objectID\": \"myID\"})\n\nYou have many ways to update an object's attributes:\n\n1. Set the attribute value\n2. Add an element to an array\n3. Remove an element from an array\n4. Add an element to an array if it doesn't exist\n5. Increment an attribute\n6. Decrement an attribute\n\nExample to update only the city attribute of an existing object:\n\n.. code:: python\n\n    index.partial_update_object({\"city\": \"San Francisco\", \n                               \"objectID\": \"myID\"})\n\nExample to add a tag:\n\n.. code:: python\n\n    index.partial_update_object({\"_tags\": { \"value\": \"MyTag\", \"_operation\": \"Add\"}, \n                               \"objectID\": \"myID\"})\n\nExample to remove a tag:\n\n.. code:: python\n\n    index.partial_update_object({\"_tags\": { \"value\": \"MyTag\", \"_operation\": \"Remove\"}, \n                               \"objectID\": \"myID\"})\n\nExample to add a tag if it doesn't exist:\n\n.. code:: python\n\n    index.partial_update_object({\"_tags\": { \"value\": \"MyTag\", \"_operation\": \"AddUnique\"}, \n                               \"objectID\": \"myID\"})\n\nExample to increment a numeric value:\n\n.. code:: python\n\n    index.partial_update_object({\"price\": { \"value\": 42, \"_operation\": \"Increment\"}, \n                               \"objectID\": \"myID\"})\n\nExample to decrement a numeric value:\n\n.. code:: python\n\n    index.partial_update_object({\"price\": { \"value\": 42, \"_operation\": \"Decrement\"}, \n                               \"objectID\": \"myID\"})\n\nSearch\n------\n\n**Notes:** If you are building a web application, you may be more\ninterested in using our `JavaScript\nclient <https://github.com/algolia/algoliasearch-client-js>`__ to\nperform queries. It brings two benefits: \\* Your users get a better\nresponse time by not going through your servers \\* It will offload\nunnecessary tasks from your servers.\n\nTo perform a search, you only need to initialize the index and perform a\ncall to the search function.\n\nThe search query allows only to retrieve 1000 hits, if you need to\nretrieve more than 1000 hits for seo, you can use `Backup / Retrieve all\nindex content <#backup--retrieve-of-all-index-content>`__\n\nYou can use the following optional arguments:\n\nQuery Parameters\n~~~~~~~~~~~~~~~~\n\nFull Text Search Parameters\n^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n-  **query**: (string) The instant search query string. All words of the\n   query are interpreted as prefixes (for example \"John Mc\" will match\n   \"John Mccamey\" and \"Johnathan Mccamey\"). If no query parameter is set\n   all objects are retrieved.\n-  **queryType**: Selects how the query words are interpreted. It can be\n   one of the following values:\n-  **prefixAll**: All query words are interpreted as prefixes.\n-  **prefixLast**: Only the last word is interpreted as a prefix\n   (default behavior).\n-  **prefixNone**: No query word is interpreted as a prefix. This option\n   is not recommended.\n-  **removeWordsIfNoResults**: This option is used to select a strategy\n   in order to avoid having an empty result page. There are three\n   different options:\n-  **lastWords**: When a query does not return any results, the last\n   word will be added as optional. The process is repeated with n-1\n   word, n-2 word, ... until there are results.\n-  **firstWords**: When a query does not return any results, the first\n   word will be added as optional. The process is repeated with second\n   word, third word, ... until there are results.\n-  **allOptional**: When a query does not return any results, a second\n   trial will be made with all words as optional. This is equivalent to\n   transforming the AND operand between query terms to an OR operand.\n-  **none**: No specific processing is done when a query does not return\n   any results (default behavior).\n-  **minWordSizefor1Typo**: The minimum number of characters in a query\n   word to accept one typo in this word.Defaults to 4.\n-  **minWordSizefor2Typos**: The minimum number of characters in a query\n   word to accept two typos in this word.Defaults to 8.\n-  **allowTyposOnNumericTokens**: If set to false, it disables typo\n   tolerance on numeric tokens (numbers). Defaults to false.\n-  **typoTolerance**: This option allows you to control the number of\n   typos in the result set:\n-  **true**: The typo tolerance is enabled and all matching hits are\n   retrieved (default behavior).\n-  **false**: The typo tolerance is disabled. For example, if one result\n   matches without typos, then all results with typos will be hidden.\n-  **min**: Only keep results with the minimum number of typos.\n-  **strict**: Hits matching with 2 typos are not retrieved if there are\n   some matching without typos. This option is useful if you want to\n   avoid false positives as much as possible.\n-  **allowTyposOnNumericTokens**: If set to false, disables typo\n   tolerance on numeric tokens (numbers). Defaults to true.\n-  **ignorePlural**: If set to true, plural won't be considered as a\n   typo. For example, car and cars will be considered as equals.\n   Defaults to false.\n-  **restrictSearchableAttributes** List of attributes you want to use\n   for textual search (must be a subset of the ``attributesToIndex``\n   index setting). Attributes are separated with a comma such as\n   ``\"name,address\"``. You can also use JSON string array encoding such\n   as ``encodeURIComponent(\"[\\\"name\\\",\\\"address\\\"]\")``. By default, all\n   attributes specified in ``attributesToIndex`` settings are used to\n   search.\n-  **advancedSyntax**: Enables the advanced query syntax. Defaults to 0\n   (false).\n\n   -  **Phrase query**: A phrase query defines a particular sequence of\n      terms. A phrase query is built by Algolia's query parser for words\n      surrounded by ``\"``. For example, ``\"search engine\"`` will\n      retrieve records having ``search`` next to ``engine`` only. Typo\n      tolerance is *disabled* on phrase queries.\n   -  **Prohibit operator**: The prohibit operator excludes records that\n      contain the term after the ``-`` symbol. For example,\n      ``search -engine`` will retrieve records containing ``search`` but\n      not ``engine``.\n\n-  **analytics**: If set to false, this query will not be taken into\n   account in the analytics feature. Defaults to true.\n-  **synonyms**: If set to false, this query will not use synonyms\n   defined in the configuration. Defaults to true.\n-  **replaceSynonymsInHighlight**: If set to false, words matched via\n   synonym expansion will not be replaced by the matched synonym in the\n   highlight results. Defaults to true.\n-  **optionalWords**: A string that contains the comma separated list of\n   words that should be considered as optional when found in the query.\n\nPagination Parameters\n^^^^^^^^^^^^^^^^^^^^^\n\n-  **page**: (integer) Pagination parameter used to select the page to\n   retrieve.Page is zero based and defaults to 0. Thus, to retrieve the\n   10th page you need to set ``page=9``.\n-  **hitsPerPage**: (integer) Pagination parameter used to select the\n   number of hits per page. Defaults to 20.\n\nGeo-search Parameters\n^^^^^^^^^^^^^^^^^^^^^\n\n-  **aroundLatLng**: Search for entries around a given\n   latitude/longitude (specified as two floats separated by a comma).For\n   example, ``aroundLatLng=47.316669,5.016670``.You can specify the\n   maximum distance in meters with the **aroundRadius** parameter and\n   the precision for ranking with **aroundPrecision**. For example, if\n   you set aroundPrecision=100, two objects that are a distance of less\n   than 100 meters will be considered as identical for the \"geo\" ranking\n   parameter).At indexing, you should specify the geo location of an\n   object with the ``_geoloc`` attribute in the form\n   ``{\"_geoloc\":{\"lat\":48.853409, \"lng\":2.348800}}``.\n\n-  **aroundLatLngViaIP**: Search for entries around a given\n   latitude/longitude automatically computed from user IP address.For\n   example, ``aroundLatLng=47.316669,5.016670``.You can specify the\n   maximum distance in meters with the **aroundRadius** parameter and\n   the precision for ranking with **aroundPrecision**. For example, if\n   you set aroundPrecision=100, two objects that are in the range 0-99m\n   will be considered as identic in the ranking for the \"geo\" ranking\n   parameter (same for 100-199, 200-299, ... ranges).At indexing, you\n   should specify the geo location of an object with the ``_geoloc``\n   attribute in the form\n   ``{\"_geoloc\":{\"lat\":48.853409, \"lng\":2.348800}}``.\n\n-  **insideBoundingBox**: Search entries inside a given area defined by\n   the two extreme points of a rectangle (defined by 4 floats:\n   p1Lat,p1Lng,p2Lat,p2Lng).For example,\n   ``insideBoundingBox=47.3165,4.9665,47.3424,5.0201``).At indexing, you\n   should specify the geo location of an object with the \\_geoloc\n   attribute in the form\n   ``{\"_geoloc\":{\"lat\":48.853409, \"lng\":2.348800}}``.\n\nParameters to Control Results Content\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n-  **attributesToRetrieve**: A string that contains the list of object\n   attributes you want to retrieve in order to minimize the answer size.\n   Attributes are separated with a comma (for example\n   ``\"name,address\"``). You can also use a string array encoding (for\n   example ``[\"name\",\"address\"]`` ). By default, all attributes are\n   retrieved. You can also use ``*`` to retrieve all values when an\n   **attributesToRetrieve** setting is specified for your index.\n-  **attributesToHighlight**: A string that contains the list of\n   attributes you want to highlight according to the query. Attributes\n   are separated by commas. You can also use a string array encoding\n   (for example ``[\"name\",\"address\"]``). If an attribute has no match\n   for the query, the raw value is returned. By default all indexed text\n   attributes are highlighted. You can use ``*`` if you want to\n   highlight all textual attributes. Numerical attributes are not\n   highlighted. A matchLevel is returned for each highlighted attribute\n   and can contain:\n-  **full**: If all the query terms were found in the attribute.\n-  **partial**: If only some of the query terms were found.\n-  **none**: If none of the query terms were found.\n-  **attributesToSnippet**: A string that contains the list of\n   attributes to snippet alongside the number of words to return (syntax\n   is ``attributeName:nbWords``). Attributes are separated by commas\n   (Example: ``attributesToSnippet=name:10,content:10``). You can also\n   use a string array encoding (Example:\n   ``attributesToSnippet: [\"name:10\",\"content:10\"]``). By default, no\n   snippet is computed.\n-  **getRankingInfo**: If set to 1, the result hits will contain ranking\n   information in the \\*\\*\\_rankingInfo\\*\\* attribute.\n\nNumeric Search Parameters\n^^^^^^^^^^^^^^^^^^^^^^^^^\n\n-  **numericFilters**: A string that contains the comma separated list\n   of numeric filters you want to apply. The filter syntax is\n   ``attributeName`` followed by ``operand`` followed by ``value``.\n   Supported operands are ``<``, ``<=``, ``=``, ``>`` and ``>=``.\n\nYou can easily perform range queries via the ``:`` operator. This is\nequivalent to combining a ``>=`` and ``<=`` operand. For example,\n``numericFilters=price:10 to 1000``.\n\nYou can also mix OR and AND operators. The OR operator is defined with a\nparenthesis syntax. For example,\n``(code=1 AND (price:[0-100] OR price:[1000-2000]))`` translates to\n``encodeURIComponent(\"code=1,(price:0 to 10,price:1000 to 2000)\")``.\n\nYou can also use a string array encoding (for example\n``numericFilters: [\"price>100\",\"price<1000\"]``).\n\nCategory Search Parameters\n^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n-  **tagFilters**: Filter the query by a set of tags. You can AND tags\n   by separating them with commas. To OR tags, you must add parentheses.\n   For example, ``tags=tag1,(tag2,tag3)`` means *tag1 AND (tag2 OR\n   tag3)*. You can also use a string array encoding. For example,\n   ``tagFilters: [\"tag1\",[\"tag2\",\"tag3\"]]`` means *tag1 AND (tag2 OR\n   tag3)*.At indexing, tags should be added in the \\*\\*\\_tags\\*\\*\n   attribute of objects. For example ``{\"_tags\":[\"tag1\",\"tag2\"]}``.\n\nFaceting Parameters\n^^^^^^^^^^^^^^^^^^^\n\n-  **facetFilters**: Filter the query with a list of facets. Facets are\n   separated by commas and is encoded as ``attributeName:value``. To OR\n   facets, you must add parentheses. For example:\n   ``facetFilters=(category:Book,category:Movie),author:John%20Doe``.\n   You can also use a string array encoding. For example,\n   ``[[\"category:Book\",\"category:Movie\"],\"author:John%20Doe\"]``.\n-  **facets**: List of object attributes that you want to use for\n   faceting. Attributes are separated with a comma. For example,\n   ``\"category,author\"``. You can also use JSON string array encoding.\n   For example, ``[\"category\",\"author\"]``. Only the attributes that have\n   been added in **attributesForFaceting** index setting can be used in\n   this parameter. You can also use ``*`` to perform faceting on all\n   attributes specified in **attributesForFaceting**.\n-  **maxValuesPerFacet**: Limit the number of facet values returned for\n   each facet. For example, ``maxValuesPerFacet=10`` will retrieve a\n   maximum of 10 values per facet.\n\nDistinct Parameter\n^^^^^^^^^^^^^^^^^^\n\n-  **distinct**: If set to 1, enables the distinct feature, disabled by\n   default, if the ``attributeForDistinct`` index setting is set. This\n   feature is similar to the SQL \"distinct\" keyword. When enabled in a\n   query with the ``distinct=1`` parameter, all hits containing a\n   duplicate value for the attributeForDistinct attribute are removed\n   from results. For example, if the chosen attribute is ``show_name``\n   and several hits have the same value for ``show_name``, then only the\n   best one is kept and the others are removed.\n\n.. code:: python\n\n    index = client.init_index(\"contacts\")\n    res = index.search(\"query string\")\n    res = index.search(\"query string\", { \"attributesToRetrieve\": \"fistname,lastname\", \"hitsPerPage\": 20})\n\nThe server response will look like:\n\n.. code:: json\n\n    {\n      \"hits\": [\n        {\n          \"firstname\": \"Jimmie\",\n          \"lastname\": \"Barninger\",\n          \"objectID\": \"433\",\n          \"_highlightResult\": {\n            \"firstname\": {\n              \"value\": \"<em>Jimmie</em>\",\n              \"matchLevel\": \"partial\"\n            },\n            \"lastname\": {\n              \"value\": \"Barninger\",\n              \"matchLevel\": \"none\"\n            },\n            \"company\": {\n              \"value\": \"California <em>Paint</em> & Wlpaper Str\",\n              \"matchLevel\": \"partial\"\n            }\n          }\n        }\n      ],\n      \"page\": 0,\n      \"nbHits\": 1,\n      \"nbPages\": 1,\n      \"hitsPerPage\": 20,\n      \"processingTimeMS\": 1,\n      \"query\": \"jimmie paint\",\n      \"params\": \"query=jimmie+paint&attributesToRetrieve=firstname,lastname&hitsPerPage=50\"\n    }\n\nMultiple queries\n----------------\n\nYou can send multiple queries with a single API call using a batch of\nqueries:\n\n.. code:: python\n\n    # perform 3 queries in a single API call:\n    # - 1st query targets index `categories`\n    # - 2nd and 3rd queries target index `products` \n    results = self.client.multiple_queries([{\"indexName\" : \"categories\", \"query\" : myQueryString, \"hitsPerPage\": 3}\n      , {\"indexName\" : \"categories\", \"query\" : myQueryString, \"hitsPerPage\": 3, \"tagFilters\": \"promotion\"}\n      , {\"indexName\" : \"categories\", \"query\" : myQueryString, \"hitsPerPage\": 10}])\n\n    print results[\"results\"]\n\nThe resulting JSON answer contains a ``results`` array storing the\nunderlying queries answers. The answers order is the same than the\nrequests order.\n\nYou can specify a strategy to optimize your multiple queries: -\n**none**: Execute the sequence of queries until the end. -\n**stopIfEnoughMatches**: Execute the sequence of queries until the\nnumber of hits is reached by the sum of hits.\n\nGet an object\n-------------\n\nYou can easily retrieve an object using its ``objectID`` and optionally\nspecify a comma separated list of attributes you want:\n\n.. code:: python\n\n    # Retrieves all attributes\n    index.get_object(\"myID\")\n    # Retrieves firstname and lastname attributes\n    res = index.get_object(\"myID\", \"firstname,lastname\")\n    # Retrieves only the firstname attribute\n    res = index.get_object(\"myID\", \"firstname\")\n\nYou can also retrieve a set of objects:\n\n.. code:: python\n\n    res = index.get_objects([\"myID1\", \"myID2\"])\n\nDelete an object\n----------------\n\nYou can delete an object using its ``objectID``:\n\n.. code:: python\n\n    index.delete_object(\"myID\")\n\nDelete by query\n---------------\n\nYou can delete all objects matching a single query with the following\ncode. Internally, the API client performs the query, deletes all\nmatching hits, and waits until the deletions have been applied.\n\n.. code:: python\n\n    params = {}\n    index.delete_by_query(\"John\", params)\n\nIndex Settings\n--------------\n\nYou can retrieve all settings using the ``get_settings`` function. The\nresult will contain the following attributes:\n\nIndexing parameters\n~~~~~~~~~~~~~~~~~~~\n\n-  **attributesToIndex**: (array of strings) The list of fields you want\n   to index.If set to null, all textual and numerical attributes of your\n   objects are indexed. Be sure to update it to get optimal results.This\n   parameter has two important uses:\n-  *Limit the attributes to index*.For example, if you store a binary\n   image in base64, you want to store it and be able to retrieve it, but\n   you don't want to search in the base64 string.\n-  *Control part of the ranking*.(see the ranking parameter for full\n   explanation) Matches in attributes at the beginning of the list will\n   be considered more important than matches in attributes further down\n   the list. In one attribute, matching text at the beginning of the\n   attribute will be considered more important than text after. You can\n   disable this behavior if you add your attribute inside\n   ``unordered(AttributeName)``. For example,\n   ``attributesToIndex: [\"title\", \"unordered(text)\"]``. You can decide\n   to have the same priority for two attributes by passing them in the\n   same string using a comma as a separator. For example ``title`` and\n   ``alternative_title`` have the same priority in this example, which\n   is different than text priority:\n   ``attributesToIndex:[\"title,alternative_title\", \"text\"]``.\n-  **numericAttributesToIndex**: (array of strings) All numerical\n   attributes are automatically indexed as numerical filters. If you\n   don't need filtering on some of your numerical attributes, you can\n   specify this list to speed up the indexing. If you only need to\n   filter on a numeric value with the operator '=', you can speed up the\n   indexing by specifying the attribute with\n   ``equalOnly(AttributeName)``. The other operators will be disabled.\n-  **attributesForFaceting**: (array of strings) The list of fields you\n   want to use for faceting. All strings in the attribute selected for\n   faceting are extracted and added as a facet. If set to null, no\n   attribute is used for faceting.\n-  **attributeForDistinct**: The attribute name used for the\n   ``Distinct`` feature. This feature is similar to the SQL \"distinct\"\n   keyword. When enabled in queries with the ``distinct=1`` parameter,\n   all hits containing a duplicate value for this attribute are removed\n   from results. For example, if the chosen attribute is ``show_name``\n   and several hits have the same value for ``show_name``, then only the\n   best one is kept and others are removed.\n-  **ranking**: (array of strings) Controls the way results are\n   sorted.We have nine available criteria:\n-  **typo**: Sort according to number of typos.\n-  **geo**: Sort according to decreasing distance when performing a geo\n   location based search.\n-  **words**: Sort according to the number of query words matched by\n   decreasing order. This parameter is useful when you use the\n   ``optionalWords`` query parameter to have results with the most\n   matched words first.\n-  **proximity**: Sort according to the proximity of the query words in\n   hits.\n-  **attribute**: Sort according to the order of attributes defined by\n   attributesToIndex.\n-  **exact**:\n\n   -  If the user query contains one word: sort objects having an\n      attribute that is exactly the query word before others. For\n      example, if you search for the TV show \"V\", you want to find it\n      with the \"V\" query and avoid getting all popular TV shows starting\n      by the letter V before it.\n   -  If the user query contains multiple words: sort according to the\n      number of words that matched exactly (not as a prefix).\n\n-  **custom**: Sort according to a user defined formula set in the\n   **customRanking** attribute.\n-  **asc(attributeName)**: Sort according to a numeric attribute using\n   ascending order. **attributeName** can be the name of any numeric\n   attribute in your records (integer, double or boolean).\n-  **desc(attributeName)**: Sort according to a numeric attribute using\n   descending order. **attributeName** can be the name of any numeric\n   attribute in your records (integer, double or boolean). The standard\n   order is [\"typo\", \"geo\", \"words\", \"proximity\", \"attribute\", \"exact\",\n   \"custom\"].\n-  **customRanking**: (array of strings) Lets you specify part of the\n   ranking.The syntax of this condition is an array of strings\n   containing attributes prefixed by the asc (ascending order) or desc\n   (descending order) operator. For example,\n   ``\"customRanking\" => [\"desc(population)\", \"asc(name)\"]``.\n-  **queryType**: Select how the query words are interpreted. It can be\n   one of the following values:\n-  **prefixAll**: All query words are interpreted as prefixes.\n-  **prefixLast**: Only the last word is interpreted as a prefix\n   (default behavior).\n-  **prefixNone**: No query word is interpreted as a prefix. This option\n   is not recommended.\n-  **separatorsToIndex**: Specify the separators (punctuation\n   characters) to index. By default, separators are not indexed. Use\n   ``+#`` to be able to search Google+ or C#.\n-  **slaves**: The list of indices on which you want to replicate all\n   write operations. In order to get response times in milliseconds, we\n   pre-compute part of the ranking during indexing. If you want to use\n   different ranking configurations depending of the use case, you need\n   to create one index per ranking configuration. This option enables\n   you to perform write operations only on this index and automatically\n   update slave indices with the same operations.\n-  **unretrievableAttributes**: The list of attributes that cannot be\n   retrieved at query time. This feature allows you to have attributes\n   that are used for indexing and/or ranking but cannot be retrieved.\n   Defaults to null.\n-  **allowCompressionOfIntegerArray**: Allows compression of big integer\n   arrays. We recommended enabling this feature and then storing the\n   list of user IDs or rights as an integer array. When enabled, the\n   integer array is reordered to reach a better compression ratio.\n   Defaults to false.\n\nQuery expansion\n~~~~~~~~~~~~~~~\n\n-  **synonyms**: (array of array of string considered as equals). For\n   example, you may want to retrieve the **black ipad** record when your\n   users are searching for **dark ipad**, even if the word **dark** is\n   not part of the record. To do this, you need to configure **black**\n   as a synonym of **dark**. For example,\n   ``\"synomyms\": [ [ \"black\", \"dark\" ], [ \"small\", \"little\", \"mini\" ], ... ]``.\n   Synonym feature also supports multi-words expression like\n   ``\"synonyms\": [ [\"NY\", \"New York\"] ]``\n-  **placeholders**: (hash of array of words). This is an advanced use\n   case to define a token substitutable by a list of words without\n   having the original token searchable. It is defined by a hash\n   associating placeholders to lists of substitutable words. For\n   example,\n   ``\"placeholders\": { \"<streetnumber>\": [\"1\", \"2\", \"3\", ..., \"9999\"]}``\n   would allow it to be able to match all street numbers. We use the\n   ``< >`` tag syntax to define placeholders in an attribute. For\n   example:\n-  Push a record with the placeholder:\n   ``{ \"name\" : \"Apple Store\", \"address\" : \"&lt;streetnumber&gt; Opera street, Paris\" }``.\n-  Configure the placeholder in your index settings:\n   ``\"placeholders\": { \"<streetnumber>\" : [\"1\", \"2\", \"3\", \"4\", \"5\", ... ], ... }``.\n-  **disableTypoToleranceOn**: (string array) Specify a list of words on\n   which automatic typo tolerance will be disabled.\n-  **altCorrections**: (object array) Specify alternative corrections\n   that you want to consider. Each alternative correction is described\n   by an object containing three attributes:\n-  **word**: The word to correct.\n-  **correction**: The corrected word.\n-  **nbTypos** The number of typos (1 or 2) that will be considered for\n   the ranking algorithm (1 typo is better than 2 typos).\n\nFor example\n``\"altCorrections\": [ { \"word\" : \"foot\", \"correction\": \"feet\", \"nbTypos\": 1 }, { \"word\": \"feet\", \"correction\": \"foot\", \"nbTypos\": 1 } ]``.\n\nDefault query parameters (can be overwritten by queries)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n-  **minWordSizefor1Typo**: (integer) The minimum number of characters\n   needed to accept one typo (default = 4).\n-  **minWordSizefor2Typos**: (integer) The minimum number of characters\n   needed to accept two typos (default = 8).\n-  **hitsPerPage**: (integer) The number of hits per page (default =\n   10).\n-  **attributesToRetrieve**: (array of strings) Default list of\n   attributes to retrieve in objects. If set to null, all attributes are\n   retrieved.\n-  **attributesToHighlight**: (array of strings) Default list of\n   attributes to highlight. If set to null, all indexed attributes are\n   highlighted.\n-  **attributesToSnippet**: (array of strings) Default list of\n   attributes to snippet alongside the number of words to return (syntax\n   is 'attributeName:nbWords').By default, no snippet is computed. If\n   set to null, no snippet is computed.\n-  **highlightPreTag**: (string) Specify the string that is inserted\n   before the highlighted parts in the query result (defaults to\n   \"<em>\").\n-  **highlightPostTag**: (string) Specify the string that is inserted\n   after the highlighted parts in the query result (defaults to\n   \"</em>\").\n-  **optionalWords**: (array of strings) Specify a list of words that\n   should be considered optional when found in the query.\n\nYou can easily retrieve settings or update them:\n\n.. code:: python\n\n    settings = index.get_settings()\n    print settings\n\n.. code:: python\n\n    index.set_settings({\"customRanking\": [\"desc(followers)\"]})\n\nList indices\n------------\n\nYou can list all your indices along with their associated information\n(number of entries, disk size, etc.) with the ``list_indexes`` method:\n\n.. code:: python\n\n    print client.list_indexes()\n\nDelete an index\n---------------\n\nYou can delete an index using its name:\n\n.. code:: python\n\n    client.delete_index(\"contacts\")\n\nClear an index\n--------------\n\nYou can delete the index contents without removing settings and index\nspecific API keys by using the clearIndex command:\n\n.. code:: python\n\n    index.clear_index()\n\nWait indexing\n-------------\n\nAll write operations in Algolia are asynchronous by design.\n\nIt means that when you add or update an object to your index, our\nservers will reply to your request with a ``taskID`` as soon as they\nunderstood the write operation.\n\nThe actual insert and indexing will be done after replying to your code.\n\nYou can wait for a task to complete using the ``waitTask`` method on the\n``taskID`` returned by a write operation.\n\nFor example, to wait for indexing of a new object:\n\n.. code:: python\n\n    res = index.add_object({\"firstname\": \"Jimmie\", \n                           \"lastname\": \"Barninger\"})\n    index.wait_task(res[\"taskID\"])\n\nIf you want to ensure multiple objects have been indexed, you only need\nto check the biggest ``taskID``.\n\nBatch writes\n------------\n\nYou may want to perform multiple operations with one API call to reduce\nlatency. We expose four methods to perform batch operations: \\*\n``add_objects``: Add an array of objects using automatic ``objectID``\nassignment. \\* ``save_objects``: Add or update an array of objects that\ncontains an ``objectID`` attribute. \\* ``delete_objects``: Delete an\narray of objectIDs. \\* ``partial_update_objects``: Partially update an\narray of objects that contain an ``objectID`` attribute (only specified\nattributes will be updated).\n\nExample using automatic ``objectID`` assignment:\n\n.. code:: python\n\n    res = index.add_objects([{\"firstname\": \"Jimmie\", \n                             \"lastname\": \"Barninger\"},\n                            {\"firstname\": \"Warren\", \n                             \"lastname\": \"Speach\"}])\n\nExample with user defined ``objectID`` (add or update):\n\n.. code:: python\n\n    res = index.save_objects([{\"firstname\": \"Jimmie\", \n                              \"lastname\": \"Barninger\",\n                               \"objectID\": \"myID1\"},\n                              {\"firstname\": \"Warren\", \n                              \"lastname\": \"Speach\",\n                               \"objectID\": \"myID2\"}])\n\nExample that deletes a set of records:\n\n.. code:: python\n\n    res = index.delete_objects([\"myID1\", \"myID2\"])\n\nExample that updates only the ``firstname`` attribute:\n\n.. code:: python\n\n    res = index.partial_update_objects([{\"firstname\": \"Jimmie\", \n                                       \"objectID\": \"myID1\"},\n                                      {\"firstname\": \"Warren\", \n                                       \"objectID\": \"myID2\"}])\n\nIf you have one index per user, you may want to perform a batch\noperations across severals indexes. We expose a method to perform this\ntype of batch:\n\n.. code:: python\n\n    res = index.batch([\n        {\"action\": \"addObject\", \"indexName\": \"index1\", {\"firstname\": \"Jimmie\", \"lastname\": \"Barninger\"}},\n        {\"action\": \"addObject\", \"indexName\": \"index2\", {\"firstname\": \"Warren\", \"lastname\": \"Speach\"}}])\n\nThe attribute **action** can have these values: - addObject -\nupdateObject - partialUpdateObject - partialUpdateObjectNoCreate -\ndeleteObject\n\nSecurity / User API Keys\n------------------------\n\nThe admin API key provides full control of all your indices. You can\nalso generate user API keys to control security. These API keys can be\nrestricted to a set of operations or/and restricted to a given index.\n\nTo list existing keys, you can use ``list_user_keys`` method:\n\n.. code:: python\n\n    # Lists global API Keys\n    client.list_user_keys()\n    # Lists API Keys that can access only to this index\n    index.list_user_keys()\n\nEach key is defined by a set of permissions that specify the authorized\nactions. The different permissions are: \\* **search**: Allowed to\nsearch. \\* **browse**: Allowed to retrieve all index contents via the\nbrowse API. \\* **addObject**: Allowed to add/update an object in the\nindex. \\* **deleteObject**: Allowed to delete an existing object. \\*\n**deleteIndex**: Allowed to delete index content. \\* **settings**:\nallows to get index settings. \\* **editSettings**: Allowed to change\nindex settings. \\* **analytics**: Allowed to retrieve analytics through\nthe analytics API. \\* **listIndexes**: Allowed to list all accessible\nindexes.\n\nExample of API Key creation:\n\n.. code:: python\n\n    # Creates a new global API key that can only perform search actions\n    res = client.add_user_key([\"search\"])\n    print res[\"key\"]\n    # Creates a new API key that can only perform search action on this index\n    res = index.add_user_key([\"search\"])\n    print res[\"key\"]\n\nYou can also create an API Key with advanced settings:\n\n-  **validity**: Add a validity period. The key will be valid for a\n   specific period of time (in seconds).\n-  **maxQueriesPerIPPerHour**: Specify the maximum number of API calls\n   allowed from an IP address per hour. Each time an API call is\n   performed with this key, a check is performed. If the IP at the\n   source of the call did more than this number of calls in the last\n   hour, a 403 code is returned. Defaults to 0 (no rate limit). This\n   parameter can be used to protect you from attempts at retrieving your\n   entire index contents by massively querying the index.\n\nNote: If you are sending the query through your servers, you must use\nthe\n``enable_rate_limit_forward(\"TheAdminAPIKey\", \"EndUserIP\", \"APIKeyWithRateLimit\")``\nfunction to enable rate-limit.\n\n-  **maxHitsPerQuery**: Specify the maximum number of hits this API key\n   can retrieve in one call. Defaults to 0 (unlimited). This parameter\n   can be used to protect you from attempts at retrieving your entire\n   index contents by massively querying the index.\n-  **indexes**: Specify the list of targeted indices. You can target all\n   indices starting with a prefix or ending with a suffix using the '\\*'\n   character. For example, \"dev\\_\\*\" matches all indices starting with\n   \"dev\\_\" and \"\\*\\_dev\" matches all indices ending with \"\\_dev\".\n   Defaults to all indices if empty or blank.\n-  **referers**: Specify the list of referers. You can target all\n   referers starting with a prefix or ending with a suffix using the\n   '\\*' character. For example, \"algolia.com/\\*\" matches all referers\n   starting with \"algolia.com/\" and \"\\*.algolia.com\" matches all\n   referers ending with \".algolia.com\". Defaults to all referers if\n   empty or blank.\n-  **queryParameters**: Specify the list of query parameters. You can\n   force the query parameters for a query using the url string format\n   (param1=X&param2=Y...).\n-  **description**: Specify a description to describe where the key is\n   used.\n\n.. code:: python\n\n    # Creates a new index specific API key valid for 300 seconds, with a rate limit of 100 calls per hour per IP and a maximum of 20 hits\n\n    params = {\n        'validity': 300,\n        'maxQueriesPerIPPerHour': 100,\n        'maxHitsPerQuery': 20,\n        'indexes': ['dev_*'],\n        'referers': ['algolia.com/*'],\n        'queryParameters': 'typoTolerance=strict&ignorePlurals=false',\n        'description': 'Limited search only API key for algolia.com'\n    }\n\n    res = client.add_user_key(params)\n    print res[\"key\"]\n\nUpdate the permissions of an existing key:\n\n.. code:: python\n\n    # Update an existing global API key that is valid for 300 seconds\n    res = client.update_user_key(\"myAPIKey\", [\"search\"], 300)\n    print res[\"key\"]\n    # Update an existing index specific API key valid for 300 seconds, with a rate limit of 100 calls per hour per IP and a maximum of 20 hits\n    res = index.update_user_key(\"myAPIKey\", [\"search\"], 300, 100, 20)\n    print res[\"key\"]\n\nGet the permissions of a given key:\n\n.. code:: python\n\n    # Gets the rights of a global key\n    print client.get_user_key_acl(\"f420238212c54dcfad07ea0aa6d5c45f\")\n    # Gets the rights of an index specific key\n    print index.get_user_key_acl(\"71671c38001bf3ac857bc82052485107\")\n\nDelete an existing key:\n\n.. code:: python\n\n    # Deletes a global key\n    print client.delete_user_key(\"f420238212c54dcfad07ea0aa6d5c45f\")\n    # Deletes an index specific key\n    print index.delete_user_key(\"71671c38001bf3ac857bc82052485107\")\n\nYou may have a single index containing per user data. In that case, all\nrecords should be tagged with their associated user\\_id in order to add\na ``tagFilters=user_42`` filter at query time to retrieve only what a\nuser has access to. If you're using the `JavaScript\nclient <http://github.com/algolia/algoliasearch-client-js>`__, it will\nresult in a security breach since the user is able to modify the\n``tagFilters`` you've set by modifying the code from the browser. To\nkeep using the JavaScript client (recommended for optimal latency) and\ntarget secured records, you can generate a secured API key from your\nbackend:\n\n.. code:: python\n\n    # generate a public API key for user 42. Here, records are tagged with:\n    #  - 'user_XXXX' if they are visible by user XXXX\n    public_key = client.generate_secured_api_key('YourSearchOnlyApiKey', 'tagFilters=user_42')\n\nThis public API key can then be used in your JavaScript code as follow:\n\n.. code:: js\n\n    var client = algoliasearch('YourApplicationID', '<%= public_api_key %>');\n    client.setExtraHeader('X-Algolia-QueryParameters', 'tagFilters=user_42'); // must be same than those used at generation-time\n\n    var index = client.initIndex('indexName')\n\n    index.search('something', function(err, content) {\n      if (err) {\n        console.error(err);\n        return;\n      }\n\n      console.log(content);\n    });\n\nYou can mix rate limits and secured API keys by setting an extra\n``user_token`` attribute both at API key generation time and query time.\nWhen set, a unique user will be identified by her ``IP + user_token``\ninstead of only by her ``IP``. This allows you to restrict a single user\nto performing a maximum of ``N`` API calls per hour, even if she shares\nher ``IP`` with another user.\n\n.. code:: python\n\n    # generate a public API key for user 42. Here, records are tagged with:\n    #  - 'user_XXXX' if they are visible by user XXXX\n    public_key = client.generate_secured_api_key('YourRateLimitedApiKey', 'tagFilters=user_42', 'user_42')\n\nThis public API key can then be used in your JavaScript code as follow:\n\n.. code:: js\n\n    var client = algoliasearch('YourApplicationID', '<%= public_api_key %>');\n\n    // must be same than those used at generation-time\n    client.setExtraHeader('X-Algolia-QueryParameters', 'tagFilters=user_42');\n\n    // must be same than the one used at generation-time\n    client.setUserToken('user_42');\n\n    var index = client.initIndex('indexName')\n\n    index.search('another query', function(err, content) {\n      if (err) {\n        console.error(err);\n        return;\n      }\n\n      console.log(content);\n    });\n\nYou can also generate secured API keys to limit the usage of a key to a\nreferer. The generation use the same function than the Per user\nrestriction. This public API key can be used in your JavaScript code as\nfollow:\n\n.. code:: js\n\n    var client = algoliasearch('YourApplicationID', '<%= public_api_key %>');\n\n    // must be same than those used at generation-time\n    client.setExtraHeader('X-Algolia-AllowedReferer', 'algolia.com/*');\n\n    var index = client.initIndex('indexName')\n\n    index.search('another query', function(err, content) {\n      if (err) {\n        console.error(err);\n        return;\n      }\n\n      console.log(content);\n    });\n\nCopy or rename an index\n-----------------------\n\nYou can easily copy or rename an existing index using the ``copy`` and\n``move`` commands. **Note**: Move and copy commands overwrite the\ndestination index.\n\n.. code:: python\n\n    # Rename MyIndex in MyIndexNewName\n    print client.move_index(\"MyIndex\", \"MyIndexNewName\")\n    # Copy MyIndex in MyIndexCopy\n    print client.copy_index(\"MyIndex\", \"MyIndexCopy\")\n\nThe move command is particularly useful if you want to update a big\nindex atomically from one version to another. For example, if you\nrecreate your index ``MyIndex`` each night from a database by batch, you\nonly need to: 1. Import your database into a new index using\n`batches <#batch-writes>`__. Let's call this new index ``MyNewIndex``.\n1. Rename ``MyNewIndex`` to ``MyIndex`` using the move command. This\nwill automatically override the old index and new queries will be served\non the new one.\n\n.. code:: python\n\n    # Rename MyNewIndex in MyIndex (and overwrite it)\n    print client.move_index(\"MyNewIndex\", \"MyIndex\")\n\nBackup / Retrieve of all index content\n--------------------------------------\n\nYou can retrieve all index content for backup purposes or for SEO using\nthe browse method. This method can retrieve up to 1,000 objects per call\nand supports full text search and filters but the distinct feature is\nnot available Unlike the search method, the sort by typo, proximity, geo\ndistance and matched words is not applied, the hits are only sorted by\nnumeric attributes specified in the ranking and the custom ranking.\n\nYou can browse the index:\n\n.. code:: python\n\n    # Iterate with a filter over the index\n    res = self.index.browse_all({\"query\": \"test\", \"numericFilters\": \"i<42\"})\n    for hit in res\n        # Do something\n\n    # Retrieve the next cursor from the browse method\n    res = self.index.browse_from({\"query\": \"test\", \"numericFilters\": \"i<42\"}, None)\n    print res[\"cursor\"]\n\nLogs\n----\n\nYou can retrieve the latest logs via this API. Each log entry contains:\n\\* Timestamp in ISO-8601 format \\* Client IP \\* Request Headers (API Key\nis obfuscated) \\* Request URL \\* Request method \\* Request body \\*\nAnswer HTTP code \\* Answer body \\* SHA1 ID of entry\n\nYou can retrieve the logs of your last 1,000 API calls and browse them\nusing the offset/length parameters: \\* ***offset***: Specify the first\nentry to retrieve (0-based, 0 is the most recent log entry). Defaults to\n0. \\* ***length***: Specify the maximum number of entries to retrieve\nstarting at the offset. Defaults to 10. Maximum allowed value: 1,000. \\*\n***onlyErrors***: Retrieve only logs with an HTTP code different than\n200 or 201. (deprecated) \\* ***type***: Specify the type of logs to\nretrieve: \\* ***query***: Retrieve only the queries. \\* ***build***:\nRetrieve only the build operations. \\* ***error***: Retrieve only the\nerrors (same as ***onlyErrors*** parameters).\n\n.. code:: python\n\n    # Get last 10 log entries\n    print client.get_logs()\n    # Get last 100 log entries\n    print client.get_logs(0, 100)\n\n.. |Build Status| image:: https://travis-ci.org/algolia/algoliasearch-client-python.svg?branch=master\n   :target: https://travis-ci.org/algolia/algoliasearch-client-python\n.. |PyPI version| image:: https://badge.fury.io/py/algoliasearch.svg?branch=master\n   :target: http://badge.fury.io/py/algoliasearch\n.. |Coverage Status| image:: https://coveralls.io/repos/algolia/algoliasearch-client-python/badge.svg?branch=master\n   :target: https://coveralls.io/r/algolia/algoliasearch-client-python",
        "url": "http://pypi.python.org/pypi/algoliasearch",
        "summary": "Algolia Search API Client for Python",
        "command": "pip install 'algoliasearch'"
      },
      "algoliasearch-django": {
        "name": "algoliasearch-django",
        "description": "Algolia Search for Django\n=========================\n\nThis package lets you easily integrate the Algolia Search API to your\n`Django <https://www.djangoproject.com/>`__ project. It's based on the\n`algoliasearch-client-python <https://github.com/algolia/algoliasearch-client-python>`__\npackage.\n\nYou might be interested in this sample Django application providing a\ntypeahead.js based auto-completion and Google-like instant search:\n`algoliasearch-django-example <https://github.com/algolia/algoliasearch-django-example>`__\n\nCompatible with **Python 2.7**, **Python 3.2+** and **Django 1.7+**\n\n|Build Status| |Coverage Status| |PyPI version|\n\nTable of Content\n----------------\n\n**Get started**\n\n1. `Install <#install>`__\n2. `Setup <#setup>`__\n3. `Quick Start <#quick-start>`__\n4. `Commands <#commands>`__\n5. `Search <#search>`__\n6. `Geo-search <#geo-search>`__\n7. `Tags <#tags>`__\n8. `Options <#options>`__\n\nInstall\n-------\n\n.. code:: sh\n\n    pip install algoliasearch-django\n\nSetup\n-----\n\nIn your Django settings, add ``django.contrib.algoliasearch`` to\n``INSTALLED_APPS`` and add these two settings:\n\n.. code:: python\n\n    ALGOLIA = {\n        'APPLICATION_ID': 'MyAppID',\n        'API_KEY': 'MyApiKey'\n    }\n\nThere are two optional settings:\n\n-  ``INDEX_PREFIX``: prefix all indexes. Use it to separate different\n   applications, like ``site1_Products`` and ``site2_Products``.\n-  ``INDEX_SUFFIX``: suffix all indexes. Use it to differenciate\n   development and production environment, like ``Location_dev`` and\n   ``Location_prod``.\n-  ``AUTO_INDEXING``: automatically synchronize the models with Algolia\n   (default to **True**).\n\nQuick Start\n-----------\n\nSimply call ``AlgoliaSearch.register()`` for each of the models you want\nto index. A good place to do this is in your application's AppConfig\n(generally named ``apps.py``). More info in the\n`documentation <https://docs.djangoproject.com/en/1.8/ref/applications/>`__\n\n.. code:: python\n\n    from django.apps import AppConfig\n    from django.contrib import algoliasearch\n\n    class YourAppConfig(AppConfig):\n        name = 'your_app'\n\n        def ready(self):\n            YourModel = self.get_model('your_model')\n            algoliasearch.register(YourModel)\n\nAnd then, don't forget the line below in the ``__init__.py`` file of\nyour Django application.\n\n.. code:: python\n\n    default_app_config = 'your_django_app.apps.YourAppConfig'\n\nBy default, all the fields of your model will be used. You can configure\nthe index by creating a subclass of ``AlgoliaIndex``. A good place to do\nthis is in a separate file, like ``index.py``.\n\n.. code:: python\n\n    from django.contrib.algoliasearch import AlgoliaIndex\n\n    class YourModelIndex(AlgoliaIndex):\n        fields = ('name', 'date')\n        geo_field = 'location'\n        settings = {'attributesToIndex': ['name']}\n        index_name = 'my_index'\n\nAnd then replace ``algoliasearch.register(YourModel)`` with\n``algoliasearch.register(YourModel, YourModelIndex)``.\n\nCommands\n--------\n\n-  ``python manage.py algolia_reindex``: reindex all the registered\n   models. This command will first send all the record to a temporary\n   index and then moves it.\n-  ``python manage.py algolia_applysettings``: (re)apply the index\n   settings.\n-  ``python manage.py algolia_clearindex``: clear the index\n\nSearch\n------\n\nWe recommend the usage of our `JavaScript API\nClient <https://github.com/algolia/algoliasearch-client-js>`__ to\nperform queries directly from the end-user browser without going through\nyour server.\n\nHowever, if you want to search from your backend you can use the\n``raw_search(YourModel, 'yourQuery', params)`` method. It retrieves the\nraw JSON answer from the API.\n\n.. code:: python\n\n    from django.contrib.algoliasearch import raw_search\n\n    params = { \"hitsPerPage\": 5 }\n    raw_search(Contact, \"jim\", params)\n\nGeo-Search\n----------\n\nUse the ``geo_field`` attribute to localize your record. ``geo_field``\nshould be a callable that returns a tuple (latitude, longitude).\n\n.. code:: python\n\n    class Contact(models.model):\n        name = models.CharField(max_lenght=20)\n        lat = models.FloatField()\n        lng = models.FloatField()\n\n        def location(self):\n            return (self.lat, self.lng)\n\n\n    class ContactIndex(AlgoliaIndex):\n        fields = 'name'\n        geo_field = 'location'\n\n\n    algoliasearch.register(Contact, ContactIndex)\n\nTags\n====\n\nUse the ``tags`` attributes to add tags to your record. It can be a\nfield or a callable.\n\n.. code:: python\n\n    class ArticleIndex(AlgoliaIndex):\n        tags = 'category'\n\nAt query time, specify ``{ tagFilters: 'tagvalue' }`` or\n``{ tagFilters: ['tagvalue1', 'tagvalue2'] }`` as search parameters to\nrestrict the result set to specific tags.\n\nOptions\n=======\n\nCustom ``objectID``\n-------------------\n\nYou can choose which field will be used as the ``objectID``. The field\nshould be unique and can be a string or integer. By default, we use the\n``pk`` field of the model.\n\n.. code:: python\n\n    class ArticleIndex(AlgoliaIndex):\n        custom_objectID = 'post_id'\n\nCustom index name\n-----------------\n\nYou can customize the index name. By default, the index name will be the\nname of the model class.\n\n.. code:: python\n\n    class ContactIndex(algoliaindex):\n        index_name = 'Entreprise'\n\nIndex settings\n--------------\n\nWe provide many ways to configure your index allowing you to tune your\noverall index relevancy. All the configuration is explained on `our\nwebsite <https://www.algolia.com/doc/python#Settings>`__.\n\n.. code:: python\n\n    class ArticleIndex(AlgoliaIndex):\n        settings = {\n            'attributesToIndex': ['name', 'description', 'url'],\n            'customRanking': ['desc(vote_count)', 'asc(name)']\n        }\n\nRestrict indexing to a subset of your data\n------------------------------------------\n\nYou can add constraints controlling if a record must be indexed or not.\n``should_index`` should be a callable that returns a boolean.\n\n.. code:: python\n\n    class Contact(models.model):\n        name = models.CharField(max_lenght=20)\n        age = models.IntegerField()\n\n        def is_adult(self):\n            return (self.age >= 18)\n\n    class ContactIndex(AlgoliaIndex):\n        should_index = 'is_adult'\n\n.. |Build Status| image:: https://travis-ci.org/algolia/algoliasearch-django.svg?branch=master\n   :target: https://travis-ci.org/algolia/algoliasearch-django\n.. |Coverage Status| image:: https://coveralls.io/repos/algolia/algoliasearch-django/badge.svg?branch=master\n   :target: https://coveralls.io/r/algolia/algoliasearch-django\n.. |PyPI version| image:: https://badge.fury.io/py/algoliasearch-django.svg?branch=master\n   :target: http://badge.fury.io/py/algoliasearch-django",
        "url": "http://pypi.python.org/pypi/algoliasearch-django",
        "summary": "Algolia Search integration for Django",
        "command": "pip install 'algoliasearch-django'"
      },
      "algometer": {
        "name": "algometer",
        "description": "",
        "url": "http://pypi.python.org/pypi/algometer",
        "summary": "Easily test the pain thresholds of your algorithms",
        "command": "pip install 'algometer'"
      },
      "algopy": {
        "name": "algopy",
        "description": "ALGOPY is a tool for Algorithmic Differentiation (AD) and Taylor polynomial approximations.\nALGOPY makes it possible to perform computations on scalar and polynomial matrices.\nIt is designed to be as compatible to numpy as possible. I.e. views, broadcasting and most\nfunctions of numpy can be performed on polynomial matrices. Exampels are dot,trace,qr,solve,\ninv,eigh.\nThe reverse mode of AD is also supported by a simple code evaluation tracer.\n\nDocumentation with examples is available at http://packages.python.org/algopy/.",
        "url": "http://pypi.python.org/pypi/algopy",
        "summary": "ALGOPY: Taylor Arithmetic Computation and Algorithmic Differentiation",
        "command": "pip install 'algopy'"
      },
      "algorithm": {
        "name": "algorithm",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/algorithm",
        "summary": "Model an algorithm as a list of functions.",
        "command": "pip install 'algorithm'"
      },
      "algorithmia": {
        "name": "algorithmia",
        "description": "Algorithmia Python Client is a client library for accessing Algorithmia from python code. This library also gets bundled with any Python algorithms in Algorithmia.",
        "url": "http://pypi.python.org/pypi/algorithmia",
        "summary": "Algorithmia Python Client",
        "command": "pip install 'algorithmia'"
      },
      "algorithms": {
        "name": "algorithms",
        "description": "Algorithms\n==========\n\nThis is an attempt to build a cohesive module of algorithms in Python.\n\nThe purpose of this repo is to be a learning tool for myself and others.\n\nI used psuedo code from various sources and I have listed them as references in the source code of each algorithm.\n\nAlgorithms implemented so far:\n------------------------------\n\n**Sorting:**\n\n- Bogo Sort\n- Bubble Sort\n- Cocktail Sort\n- Comb Sort\n- Heap Sort\n- Insertion Sort\n- Merge Sort\n- Quick Sort\n- Selection Sort\n- Shell Sort\n\n**Searching:**\n\n- Binary Search\n- Boyer-Moore-Horspool\n- Knuth-Morris-Pratt\n- Rabin-Karp\n\n**Shuffling:**\n\n- Knuth/Fisher-Yates Shuffle\n\n**Math:**\n\n- Extended GCD\n\n\nInstallation:\n-------------\n\nTo install, simply\n\n::\n\n    $ pip install algorithms\n\n\nUsage:\n------\n\nOnce installed you can simply do the following in your program:\n\n::\n\n    from algorithms.sorting import bubble_sort\n\n    my_list = bubble_sort.sort(my_list)\n\n\nAll prequisites for the algorithms are listed in the source code for each algorithm.\n\n\nTests:\n------\n\nNose is used as the main test runner and all Unit Tests can be run by: \n\n::\n\n    $ python algorithms/run_tests.py\n\n\nContributing:\n-------------\n\nIf there is an algorithm or data structure that you do not see, but would like to add please feel free to do a pull request. I only ask two things:\n\n1. For each algorithm and data structure you implement please have corresponding unit tests to prove correctness.\n2. Please make sure that your module follows similar style guidelines that are laid out in the other modules.\n\nI want to personally thank everybody that has contributed so far and your names will be added to `AUTHORS.rst`.\n\n\nTODO:\n-----\n\nSee `TODO.rst`.\n\n\nLicense:\n--------\n\nCopyright (c) 2012 by Nic Young and contributors. See AUTHORS.rst for more details\n\nSome rights reserved.\n\nRedistribution and use in source and binary forms of the software as well as documentation, with or without modification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n\n* The names of the contributors may not be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE AND DOCUMENTATION IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE AND DOCUMENTATION, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",
        "url": "http://pypi.python.org/pypi/algorithms",
        "summary": "module of algorithms for Python",
        "command": "pip install 'algorithms'"
      },
      "alib": {
        "name": "alib",
        "description": "Alib provides simple testing without boilerplate.  For example, if\n*myfile.py* contains the line::\n\n     7 * 8 == 54  # I'm not sure about this!\n\nthen running::\n\n    $ python -m alib.test myfile.py\n\nwill, because the test fails, report the test line and the nature of\nthe failure::\n\n    line 3:  7 * 8 == 54  # I'm not sure about this!\n    (['Eq'], [ReturnValue(56), ReturnValue(54)])\n\nExceptions are caught.  The input line::\n\n    (1 + '2') == 3  # Can we add a string to a number?\n\nproduces::\n\n    line 4:  (1 + '2') == 3  # Can we add a string to a number?\n    (['Eq'], [ExceptionInstance(TypeError), ReturnValue(3)]\n\nThis test line succeeds (because the left hand side raises the right\nhand side).::\n\n    (1 + '2') ** TypeError  # We can't add a string to a number.\n\nTo test all Python files in the folder *path/to/mydir* run the command::\n\n    $ python -m alib.test path/to/mydir",
        "url": "http://pypi.python.org/pypi/alib",
        "summary": "A LIB-rary of useful Python code",
        "command": "pip install 'alib'"
      },
      "alibaba-python-sdk": {
        "name": "alibaba-python-sdk",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alibaba-python-sdk",
        "summary": "Aibaba SDK for python.",
        "command": "pip install 'alibaba-python-sdk'"
      },
      "alicat": {
        "name": "alicat",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alicat",
        "summary": "Python driver for Alicat mass flow controllers.",
        "command": "pip install 'alicat'"
      },
      "alice": {
        "name": "alice",
        "description": "",
        "url": "http://pypi.python.org/pypi/alice",
        "summary": "",
        "command": "pip install 'alice'"
      },
      "alienbuild": {
        "name": "alienbuild",
        "description": "A large code and asset build system written in python.",
        "url": "http://pypi.python.org/pypi/alienbuild",
        "summary": "A large code and asset build system written in python.",
        "command": "pip install 'alienbuild'"
      },
      "AlienFeed": {
        "name": "alienfeed",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AlienFeed",
        "summary": "AlienFeed is a simple Reddit client for viewing and opening links from your console.",
        "command": "pip install 'AlienFeed'"
      },
      "alignak_backend": {
        "name": "alignak_backend",
        "description": "Alignak-backend\r\n=================\n\r\n.. image:: https://travis-ci.org/Alignak-monitoring-contrib/alignak-backend.svg?branch=master\r\n    :target: https://travis-ci.org/Alignak-monitoring-contrib/alignak-backend\r\n\r\nDocumentation\r\n-------------------\n\r\nDocumentation is available on `Read the docs <http://alignak-backend.readthedocs.org/>`_.\r\n\r\nShort description\r\n-------------------\n\r\nThis package is an Alignak Backend.\r\n\r\nIt is used to:\r\n\r\n* manage configuration (hosts, services, contacts, timeperiods...)\r\n\r\n   * end user (webui, command line...) can get and add configurations elements\r\n   * Alignak gets this configuration when its arbiter module starts\r\n\r\n* manage retention\r\n\r\n   * Alignak load and save retention information for checks/hosts/services\r\n\r\n* manage live states\r\n\r\n   * Alignak add/update states for hosts and services\r\n   * end user (webui, command line...) can get these information",
        "url": "http://pypi.python.org/pypi/alignak_backend",
        "summary": "Alignak REST Backend",
        "command": "pip install 'alignak_backend'"
      },
      "alignak_backend_client": {
        "name": "alignak_backend_client",
        "description": "Package alignak_backend_client\r\n==============================\r\n[![Build Status](https://travis-ci.org/Alignak-monitoring-contrib/alignakbackend-api-client.svg?branch=master)](https://travis-ci.org/Alignak-monitoring-contrib/alignakbackend-api-client)\r\n[![Coverage Status](https://coveralls.io/repos/Alignak-monitoring-contrib/alignak-backend-client/badge.svg?branch=master&service=github)](https://coveralls.io/github/Alignak-monitoring-contrib/alignak-backend-client?branch=master)\r\n\r\nAlignak backend client\r\n\r\nThis package contains a Python class to use for interactions with Alignak backend REST API.",
        "url": "http://pypi.python.org/pypi/alignak_backend_client",
        "summary": "Client API for Alignak Backend",
        "command": "pip install 'alignak_backend_client'"
      },
      "alignak-mod-surveil-config": {
        "name": "alignak-mod-surveil-config",
        "description": "",
        "url": "http://pypi.python.org/pypi/alignak-mod-surveil-config",
        "summary": "Alignak module load config from Surveil API",
        "command": "pip install 'alignak-mod-surveil-config'"
      },
      "alignak_webui": {
        "name": "alignak_webui",
        "description": "Alignak Web UI\n==============\n\n.. image:: https://travis-ci.org/Alignak-monitoring-contrib/alignak-webui.svg?branch=master\n    :target: https://travis-ci.org/Alignak-monitoring-contrib/alignak-webui\n\n\n.. image:: https://coveralls.io/repos/Alignak-monitoring-contrib/alignak-webui/badge.svg?branch=master&service=github\n  :target: https://coveralls.io/github/Alignak-monitoring-contrib/alignak-webui?branch=master\n\n\n*Web User Interface for Alignak backend ...*\n\nDocumentation\n----------------------------------------\n\nYou can find documentation in the */docs* directory. **To be updated ...**\n\nBugs, issues and contributing\n----------------------------------------\n\nBefore submitting an issue or a pull request to the project, please take a moment to look over\nthe `contributing guidelines<https://github.com/Alignak-monitoring-contrib/alignak-webui/master/CONTRIBUTING.md/>`_ first.\n\nLicense\n----------------------------------------\n\nAlignak WebUI is available under the [GPL version 3](http://opensource.org/licenses/GPL-3.0).",
        "url": "http://pypi.python.org/pypi/alignak_webui",
        "summary": "Web User Interface for Alignak REST backend",
        "command": "pip install 'alignak_webui'"
      },
      "alignlib-lite": {
        "name": "alignlib-lite",
        "description": "alignlib - python wrapped C++ library around sequence alignment",
        "url": "http://pypi.python.org/pypi/alignlib-lite",
        "summary": "alignlib-lite - simple wrapper around alignlib C++ library for sequence alignment",
        "command": "pip install 'alignlib-lite'"
      },
      "alignment": {
        "name": "alignment",
        "description": "=========\nAlignment\n=========\n\nAlignment is a native Python library for generic sequence alignment. It is\nuseful in cases where your alphabet is arbitrarily large and you cannot use\ntraditional biological sequence analysis tools. It supports global and local\npairwise sequence alignment. I also plan to add support for profile-profile\nalignments, but who knows when.\n\nInstallation\n============\n\nYou can install the most recent release using pip:\n\n    pip install alignment\n\nUsage\n=====\n\nTypical usage looks like this::\n\n    from alignment.sequence import Sequence\n    from alignment.vocabulary import Vocabulary\n    from alignment.sequencealigner import SimpleScoring, GlobalSequenceAligner\n\n    # Create sequences to be aligned.\n    a = Sequence('what a beautiful day'.split())\n    b = Sequence('what a disappointingly bad day'.split())\n\n    # Create a vocabulary and encode the sequences.\n    v = Vocabulary()\n    aEncoded = v.encodeSequence(a)\n    bEncoded = v.encodeSequence(b)\n\n    # Create a scoring and align the sequences using global aligner.\n    scoring = SimpleScoring(2, -1)\n    aligner = GlobalSequenceAligner(scoring, -2)\n    score, encodeds = aligner.align(aEncoded, bEncoded, backtrace=True)\n\n    # Iterate over optimal alignments and print them.\n    for encoded in encodeds:\n        alignment = v.decodeSequenceAlignment(encoded)\n        print alignment\n        print 'Alignment score:', alignment.score\n        print 'Percent identity:', alignment.percentIdentity()\n        print\n\nTODO List\n=========\n\n- Profile-profile alignment is not working yet.",
        "url": "http://pypi.python.org/pypi/alignment",
        "summary": "Native Python library for generic sequence alignment.",
        "command": "pip install 'alignment'"
      },
      "alioss": {
        "name": "alioss",
        "description": "osscmd lets you create/delete/list bucket and upload/download/copy/delete file from/to\n        Aliyun OSS (Open Storage Service).\n\nThe package would not be update .\n===============================\n\nOSSCMS使用方法如READMD，安装方法如下:\n==================================\n\teasy_install alioss\n\t\n用法和ali的说明文档一致，但是可直接调用OSSCMD，方法类似于django-admin.py\nwindows下直接运行\n\tosscmd.py\n\n原文README如下\n===============================\n\n\n阿里云开放存储服务 Open Storage Service (OSS) Python SDK说明文档\n===============================================================\n\n阿里云开放存储服务官方网站:\n    http://oss.aliyun.com\n\n阿里云开放存储 \n===============================================================\n存储在OSS里的文件叫做\"object\". 所有的object都放在bucket里面。\n\n简介\n===============================================================\n这篇文档主要介绍如何使用Python来进行OSS API调用，并且介绍osscmd\n的简单使用。\n这篇文档假设你已经熟悉Python，熟悉OSS的相关概念，并且已经注册了\n阿里云的OSS服务，且获得了相应的ID和KEY。\n如果你还没有开通或者还不了解OSS，请移步OSS官方网站。\n\n环境要求\n===============================================================\nPython SDK需要：安装python 2.5（包括）以上且在3.0（不包括）以下\n的版本。\n可以在Windows平台和Linux平台使用。\n\n如何获取\n===============================================================\n1.  打开浏览器，输入oss.aliyun.com\n2.  找到Python SDK链接：\n3.  下载后可以得到类似OSS_Python_API_xxxxxxxx.tar.gz的包\n4.  进入压缩包所在的目录，进行解压缩\n5.  解压缩后得到，oss文件夹和osscmd文件\n \n使用说明\n===============================================================\n使用oss_api.py \n===============================================================\n1.  创建bucket\n    def put_bucket(self, bucket, acl='', headers=None):\n        等同create_bucket函数\n    def create_bucket(self, bucket, acl='', headers=None):\n        参数说明：\n            bucket，类型：string\n            acl，类型：string，目前为private，public-read， \n                public-read-write中的一种\n            headers， 类型：dict，默认为空\n        返回值说明：\n            HTTP Response \n            参见http://docs.python.org/2/library/httplib.html\n    def put_bucket_with_location(self, bucket, acl='',                                  location='', headers=None):\n        参数说明：\n            bucket，类型：string\n            acl，类型：string\n            location， 类型：string\n            headers， 类型：dict\n        返回值说明：\n            HTTP Response\n2.  删除bucket\n    def delete_bucket(self, bucket, headers=None):\n        参数说明：\n            bucket，类型：string\n            headers， 类型：dict\n        返回值说明：\n            HTTP Response\n3.  修改bucket访问权限\n    def put_bucket(self, bucket, acl='', headers=None):\n    def create_bucket(self, bucket, acl='', headers=None):\n        同1中的put_bucket和create_bucket\n4.  获取bucket访问权限\n    def get_bucket_acl(self, bucket):\n        参数说明：\n            bucket，类型：string\n        返回值说明：\n            HTTP Response\n5.  显示创建的bucket\n    def get_service(self, headers=None):\n        参数说明：\n            headers， 类型：dict\n        返回值说明：\n            HTTP Response\n    def list_all_my_buckets(self, headers=None):\n        参数说明：\n            headers， 类型：dict\n        返回值说明：\n            HTTP Response\n6.  上传object\n    def put_object_from_string(self, bucket, object,                               input_content,                               content_type=DefaultContentType,                               headers=None, params=None):\n        参数说明：   \n            bucket，类型：string\n            object，类型：string\n            input_content，类型：string\n            content_type，类型：string\n            headers，类型：dict\n            params，类型：dict\n        返回值说明：\n            HTTP Response\n    def put_object_from_file(self, bucket, object,                             filename, content_type='',                             headers=None, params=None):\n        参数说明：   \n            bucket，类型：string\n            object，类型：string\n            filename，类型：string，本地需要上传的文件名\n            content_type，类型：string，object的类型\n            headers，类型：dict\n            params，类型：dict\n        返回值说明：\n            HTTP Response\n7.  显示上传的object\n    def get_bucket(self, bucket, prefix='', marker='',                   delimiter='', maxkeys='', headers=None):\n        同list_bucket \n    def list_bucket(self, bucket, prefix='', marker='',                    delimiter='', maxkeys='', headers=None):\n        参数说明：   \n            bucket，类型：string\n            prefix，类型：string\n            marker，类型：string\n            delimiter，类型：string\n            maxkeys，类型：string\n            headers，类型：dict\n        返回值说明：\n            HTTP Response\n8.  删除object\n    def delete_object(self, bucket, object, headers=None):\n        参数说明：   \n            bucket，类型：string\n            object，类型：string\n            headers，类型：dict\n        返回值说明：\n            HTTP Response\n9.  下载object\n    def get_object_to_file(self, bucket, object,                           filename, headers=None):\n        参数说明：   \n            bucket，类型：string\n            object，类型：string\n            filename，类型：string，\n                将object内容下载到本地文件的文件名\n            headers，类型：dict\n        返回值说明：\n            HTTP Response\n10. 使用示例：\n在解压的oss目录下，创建一个测试文件test.py内容如下，\n并将ACCESS_ID和SECRET_ACCESS_KEY的内容填写正确，\n并且将BUCKET填写一个唯一的名字。\n\n#!/usr/bin/env python\n#coding=utf8\nimport time\nfrom oss_api import *\nfrom oss_xml_handler import *\nHOST=\"oss.aliyuncs.com\"\nACCESS_ID = \"\"\nSECRET_ACCESS_KEY = \"\"\n#ACCESS_ID and SECRET_ACCESS_KEY 默认是空，\n#请填入您申请的正确的ID和KEY.\nBUCKET = \"\"\n#bucket 默认是空，请填入唯一的bucket名称\n#例如test-bucket-20130101等带唯一日期的bucket名字.\n\ndef check_not_empty(input, msg=\"\"):\n    if not input:\n        print \"Please make sure %s not empty!\" % msg \n        exit(-1)\ndef check_res(res, msg=\"\"):\n    if res.status / 100 == 2:\n        print \"%s OK\" % msg\n    else:\n        print \"%s FAIL\" % msg\n        print \"ret:%s\" % res.status\n        print \"request-id:%s\" % res.getheader(\"x-oss-request-id\")\n        print \"reason:%s\" % res.read()\n        exit(-1)\n   \nif __name__ == \"__main__\": \n    #初始化\n    check_not_empty(ACCESS_ID, \"ACCESS_ID\")\n    check_not_empty(SECRET_ACCESS_KEY, \"SECRET_ACCESS_KEY\")\n    oss = OssAPI(HOST, ACCESS_ID, SECRET_ACCESS_KEY)\n    #创建属于自己的bucket\n    bucket = BUCKET \n    check_not_empty(bucket, \"bucket\")\n    acl = 'private'\n    headers = {}\n    res = oss.put_bucket(bucket, acl, headers)\n    check_res(res, \"create bucket\")\n\n    #列出创建的bucket\n    res = oss.get_service()\n    check_res(res, \"list all buckets\")\n    #把指定的字符串内容上传到bucket中,在bucket中的文件名叫object。\n    object = \"object_test\"\n    input_content = \"hello, OSS\"\n    content_type = \"text/HTML\"\n    headers = {}\n    res = oss.put_object_from_string(bucket, object, input_content, content_type, headers)\n    check_res(res, \"upload from string\")\n    #指定文件名, 把这个文件上传到bucket中,在bucket中的文件名叫object。\n    object = \"object_test\"\n    filename = __file__ \n    content_type = \"text/HTML\"\n    headers = {}\n    res = oss.put_object_from_file(bucket, object, filename, content_type, headers)\n    check_res(res, \"upload from localfile\")\n    #下载bucket中的object，内容在body中\n    object = \"object_test\"\n    headers = {}\n    res = oss.get_object(bucket, object, headers)\n    check_res(res, \"download object\")\n    #下载bucket中的object，把内容写入到本地文件中\n    object = \"object_test\"\n    headers = {}\n    filename = \"get_object_test_file\"\n    res = oss.get_object_to_file(bucket, object, filename, headers)\n    if os.path.isfile(filename):\n        os.remove(filename)\n    check_res(res, \"download object to localfile\")   \n    #查看bucket中所拥有的权限\n    res = oss.get_bucket_acl(bucket)\n    check_res(res, \"get bucket acl\")\n    #列出bucket中所拥有的object\n    prefix = \"\"\n    marker = \"\"\n    delimiter = \"/\"\n    maxkeys = \"100\"\n    headers = {}\n    res = oss.get_bucket(bucket, prefix, marker, delimiter, maxkeys, headers)   \n    check_res(res, \"list objects in bucket\")\n    #删除bucket中的object\n    object = \"object_test\"\n    headers = {}\n    res = oss.delete_object(bucket, object, headers)\n    check_res(res, \"delete object\")\n    #删除bucket\n    res = oss.delete_bucket(bucket)\n    check_res(res, \"delete bucket\")\n\n11. 示例的预期结果：\n    create bucket OK\n    list all buckets OK\n    upload from string OK\n    upload from localfile OK\n    download object OK\n    download object to localfile OK\n    get bucket acl OK\n    list objects in bucket OK\n    delete object OK\n    delete bucket OK\n\n使用osscmd\n===============================================================\n1.  在Linux上安装 osscmd.\n    sudo rm -r /usr/local/oss\n    sudo mkdir -p /usr/local/oss\n    sudo tar -zxf oss.tar.gz -C /usr/local/oss\n    sudo rm -f /usr/bin/osscmd\n    sudo ln -s /usr/local/oss/osscmd /usr/bin/osscmd\n    sudo chmod 755 /usr/local/oss/osscmd\n\n    在Windows上安装osscmd\n    解压缩包\n   \n2.  运行\"python osscmd config --id=YOUR_ID --key=YOUR_KEY\" \n    用来配置访问OSS所需要的认证码\n   \n\n3.  运行\"python osscmd getallbucket\" 列出创建的bucket.\n    如果是刚刚使用OSS的用户因为没有创建bucket，输出是空\n\n4.  运行\"python osscmd createbucket mybucket\" 创建一个名字\n    叫mybucket的bucket，有可能不成功，这个时候需要换一个名字。\n    因为OSS中的bucket名字是全局唯一的。\n\n5.  可以再次运行\"python osscmd getallbucket\" 查看是否创建成功。\n    如果没有成功请检查osscmd返回的错误信息。\n\n6.  成功创建bucket后。运行\"python osscmd list oss://mybucket/\",\n    查看bucket中有哪些object。\n    由于bucket中还没有\n    object，输出是空的。\n\n7.  向bucket中上传一个object.\n    $ md5sum my_local_file\n    7625e1adc3a4b129763d580ca0a78e44 my_local_file\n\n    $ python osscmd put my_local_file oss://mybucket/myobject\n\n8.  如果创建成功，再次运行\"python osscmd list oss://mybucket/\" \n\n9.  从bucket中下载object到本地文件，并比对下载的文件的md5值\n    $ python osscmd get oss://mybucket/myobject local_file\n\n    $ md5sum local_file\n    7625e1adc3a4b129763d580ca0a78e44  local_file\n\n10. 删除bucket中的object \n    $ python osscmd delete oss://mybucket/myobject\n\n11. 删除bucket, 注意，如果bucket中有object或者parts\n    则这个bucket不能被删除\n    $ python osscmd deletebucket test-oss-aliyun-com\n\nChangeHistory\n===============================================================\n0.3.2   -   2013-10-20\n* 修复osscmd的uploadfromdir命令中，在中文目录下，上传的object名字被截断的问题。\n* 修复oss_util.py中DEBUG被设置成True的情况下无法打印log的问题。\n* oss_api.py中增加了设置每次上传和下载大小的接口。\n* osscmd增加了--debug=true来打印日志。\n* oss_api.py中增加了上传失败时候的重试，最大重试100次。\n\n0.3.1   -   2013-08-02\n* 支持跳转。\n* 给oss_api.py部分函数增加说明。\n\n0.1.3   -   2013-07-12\n* 支持multipart相关操作，osscmd增加multipart相关的接口。\n  osscmd支持本地目录上传。\n  osscmd支持将bucket的某一个prefix的object下载到本地的目录。\n\n0.1.0   -   2011-11-15\n* 第一次操作支持基本的创建，删除和显示bucket。\n  支持创建，删除和显示object。",
        "url": "http://pypi.python.org/pypi/alioss",
        "summary": "Command line tool for managing Aliyun Open Storage Service.",
        "command": "pip install 'alioss'"
      },
      "alipay": {
        "name": "alipay",
        "description": "An Unofficial Alipay API for Python\n=======================================\n\n.. image:: https://img.shields.io/travis/lxneng/alipay.svg\n    :target: https://travis-ci.org/lxneng/alipay\n\n.. image:: https://img.shields.io/pypi/v/alipay.svg\n    :target: https://pypi.python.org/pypi/alipay/\n\n.. image:: https://img.shields.io/pypi/dm/alipay.svg\n    :target: https://pypi.python.org/pypi/alipay/\n\nOverview\n---------------------------------------\n\nAn Unofficial Alipay API for Python, It Contain these API:\n\n- Generate direct payment url\n- Generate partner trade payment url\n- Generate standard mixed payment url\n- Generate batch trans pay url\n- Generate send goods confirm url\n- Generate forex trade url\n- Generate QR code url\n- Verify notify\n\nofficial document: https://b.alipay.com/order/techService.htm\n\nInstall\n---------------------------------------\n\n.. code-block:: bash\n\n    pip install alipay\n\nUsage\n---------------------------------------\n\nInitialization\n~~~~~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: python\n\n    >>> from alipay import Alipay\n    >>> alipay = Alipay(pid='your_alipay_pid', key='your_alipay_key', seller_email='your_seller_mail')\n\nOr you can use `seller_id` instead of `seller_email`:\n\n.. code-block:: python\n\n    >>> alipay = Alipay(pid='your_alipay_pid', key='your_alipay_key', seller_id='your_seller_id')\n\nGenerate direct payment url\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n..\n\n    生成即时到账支付链接\n\nIntroduction: https://b.alipay.com/order/productDetail.htm?productId=2012111200373124\n\n.. code-block:: python\n\n\t>>> alipay.create_direct_pay_by_user_url(out_trade_no='your_order_id', subject='your_order_subject', total_fee='100.0', return_url='your_order\n\t_return_url', notify_url='your_order_notify_url')\n\t'https://mapi.alipay.com/gateway.do?seller_email=.....'\n\nGenerate partner trade payment url\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n..\n\n    生成担保交易支付链接\n\nIntroduction: https://b.alipay.com/order/productDetail.htm?productId=2012111200373121\n\n.. code-block:: python\n\n\t>>> params = {\n\t... 'out_trade_no': 'your_order_id',\n\t... 'subject': 'your_order_subject',\n\t... 'logistics_type': 'DIRECT',\n\t... 'logistics_fee': '0',\n\t... 'logistics_payment': 'SELLER_PAY',\n\t... 'price': '10.00',\n\t... 'quantity': '12',\n\t... 'return_url': 'your_order_return_url',\n\t... 'notify_url': 'your_order_notify_url'\n\t... }\n\t>>> alipay.create_partner_trade_by_buyer_url(**params)\n\t'https://mapi.alipay.com/gateway.do?seller_email=.....'\n\nGenerate standard mixed payment url\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n..\n\n    生成标准双接口支付链接\n\nIntroduction: https://b.alipay.com/order/productDetail.htm?productId=2012111300373136\n\n.. code-block:: python\n\n    >>> alipay.trade_create_by_buyer_url(**params)\n    'https://mapi.alipay.com/gateway.do?seller_email=.....'\n\nGenerate batch trans pay url\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n..\n\n    生成批量付款链接\n\nIntroduction: https://b.alipay.com/order/productDetail.htm?productId=2012111200373121\n\n.. code-block:: python\n\n\t>>> params = {\n\t... 'batch_list': (), #批量付款用户列表\n\t... 'account_name': 'seller_account_name', #卖家支付宝名称\n\t... 'batch_no': 'batch_id', #转账流水号，须唯一\n\t... 'notify_url': 'your_batch_notify_url' #异步通知地址\n\t... }\n\t>>> alipay.create_batch_trans_notify_url(**params)\n\t'https://mapi.alipay.com/gateway.do?seller_email=xxx&detail_data=....'\n\nNote: batch_list 为批量付款用户列表，具体格式如下例子：(如涉及中文请使用unicode字符)\n\n.. code-block:: python\n\n\t>>> batch_list = ({'account': 'test@xxx.com', #支付宝账号\n\t...                'name': u'测试', #支付宝用户姓名\n\t...                'fee': '100', #转账金额\n\t...                'note': 'test'},\n\t...               {'account': 'test@xxx.com', #支付宝账号\n\t...                'name': u'测试', #支付宝用户姓名\n\t...                'fee': '100', #转账金额\n\t...                'note': 'test'}) #转账原因\n\nGenerate send goods confirm url\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n..\n\n    生成确认发货链接\n\nIntroduction: https://cshall.alipay.com/support/help_detail.htm?help_id=491097\n\n.. code-block:: python\n\n    >>> params = {\n    ... 'trade_no': 'your_alipay_trade_id',\n    ... 'logistics_name': 'your_logicstic_name',\n    ... 'transport_type': 'EXPRESS',\n    ... 'invocie_no': 'your_invocie_no'\n    ... }\n    >>> alipay.send_goods_confirm_by_platform(**params)\n    'https://mapi.alipay.com/gateway.do?sign=.....&trade_no=...'\n\nGenerate forex trade url\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n..\n\n    - Create website payment for foreigners (With QR code)\n    - Create mobile payment for foreigners\n\nIntroduction: http://global.alipay.com/ospay/home.htm\n\n.. code-block:: python\n\n    >>> params = {\n    ... 'out_trade_no': 'your_order_id',\n    ... 'subject': 'your_order_subject',\n    ... 'logistics_type': 'DIRECT',\n    ... 'logistics_fee': '0',\n    ... 'logistics_payment': 'SELLER_PAY',\n    ... 'price': '10.00',\n    ... 'quantity': '12',\n    ... 'return_url': 'your_order_return_url',\n    ... 'notify_url': 'your_order_notify_url'\n    ... }\n    >>> # Create website payment for foreigners\n    >>> alipay.create_forex_trade_url(**params)\n    'https://mapi.alipay.com/gateway.do?service=create_forex_trade......'\n    >>> # Create mobile payment for foreigners\n    >>> alipay.create_forex_trade_wap_url(**params)\n    'https://mapi.alipay.com/gateway.do?service=create_forex_trade_wap......'\n\n\nGenerate QR code url\n~~~~~~~~~~~~~~~~~~~\n\n..\n\n    生成创建 QR 码链接\n\nIntroduction: https://b.alipay.com/order/productDetail.htm?productId=2012120700377303\n\n.. code-block:: python\n\n    >>> alipay.add_alipay_qrcode_url(**params)\n    'https://mapi.alipay.com/gateway.do?seller_id=.......'\n\nNote: 如果你的 `biz_data` 中有 Unicode 字符，在 dumps 的时候需要把 `ensure_ascii` 设置为 `False`，即 :code:`json.dumps(d, ensure_ascii=False)` 否则会遇到错误\n\n\nVerify notify\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nverify notify from alipay server, example in Pyramid Application\n\n.. code-block:: python\n\n    def alipy_notify(request):\n        alipay = request.registry['alipay']\n        if alipay.verify_notify(**request.params):\n            # this is a valid notify, code business logic here\n        else:\n            # this is a invalid notify\n\n\nExample in Pyramid Application\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nInclude alipay either by setting your includes in your .ini, or by calling config.include('alipay').\n\n.. code-block:: python\n\n\tpyramid.includes = alipay\n\nnow in your View\n\n.. code-block:: python\n\n    def some_view(request):\n        alipay = request.registry['alipay']\n        url = alipay.create_direct_pay_by_user_url(...)\n\n\nReference\n---------------------------------------\n\n- `Ruby Alipay GEM <https://github.com/chloerei/alipay>`_\n- `Official document <https://b.alipay.com/order/techService.htm>`_\n\n\nChangelog\n==============================\n\n\n0.7.1 - Sep.16, 2015\n--------------------------------\n\n- Fix verify_notify raise KeyError: 'sign' bug\n  https://github.com/lxneng/alipay/pull/18\n\n0.7 - Sep.07, 2015\n--------------------------------\n\n- add `create_forex_trade_url` method\n- add `create_forex_trade_wap_url` method\n- add `create_batch_trans_notify_url` method\n\n0.6 - Jul.27, 2015\n--------------------------------\n\n- add `send_goods_confirm_by_platform` method\n\n0.5 - Apr.16, 2015\n--------------------------------\n\n- add `add_alipay_qrcode` method\n\n0.4.2 - Feb.14, 2015\n--------------------------------\n\n- Fix argument type error of verify_notify in README\n\n- FIX SEVERE FAULT IN `check_notify_remotely`\n\n\n0.4.1 - Feb.09, 2015\n--------------------------------\n\n- Resolved README.rst is not formatted on pypi.python.org\n\n0.4 - Feb.09, 2015\n--------------------------------\n\n- Seller id support\n\n\n0.3 - Aug.03, 2014\n--------------------------------\n\n- Add wap payment support\n\n0.2.3 - Nov.20, 2013\n--------------------------------\n\n- english version readme doc\n\n0.2.2 - Nov.12, 2013\n--------------------------------\n\n- add includeme func for pyramid\n\n- update readme\n\n0.2.1 - Nov.11, 2013\n--------------------------------\n\n- fix rst doc\n\n0.2 - Nov.11, 2013\n--------------------------------\n\n- add unittest\n\n- update readme\n\n- add verify_notify func\n\n- add check_parameters func\n\n- add travis.yml\n\n- add tox.ini\n\n0.1 - Nov.11, 2013\n------------------------------\n\n- first commit",
        "url": "http://pypi.python.org/pypi/alipay",
        "summary": "An Unofficial Alipay API for Python",
        "command": "pip install 'alipay'"
      },
      "aliquoter": {
        "name": "aliquoter",
        "description": "Aliquoter\n=========\n\nAliquot mogrifier utilizing the BLM PLSS method of quartering/halving sections.\n\nPurpose\n-------\n\nGiven a quad of point pairs (long, lat) return a quad of point pairs for a \nspecific aliquot string.\n\nThis code should work on any quad in any orientation as long as north, south, \neast, west can be defined appropriately.\n\nThis code uses specific points rather than a bounding box set to 0 degrees.\n\nExample\n-------\n\nAliquot string: **E2SW4SW4**\n\nAliquot meaning: **The East half of the South West quarter of the South West quarter**\n\nThis would mean that the quad would be split up into a South West square (SW4) \nand then another South West square (SW4) and then the East half of that square \nwould be returned.\n\n<pre>\n4,0                                           4,4\n+-----------------------+-----------------------+\n|                       |                       |\n|                       |                       |\n|                       |                       |\n|                       |                       |\n|                       |                       |\n|                       |                       |\n|                       |                       |\n|                       |                       |\n|                       |                       |\n|          S-W          |                       |\n|          \\ /          |                       |\n+-----------+-----------+-----------------------+\n|           |           |                       |\n|           |           |                       |\n|           |           |                       |\n|    S-W    |           |                       |\n|    \\ /    |           |                       |\n+-----*******-----------+-----------------------+\n|     *     *           |                       |\n|     *     *           |                       |\n|     *  E  *           |                       |\n|     *     *           |                       |\n|     *     *           |                       |\n+-----*******-----------+-----------------------+\n0,0                                           0,4\n</pre>\n\nUsage\n-----\n\nCheck out 'test.py'.  It represents the above example and outputs the following.\n\nCode:\n\n```python\nfrom aliquoter import aliquot, Quad, Point\n\nprint aliquot(\n            Quad(\n                nw=Point(lat=4, long=0),\n                sw=Point(lat=0, long=0),\n                ne=Point(lat=4, long=4),\n                se=Point(lat=0, long=4),\n            ),\n            ['SW', 'SW', 'E']\n        )\n```\n\nIn the above code the list of aliquot quarters/halves is reversed to make \nprocessing more straight forward.\n\nResult:\n\n```\nQuad(\n    nw=Point(lat=1.0, long=0.5),\n    sw=Point(lat=0.0, long=0.5),\n    ne=Point(lat=1.0, long=1.0),\n    se=Point(lat=0.0, long=1.0)\n)\n```",
        "url": "http://pypi.python.org/pypi/aliquoter",
        "summary": "Aliquot Mogrifier",
        "command": "pip install 'aliquoter'"
      },
      "aliUtil": {
        "name": "aliutil",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aliUtil",
        "summary": "milehao util",
        "command": "pip install 'aliUtil'"
      },
      "Aliyun": {
        "name": "aliyun",
        "description": "==========================================\nA shell client for Aliyun public services.\n==========================================\nThis is a set of Aliyun public service shell client.\nSuch as Moye, Ganjiang, or some other services. It\nprovides a set of commands to communicate with Aliyun's\nREST server to fetch user specified information or\nto execute user commands for Aliyun cloud service.",
        "url": "http://pypi.python.org/pypi/Aliyun",
        "summary": "UNKNOWN",
        "command": "pip install 'Aliyun'"
      },
      "aliyuncli": {
        "name": "aliyuncli",
        "description": "##Aliyun Command Line Interface\n###Brief introduction\nAliyun Command Line Interface (aliyuncli) is a unified tool to manage your Aliyun services. From this tool you can invoke the open API of Aliyun productions easily. With just this one tool to download and configure , you can control multiple Aliyun services from the command line and automate them through scripts (like shell or python). \n\n\n###Aliyuncli on github\n\nNow aliyuncli has been uploaded the source code to github, and any one can fork the code freely. You can access the url of github: https://github.com/aliyun/aliyun-cli\n\n\n\n\n###How to install aliyuncli\n\nNow aliyun provides two way to install the aliyuncli:\n\n1. install aliyuncli using pip\n\n2. install from software package\n\n\n####Install aliyuncli using pip:\nIf you have installed the pip in your operation system, no matter windows Linux or Mac OS, you can install aliyuncli using pip:\n####Windows:\n\t\n\n\t> pip install aliyuncli\n\nTo upgrade the existing aliyuncli , use the --upgrade option:\n\t\n\n\t> pip install --upgrade aliyuncli\n\n####Linux , Mac OS and Unix:\n\n\t$ sudo pip install aliyuncli\n\nTo upgrade the existing aliyuncli , use the --upgrade option:\n\n\t$ pip install --upgrade aliyuncli\n\n\n###Install from software package\n\nIf you dont have the pip tool, you can also install aliyuncli from software package.\n\nAliyuncli supports all kind of operation systems: Windows , Linux and mac OS. You can choose the method by different OS.\n\nYou can find the software package from the following link:\n\t\n[click and download](http://market.aliyun.com/products/53690006/cmgj000314.html?spm=5176.900004.4.2.esAaC2)\n\nIt is free downloading now. The package contains three install packages: \ncli.tar.gz is for Linux and mac OS, AliyunCLI_x86 is for windows 32 OS and AliyunCLI_x64 is for windows 64 OS. \n\nYou can choose the install package according your operation system.\n\n\n####For windows:\n1.\tFind AliyunCLI.msi and double click the msi, you will go into the installation guide.\n\n2.\tClick the “next” button and choose your favorite path and confirm\n\n\n3.\tfinish the install\n\n\n\n \n\n####For Linux and Mac OS:\nYou can install like follow step:\n\n\t$ tar -zxvf cli.tar.gz\n\t$ cd cli\n\t$ sudo sh install.sh\n\n\n\n###Check the aliyuncli installation:\n\n\nConfirm the aliyuncli installed correctly by viewing the help file:\n\n\t$ aliyuncli help\n\nor \ndddd\n\t$ aliyuncli\n\n###How to install Aliyun python SDK\naliyuncli must work with aliyun python sdk(2.0) , you should install the sdk after you install the aliyuncli. Otherwise you can not access the aliyun service normally.\n\n\n####Install SDK using pip:\nAliyun python sdk only can be installed by pip. So please make sure your operation system has installed pip. Each product of aliyun has one sdk , you can install the required sdk one by one and no need install all of them.\n\n\nSuch as you need ECS sdk, you just install it as following command:\n\n\t$ sudo pip install aliyun-python-sdk-ecs\nIf you need RDS sdk, you just install it using:\n\n\t$ sudo pip install aliyun-python-sdk-rds\nFor SLB, you using:\n\n\t$ sudo pip install aliyun-python-sdk-slb\n\n\n####The SDK list:\n\nProduct|SDK\n----|----\nBatchCompute\t|aliyun-python-sdk-batchcompute\nBsn\t\t\t\t|aliyun-python-sdk-bsn\nBss\t\t\t\t|aliyun-python-sdk-bss\nCms\t\t\t\t|aliyun-python-sdk-cms\nCrm\t\t\t\t|aliyun-python-sdk-crm\nDrds\t\t\t|aliyun-python-sdk-drds\nEcs\t\t\t\t|aliyun-python-sdk-ecs\nEss\t\t\t\t|aliyun-python-sdk-ess\nFt\t\t\t\t|aliyun-python-sdk-ft\nOcs\t\t\t\t|aliyun-python-sdk-ocs\nOms\t\t\t\t|aliyun-python-sdk-oms\nOssAdmin\t\t|aliyun-python-sdk-ossadmin\nRam\t\t\t\t|aliyun-python-sdk-ram\nRds\t\t\t\t|aliyun-python-sdk-rds\nRisk\t\t\t|aliyun-python-sdk-risk\nR-kvstore\t\t|aliyun-python-sdk-r-kvstore\nSlb\t\t\t\t|aliyun-python-sdk-slb\nSts\t\t\t\t|aliyun-python-sdk-sts\nUbsms\t\t\t|aliyun-python-sdk-ubsms\nYundun\t\t\t|aliyun-python-sdk-yundun\n\n\n\n\t\n\n####Install python environment:\n\n\nAliyuncli must run under python environment, so please make sure your operation system has installed python environment. \n\nIf you don’t have python installed , installed version 2.6 or 2.7 (not support 3.X now) using one of the following methods:\n\n\nOn Windows or OS X, download the Python package for your operating system from python.org and run the installer.\n\nOn Linux, OS X, or Unix, install Python using your distribution's package manager.\n\n\n\n###How to configure aliyuncli\nBefore using aliyuncli you should create a AccessKey from your console. After login the aliyun console you can click the like as follow: \n\n\nThen you can create the access key and access secret:\n\n\n\n###Configure the aliyuncli quickly\n\nAfter create access key and access secret , you can configure aliyuncli quickly:\n\n\t$ aliyuncli configure\n\tAliyun Access Key ID [None]: <Your aliyun access key id>\n\tAliyun Access Key Secret [None]: <Your aliyun access key secret>\n\tDefault Region Id [None]: cn-hangzhou\n\tDefault output format [None]: table\n\nAccess key and access secret are certificate invoke the aliyun open API. Region id is the region area of aliyun ECS. Output format you can choose is table , json and text.\n\nTable format likes:\n \nJson format likes:\n \nText format like:\n\n \nYou can choose one format as your wish. \n\n\n###How to use aliyuncli\naliyuncli has four parts:\n\n\nFirst part is the name of the tool “aliyuncli”\n\nSecond part is the available service name, such as: ecs , rds, slb, ots\n\nThe third part is the available operation of each service.\n\nThe final part is the list of keys and values, this part can has multiple keys and values. The values can be number, string or json format. \n\nHere are some examples:\n\n\t$ aliyuncli rds DescribeDBInstances --PageSize 50\n\t$ aliyuncli ecs DescribeRegions\n\t$ aliyuncli rds DescribeDBInstanceAttribute --DBInstanceId xxxxxx\n\n####More usage\n\t--filter\nAliyuncli supports filter function. When we call any open API , the data from the server is json format by default. And filter function can help user handle the \"json\" format data easily. \n\nHere are some examples:\n\n\t$ aliyuncli ecs DescribeRegions --output json --filter Regions.Region[0]\n\t{\n\t\t\"LocalName\":\"\\u6df1\\u5733\"\n\t\t\"RegionId\": \"cn-shenzhen\"\n\t}\n\t$ aliyuncli ecs DescribeRegions --output json --filter Regions.Region[*].RegionId\n\t[\n    \t\"cn-shenzhen\", \n    \t\"cn-qingdao\", \n    \t\"cn-beijing\", \n    \t\"cn-hongkong\", \n    \t\"cn-hangzhou\", \n    \t\"us-west-1\"\n\t]\n\t$ aliyuncli ecs DescribeRegions --output json --filter Regions.Region[3].RegionId\n\t\"cn-hongkong\"\n\n\n\n\n###Command Completion\nOn Unix-like systems, the aliyuncli includes a command-completion feature that enables you to use the TAB key to complete a partially typed command. This feature is not automatically installed so you need to configure it manually.\n\n\nConfiguring command completion requires two pieces of information: the name of the shell you are using and the location of aliyun_completer script.\n####Check your shell:\nCurrent aliyuncli only supports two shells: bash and zsh. \n\n\n1.find aliyun_completer, you can use:\n\n\t$ which aliyun_completer\n\t/usr/local/bin/aliyun_completer\n2.enable command completion:\n\n\nbash - use the build-in command complete:\n\n\n\t$ complete -C ‘/usr/local/bin/aliyun_completer’ aliyuncli\nzsh - source bin/aliyun_zsh_completer.sh\n\n\t% source /usr/local/bin/aliyun_zsh_completer.sh\n####Test Command Completion\n\n\t$ aliyuncli sTAB\n\tecs     rds     slb\nThe services showing dependences the sdk you installed. \n\nFinally, to ensure that completion continues to work after a reboot, add the configuration command that you used to enable command completion to your shell profile.\n\n\n\t$ vim ~/.bash_profile\n\tAdd complete -C ‘/usr/local/bin/aliyun_completer’ aliyuncli to the end line.",
        "url": "http://pypi.python.org/pypi/aliyuncli",
        "summary": "Universal Command Line Environment for aliyun",
        "command": "pip install 'aliyuncli'"
      },
      "aliyunoss": {
        "name": "aliyunoss",
        "description": "Python SDK for Aliyun OSS(Open Storage Service).\nHope we will get an official packaging fron Aliyun Lazy Team soon.",
        "url": "http://pypi.python.org/pypi/aliyunoss",
        "summary": "Unofficial packaging for official aliyun oss python sdk",
        "command": "pip install 'aliyunoss'"
      },
      "aliyun-oss": {
        "name": "aliyun-oss",
        "description": "osscmd lets you create/delete/list bucket and upload/download/copy/delete file from/to\n        Aliyun OSS (Open Storage Service).",
        "url": "http://pypi.python.org/pypi/aliyun-oss",
        "summary": "Command line tool for managing Aliyun Open Storage Service.",
        "command": "pip install 'aliyun-oss'"
      },
      "aliyun-python-sdk": {
        "name": "aliyun-python-sdk",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk",
        "summary": "All modules of aliyun python sdk.",
        "command": "pip install 'aliyun-python-sdk'"
      },
      "aliyun-python-sdk-acs": {
        "name": "aliyun-python-sdk-acs",
        "description": "aliyun-python-sdk-acs\r\nThis is the acs module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-acs",
        "summary": "The acs module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-acs'"
      },
      "aliyun-python-sdk-batchcompute": {
        "name": "aliyun-python-sdk-batchcompute",
        "description": "aliyun-python-sdk-batchcompute\r\nThis is the batchcompute module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-batchcompute",
        "summary": "The batchcompute module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-batchcompute'"
      },
      "aliyun-python-sdk-bsn": {
        "name": "aliyun-python-sdk-bsn",
        "description": "aliyun-python-sdk-bsn\r\nThis is the bsn module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-bsn",
        "summary": "The bsn module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-bsn'"
      },
      "aliyun-python-sdk-bss": {
        "name": "aliyun-python-sdk-bss",
        "description": "aliyun-python-sdk-bss\r\nThis is the bss module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-bss",
        "summary": "The bss module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-bss'"
      },
      "aliyun-python-sdk-cms": {
        "name": "aliyun-python-sdk-cms",
        "description": "aliyun-python-sdk-cms\r\nThis is the cms module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-cms",
        "summary": "The cms module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-cms'"
      },
      "aliyun-python-sdk-core": {
        "name": "aliyun-python-sdk-core",
        "description": "======================\naliyun-python-sdk-core\n======================\n\nThis is the core module of Aliyun Python SDK.\n\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application,\nlibrary, or script with Aliyun services.\n\nThis module works on Python versions:\n\n   * 2.6.5 and greater\n\n\nDocumentation:\n\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-core",
        "summary": "The core module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-core'"
      },
      "aliyun-python-sdk-crm": {
        "name": "aliyun-python-sdk-crm",
        "description": "aliyun-python-sdk-crm\r\nThis is the crm module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-crm",
        "summary": "The crm module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-crm'"
      },
      "aliyun-python-sdk-drds": {
        "name": "aliyun-python-sdk-drds",
        "description": "aliyun-python-sdk-drds\r\nThis is the drds module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-drds",
        "summary": "The drds module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-drds'"
      },
      "aliyun-python-sdk-ecs": {
        "name": "aliyun-python-sdk-ecs",
        "description": "aliyun-python-sdk-ecs\r\nThis is the ecs module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-ecs",
        "summary": "The ecs module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-ecs'"
      },
      "aliyun-python-sdk-ess": {
        "name": "aliyun-python-sdk-ess",
        "description": "aliyun-python-sdk-ess\r\nThis is the ess module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-ess",
        "summary": "The ess module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-ess'"
      },
      "aliyun-python-sdk-ft": {
        "name": "aliyun-python-sdk-ft",
        "description": "aliyun-python-sdk-ft\r\nThis is the ft module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-ft",
        "summary": "The ft module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-ft'"
      },
      "aliyun-python-sdk-ocs": {
        "name": "aliyun-python-sdk-ocs",
        "description": "aliyun-python-sdk-ocs\r\nThis is the ocs module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-ocs",
        "summary": "The ocs module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-ocs'"
      },
      "aliyun-python-sdk-oms": {
        "name": "aliyun-python-sdk-oms",
        "description": "aliyun-python-sdk-oms\r\nThis is the oms module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-oms",
        "summary": "The oms module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-oms'"
      },
      "aliyun-python-sdk-oss": {
        "name": "aliyun-python-sdk-oss",
        "description": "osscmd lets you create/delete/list bucket and upload/download/copy/delete file from/to\n        Aliyun OSS (Open Storage Service).",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-oss",
        "summary": "Command line tool for managing Aliyun Open Storage Service.",
        "command": "pip install 'aliyun-python-sdk-oss'"
      },
      "aliyun-python-sdk-ossadmin": {
        "name": "aliyun-python-sdk-ossadmin",
        "description": "aliyun-python-sdk-ossadmin\r\nThis is the ossadmin module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-ossadmin",
        "summary": "The ossadmin module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-ossadmin'"
      },
      "aliyun-python-sdk-ram": {
        "name": "aliyun-python-sdk-ram",
        "description": "aliyun-python-sdk-ram\r\nThis is the ram module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-ram",
        "summary": "The ram module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-ram'"
      },
      "aliyun-python-sdk-rds": {
        "name": "aliyun-python-sdk-rds",
        "description": "aliyun-python-sdk-rds\r\nThis is the rds module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-rds",
        "summary": "The rds module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-rds'"
      },
      "aliyun-python-sdk-risk": {
        "name": "aliyun-python-sdk-risk",
        "description": "aliyun-python-sdk-risk\r\nThis is the risk module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-risk",
        "summary": "The risk module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-risk'"
      },
      "aliyun-python-sdk-r-kvstore": {
        "name": "aliyun-python-sdk-r-kvstore",
        "description": "aliyun-python-sdk-r-kvstore\r\nThis is the r-kvstore module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-r-kvstore",
        "summary": "The r-kvstore module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-r-kvstore'"
      },
      "aliyun-python-sdk-slb": {
        "name": "aliyun-python-sdk-slb",
        "description": "aliyun-python-sdk-slb\r\nThis is the slb module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-slb",
        "summary": "The slb module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-slb'"
      },
      "aliyun-python-sdk-sts": {
        "name": "aliyun-python-sdk-sts",
        "description": "aliyun-python-sdk-sts\r\nThis is the sts module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-sts",
        "summary": "The sts module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-sts'"
      },
      "aliyun-python-sdk-ubsms": {
        "name": "aliyun-python-sdk-ubsms",
        "description": "aliyun-python-sdk-ubsms\r\nThis is the ubsms module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-ubsms",
        "summary": "The ubsms module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-ubsms'"
      },
      "aliyun-python-sdk-yundun": {
        "name": "aliyun-python-sdk-yundun",
        "description": "aliyun-python-sdk-yundun\r\nThis is the yundun module of Aliyun Python SDK.\r\n\r\nAliyun Python SDK is the official software development kit. It makes things easy to integrate your Python application, library, or script with Aliyun services.\r\n\r\nThis module works on Python versions:\r\n\r\n2.6.5 and greater\r\nDocumentation:\r\n\r\nPlease visit http://develop.aliyun.com/sdk/python",
        "url": "http://pypi.python.org/pypi/aliyun-python-sdk-yundun",
        "summary": "The yundun module of Aliyun Python sdk.",
        "command": "pip install 'aliyun-python-sdk-yundun'"
      },
      "alkey": {
        "name": "alkey",
        "description": "# Alkey\n\n[Alkey][] is a [Redis][] backed tool for generating cache keys that implicitly\nupdate / invalidate when [SQLAlchemy][] model instances change, e.g.:\n\n    from alkey.cache import get_cache_key_generator\n    key_generator = get_cache_key_generator()\n    \n    # The `cache_key` will be invalidated when `instance1` or `instance2` change.\n    cache_key = key_generator(instance1, instance2)\n\nIt can be used by any [SQLAlchemy][] application that has access to [Redis][].\nPlus it has (optional) integration with the [Pyramid][] framework:\n`config.include` the package and generate keys using, e.g.:\n\n    cache_key = request.cache_key(request.context)\n\n## How it Works\n\n[Alkey][] works by binding to the SQLAlchemy session's [before_flush][] and\n[after_commit][] events to maintain a unique token, in Redis, against every\nmodel instance. As long as the model instance has a unique `id` property, this\ntoken will change whenever the instance is updated or deleted. In addition,\nAlkey maintains a global write token and a token against each database table.\nYou can use these to generate cache keys that invalidate:\n\n* when an *instance* changes\n* when a *table* changes; or\n* when *anything* changes\n\nThe main algorithm is to record instances as changed when they're flushed to\nthe db in the session's new, dirty or deleted lists (identifiers in the format\n`alkey:tablename#row_id`, e.g.: `alkey:users#1`, are stored in a Redis set).\nThen, when the session's transaction is committed, the tokens for each recorded\ninstance (plus their table and the global write token) are updated. This means\nthat a cache key that contains the tokens will miss, causing the cached value\nto be regenerated.\n\nNew tokens are generated when instances are looked up that are not already\nin the cache. So keys will always be invalidated if you lose / flush your\nRedis data.\n\n> Note also that changes recorded during a transaction that's\nsubsequently rolled back will be discarded (i.e.: the tokens will not be updated)\n*unless* the rolled-back transaction is a sub-transaction. In that case &mdash; if\nyour application code explicitly uses sub-transactions &mdash; rollbacks may lead\nto unnecessary cache-misses.\n\n## Configuring a Redis Client\n\n[Alkey][] looks in the `os.environ` (i.e.: you need to provide\n[environment variables][]) for a values to configure a [redis client][]:\n\n* `REDIS_URL`: a connection string including any authenticaton information, e.g.:\n  `redis://username:password@hostname:port`\n* `REDIS_DB`: defaults to `0`\n* `REDIS_MAX_CONNECTIONS`: the maximum number of connections for the client's\n  connection pool (defaults to not set)\n\n## Binding to Session Events\n\nUse the `alkey.events.bind` function, e.g.:\n    \n    from alkey import events\n    from myapp import Session # the sqlalchemy session you're using\n    \n    events.bind(Session)\n\n## Generating Cache Keys\n\nYou can then instantiate an `alkey.cache.CacheKeyGenerator` and call it with\nany of the following types as positional arguments to generate a cache key:\n\n* SQLAlchemy model instances\n* model instance identifiers in the format `alkey:tablename#row_id`\n* SQLAlchemy model classes\n* model class identifiers in the format `alkey:tablename#*`\n* the `alkey.constants.GLOBAL_WRITE_TOKEN`, which has the value `alkey:*#*`\n* arbitrary values that can be coerced to a unicode string\n\nE.g. using the `alkey.cache.get_cache_key_generator` factory to instantiate:\n\n    from alkey.cache import get_cache_key_generator\n    \n    key_generator = get_cache_key_generator()\n    cache_key = key_generator(instance, 'alkey:users#1', 1, 'foo', {'bar': 'baz'})\n\nOr, for example, imagine you have a `users` table, of which `user` is an instance\nwith an `id` of `1`:\n\n    # Invalidate when this user changes.\n    cache_key = key_generator(user)\n    cache_key = key_generator('alkey:users#1')\n\n    # Invalidate when any user is inserted, updated or deleted.\n    cache_key = key_generator(user.__class__)\n    cache_key = key_generator('alkey:users#*')\n\n    # Invalidate when any instance of any type is inserted, updated or deleted.\n    cache_key = key_generator('alkey:*#*')\n\nOr you can directly get the instance token with `alkey.cache.get_token`, e.g.:\n\n    from alkey.cache import get_token\n    from alkey.client import get_redis_client\n    \n    redis_client = get_redis_client()\n    \n    token = get_token(redis_client, user)\n    token = get_token(redis_client, 'alkey:users#1')\n\n## Pyramid Integration\n\nIf you're writing a [Pyramid][] application, you can bind to the session events\nby just including the package:\n\n    config.include('alkey')\n\nThis will, by default, use the [pyramid_basemodel][] threadlocal scoped session.\nTo use a different session class, provide a dotted path to it as the\n`alkey.session_cls` in your .ini settings, e.g.:\n\n    alkey.session_cls=myapp.model.Session\n\nAn appropriately configured `alkey.cache.CacheKeyGenerator` instance will then\nbe available as ``request.cache_key``, e.g:\n\n    key = request.cache_key(instance1, instance2, 'arbitrary string')\n\nOr e.g.: in a [Mako template][]:\n\n    <%page cached=True, cache_key=${request.cache_key(1, self.uri, instance)} />\n\n## Tests\n\n[Alkey][] has been developed and tested against Python2.7. To run the tests,\ninstall `mock`, `nose` and `coverage` and either hack the `setUp` method in\n`alkey.tests:IntegrationTest` or have a Redis db available at\n`redis://localhost:6379`. Then, e.g.:\n\n    $ nosetests alkey --with-doctest --with-coverage --cover-tests --cover-package alkey\n    ..........................\n    Name               Stmts   Miss  Cover   Missing\n    ------------------------------------------------\n    alkey                 11      0   100%   \n    alkey.cache           74      0   100%   \n    alkey.client          73      0   100%   \n    alkey.constants        6      0   100%   \n    alkey.events          12      0   100%   \n    alkey.handle          76      0   100%   \n    alkey.interfaces       6      0   100%   \n    alkey.tests          184      0   100%   \n    alkey.utils           30      0   100%   \n    ------------------------------------------------\n    TOTAL                472      0   100%   \n    ----------------------------------------------------------------------\n    Ran 26 tests in 0.566s\n    \n    OK\n\n[alkey]: http://github.com/thruflo/alkey\n[Redis]: http://redis.io\n[SQLAlchemy]: http://www.sqlalchemy.org/\n[redis client]: https://github.com/andymccurdy/redis-py\n[before_flush]: http://docs.sqlalchemy.org/ru/latest/orm/events.html#sqlalchemy.orm.events.SessionEvents.before_flush\n[after_commit]: http://docs.sqlalchemy.org/ru/latest/orm/events.html#sqlalchemy.orm.events.SessionEvents.after_commit\n[Pyramid]: http://docs.pylonsproject.org/projects/pyramid/en/latest\n[Mako template]: http://www.makotemplates.org/\n[pyramid_basemodel]: http://github.com/thruflo/pyramid_basemodel\n[environment variables]: http://blog.akash.im/per-project-environment-variables-with-forema\n[Heroku addons]: https://www.google.co.uk/search?q=Heroku+addons+redis\n",
        "url": "http://pypi.python.org/pypi/alkey",
        "summary": "Redis backed tool for generating cache keys.",
        "command": "pip install 'alkey'"
      },
      "Allanon": {
        "name": "allanon",
        "description": ".. contents::\n\nIntroduction\n============\n\nLet's say that you want to access a slow streaming site to see something (obviously: something not\nprotected by copyright).\n\nThe streaming site use URLs in that format:\n\n    http://legal-streaming-site.org/program-name/season5/episode4/\n\nEvery page contains some HTML code like the following::\n\n    ....\n        <div id=\"video-container\">\n           ...\n           <embed src=\"http://someotherurl.org/qwerty.flv\" ... \n           ...\n        <div>\n    ...\n\nLet say this is the URL for the episode 4 of the fifth season of your program.\nYou know that this program has 6 seasons with 22 episode each.\n\nAs said before: this site is very slow so you prefer downloading episodes in background\nthen watch them later.\n\nTo download them you need to watch the HTML inside the page and get some resources\n(commonly: and FLV file).\nThe best would be download *all* episode in a single (long running) operation instead of manually\ndoing it.\n\n**Allanon** will help you exactly in such tasks.\nYou simply need to provide it:\n\n* a simple URL or a *dynamic URL pattern*\n* a *query selector* for resources inside the page\n\nQuick example (you can keep it single lined)::\n\n    $ allanon --search=\"#movie-container embed\" \\\n    > \"http://legal-streaming-site.org/program-name/season{1:6}/episode{1:22}\"\n\nDocumentation\n=============\n\nInstallation\n------------\n\nYou can use `distribute`__ or `pip`__ to install the utility in your Python environment.\n\n__ http://pypi.python.org/pypi/distribute\n__ http://pypi.python.org/pypi/pip\n\n::\n\n    $ easy_install Allanon\n\nor alternately::\n\n    $ pip install Allanon\n\nInvocation\n----------\n\nAfter installing you will be able to run the ``allanon`` script from command line.\nFor example: run the following for access the utility help::\n\n    $ allanon --help\n\nBasic usage (you probably don't need Allanon at all for this)\n-------------------------------------------------------------\n\nThe ``allanon`` script accept an URL (or a list of URLs) to be downloaded::\n\n    $ allanon http://myhost/folder/image1.jpg http://myhost/folder/image2.jpg ...\n\nEvery command line URL given to Allanon can be a simple URL or an *URL model* like the following::\n\n    $ allanon \"http://myhost/folder/image{1:50}.jpg\"\n\nThis will crawl 50 different URLs automatically. \n\nMain usage (things became interesting now)\n------------------------------------------\n\nThe ``allanon`` script take an additional ``--search`` parameter (see the first example given\nabove).\nWhen you provide it, you are meaning:\n\n    \"*I don't want to download those URLs directly, but those URLs contain links to\n    file that I really want*\".\n\nThe search parameter format must be CSS 3 compatible, like the one supported the famous\n`jQuery library`__, and it's based onto the `pyquery`__ library.\nSee it's documentation for more details about what you can look for.\n\n__ http://api.jquery.com/category/selectors/\n__ http://packages.python.org/pyquery/\n\nExtreme usage\n-------------\n\nThe ``--search`` parameter can be provided multiple times::\n\n    $ allanon --search=\"ul.image-repos a\" \\\n    > --search=\"div.image-containers img\" \\\n    > \"http://image-repository-sites.org/category{1:30}.html\"\n\nWhen you provide (for example) two different search parameters, you are meaning:\n\n    \"*I don't want to download resources at given URLs. Those URLs contain links to secondary pages,\n    and inside those pages there're links to resources I want to download*\"\n\nFilters are applied in the given order, so:\n\n* Allanon will search inside 30 pages named *category1.html*, *category2.html*, ...\n* inside those pages, Allanon will look for all links inside ``ul`` tags with CSS class\n  *image-repos* and recursively crawl them.\n* inside those pages, Allanon will looks for images inside ``div`` with class *image-containers*.\n* images will be downloaded.\n\nPotentially you can continue this way, providing a third level of filters, and so on.\n\nNaming and storing downloaded resources\n---------------------------------------\n\nBy default Allanon download all files in the current directory so a filename conflict\nis possible.\nYou can control how/where download, changing dynamically the filename using the\n``--filename`` option and/or change the directory where to store files with the\n``--directory`` option.\n\nAn example::\n\n    $ allanon --filename=\"%HOST-%INDEX-section%1-version%3-%FULLNAME\" \\\n    > \"http://foo.org/pdf-repo-{1:10}/file{1:50}.pdf?version={0:3}\"\n\nAs you seen ``--filename`` accept some *markers* that can be used to better organize\nresources:\n\n``%HOST``\n    Will be replaced with the hostname used in the URL.\n``%INDEX``\n    Is a progressive from 1 to the number of downloaded resources.\n``%X``\n    When using dynamic URLs models you can refer to the current number of an URL\n    section.\n    \n    In this case \"%1\" is the current \"pdf-repo-*x*\" number and \"%3\" is the \"version\"\n    parameter value.\n``%FULLNAME``\n    The original filename (the one used if ``--filename`` is not provided).\n    \n    You can also use the ``%NAME`` and ``%EXTENSION`` to get only the name of the file\n    (without extension) or simply the extension.\n\nThe ``--directory`` option can be a simple directory name or a directory path (in unix-like\nformat, for example \"``foo/bar/baz``\").\n\nAn example::\n\n    $ allanon --directory=\"/home/keul/%HOST/%1\" \\\n    > \"http://foo.org/pdf-repo-{1:10}/file{1:50}.pdf\" \\\n    > \"http://baz.net/pdf-repo-{1:10}/file{1:50}.pdf\"\n\nAlso the ``--directory`` option supports some of the markers: you can use ``%HOST``, ``%INDEX`` and ``%X``\nwith the same meaning given above.\n\nTODO\n====\n\nThis utility is in alpha stage, a lot of thing can goes wrong when downloading and many features\nare missing:\n\n* verbosity controls\n* bandwidth control\n* multi-thread (let's look at `grequests`__)\n* Python 3\n\n__ https://github.com/kennethreitz/grequests\n\nIf you find other bugs or want to ask for missing features, use the `product's issue tracker`__.\n\n__ https://github.com/keul/Allanon/issues\n\n\nChangelog\n=========\n\n0.2 (2014-01-02)\n----------------\n\n- Do not crawl or download when on error pages\n- Handle duplicate filename when downloading resources:\n  added the ``--check-duplicate`` option\n- Application specific user agent header (configurable\n  through ``--user-agent`` option)\n- The ``--directory`` option can be a path and so create\n  intermediate directories, and accept markers\n- More efficient memory usage\n- Show progress bar when getting resources\n  (now requires `progress`__)\n- Fixed problem when getting quoted filename from response\n  header\n- Added the ``--timeout`` option\n- Added the ``--sleep`` option\n\n__ https://pypi.python.org/pypi/progress\n\n0.1 (2013-01-05)\n----------------\n\n- first release",
        "url": "http://pypi.python.org/pypi/Allanon",
        "summary": "A Web crawler that visit a predictable set of URLs, and automatically download resources you want from them",
        "command": "pip install 'Allanon'"
      },
      "AllanTools": {
        "name": "allantools",
        "description": "Given phase or fractional frequency data this package calculates:\n                        Allan deviation, overlapping Allan deviation, modified Allan deviation\n                        Hadamard deviation, overlapping Hadamard deviation, time deviation,\n                        total deviation, MTIE, TIE-rms",
        "url": "http://pypi.python.org/pypi/AllanTools",
        "summary": "Allan deviation and related time/frequency statistics",
        "command": "pip install 'AllanTools'"
      },
      "AllAttachmentsMacro": {
        "name": "allattachmentsmacro",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AllAttachmentsMacro",
        "summary": "A Trac wiki macro that shows all attachments uploaded on a Trac site.",
        "command": "pip install 'AllAttachmentsMacro'"
      },
      "Allegra": {
        "name": "allegra",
        "description": "",
        "url": "http://pypi.python.org/pypi/Allegra",
        "summary": "Asynchronous Network Peer Programming",
        "command": "pip install 'Allegra'"
      },
      "allegrordf": {
        "name": "allegrordf",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/allegrordf",
        "summary": "RDFLIB Allegro bindings",
        "command": "pip install 'allegrordf'"
      },
      "allen": {
        "name": "allen",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/allen",
        "summary": "printemyname",
        "command": "pip install 'allen'"
      },
      "allfiles": {
        "name": "allfiles",
        "description": "############################################\nallfiles: Iterate files in directory trees\n############################################\nallfiles privites functions which iterate files or directories\nin direcotory trees.\nThe code of allfiles is almost a recipe 2.17 \"Walking Directory Trees\" in Python Cookbook, 2nd Edition.\nHowever, it is modified as my wish.\n\nExample\n=======\n::\n  >>> from allfiles import allfiles\n  >>> allfiles('C:\\Python32\\lib')\n  <generator object allfiles at 0x02C8A2B0>\n  >>> for f in allfiles('C:\\Python32\\lib'):\n  ...     print(f)\n  ...\n  C:\\Python32\\lib\\abc.py\n  C:\\Python32\\lib\\aifc.py\n  C:\\Python32\\lib\\antigravity.py\n  C:\\Python32\\lib\\argparse.py\n  C:\\Python32\\lib\\ast.py\n  C:\\Python32\\lib\\asynchat.py\n  C:\\Python32\\lib\\asyncore.py\n  C:\\Python32\\lib\\base64.py\n  C:\\Python32\\lib\\bdb.py\n  C:\\Python32\\lib\\binhex.py\n     (and more files...)",
        "url": "http://pypi.python.org/pypi/allfiles",
        "summary": "Iterate matched files in directory trees",
        "command": "pip install 'allfiles'"
      },
      "alligator": {
        "name": "alligator",
        "description": "Alligator\n=========\n\n.. image:: https://travis-ci.org/toastdriven/alligator.png?branch=master\n        :target: https://travis-ci.org/toastdriven/alligator\n\nSimple offline task queues. For Python.\n\n\"See you later, alligator.\"\n\nLatest documentation at http://alligator.readthedocs.org/en/latest/.\n\n\nRequirements\n------------\n\n* Python 2.6+ or Python 3.3+\n* (Optional) ``redis`` for the Redis backend\n* (Optional) ``beanstalkc`` for the Beanstalk backend\n* (Optional) ``PyYAML`` for the Beanstalk backend\n* (Optional) ``boto>=2.35.0`` for the SQS backend\n\n\nWHY?!!1!\n--------\n\n* Because I have NIH-syndrome.\n* Or because I longed for something simple (~375 loc).\n* Or because I wanted something with tests (90%+ coverage) & docs.\n* Or because I wanted pluggable backends.\n* Or because testing some other queuing system was a pain.\n* Or because I'm an idiot.\n\n\nBasic Usage\n-----------\n\nThis example uses Django, but there's nothing Django-specific about Alligator.\n\nI repeat, You can use it with **any** Python code that would benefit from\nbackground processing.\n\n.. code:: python\n\n    from alligator import Gator\n\n    from django.contrib.auth.models import User\n    from django.shortcuts import send_email\n\n\n    # Make a Gator instance.\n    # Under most circumstances, you would configure this in one place &\n    # import that instance instead.\n    gator = Gator('redis://localhost:6379/0')\n\n\n    # The task itself.\n    # Nothing special, just a plain *undecorated* function.\n    def follow_email(followee_username, follower_username):\n        followee = User.objects.get(username=followee_username)\n        follower = User.objects.get(username=follower_username)\n\n        subject = 'You got followed!'\n        message = 'Hey {}, you just got followed by {}! Whoohoo!'.format(\n            followee.username,\n            follower.username\n        )\n        send_email(subject, message, 'server@example.com', [followee.email])\n\n\n    # An simple, previously expensive view.\n    @login_required\n    def follow(request, username):\n        # You'd import the task function above.\n        if request.method == 'POST':\n            # Schedule the task.\n            # Use args & kwargs as normal.\n            gator.task(follow_email, request.user.username, username)\n            return redirect('...')\n\n\nRunning Tasks\n-------------\n\nRather than trying to do autodiscovery, fanout, etc., you control how your\nworkers are configured & what they consume.\n\nIf your needs are simple, run the included ``latergator.py`` worker:\n\n.. code:: bash\n\n    $ python latergator.py redis://localhost:6379/0\n\nIf you have more complex needs, you can create a new executable file\n(bin script, management command, whatever) & drop in the following code.\n\n.. code:: python\n\n    from alligator import Gator, Worker\n\n    # Bonus points if you import that one pre-configured ``Gator`` instead.\n    gator = Gator('redis://localhost:6379/0')\n\n    # Consume & handle all tasks.\n    worker = Worker(gator)\n    worker.run_forever()\n\n\nLicense\n-------\n\nNew BSD\n\n\nFuture Wishlist\n---------------\n\nThese things aren't present yet, but maybe someday they will be.\n\n.. code:: python\n\n    # Delayed tasks (run in an hour).\n    with gator.options(run_after=60 * 60) as task:\n        task(this_can_wait)\n\n    # Dependent tasks, will only run if the listed tasks succeed.\n    # Maybe.\n    with gator.options(depends_on=[feeds_job]) as task:\n        task(rebuild_cache)\n\n\nRunning Tests\n-------------\n\nAlligator has 95%+ test coverage & aims to be passing/stable at all times.\n\nIf you'd like to run the tests, clone the repo, then run::\n\n    $ virtualenv env2\n    $ . env2/bin/activate\n    $ pip install -r requirements.txt\n    $ python setup.py develop\n    $ py.test -s -v --cov=alligator --cov-report=html tests\n\n\nTODO\n----\n\n* Scheduled tasks\n* Dependent tasks",
        "url": "http://pypi.python.org/pypi/alligator",
        "summary": "Simple offline task queues.",
        "command": "pip install 'alligator'"
      },
      "allink_essentials": {
        "name": "allink_essentials",
        "description": "collection of code fragments",
        "url": "http://pypi.python.org/pypi/allink_essentials",
        "summary": "collection of code fragments",
        "command": "pip install 'allink_essentials'"
      },
      "allmychanges": {
        "name": "allmychanges",
        "description": "Command Line Client to AllMyChanges.com\n=======================================\n\n[![](https://allmychanges.com/p/python/allmychanges/badge/)](https://allmychanges.com/p/python/allmychanges/)\n\nInstallation\n------------\n\n    pip install allmychanges\n\nNext, go to <https://allmychanges.com/account/token/> and obtain\nyour personal OAuth token.\n\nWrite this token into the config file like that:\n\n    # allmychanges.cfg\n    [allmychanges]\n    token = MY-SECRET-TOKEN\n\nExporting package list\n----------------------\n\n    amch export\n\nExport to a number of formats is available `--help` will tell you everything.\n\n\nAdding new packages in batch mode\n---------------------------------\n\nPrepare a datafile in one of supported formats and run\n\n    amch import --format yaml --input data.yaml\n\nIf you didn't entered sources for some packages, script\nwill ask you where these sources are. Answer honestly. :)\n\nIn some cases, script will try to help you. If somebody\nalready added package with such name and namespace, it will\nsuggest you the source. For python and perl packages, it will\nsearch different urls on the PyPi's pages or metacpan.org\nrespectively.\n\n\nAdding one or few packages from command line\n--------------------------------------------\n\nThis is also very easy:\n\n    amch add python/clint python/requests perl/Dancer\n\nYou could also specify a source url, like that:\n\n    amch add python/Dancer/https://github.com/PerlDancer/Dancer\n\nBut if you didn't, service will try to figure out url automatically\nand will suggest it in same way as it does in `import` command.\n\nUsing amch to import requirements.txt\n-------------------------------------\n\n### On Linux\n    cat requirements.txt | grep -v '^-e' | sed -e 's/\\([^=]\\+\\).*/python,\\1/' -e '1 i\\namespace,name' > data\n    amch import --input data\n\n### On OSX\n\nOSX have a posix `sed` command which is more strict and don't allow to do what we want in one line. The easiest way to overcome this, is to install `gnu-sed` via brew and to use `gsed` instead of `sed`: \n\n    brew install gnu-sed\n    cat requirements.txt | grep -v '^-e' | gsed -e 's/\\([^=]\\+\\).*/python,\\1/' -e '1 i\\namespace,name' > data\n    amch import --input data\n\nRoadmap\n-------\n\n* Process pip's requirements.txt files.\n* May be process some requirements of ruby and npm packages too.\n\nHacking\n-------\n\nFeel free [to fork](https://github.com/svetlyak40wt/allmychanges), file issues and send me patches.\n",
        "url": "http://pypi.python.org/pypi/allmychanges",
        "summary": "A command line client to AllMyChanges.com.",
        "command": "pip install 'allmychanges'"
      },
      "allmydata-tahoe": {
        "name": "allmydata-tahoe",
        "description": "==========\nTahoe-LAFS\n==========\n\nTahoe-LAFS is a Free and Open decentralized cloud storage system. It distributes\nyour data across multiple servers. Even if some of the servers fail or are taken\nover by an attacker, the entire file store continues to function correctly,\npreserving your privacy and security.\n\nTo get started please see `quickstart.rst`_ in the docs directory.\n\nLICENCE\n=======\n\nCopyright 2006-2015 The Tahoe-LAFS Software Foundation\n\nYou may use this package under the GNU General Public License, version 2 or, at\nyour option, any later version.  You may use this package under the Transitive\nGrace Period Public Licence, version 1.0, or at your option, any later\nversion. (You may choose to use this package under the terms of either licence,\nat your option.)  See the file `COPYING.GPL`_ for the terms of the GNU General\nPublic License, version 2.  See the file `COPYING.TGPPL.rst`_ for the terms of\nthe Transitive Grace Period Public Licence, version 1.0.\n\nSee `TGPPL.PDF`_ for why the TGPPL exists, graphically illustrated on three slides.\n\n.. _quickstart.rst: https://github.com/tahoe-lafs/tahoe-lafs/blob/master/docs/quickstart.rst\n.. _COPYING.GPL: https://github.com/tahoe-lafs/tahoe-lafs/blob/master/COPYING.GPL\n.. _COPYING.TGPPL.rst: https://github.com/tahoe-lafs/tahoe-lafs/blob/master/COPYING.TGPPL.rst\n.. _TGPPL.PDF: https://tahoe-lafs.org/~zooko/tgppl.pdf\n\n----\n\n.. image:: https://travis-ci.org/tahoe-lafs/tahoe-lafs.png?branch=master\n  :target: https://travis-ci.org/tahoe-lafs/tahoe-lafs\n\n.. image:: https://coveralls.io/repos/tahoe-lafs/tahoe-lafs/badge.png?branch=master\n  :target: https://coveralls.io/r/tahoe-lafs/tahoe-lafs?branch=master",
        "url": "http://pypi.python.org/pypi/allmydata-tahoe",
        "summary": "secure, decentralized, fault-tolerant filesystem",
        "command": "pip install 'allmydata-tahoe'"
      },
      "allocine-wrapper": {
        "name": "allocine-wrapper",
        "description": "===========\r\nPython Allocine\r\n===========\r\n\r\nPython Allocine provides a generic wrapper for Allocine API v3. Typical usage\r\noften looks like this::\r\n\r\n#!/usr/bin/env python\r\n\r\nfrom allocine.Allocine import Allocine\r\n\r\nresults = Allocine().search(\"the godfather\")\r\nmovie = results.movies[0]\r\nprint(movie.title)\r\nmovie.getInfo()\r\nprint(movie.synopsisShort)\r\n\r\n\r\nWhat this wrapper can do\r\n=========\r\n\r\nThis API allows you to query Allocine\r\n\r\n* Search\r\n* Access Person & Movies & Reviews",
        "url": "http://pypi.python.org/pypi/allocine-wrapper",
        "summary": "Wrapper of Allocine API",
        "command": "pip install 'allocine-wrapper'"
      },
      "allostery": {
        "name": "allostery",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/allostery",
        "summary": "This package deals with analysis of MD trajectories in order to understantd allostery.",
        "command": "pip install 'allostery'"
      },
      "alloy": {
        "name": "alloy",
        "description": "",
        "url": "http://pypi.python.org/pypi/alloy",
        "summary": "",
        "command": "pip install 'alloy'"
      },
      "alloyclient": {
        "name": "alloyclient",
        "description": "Alloy Client\n============\n\nDescription\n-----------\n\nA Python client and command-line tool for the Alloy digital archive. Also\nincludes a rudimentary client for any CDMI enabled cloud storage.\n\nAfter Installation_, connect to an Alloy archive::\n\n    alloy init --api=https://alloy.example.com/api/cdmi\n\n(or if authentication is required by the archive)::\n\n    alloy init --api=https://alloy.example.com/api/cdmi --username=USER --password=PASS\n\nShow current working container::\n\n    alloy pwd\n\nList a container or object::\n\n    alloy ls [name]\n\nMove to a new container::\n\n    alloy cd subdir\n    ...\n    alloy cd ..  # back up to parent\n\nCreate a new container::\n\n    alloy mkdir new\n\nPut a local file::\n\n    alloy put source.txt\n    ...\n    alloy put source.txt destination.txt  # Put to a different name remotely\n\nProvide the MIME type of the object (if not supplied ``alloy put`` will attempt\nto guess)::\n\n     alloy put --mimetype \"text-plain\" source.txt\n\nFetch a data object from the archive to a local file::\n\n    alloy get source.txt\n\n    alloy get source.txt destination.txt  # Get with a different name locally\n\n    alloy get --force source.txt  # Overwrite an existing local file\n\nRemove an object::\n\n    alloy rm file.txt\n\nRecursively remove a container (WARNING: Dangerous!)::\n\n    alloy rm -r container\n\nRemove an already empty container (Safer!)::\n\n    alloy rmdir container\n\nClose the current session to prevent unauthorized access::\n\n    alloy exit\n\n\nAdvanced Use - Metadata\n~~~~~~~~~~~~~~~~~~~~~~~\n\nSet (overwrite) a metadata value for a field::\n\n    alloy meta file.txt \"org.dublincore.creator=S M Body\"\n    alloy meta . \"org.dublincore.title=My Collection\"\n\nAdd another value to an existing metadata field::\n\n    alloy meta file.txt \"org.dublincore.creator+=A N Other\"\n\nList metadata values for all fields::\n\n    alloy meta file.txt\n\nList metadata value(s) for a specific field::\n\n    alloy meta file.txt org.dublincore.creator\n\nDelete a metadata field::\n\n    alloy meta file.txt \"org.dublincore.creator=\"\n\n\nInstallation\n------------\n\nCreate And Activate A Virtual Environment\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    $ virtualenv ~/ve/alloyclient<version>\n    ...\n    $ source ~/ve/alloyclient/bin/activate\n\n\nInstall Dependencies\n~~~~~~~~~~~~~~~~~~~~\n::\n\n    pip install -r requirements.txt\n\n\nInstall Alloy Client\n~~~~~~~~~~~~~~~~~~~~\n::\n\n    pip install -e .\n\n\nDetailed OSX install  commands\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n::\n\n    sudo easy_install virtualenv      # virtualenv installs pip\n    python -m virtualenv ~/ve/alloyclient<version>\n    source ~/ve/alloyclient<version>/bin/activate\n    pip install -r requirements.txt\n    pip install -e .\n\n\nLicense\n-------\n\nCopyright 2014 Archive Analytics Solutions\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.",
        "url": "http://pypi.python.org/pypi/alloyclient",
        "summary": "Alloy Client",
        "command": "pip install 'alloyclient'"
      },
      "AllPairs": {
        "name": "allpairs",
        "description": "Pairwise (aka \"all-pairs\") test combinations generator written in\nPython. Allows one to create a set of tests using \"pairwise \ncombinations\" method, reducing a number of combinations of variables\ninto a lesser set that covers most situations.",
        "url": "http://pypi.python.org/pypi/AllPairs",
        "summary": "Pairwise test combinations generator",
        "command": "pip install 'AllPairs'"
      },
      "allparts": {
        "name": "allparts",
        "description": "amsin is a simple command line tool to shortlink an\namazon URL.",
        "url": "http://pypi.python.org/pypi/allparts",
        "summary": "A tool to merge all part files in an s3 bucket.",
        "command": "pip install 'allparts'"
      },
      "allset": {
        "name": "allset",
        "description": "allset\r\n======\r\n\r\nA small python utility for auto-completing ``__all__`` and binding\r\nsub-modules in ``__init__.py`` files.\r\n\r\nHow to Use\r\n----------\r\n\r\nAdd these lines to the top of your ``__init__.py``.\r\n\r\n::\r\n\r\n    import allset\r\n    allset.set_all_submodules(globals())\r\n    allset.bind_all_submodules(globals())\r\n    del allset\r\n\r\nNow you can reference any sub-module with ``import mysubmodule`` or\r\n``from mysubmodule import SubModClassDef``. Additionally, the\r\n``from mymodule import *`` will work as though you specified all\r\nsub-modules in ``__all__`` manually.\r\n\r\nWhat's it do?\r\n-------------\r\n\r\n-  ``set_all_submodules`` sets up you ``__all__`` variable by\r\n   auto-detecting the files and sub-modules in the current directory.\r\n-  ``bind_all_submodules`` takes the submodules found in\r\n   ``set_all_submodules`` and applies them to the current namespace.",
        "url": "http://pypi.python.org/pypi/allset",
        "summary": "Generates dynamic bindings for module imports",
        "command": "pip install 'allset'"
      },
      "all_spark_cube_client": {
        "name": "all_spark_cube_client",
        "description": "See docs online at http://chadharrington.github.io/all_spark_cube/\n",
        "url": "http://pypi.python.org/pypi/all_spark_cube_client",
        "summary": "Python client library for the All Spark Cube",
        "command": "pip install 'all_spark_cube_client'"
      },
      "AllSpeak": {
        "name": "allspeak",
        "description": "========================\nAllspeak\n========================\n\nAllspeak is a pythonic (yet ironically inspired by Rails) i18n/l10n solution\nfor humans. It's flexible, easy to use and —unlike gettext— independent of\nany external compilation tool.\n\nHow can the translator of your multi-language web application update a text?\nCompiling `.po` files for a web app, really? How the Rails community solved\nthat problem? Translations in `yaml` or `json` files. With Python it should\nbe that simple. **Now it is**.\n\nAnd the files used by Allspeak are compatible with those of Rails, so you can\nuse any third-party service already compatible with them\n(for example, `Transifex <https://www.transifex.com/>`_).\n\nPowered by the awesome Babel and pytz libraries for the l10n part.\n\nWhat's in a name?\n----------------------------------------------\n\n    \"When Thor speaks with the All-Speak anyone who hears him will hear him\n    speak their native language in their hearts\" ——(from Thor's wiki page)\n\n:copyright: `Juan-Pablo Scaletti <http://jpscaletti.com>`_.\n:license: Three clause BSD License, see LICENSE for more details.",
        "url": "http://pypi.python.org/pypi/AllSpeak",
        "summary": "A pythonic internationalization and localization solution",
        "command": "pip install 'AllSpeak'"
      },
      "AllTray": {
        "name": "alltray",
        "description": "AllTray\n=========\nMake a System Tray Icon for all application.\n\nInstall\n-------\nSimple Install with pip::\n\n    pip install alltray --user\n\nFrom source::\n\n    python setup.py install\n\nUsage\n-----\n::\n\n    $ alltray --help\n\n    usage: alltray.py [-h] [--config CONFIG] [--tooltip TOOLTIP] [--icon ICON]\n                      [command]\n\n    positional arguments:\n      command            To run command\n\n    optional arguments:\n      -h, --help         show this help message and exit\n      --config CONFIG    command group\n      --tooltip TOOLTIP  tray tool tip\n      --icon ICON        command icon\n\nexample::\n\n    alltray --config chinadns\n\nPack execute or app file\n-------------------------\nFor window, use cx_Freeze_\nFor mac os x, still has some issue...\n\ncx_Freeze\n~~~~~~~~~\n::\n\n    python cx_Freeze_setup.py bdist\n\npyinstaller\n~~~~~~~~~~~\n\n1. install pywin32 from http://sourceforge.net/projects/pywin32/files/\n2. pip install pyinstaller\n3. [option] install upx from http://upx.sourceforge.net/\n4. Run ``pyinstaller --clean -i Apps-wheelchair.icns -w alltray.py``\n\nExecute file will be found in \"dist\" directory.\n\n.. important::\n\n    + The execute file only be exectuted in ASCII directory. No support other encoding directory. It just is pyinstaller bug.\n    + The single execute file could not be run in window 64bit! bug!\n\npy2exe\n~~~~~~~\ntoo old, please ignore it.\n::\n\n    python py2exe_setup.py py2exe\n\nIcon\n-----\nhttp://www.iconarchive.com/show/nuoveXT-2-icons-by-saki/Apps-wheelchair-icon.html\n\nScreenshot\n----------\n+ Window\n\n.. image:: screenshot_window.png\n\n+ Ubuntu\n\n.. image:: screenshot_ubuntu.png",
        "url": "http://pypi.python.org/pypi/AllTray",
        "summary": "Tray all application",
        "command": "pip install 'AllTray'"
      },
      "Allura": {
        "name": "allura",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Allura",
        "summary": "UNKNOWN",
        "command": "pip install 'Allura'"
      },
      "ally": {
        "name": "ally",
        "description": "",
        "url": "http://pypi.python.org/pypi/ally",
        "summary": "",
        "command": "pip install 'ally'"
      },
      "allyourbase": {
        "name": "allyourbase",
        "description": "allyourbase\n===========\n\nAll Your Base is a python library for converting number strings from any base to number strings of any other base.\n\nThis library was created to make the following improvements on existing base conversion libraries out there:\n\n- Can convert both integers and floats\n- Uses Decimal package to allow for arbitrary precision / number of digits\n- Uses Decimal package to avoid binary rounding errors\n- Is not limited to base 36, 62, 64 due to available characters. Can convert to/from any integer base from 2 to whatever you like. (higher bases use delimited decimal format)",
        "url": "http://pypi.python.org/pypi/allyourbase",
        "summary": "Numerical base converter, allowing arbitrary floating point precision and conversion between any integer bases",
        "command": "pip install 'allyourbase'"
      },
      "ally-py": {
        "name": "ally-py",
        "description": "REST development framework",
        "url": "http://pypi.python.org/pypi/ally-py",
        "summary": "Ally-Py",
        "command": "pip install 'ally-py'"
      },
      "alman": {
        "name": "alman",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alman",
        "summary": "Alman is a calendar scheduling API.",
        "command": "pip install 'alman'"
      },
      "almir": {
        "name": "almir",
        "description": "Documentation: http://readthedocs.org/docs/almir/\r\n\n\nChangelog\n=========\n\n0.1.8 (2013-05-16)\n------------------\n\n- fix bug introduced in 0.1.5 that crashed almir while doing configuration\n  [Domen Kožar]\n\n\n0.1.7 (2013-03-27)\n------------------\n\n- [bug] Add also LICENSE to MANIFEST.in\n  [Domen Kožar]\n\n\n0.1.6 (2013-03-27)\n------------------\n\n- [bug] Add .ini to MANIFEST.in\n  [Domen Kožar]\n\n\n0.1.5 (2013-03-27)\n------------------\n\n- [feature] Refactor the package a bit, so it's easier to package it for Linux distributions\n  [Domen Kožar]\n\n- [bug] Update MANIFEST.in so all files are included in release\n  [Domen Kožar]\n\n- [bug] Add new bootstrap.py and pin down zc.buildout version to avoid upgrading zc.buildout to 2.0\n  [Domen Kožar]\n\n- [feature] Add apache2 configuration example\n  [Iban]\n\n0.1.4 (2013/03/23)\n------------------\n\n- brownbag release\n\n0.1.3 (2012/08/27)\n------------------\n\n- [bug] upgraded doctutils as it was failing buildout\n  [Domen Kožar]\n\n- removed some dependencies on production, upgraded zc.buildout to 1.6.3 for faster installation\n  [Domen Kožar]\n\n- determine version from distribution metadata\n  [Domen Kožar]\n\n0.1.2 (2012/05/31)\n------------------\n\n- [bug] interactive installer would swallow error message when SQL connection string was not formatted correctly\n\n- [bug]: #7: don't word wrap size columns\n\n- [feature] add manual install steps\n\n- [bug] #4: client detail page did not render if client had no successful backup\n\n- [bug] #5: correctly parse scheduled jobs (choked on Admin job)\n\n- [feature] use python2.7 or python2.6, otherwise abort installation\n\n\n0.1.1 (2012/04/18)\n------------------\n\n- [bug] fix support for postgresql 9.1\n  [Domen Kožar]\n\n- [feature] add reboot crontab for almir daemon\n  [Domen Kožar]\n\n- [bug] MySQL database size calculation was wrong, sometimes crashing the dashboard\n  [Domen Kožar]\n\n- [bug] console command list was not ordered and search box was not shown\n  [Domen Kožar]\n\n- [bug] bconsole did not accept non-asci input\n  [Domen Kožar]\n\n\n0.1 (2012/04/06)\n----------------\n\n- Initial version\n  [Domen Kožar]",
        "url": "http://pypi.python.org/pypi/almir",
        "summary": "Almir is a Bacula (backup solution) web interface written in Python.",
        "command": "pip install 'almir'"
      },
      "almost": {
        "name": "almost",
        "description": "Almost\n~~~~~~\n\nA helper for approximate comparison.\n\n::\n\n    from almost import almost\n    \n    def test_repeating_decimal():\n        assert almost(1 / 3.) == 0.333\n        assert almost(1 / 6.) == 0.167\n        assert almost(3227 / 555., precision=6) == 5.814414\n\n    def test_irrational_number():\n        import math\n        assert almost(math.pi) == 3.142\n        assert almost(math.sqrt(2)) == 1.414\n\n    def test_random_text():\n        import random\n        def gen_text_with_prefix(prefix):\n            return prefix + str(random.random())[:-5]\n        assert almost(gen_text_with_prefix('@')) == '@...'\n\nLinks\n`````\n\n* `GitHub repository <http://github.com/sublee/almost>`_\n* `development version\n  <http://github.com/sublee/almost/zipball/master#egg=almost-dev>`_",
        "url": "http://pypi.python.org/pypi/almost",
        "summary": "A helper to compare two numbers generously",
        "command": "pip install 'almost'"
      },
      "almost-empty": {
        "name": "almost-empty",
        "description": "AlmostEmpty is a command-line utility for creating barebones projects in\na variety of languages.\n\nAn *AlmostEmpty* project is one which follows community-accepted\nstructure guidelines, makes it easy for new contributors to join in, and\nsets you up with git hooks,\n`Shippable <https://www.shippable.com/>`__,\n`requires.io <https://requires.io/>`__...\n\nAlmostEmpty currently supports Python, Django, Flask, Scala, and TeX projects.\n\nInstallation\n============\nAlmostEmpty is now available from `PyPI <https://pypi.python.org/pypi/almost-empty/>`_! You can install the latest beta with:\n\n    pip install almost-empty --pre\n\nOr you can build AlmostEmpty from source by cloning this repo and running:\n\n    python setup.py install\n\nUsage\n=====\n\n*AlmostEmpty* projects can be created by running:\n\n::\n\n    almost-empty <language> -n <project name>\n\nWhere ``language`` is the (supported) language of your choice. Each\nproject can be created either with or without a GitHub repository\nattached; you can chose to skip adding the repo right away, though\nyou'll miss out on a few great features (Shippable and requires.io\nintegration, git hooks...).",
        "url": "http://pypi.python.org/pypi/almost-empty",
        "summary": "Create AlmostEmpty packages",
        "command": "pip install 'almost-empty'"
      },
      "alm.solrindex": {
        "name": "alm.solrindex",
        "description": "Introduction\n============\n\n.. image:: http://www.sixfeetup.com/logos/solr-index.png\n   :height: 111\n   :width: 327\n   :alt: SolrIndex\n   :align: left\n\nSolrIndex is a product for Plone/Zope that provides enhanced searching capabilities by leveraging Solr, the popular open source enterprise search platform from the Apache Lucene project.\n\nOut of the box, SolrIndex brings in more relevant search results by replacing Plone's default full-text indexing with Solr-based search features, and including the ability to assign weights to certain fields.\n\nLeveraging Solr's advanced search algorithms, SolrIndex comes with exciting features, such as the ability to use stopwords and synonyms. Stopwords allow to control which words the search mechanism should ignore, and synonyms make it possible to extend a query by including additional matches.\n\nSolrIndex also comes with blazing fast and highly scalable search capabilities. SolrIndex is extensible by design, which means it has the ability to integrate with other indexes and catalogs. This is good news for sites that need to provide search capabilities across multiple repositories.\n\nWith additional customization, SolrIndex also has the ability to provide faceted search, highlighting of query terms, spelling suggestions and \"more like this\" suggestions.\n\nThanks to SolrIndex, Plone and Zope-powered sites now benefit from truly enterprise search capabilities.\n\nUseful Links\n============\n\n- Solr: http://lucene.apache.org/solr/\n- pypi: http://pypi.python.org/pypi/alm.solrindex\n- Plone: http://plone.org/products/alm.solrindex\n- issue tracker: http://plone.org/products/alm.solrindex/issues\n- svn repository: http://dev.plone.org/collective/browser/alm.solrindex\n\n\nSpecial Thanks\n==============\n\nSix Feet Up would especially like to thank Shane Hathaway for his key contribution to  SolrIndex.\n\n\nDetailed Documentation\n======================\n\n\nInstallation\n------------\n\nInclude this package in your Zope 2 or Plone buildout. If you are using\nthe ``plone.recipe.zope2instance`` recipe, add ``alm.solrindex`` to the\n``eggs`` parameter and the ``zcml`` parameter. See the ``buildout.cfg``\nin this package for an example. The example also shows how to use the\n``collective.recipe.solrinstance`` recipe to build a working Solr\ninstance with little extra effort.\n\nOnce Zope is running with this package installed, you can visit a\nZCatalog and add ``SolrIndex`` as an index. You should only add one\nSolrIndex to a ZCatalog, but a single SolrIndex can take the place of\nmultiple ZCatalog indexes.\n\n\nThe Solr Schema\n---------------\n\nConfigure the Solr schema to store an integer unique key.  Add fields\nwith names matching the attributes of objects you want to index in Solr.\nYou should avoid creating a Solr field that will index the same data\nas what will be indexed in ZODB by another ZCatalog index.  In other\nwords, if you add a ``Description`` field to Solr, you probably ought\nto remove the index named ``Description`` from ZCatalog, so that you\ndon't force your system to index descriptions twice.\n\nOnce the SolrIndex is installed, you can query all of the fields\ndescribed by the Solr schema, even if there is no ZCatalog index with\na matching name.  For example, if you have configured a ``Description``\nfield in the Solr schema, then you can issue catalog queries against\nthe ``Description`` field using the same syntax you would use with\nother ZCatalog indexes.  For example::\n\n    results = portal.portal_catalog(Description={'query': 'waldo'})\n\nQueries of this form pass through a configurable translation layer made\nof field handler objects. When you need more flexibility than the field\nhandlers provide, you can either write your own field handlers (see the\n\"Writing Your Own Field Handlers\" section) or you can provide Solr\nparameters that do not get translated (see the \"Translucent Solr\nQueries\" section).\n\n\nTranslucent Solr Queries\n------------------------\n\nYou can issue a Solr query through a ZCatalog containing a SolrIndex by\nproviding a ``solr_params`` dictionary in the ZCatalog query. For\nexample, if you have a SolrIndex installed in portal_catalog, this call\nwill query Solr::\n\n    results = portal.portal_catalog(solr_params={'q': 'waldo'})\n\nThe SolrIndex in the catalog will issue the query parameters specified\nin ``solr_params`` to Solr. Each parameter value can be a string\n(including unicode) or a list of strings. If you provide query\nparameters for other Solr fields, the parameters passed to Solr will be\nmixed with parameters generated for the other fields.  Note that Solr\nrequires some value for the '``q``' parameter, so if you provide Solr\nparameters but no value for '``q``', SolrIndex will supply '``*:*``' as the\nvalue for '``q``'.\n\nSolr will return to the SolrIndex a list of matching document IDs and\nscores, then the SolrIndex will pass the document IDs and scores to\nZCatalog, then ZCatalog will intersect the document IDs with results\nfrom other indexes. Finally, ZCatalog will return a sorted list of\nresult objects (\"brain\" objects) to application code.\n\nIf you need access to the Solr response object, provide a\n``solr_callback`` function in the catalog query. After Solr sends its\nresponse, the SolrIndex will call the callback function with the parsed\nSolr response object. The response object conforms with the\ndocumentation of the ``solrpy`` package.\n\n\nSorting\n-------\n\nSolrIndex only provides document IDs and scores, while ZCatalog retains\nthe responsibility for sorting the results. To sort the results from a\nquery involving SolrIndex, use the ``sort_on`` parameter like you\nnormally would with ZCatalog. At this time, you can not use a SolrIndex\nas the index to sort on, but that could change in the future.\n\n\nWriting Your Own Field Handlers\n-------------------------------\n\nField handlers serve two functions. They parse object attributes for\nindexing, and they translate field-specific catalog queries to Solr\nqueries. They are registered as utilities, so you can write your own\nhandlers and register them using ZCML.\n\nTo determine the field handler for a Solr field, ``alm.solrindex`` first\nlooks for an ``ISolrFieldHandler`` utility with a name matching the field\nname. If it doesn't find one, it looks for an ``ISolrFieldHandler`` utility\nwith a name matching the name of the Java class that handles the field\nin Solr. If that also fails, it retrieves the ``ISolrFieldHandler`` with no\nname.\n\nSee the documentation of the ``ISolrFieldHandler`` interface and the examples\nin handlers.py.\n\n\nIntegration with ZCatalog\n-------------------------\n\nOne ``SolrIndex`` can take the place of several ZCatalog indexes. In\ntheory, you could replace all of the catalog indexes with just a single\n``SolrIndex``. Don't do that yet, though, because this package needs\nmore maturity before it's ready to take on that many responsibilities.\n\nFurthermore, replacing all ZCatalog indexes might not be the right\ngoal. ZCatalog indexes are under appreciated. ZCatalog indexes are built\non the excellent transaction-aware object cache provided by ZODB. This\ngives them certain inherent performance advantages over network bound\nsearch engines like Solr. Any communication with Solr incurs a delay on\nthe order of a millisecond, while a ZCatalog index can often answer a\nquery in a few microseconds. ZCatalog indexes also simplify cluster\ndesign. The ZODB cache allows cluster nodes to perform searches without\nrelying on a large central search engine.\n\nWhere ZCatalog indexes currently fall short, however, is in the realm\nof indexing text. None of the text indexes available for ZCatalog match\nthe features and performance of text search engines like Solr.\n\nTherefore, one good way to use this package is to move all text indexes\nto Solr. That way, queries that don't need the text engine will avoid\nthe expense of invoking Solr. You can also move other kinds of indexes\nto Solr.\n\n\nHow This Package Maintains Persistent Connections\n-------------------------------------------------\n\nThis package uses a new method of maintaining an external database\nconnection from a ZODB object. Previous approaches included storing\n``_v_`` (volatile) attributes, keeping connections in a thread local\nvariable, and reusing the multi-database support inside ZODB, but\nthose approaches each have significant drawbacks.\n\nThe new method is to add dictionary called ``foreign_connections`` to\nthe ZODB Connection object (the ``_p_jar`` attribute of any persisted\nobject). Each key in the dictionary is the OID of the object that needs\nto maintain a persistent connection. Each value is an\nimplementation-dependent database connection or connection wrapper. If\nit is possible to write to the external database, the database\nconnection or connection wrapper should implement the ``IDataManager``\ninterface so that it can be included in transaction commit or abort.\n\nWhen a SolrIndex needs a connection to Solr, it first looks in the\n``foreign_connections`` dictionary to see if a connection has already\nbeen made. If no connection has been made, the SolrIndex makes the\nconnection immediately. Each ZODB connection has its own\n``foreign_connections`` attribute, so database connections are not\nshared by concurrent threads, making this a thread safe solution.\n\nThis solution is better than ``_v_`` attributes because connections will\nnot be dropped due to ordinary object deactivation. This solution is\nbetter than thread local variables because it allows the object\ndatabase to hold any number of external connections and it does not\nbreak when you pass control between threads. This solution is better\nthan using multi-database support because participants in a\nmulti-database are required to fulfill a complex contract that is\nirrelevant to databases other than ZODB.\n\nOther packages that maintain an external database connection should try\nout this scheme to see if it improves reliability or readability. Other\npackages should use the same ZODB Connection attribute name,\n``foreign_connections``, which should not cause any clashes, since\nOIDs can not be shared.\n\nAn implementation note: when ZODB objects are first created, they are\nnot stored in any database, so there is no simple way for the object to\nget a ``foreign_connections`` dictionary. During that time, one way to hold\na database connection is to temporarily fall back to the volatile\nattribute solution. That is what SolrIndex does (see the ``_v_temp_cm``\nattribute).\n\n\nTroubleshooting\n---------------\n\nIf the Solr index is preventing you from accessing Zope for some reason,\nyou can set ``DISABLE_SOLR=YES`` in the environment, causing the SolrIndex\nclass to bypass Solr for all queries and updates.\n\n\nChangelog\n=========\n\n1.1.1 (2010-11-04)\n------------------\n\n- Fix up links to issue tracker and Plone product page\n  [clayton]\n\n1.1 (2010-10-12)\n----------------\n\n- Added `z3c.autoinclude` support for Plone\n  [claytron]\n\n1.0 (2010-05-27)\n----------------\n\n- Initial public release\n\n- Clean up docs in prep for release.\n  [claytron]\n\n- Fix up reST errors.\n  [claytron]\n\n0.14 (2010-05-11)\n-----------------\n\n- Updated SolrConnectionManager to have a dummy savepoint\n  implementation, refs #2451.\n  [davidb]\n\n0.13 (2010-03-01)\n-----------------\n\n- commit to cleanup version #'s \n\n0.12 (2010-03-01)\n-----------------\n\n- PEP8 cleanup\n  [clayton]\n\n0.11 (2009-11-27)\n-----------------\n\n- A commit after an aborted index update no longer breaks with an\n  assertion error.  Refs #1340\n\n0.10 (2009-10-15)\n-----------------\n\n- Filter out invalid XML characters from indexed documents.\n\n0.9 (2009-10-14)\n----------------\n\n- Fixed test failure by going to the login_form to log in, instead of\n  the front page, where we get ambiguity errors.\n  [maurits]\n\n- Fixed the catalog object information page.  Solr was unable to parse\n  a negative number in the query.\n\n\n0.8 (2009-09-18)\n----------------\n\n- Added support for Solr boolean fields.\n\n- GenericSetup profiles now have the option of clearing the\n  index.\n\n- Made the waituri script wait up to 90 seconds by default,\n  pause a little more between polls, and accept a timeout\n  parameter.\n\n0.7 (2009-09-13)\n----------------\n\n- The Solr URI can now be provided by an environment variable,\n  so that catalog.xml does not need to hard code the URI.\n\n0.6 (2009-09-11)\n----------------\n\n- Added narrative documentation.\n\n- Don't clear the index when running GenericSetup.  Clearing\n  indexes turns out to be a long-standing problem with GenericSetup;\n  in this case the easy solution is to just not clear it.\n\n0.5 (2009-09-10)\n----------------\n\n- Added a script that waits for Solr to start up.\n\n- Brought in a private copy of solrpy to fix some bugs:\n\n  - The connection retry code reconnected, but wasn't\n    actually retrying the request.\n\n  - The raw_query method should not assume the parameter\n    values are unicode (they could be lists of unicode).\n\n0.4 (2009-09-10)\n----------------\n\n- Purge Solr when importing a SolrIndex via GenericSetup.\n\n0.3 (2009-09-10)\n----------------\n\n- Made field handlers more flexible.  Now they can add any\n  kind of query parameter to the Solr query.\n\n- The default field handler now generates \"fq\" parameters\n  instead of \"q\" parameters.  This seems to fit the intent of\n  the Solr authors much better.\n\n- Renamed \"solr_additional\" to \"solr_params\".\n\n0.2 (2009-09-09)\n----------------\n\n- Added a GenericSetup profile that replaces SearchableText\n  with a SolrIndex.\n\n- Renamed the catalog parameter for passing extra args to Solr\n  \"solr_additional\".  Also renamed the response callback\n  parameter to \"solr_callback\".\n\n0.1 (2009-09-09)\n----------------\n\n- First release",
        "url": "http://pypi.python.org/pypi/alm.solrindex",
        "summary": "A ZCatalog multi-index that uses Solr",
        "command": "pip install 'alm.solrindex'"
      },
      "alnair": {
        "name": "alnair",
        "description": "Alnair\n======\n\nAlnair is a simple system configuration framework.\nAnd also are intended to be used in conjunction with the Fabric (https://github.com/fabric/fabric).\n\nRequirement\n-----------\n\n- Python 2.6 and later (but does not work in 3.x)\n\nInstallation\n------------\n\nfrom pypi::\n\n   # using pip\n   % pip install -U alnair\n\n   # or using easy_install\n   % easy_install -U alnair\n\nfrom source::\n\n   % python setup.py install\n\nBasic usage\n-----------\n\nFirst, generate the recipes template set by following command::\n\n   % alnair generate template archlinux\n\nIn this example, distribution name using ``archlinux``.\n``recipes/archlinux/common.py`` directories and file are created to current directory by this command.\nAlso \"``g``\" as an alias for the ``generate`` command has been defined.\nThe following command is same meaning as above::\n\n   % alnair g template archlinux\n\nNext, edit ``install_command`` variable in ``common.py`` for the target distribution::\n\n   # common.py\n   install_command = 'pacman -Sy'\n\nNext, generate recipe template for package setup by following command::\n\n   % alnair g recipe python\n\n``python.py`` file is created on ``recipes/archlinux/`` directory by this command.\nIn fact, directories where you want to create the files are ``recipes/*/``.\n\nFinally, edit ``python.py`` for more settings if necessary and setup to the server by following command::\n\n   % alnair setup archlinux python\n\nUsing as a library\n------------------\n\nYou can use the following code instead of \"``alnair setup archlinux python``\" command::\n\n   from alnair import Distribution\n\n   distname = 'archlinux'\n   with Distribution(distname) as dist:\n       dist.setup('python')\n\nFor more documentation, read the sources or please wait while the document is being prepared.\n\n\nChanges\n=======\n\n0.3.2\n-----\n\n- Add --dry-run option to CLI\n- Implement the multiple packages in the single package name\n- Implement a host specific configuration\n\n0.3\n---\n\n- Add command-line interface\n- Add Distribution.config() API\n\n0.2\n---\n\n- Change the APIs (An incompatible with older releases)\n\n0.1.2\n-----\n\n- Implement the commands execution to make before setup\n- Bug fixes\n\n0.1.1\n-----\n\n- A few bug fixes\n\n0.1\n---\n\n- First release",
        "url": "http://pypi.python.org/pypi/alnair",
        "summary": "A simple system configuration framework",
        "command": "pip install 'alnair'"
      },
      "alnvu": {
        "name": "alnvu",
        "description": "=======\n alnvu\n=======\n\n``alnvu`` makes a multiple alignment of biological sequences more\neasily readable by condensing it and highlighting variability.\n\ndependencies\n============\n\nRequired:\n\n * Python 2.7\n\nOptional:\n\n * ``reportlab`` (http://www.reportlab.com/software/opensource/) for pdf output.\n * ``biopython`` (http://biopython.org/) to sort alignments in tree order.\n\ninstallation\n============\n\nUsing ``setup.py``::\n\n    cd alnvu\n    python setup.py install\n\nexamples\n========\n\nAll of these examples can be run from within the package directory::\n\n    % cd alnvu\n    % ./av --help\n\n    usage: av [-h] [-v] [-q] [-w NUMBER] [-L NUMBER] [-x] [-g] [-r INTERVAL]\n\t      [-s NUMBER] [-c] [-d NUMBER] [-D] [-C CASE] [-G] [-i] [-n NUMBER]\n\t      [-N CHARACTER] [-S FILE] [-T FILE] [-o OUTFILE] [-F NUMBER]\n\t      [-O ORIENTATION] [-b NUMBER]\n\t      [infile]\n\n    Create formatted sequence alignments with optional pdf output.\n\n    positional arguments:\n      infile                Input file in fasta format (reads stdin if missing)\n\n    optional arguments:\n      -h, --help            show this help message and exit\n      -v, --version         show program's version number and exit\n      -q, --quiet           Suppress output of alignment to screen.\n\n    Layout:\n      -w NUMBER, --width NUMBER\n\t\t\t    Width of sequence to display in each block in\n\t\t\t    characters [115]\n      -L NUMBER, --lines-per-block NUMBER\n\t\t\t    Sequences (lines) per block. [75]\n\n    Column selection:\n      -x, --exclude-invariant\n\t\t\t    Show only columns with at least N non-consensus bases\n\t\t\t    (set N using the '-a/--min-subs')\n      -g, --include-gapcols\n\t\t\t    Show columns containing only gap characters.\n      -r INTERVAL, --range INTERVAL\n\t\t\t    Range of columns to display (eg '-r start,stop')\n      -s NUMBER, --min-subs NUMBER\n\t\t\t    Minimum NUMBER of substitutions required to define a\n\t\t\t    position as variable. [1]\n\n    Consensus display and sequence appearance:\n      -c, --consensus       Show the consensus sequence [False]\n      -d NUMBER, --compare-to NUMBER\n\t\t\t    Identify the reference sequence. Nucleotide positions\n\t\t\t    identical to the reference will be shown as a '.' The\n\t\t\t    default behavior is to use the consensus sequence as a\n\t\t\t    reference. Use the -i option to display the sequence\n\t\t\t    numbers for reference.\n      -D, --no-comparison   Show all bases (ie, suppress comparsion with the\n\t\t\t    reference sequence).\n      -C CASE, --case CASE  Convert all characters to a uniform case\n\t\t\t    ('upper','lower')\n      -G, --ignore-gaps     Ignore gaps in the calculation of a consensus.\n\n    Sequence annotation:\n      -i, --number-sequences\n\t\t\t    Show sequence number to left of name.\n      -n NUMBER, --name-max NUMBER\n\t\t\t    Maximum width of sequence name in characters [35]\n      -N CHARACTER, --name-split CHARACTER\n\t\t\t    Specify a character delimiting sequence names. By\n\t\t\t    default, the name of each sequence is the first\n\t\t\t    whitespace-delimited word. '--name-split=none' causes\n\t\t\t    the entire line after the '>' to be displayed.\n      -S FILE, --sort-by-name FILE\n\t\t\t    File containing sequence names defining the sort-order\n\t\t\t    of the sequences in the alignment.\n      -T FILE, --sort-by-tree FILE\n\t\t\t    File containing a newick-format tree defining the\n\t\t\t    sort-order of the sequences in the alignment (requires\n\t\t\t    biopython).\n\n    PDF output:\n      These options require reportlab.\n\n      -o OUTFILE, --outfile OUTFILE\n\t\t\t    Write output to a pdf file.\n      -F NUMBER, --fontsize NUMBER\n\t\t\t    Font size for pdf output [7]\n      -O ORIENTATION, --orientation ORIENTATION\n\t\t\t    Set page orientation; choose from portrait, landscape\n\t\t\t    [portrait]\n      -b NUMBER, --blocks-per-page NUMBER\n\t\t\t    Number of aligned blocks of sequence per page [1]\n\n\nThe default output. Note that columns are numbered (column 8 is the first shown, column 122 is the last)::\n\n    % ./av testfiles/10patients_aln.fasta | head -n 15\n\t     # 0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n\t     # 0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000011111111111111111111111\n\t     # 0011111111112222222222333333333344444444445555555555666666666677777777778888888888999999999900000000001111111111222\n\t     # 8901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012\n\tH59735 AGAGTTTGATCCTGGCTCAGGACGAACGC.......GT.......................A.G..GCGGT....GCACCGTGGATT..........................T.\n\tT70875 ...........................---------------------------------------------------.----..--......--------------......T.\n\tF58095 AGAGTTTGATCCTGGCTCAGAGCGAACGC.......AT...................C....GTGGTTTCG..CATC-.----..--.............G.............G\n\tT70854 ...........................--.......AG..C.................G...ATG.CGGG.....GCTCCTTGATTC........C....G............TG\n\tF62024 AGAGTTTGATCCTGGCTCAGGACGAACGC.......GT.......................A.G..GCCTTT.GGGGTGGATT..--............................\n\tH59895 ...........................------------------------............G..AGAG.....AGCTCTCTGGATC...........................\n\tF57728 ...........................--------------------------------TT-----------------.----..--...........................G\n\tM10734 ...........................GC..A....GT........................GATCCATT...GCTTTTGTGTTTTTGGTGAG......................\n\tT71041 ..........................CGC.......AG.......................A.G..GTCT.....GCTAGACGGATT..........................TG\n\tM6161O ...........................--......T-G..C.....................ATCCTTCGG.A..---.----..--.............G..............\n\n\nThe input file can be provided via stdin::\n\n   % cat testfiles/10patients_aln.fasta | ./av\n\nExercising some of the options (show sequence numbers and a consensus; show differences with sequence number 1, restrict to columns 200-300)::\n\n    % ./av testfiles/10patients_aln.fasta --number-sequences --consensus --compare-to 1 --range 200,300\n\t\t   # 00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n\t\t   # 22222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222223\n\t\t   # 00000000001111111111222222222233333333334444444444555555555566666666667777777777888888888899999999990\n\t\t   # 01234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890\n     1 -ref-> H59735 TGGGGtG-TTGGTgGAAAGCgttatgga------------GTGGTTTTAGATGGGCTCACGGCCTATCAGCTTGTTGGTGAGGTAATGGCTTACCAAGGCG\n     2        T70875 G..T---.------.....T.GGGGACCGCAAGGCCTC..AC.CAGCAG..GC...CG.T.T.TG..T....A.......G.....A...CC.........\n     3        F58095 G.CC---.------C.....CGA.A.--.............C.CC...G..GC...CTG..T..G..T..G.A.......G.....A...C.......C.T\n     4        T70854 G..A---.------......AGGGGACCTTCGGGCCTT...C.C.A.C.....A..CT.G.T.GG..T....A.......G..........C.........\n     5        F62024 ....A-C.GG...TA.....TCCG----.............C...GAAG....A..C.G.....................G.........C..........\n     6        H59895 .CTTCA..CA.C.......AA..-----............TC...CAGG....A....G................................C.........\n     7        F57728 .C.A.-.A.A.A.-.....GTGGCCTCTACATGTAAGCTATCAC.GAAG..G...A.TG..T.TG..T....A.....A.G.....C...CC.........\n     8        M10734 .....-T..GTTG......GT..T.T--............C...A..GG.........G....T................G...G...............T\n     9        T71041 GA.A---.------.....G.GGC.TTTAGCTC.......TC.C.AA......A..CT.A.T.GG..T....A.......G.....A...C..........\n    10        M6161O G...---.------.....AT...----............TC.CCA..G..GC...C.G..T.TG..T....A.......G.....A....C.........\n    11     CONSENSUS X..X.X.A.X.X.......XXXXXXXCXXXXXGXXXXXTAXC.C.XXXG.......CXG..T.XG..T....A.......G.....X...XX.........\n\n\nWrite a single-page pdf file::\n\n    % ./av testfiles/10patients_aln.fasta --outfile=test.pdf --quiet --blocks-per-page=5\n\nSame as above::\n\n    % ./av testfiles/10patients_aln.fasta -o test.pdf -q -b 5\n\nAnd do you know about ``seqmagick``? If not, run, don't walk to\nhttps://github.com/fhcrc/seqmagick and check it out, so that you can\ndo this::\n\n    % seqmagick convert testfiles/ae_like.sto --output-format=fasta - | ./av -cx\n\t\t   # 000000000000000000000000000000000\n\t\t   # 445555555555566666666666666667777\n\t\t   # 990111111155813445566778888991122\n\t\t   # 791123678914209568907050235891215\n      GA05AQR01D2ULR ...............TTGGT.GT..AG...A..\n      GA05AQR01DFGSE ........................T.TAAGT..\n      GA05AQR01CI0QB ...........A.....................\n      GA05AQR01DW22X .TC..G.T.T.......................\n      GA05AQR01A5WF4 ....................A........-T..\n      GA05AQR01BUV2U ---..............................\n      GA05AQR01B1R8I .............T...............CT..\n      GA05AQR02JASPX ........A........................\n      GCX02B001AYSTJ .............................-TA.\n      GCX02B001DP9EQ ............A..........CA.......T\n      GCX02B001AFAY1 ..............G..................\n      GCX02B002J489C ...-......A......................\n      GLKT0ZE01EDLCP AT...ATT.T.......................\n      GLKT0ZE02I8LRD ---GA............................\n    -ref-> CONSENSUS TCTAGCGCGCGGGGACGAACGAGGCGCGCTGGA\n",
        "url": "http://pypi.python.org/pypi/alnvu",
        "summary": "Reformat and condense multiple sequence alignments to highlight variability",
        "command": "pip install 'alnvu'"
      },
      "alo-aes": {
        "name": "alo-aes",
        "description": "AES module with ECB and CBC encryption.",
        "url": "http://pypi.python.org/pypi/alo-aes",
        "summary": "Python AES module.",
        "command": "pip install 'alo-aes'"
      },
      "aloe": {
        "name": "aloe",
        "description": "Aloe\n----\n\nA [Gherkin][gherkin] runner for Python based on [Nose][nose] and\n[Lettuce][lettuce].\n\nInstall:\n\n    pip install aloe\n\nRead the [documentation][docs].\n\nInvocation\n==========\n\n`aloe` command line tool is a wrapper for the `nose` runner, configured to only\nrun Gherkin tests. As such, the invocation is the same as `nose`, but the\nfollowing parameters are added:\n\n* `-n N[,N...]` - only run the specified scenarios (by number, 1-based) in each\n  feature. Makes sense when only specifying one feature to run, for example\n\n  `aloe features/calculator.feature -n 1`\n\n* `--test-class` - override the class used as a base for each feature.\n\n* `--no-ignore-python` - run Python tests as well as Gherkin.\n\nMigrating from Lettuce\n======================\n\nAloe, started as a fork of Lettuce, tries to be compatible where it makes\nsense. However, there are following incompatible changes:\n\n* `each_scenario` and `each_background` callbacks are removed. Use\n  `each_example`.\n* `-s` option for running particular scenarios is renamed to `-n`.\n* Django-related functionality, including the `harvest` command, is moved to a\n  separate project, [Aloe-Django][aloe-django].\n* `terrain.py` has no particular significance. It will be imported but only if\n  it exists at the same directory with the other step definition files, and not\n  above it.\n* Scenario outlines must be declared with \"Scenario Outline\", and scenarios\n  without examples must use \"Scenario\" - Lettuce allowed using either.\n\nTODO\n====\n\nIn no particular order:\n\n* Verbose output (all steps printed as they run) is missing.\n\nLicense\n=======\n\nAloe - Cucumber runner for Python based on Lettuce and Nose\n\nCopyright (C) <2015> Alexey Kotlyarov <a@koterpillar.com>\n\nCopyright (C) <2014-2015> Danielle Madeley <danielle@madeley.id.au>\n\nCopyright (C) <2010-2012> Gabriel Falcão <gabriel@nacaolivre.org>\n\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n[gherkin]: https://cucumber.io/\n[nose]: https://nose.readthedocs.org/\n[nose-plugin-attrib]: https://nose.readthedocs.org/en/latest/plugins/attrib.html\n[lettuce]: http://lettuce.it/\n[gherkin-syntax]: https://cucumber.io/docs/reference\n[aloe-django]: https://github.com/koterpillar/aloe_django\n[docs]: http://aloe.readthedocs.org/",
        "url": "http://pypi.python.org/pypi/aloe",
        "summary": "Gherkin runner compatible with Lettuce",
        "command": "pip install 'aloe'"
      },
      "aloe_django": {
        "name": "aloe_django",
        "description": "Aloe-Django\n-------------\n\nUtilities for using [Aloe](https://github.com/koterpillar/aloe) with\n[Django](http://djangoproject.com):\n\n- A `harvest` command to run Gherkin tests\n- A collection of steps to aid in testing Django applications\n\nInstall:\n\n    pip install aloe_django\n\nRead the [documentation](http://aloe.readthedocs.org/projects/aloe_django/en/latest/).\n\nAloe and Aloe-Django are based on [Lettuce](http://lettuce.it/).\n\nLicense\n=======\n\nAloe-Django - Django utils for Aloe based on Lettuce\n\nCopyright (C) <2015> Alexey Kotlyarov <a@koterpillar.com>\n\nCopyright (C) <2015> Danielle Madeley <danielle@madeley.id.au>\n\nCopyright (C) <2013-2014> Infoxchange <devs@ix.org.au>\n\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.",
        "url": "http://pypi.python.org/pypi/aloe_django",
        "summary": "Package for testing Django applications with Aloe",
        "command": "pip install 'aloe_django'"
      },
      "aloe_webdriver": {
        "name": "aloe_webdriver",
        "description": "Aloe steps for Web Testing with Selenium\n========================================\n\nA set of Gherkin_ steps for use with Aloe_ to test Web applications using\nSelenium_.\n\nBased on lettuce_webdriver_ which, in turn, is inspired by cucumber_watir_.\n\nInstall:\n\n::\n\n    pip install aloe_webdriver\n\nRead the documentation_.\n\n.. _aloe: http://aloe.readthedocs.org/\n.. _gherkin: https://cucumber.io\n.. _documentation: http://aloe.readthedocs.org/projects/aloe_webdriver/en/latest/\n.. _lettuce_webdriver: https://github.com/bbangert/lettuce_webdriver\n.. _cucumber_watir: https://github.com/napcs/cucumber_watir\n\nLicense\n=======\n\nThe MIT License (MIT)\n\nCopyright (C) <2015> Alexey Kotlyarov a@koterpillar.com\n\nCopyright (C) <2015> Danielle Madeley danielle@madeley.id.au\n\nCopyright (C) <2013-2014> Infoxchange devs@ix.org.au\n\nCopyright (C) <2011> Ben Bangert and all contributors.\n\nPermission is hereby granted, free of charge, to any person obtaining a\ncopy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be included\nin all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\nOR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
        "url": "http://pypi.python.org/pypi/aloe_webdriver",
        "summary": "Selenium webdriver extension for Aloe",
        "command": "pip install 'aloe_webdriver'"
      },
      "aloft.py": {
        "name": "aloft.py",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aloft.py",
        "summary": "A simple API for getting winds aloft data from NOAA",
        "command": "pip install 'aloft.py'"
      },
      "alogator": {
        "name": "alogator",
        "description": "Alogator\n============\n\nAlogator is an aggregated logging actor system.\n\n\n.. contents:: Table of Contents\n\n\nInstallation\n------------\n\nTo get the latest stable release from PyPi\n\n.. code-block:: bash\n\n    pip install alogator\n\nTo get the latest commit from GitHub\n\n.. code-block:: bash\n\n    pip install -e git+git://github.com/arteria/alogator.git#egg=alogator\n\n.. TODO: Describe further installation steps (edit / remove the examples below):\n\nAdd ``alogator`` to your ``INSTALLED_APPS`` and define a logger\n\n.. code-block:: python\n\n    INSTALLED_APPS = (\n        ...,\n        'alogator',\n    )\n\n    LOGFILE_PATH = os.path.join(os.path.join(BASE_DIR, 'logs/'), \"alogator.log\")\n\n    LOGGING = {\n        'version': 1,\n        'disable_existing_loggers': False,\n        'filters': {\n            'require_debug_false': {\n                '()': 'django.utils.log.RequireDebugFalse'\n            }\n        },\n        'formatters': {\n            'standard': {\n                'format': \"[%(asctime)s] %(levelname)s [%(name)s:%(lineno)s] %(message)s\",\n                'datefmt': \"%d/%b/%Y %H:%M:%S\"\n            },\n        },\n        'handlers': {\n            'logfile': {\n                'level': 'DEBUG',\n                'class': 'logging.handlers.RotatingFileHandler',\n                'filename': LOGFILE_PATH,\n                'maxBytes': 1000000,\n                'backupCount': 0,\n                'formatter': 'standard',\n            }\n        },\n        'loggers': {\n            'alogator': {\n                'handlers': ['logfile'],\n                'level': 'DEBUG',\n            },\n        }\n    }\n\n\n\n\nDon't forget to create the tables for your database\n\n.. code-block:: bash\n\n    ./manage.py syncdb alogator\n    # python manage.py migrate\n\n\nUsage\n-----\n\nSetup your logfiles, search patterns and actors in the admin backend.\n\nTo run one (scan all logfiles for patterns) just call the ``scanlogfiles`` management command.\n\n.. code-block:: bash\n    \n    python manage.py scanlogfiles\n\nYou can use ``alogator_cli`` to check the log files in a project. Simple add paths to settings files as arguments. Be aware that you have to run the project, so you need to first activate your virtualenv if you have one.\n\n.. code-block:: bash\n\n    # if you have a virtualenv\n    . /path/to/env/bin/activate\n\n    alogator_cli /path/to/project/settings.py\n\nTo run this continously you could setup a cronjob. For example, to run this every other minute use\n\n.. code-block:: bash\n\n    crontab -e\n    \nThan add \n\n.. code-block:: bash\n\n    */2 * * * * /path/to/your/manage.py scanlogfiles\n    \nYou may have to activate your virtualenv depending on your setup.\n\n\n\nTODO\n----\n\n* Customizable temporary working dir instead of /tmp\n* Customizable subject, eg. [Alogator] (to filter inbox)\n* Add \"To mute this actor, visit...\" in message/email.\n\nHistroy\n-------\n\nPlease refer to CHANGELOG.txt\n\n\nContribute\n----------\n\nIf you want to contribute to this project, simply send us a pull request. Thanks. :)",
        "url": "http://pypi.python.org/pypi/alogator",
        "summary": "Alogator is an aggregated logging actor system.",
        "command": "pip install 'alogator'"
      },
      "aloha": {
        "name": "aloha",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/aloha",
        "summary": "A Django template tag that renders \"Hello\" in different langauges",
        "command": "pip install 'aloha'"
      },
      "aloharedis": {
        "name": "aloharedis",
        "description": "Aloharedis is a set of tools for working with redis-py. These tools include\ncaches, locks, serial generators and a simple Object Hash Mapper layer.",
        "url": "http://pypi.python.org/pypi/aloharedis",
        "summary": "Aloharedis is a set of tools for working with redis-py.",
        "command": "pip install 'aloharedis'"
      },
      "aloisius": {
        "name": "aloisius",
        "description": "===========\naloisius\n===========\n\nAbout\n=====\n\naloisius helps you to manage the life-cycle of AWS CloudFormation stacks. It\nallows you to use outputs from one stack as input parameters to other stacks.\nThere are other tools which allow you to do so, like i.e. Cumulus or Ansible,\nbut I couldn't find one which doesn't require you to use YAML or Jinja2. It\nis a pure Python library and it is intended to be used in inter-play with\ntroposphere, but you can also use it with any CloudFormation JSON templates.\n\nLicense\n=======\n\nThe BSD 2-Clause License: http://opensource.org/licenses/BSD-2-Clause\n\nExamples\n========\n\nA simple example creating a VPC containing an RDS could look like this::\n\n   #!/usr/bin/env python\n\n   from aloisius import Stack\n\n   # I keep my troposphere templates as modules in a package.\n   from templates.vpc import template as template_vpc\n   from templates.rds import template as template_rds\n\n\n   # I normally put some constants and helper functions here.\n   app_name = 'myapp'\n   region_name = 'eu-central-1'\n   stack_name = lambda x: '-'.join([app_name, region_name, x])\n\n   vpc = Stack(\n       StackName=stack_name('vpc'),\n       TargetState='present',\n       RegionName=region_name,\n       TemplateBody=template_vpc.to_json(),\n   )\n\n   rds = Stack(\n       StackName=stack_name('rds'),\n       TargetState='present',\n       RegionName=region_name,\n       TemplateBody=template_rds.to_json(),\n       Parameters={\n           # You can use outputs of previously created stacks as parameters.\n           'VpcId': vpc.outputs['VpcId'],\n           'PrivateSubnets': vpc.outputs['PrivateSubnets'],\n           # More parameters here.\n       },\n   )\n\nWhy you shouldn't use aloisius\n==============================\n\n- It's not tested. I simply use it myself. There are probably many bugs.\n- There's not much documentation (but there are comments in the code).\n\nWhy you should use aloisius\n===========================\n\n- You could find some bugs and help to make it better.\n- Parallel stack creation/deletion.\n- Integrates nicely with troposphere: No JSON and no YAML.\n",
        "url": "http://pypi.python.org/pypi/aloisius",
        "summary": "Create/Update/Delete AWS CloudFormation stacks in parallel",
        "command": "pip install 'aloisius'"
      },
      "alot": {
        "name": "alot",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alot",
        "summary": "Terminal MUA using notmuch mail",
        "command": "pip install 'alot'"
      },
      "alotofeffort": {
        "name": "alotofeffort",
        "description": "=============================\nA Lot of Effort\n=============================\n\n.. image:: https://badge.fury.io/py/alotofeffort.png\n    :target: http://badge.fury.io/py/alotofeffort\n    \n.. image:: https://travis-ci.org/audreyr/alotofeffort.png?branch=master\n        :target: https://travis-ci.org/audreyr/alotofeffort\n\nInstantly deploy static HTML sites to S3 at the command line.\n\nI created this out of frustration, after spending a lot of effort trying to\nfind a PyPI package that did this without problems.\n\nDocumentation\n-------------\n\nThe full documentation is at http://alotofeffort.rtfd.org.\n\nQuickstart\n----------\n\nInstall it::\n\n    pip install alotofeffort\n    \nConfigure Boto the standard way in `~/.boto`::\n\n    [Credentials]\n    aws_access_key_id = ...\n    aws_secret_access_key = ...\n\nThen use it to deploy a static HTML website to an S3 bucket::\n\n\t$ alotofeffort www/ mybucket\n\nFeatures\n--------\n\n* Uses standard Boto configuration.\n* Prints the S3 endpoint URL after deploying.\n* Auto-configures the bucket to be a website, with all files public.\n* Only files that have changed get uploaded. Files are checked for changes by\n  comparing the local and remote MD5 hashes of the files.\n* Never auto-deletes. In fact, it doesn't delete files at all! (In the future,\n  it will check if any files need to be deleted from S3, and prompt you before\n  deleting anything.)\n\n\n\n\nHistory\n-------\n\n0.4.0 (2015-09-15)\n++++++++++++++++++\n\n* Upgraded boto to 2.38.0.\n* Added tox envs for Python 3.3, 3.4, 3.5.\n* PEP 8 cleanup.\n* README cleanup.\n* Improvements to setup.py.\n\n0.3 (2013-07-27)\n++++++++++++++++++\n\n* Only files that have changed get uploaded. Files are checked for changes by\n  comparing the local and remote MD5 hashes of the files.\n\n0.2 (2013-07-17)\n++++++++++++++++++\n\n* It works on Python 2.6 and 2.7.\n\n0.1 (2013-07-14)\n++++++++++++++++++\n\n* First release on PyPI.",
        "url": "http://pypi.python.org/pypi/alotofeffort",
        "summary": "Deploy static HTML sites to S3 at the command line.",
        "command": "pip install 'alotofeffort'"
      },
      "Alp": {
        "name": "alp",
        "description": "============\nAlp software\n============\n\nThe Alp is a new unit meant for measuring time. To understand and use\nthis unit, the program included in this distribution has been\ncreated. It's both a command-line tool, named \"alp\", and a Python\nmodule.\n\nYou can learn about the Alp unit and download documentation about it\nat http://metanohi.name/projects/alp/\n\n\nLicense\n=======\n\nAlp software is free software under the terms of the GNU General\nPublic License version 3 (or any later version). The author of Alp\nsoftware is Niels G. W. Serup, contactable at ngws@metanohi.name. This is\nversion 0.1.1 of the program.\n\nThe libraries used by Alp software are GPL-compatible.\n\n\nInstalling\n==========\n\nThe Alp program and module is contained in a single file,\n``alp.py``. It is not necessary to install it, but it can make it\neasier to use the Alp software.\n\nWay #1\n------\nJust run this (requires that you have python-setuptools installed)::\n\n  # easy_install Alp\n\nWay #2\n------\nGet the newest version of Alp at\nhttp://metanohi.name/projects/alp/ or at\nhttp://pypi.python.org/pypi/Alp\n\nExtract the downloaded file and run this in a terminal::\n\n  # python setup.py install\n\nDependencies\n============\n\nPython 2.5+ is probably a requirement.\n\nFor formatting and control codes, Alp will attempt to use ncurses. If\nthat fails, Alp will try to use the Python termcolor module, available\nat http://pypi.python.org/pypi/termcolor/, installable using ``$ sudo\neasy_install termcolor`` (released under the GPLv3+).\n\nIf present, Alp will also use the ``setproctitle`` Python module,\navailable at http://pypi.python.org/pypi/setproctitle/, installable\nusing ``$ sudo easy_install setproctitle`` (released under the New BSD\nLicense).\n\n\nUsing\n=====\n\nWhen using the Alp software as a command-line tool, simply run\n``alp``. Run ``alp --help`` to see what options you can specify.\n\nWhen using it as a module, just use ``import alp`` in your Python\nprogram. To learn how the Alp module works, run ``pydoc alp`` or\n``python -c 'import alp; help(alp)'``. There are also a couple of\ntests in the ``tests`` directory.\n\n\nDeveloping\n==========\n\nAlp software is written in Python and uses Git for branches. To get the\nlatest branch, get it from gitorious.org like this::\n\n  $ git clone git://gitorious.org/Alp/alp.git\n\n\nThis document\n=============\nCopyright (C) 2010  Niels G. W. Serup\n\nCopying and distribution of this file, with or without modification,\nare permitted in any medium without royalty provided the copyright\nnotice and this notice are preserved.  This file is offered as-is,\nwithout any warranty.",
        "url": "http://pypi.python.org/pypi/Alp",
        "summary": "Alp time tools",
        "command": "pip install 'Alp'"
      },
      "alpaca": {
        "name": "alpaca",
        "description": "alpaca-llama\n============\n# alpaca\n将一个描述词法的正则表达式转换成最小化的DFA，以dot语言形式输出。\n\n# llama\n将描述语法的范式转换成分析转换表，以图形的方式输出，同时能够根据不同的语法分析算法检查范式的定义错误，并且能够修正错误。\n\n详情请参考[alpace-llama wiki](https://github.com/activesys/alpaca-llama/wiki)。\n",
        "url": "http://pypi.python.org/pypi/alpaca",
        "summary": "UNKNOWN",
        "command": "pip install 'alpaca'"
      },
      "alpaca-django": {
        "name": "alpaca-django",
        "description": "alpaca-django\n=============\n\nThis is an Alpaca error logger for Django-based applications.\n\nSee https://github.com/msiedlarek/alpaca\n\nInstallation\n------------\n\n    $ pip install alpaca-django\n\nExample configuration\n---------------------\n\n    LOGGING = {\n        'version': 1,\n        'disable_existing_loggers': False,\n        'formatters': {\n            'simple': {\n                'format': '%(asctime)s %(levelname)s %(name)s #%(lineno)s: %(message)s',\n            },\n        },\n        'filters': {\n            'require_debug_false': {\n                '()': 'django.utils.log.RequireDebugFalse'\n            }\n        },\n        'handlers': {\n            'console': {\n                'level': 'DEBUG',\n                'class': 'logging.StreamHandler',\n                'formatter': 'simple'\n            },\n            'mail_admins': {\n                'level': 'ERROR',\n                'filters': ['require_debug_false'],\n                'class': 'django.utils.log.AdminEmailHandler'\n            },\n            'alpaca': {\n                'level': 'ERROR',\n                'filters': [],\n                'class': 'alpaca_django.log_handler.AlpacaLogHandler',\n            },\n        },\n        'loggers': {\n            'django.request': {\n                'handlers': ['mail_admins', 'alpaca',],\n                'level': 'ERROR',\n                'propagate': True,\n            },\n            'alpaca_django': {\n                'handlers': ['mail_admins', 'console',],\n                'level': 'DEBUG',\n                'propagate': False,\n            },\n        }\n    }\n\n    ALPACA_PROJECT_PATH_FRAGMENT = 'myproject'\n    ALPACA_ENVIRONMENT = 'staging'\n    ALPACA_MONITOR_HOST = 'monitoring.example.com'\n\nLicense\n-------\n\nCopyright 2013 Mikołaj Siedlarek <msiedlarek@nctz.net>\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.",
        "url": "http://pypi.python.org/pypi/alpaca-django",
        "summary": "Alpaca error logger for Django applications.",
        "command": "pip install 'alpaca-django'"
      },
      "alpaca-monitor": {
        "name": "alpaca-monitor",
        "description": "alpaca\n======\n\nAlpaca is a software error aggregator based on ZeroMQ transport layer.\nMultiple reporters (such as https://github.com/msiedlarek/alpaca-django)\npublish detected problems to a central monitoring server using flexible\nAPI. Monitoring server (monitor) shares its database with a web\napplication (frontend), allowing detailed inspection of each problem.\n\nInstalling\n----------\n\n    pip install alpaca-monitor\n\nRunning\n-------\n\nStarting frontend:\n\n    pserve configuration/development.ini --server-name=frontend \\\n        --app-name=frontend\n\nStarting monitor:\n\n    pserve configuration/development.ini --server-name=monitor \\\n        --app-name=monitor\n\nDevelopment\n-----------\n\n$ vagrant up\n$ vagrant ssh\n$ alpaca-admin /vagrant/configuration/development.ini createuser -a user@example.com\n\nTesting\n-------\n\n$ vagrant up\n$ vagrant ssh\n$ python setup.py test\n\nLicense\n-------\n\nCopyright 2013 Mikołaj Siedlarek <msiedlarek@nctz.net>\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.",
        "url": "http://pypi.python.org/pypi/alpaca-monitor",
        "summary": "Software error aggregator.",
        "command": "pip install 'alpaca-monitor'"
      },
      "alpaca-variant-caller": {
        "name": "alpaca-variant-caller",
        "description": "==============================================\r\nALPACA - The ALgebraic PArallel Variant CAller\r\n==============================================\r\n\r\nALPACA is a single nucleotide variant caller for next-generation sequencing\r\ndata, providing intuitive control over the false discovery rate with generic\r\nsample filtering scenarios, leveraging OpenCL on CPU, GPU or any coprocessor to\r\nspeed up calculations and an using HDF5 based persistent storage for iterative\r\nrefinement of analyses within seconds.\r\n\r\nOften, variant calling entails filtering different samples\r\nagainst each other, e.g. disease samples vs. healthy samples, tumor vs. normal or\r\nchildren vs. parents.\r\nThe filtering can be seen as operations over the set algebra of variant loci.\r\nIn general, the filtering is applied after calling.\r\nThis results in the null hypothesis considered by the variant caller to not\r\nproperly reflect the actual research question, which in fact entails the filtering.\r\nIn consequence, controlling the false discovery rate becomes difficult.\r\n\r\nUnlike other state of the art variant callers,\r\n**ALPACA integrates the filtering into the calling**\r\nby introducing a novel algebraic variant calling model.\r\nWhen calling, a filtering scenario can be specified with an algebraic expression\r\nlike A - (B + C) with A, B and C being samples. Algebraic calling allows ALPACA\r\nto report **posterior probabilities** for a variant to occur in the\r\n**unknown set of true variant loci**\r\nin A that are not in B or C here. Since the probabilities reflect the filtering,\r\nthey can be directly used to **intuitively control the false discovery rate**.\r\n\r\nALPACA splits variant calling into a preprocessing\r\nstep and the actual calling. Preprocessed samples are stored in HDF5 index data\r\nstructures. In a lightweight and massively parallel step, the sample indexes are merged\r\ninto an optimized index. On the optimized index, **variant calling becomes a matter of seconds**.\r\nUpon the addition of a sample, merging and the calling have to be repeated.\r\nThe sample indexes of the other samples remain untouched, **avoiding redundant computations**.\r\n\r\nAlgorithmic and mathematical details will be described in my thesis:\r\n\r\n    Parallelization, Scalability and Reproducibility in Next-Generation Sequencing Analysis,\r\n    Johannes Köster, 2015 (work in progress)\r\n\r\n\r\nPrerequisites\r\n-------------\r\n\r\nALPACA needs\r\n\r\n* Linux\r\n* Python >= 3.3\r\n* Numpy >= 1.7\r\n* PyOpenCL >= 2013.1\r\n* h5py >= 1.8.4\r\n* samtools >= 1.0\r\n* mawk\r\n* a working OpenCL device (CPU, GPU, a coprocessor like Intel Xeon Phi or an FPGA)\r\n\r\nPython 3 should be installed on most systems.\r\nYou can make Debian and Ubuntu ready for installing ALPACA by issueing::\r\n\r\n   $ sudo apt-get install python3-setuptools python3-numpy python3-h5py samtools mawk\r\n\r\nWithout admin rights, we recommend to use a userspace Python 3 distribution like\r\nhttps://store.continuum.io/cshop/anaconda.\r\n\r\nIf you want to use ALPACA on the GPU, a decent NVIDIA or AMD GPU with the proprietary\r\ndrivers installed should be enough. On Ubuntu and Debian, you can install them\r\nvia::\r\n\r\n   $ sudo apt-get install nvidia-current\r\n\r\nor::\r\n\r\n   $ sudo apt-get install fglrx\r\n\r\nTo use ALPACA with the CPU, you need an OpenCL runtime installed.\r\nYou can e.g. install the AMD APP SDK (which will work on any x86 CPU) from here:\r\nhttp://developer.amd.com/tools-and-sdks/opencl-zone/amd-accelerated-parallel-processing-app-sdk\r\n\r\n\r\nInstallation\r\n------------\r\n\r\nOnce the prerequisites are in place, ALPACA can be installed and updated with::\r\n\r\n   $ easy_install3 --user -U alpaca\r\n\r\n\r\nUsage\r\n-----\r\n\r\nUsage of ALPACA consists of three major steps.\r\n\r\n* sample indexing\r\n* index merging\r\n* calling\r\n\r\nGiven mapped reads for a sample *A* in BAM format and a reference genome in FASTA format,\r\na sample index can be created with::\r\n\r\n   $ alpaca index reference.fasta A.bam A.hdf5\r\n\r\nHere, various parameters like the expected ploidy of the sample can be adjusted.\r\nThe resulting index *A.hdf5* will be much smaller than the BAM file.\r\nMerging indexes for samples *A* and *B* is achieved with::\r\n\r\n   $ alpaca merge A.hdf5 B.hdf5 all.hdf5\r\n\r\nFinally, calling can be performed on the merged index.\r\nALPACA allows to specify query expressions at the command line by representing\r\nthe union operator with a plus sign and the difference operator with a minus sign.\r\nThe variant calls are streamed out in VCF::\r\n\r\n   $ alpaca call --fdr 0.05 all.hdf5 A-B > calls.vcf\r\n\r\nHere, we limit the desired rate of false discoveries to 5%.\r\nTo assess the biological importance of a variant, it is useful to annotate it with additional information like the gene it may be contained in, its effect on a protein that is encoded by the gene or whether it is already known and maybe associated to some disease.\r\nALPACA can annotate a VCF file with such information, using the Ensembl Variant Effect Predictor web service.\r\nSince the VCF format is rather technical, ALPACA can compose a human readable HTML file summarizing the calls.\r\nWe can combine the two commands using Unix pipes::\r\n\r\n   $ alpaca annotate < calls.vcf | alpaca show > calls.html\r\n\r\nFor further information on various parameters of all steps (e.g. how to select\r\nthe compute device) can be obtained with::\r\n\r\n   $ alpaca --help\r\n\r\n\r\nNews\r\n----\r\n\r\n=========== ========================================================================\r\n6 Feb 2014  Release 0.3.3 of ALPACA. Fixed mixed up annotations with annotate\r\n            subcommand. Added column filters to HTML output.\r\n----------- ------------------------------------------------------------------------\r\n13 Jan 2014 Release 0.3.2 of ALPACA. Fixed imprecision in strand bias results.\r\n            Further, this release introduces the k-relaxed intersection operator.\r\n            A locus is contained in the k-relaxed intersection of a given set of\r\n            samples if and only if it is variant in at least k samples.\r\n----------- ------------------------------------------------------------------------\r\n2 Dez 2014  Release 0.2.4 of ALPACA. Further improved HTML output of alpaca show.\r\n----------- ------------------------------------------------------------------------\r\n1 Dez 2014  Release 0.2.3 of ALPACA. Improved HTML output of alpaca show.\r\n----------- ------------------------------------------------------------------------\r\n30 Nov 2014 Release 0.2.2 of ALPACA. This initial release provides all functionality\r\n            descibed in my thesis \"Parallelization, Scalability and Reproducibility\r\n            in Next-Generation Sequencing Analysis\".\r\n=========== ========================================================================\r\n",
        "url": "http://pypi.python.org/pypi/alpaca-variant-caller",
        "summary": "An algebraic parallel SNV caller using OpenCL",
        "command": "pip install 'alpaca-variant-caller'"
      },
      "al_papi": {
        "name": "al_papi",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/al_papi",
        "summary": "AuthorityLabs Partner API Wrapper",
        "command": "pip install 'al_papi'"
      },
      "alphabet-detector": {
        "name": "alphabet-detector",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alphabet-detector",
        "summary": "A library to detect what alphabet something is written in.",
        "command": "pip install 'alphabet-detector'"
      },
      "alphabetic-simple": {
        "name": "alphabetic-simple",
        "description": "Django Template tag for building alphabetical index\n===================================================\n\nLink to repository: https://github.com/Arpaso/alphabetic-simple\n\nBuilds alpabetic index to navigate through collection sorted by firstletter.\nSupports **english** and **russian** groups of alphabets.\n\nUsage\n=====\n\n**view.py**::\n\n    from django.views.generic.list_detail import object_list\n    from alphabetic.utils import alphabetic_setup\n    from .models import MyModel\n\n        def myview(request):\n            ...\n            queryset = MyModel.objects.all()\n            return object_list(request, alphabetic_setup(request, queryset, 'last_name'), template_name=template)\n\n**template.html**::\n\n    {% show_alphabetic_filter %}\n\n\n**alphabetic_setup(request, queryset, 'last_name')** - returns sorted queryset in alphabetical order by firstletter of\nthe attribute name, e.g. **last_name** or whatever attribute of the model you specified.  \n\n**show_alphabetic_filter** - template tag shows clickable alphabet in the template.\n\nClicking on the letter will produce GET request to the current url with a tail **?firstletter=X**,\nwhere **X** is the clicked letter.\n\n\nWritten by the development team of Arpaso company: http://arpaso.com",
        "url": "http://pypi.python.org/pypi/alphabetic-simple",
        "summary": "Alphabetic template tag to filter django queryset",
        "command": "pip install 'alphabetic-simple'"
      },
      "alphadict": {
        "name": "alphadict",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alphadict",
        "summary": "Recursively sorts dictionaries by key.",
        "command": "pip install 'alphadict'"
      },
      "AlphaID": {
        "name": "alphaid",
        "description": "Python library to generate ID like youtube, twitter, tinyURL...",
        "url": "http://pypi.python.org/pypi/AlphaID",
        "summary": "UNKNOWN",
        "command": "pip install 'AlphaID'"
      },
      "alphasign": {
        "name": "alphasign",
        "description": "Implementation of the Alpha Sign Communications Protocol, which is used by many commercial LED signs, including the Betabrite.",
        "url": "http://pypi.python.org/pypi/alphasign",
        "summary": "Implementation of the Alpha Sign Communications Protocol",
        "command": "pip install 'alphasign'"
      },
      "alphasms-client": {
        "name": "alphasms-client",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alphasms-client",
        "summary": "Ukrainian AlphaSMS service client API implementation for Python",
        "command": "pip install 'alphasms-client'"
      },
      "Alquimia": {
        "name": "alquimia",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Alquimia",
        "summary": "An API to work with JSON schemas in SQLAlchemy",
        "command": "pip install 'Alquimia'"
      },
      "alsaseq": {
        "name": "alsaseq",
        "description": "alsaseq is a Python 3 and Python 2 module that allows to interact with ALSA\nsequencer clients. It can create an ALSA client, connect to other\nclients, send and receive ALSA events immediately or at a scheduled\ntime using a sequencer queue. It provides a subset of the ALSA\nsequencer capabilities in a simplified model. It is implemented in\nC language and licensed under the Gnu GPL license version 2 or\nlater.",
        "url": "http://pypi.python.org/pypi/alsaseq",
        "summary": "ALSA sequencer bindings for Python",
        "command": "pip install 'alsaseq'"
      },
      "also": {
        "name": "also",
        "description": "## Also\nEver had lots of methods that do the same thing?!\nYou want to set them to the same thing but dont want to do something lame like\n```python\n   def method(self):\n       pass\n\n   othermethod = method\n```\n\nRather you want to do it with style like\n\n```python\n   @also('othermethod')\n   def method(self):\n       pass\n```\n\nThen do I have a solution for you!\n\n## Installation\n```\npip install also\n```\n\n## Usage\n```python\nfrom also import also, AlsoMetaClass\n\nclass Foo:\n    __metaclass__ = AlsoMetaClass\n\n    @also('getThing')\n    @also('get_thing')\n    def getthing(self):\n        return 'go bears'\n\nfoo = Foo()\nassert (foo.getthing() == foo.get_thing() == \n        foo.getThing() == 'go bears')\n```",
        "url": "http://pypi.python.org/pypi/also",
        "summary": "UNKNOWN",
        "command": "pip install 'also'"
      },
      "alsosweet": {
        "name": "alsosweet",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alsosweet",
        "summary": "A simple printer of nested lists",
        "command": "pip install 'alsosweet'"
      },
      "alstat": {
        "name": "alstat",
        "description": "Welcome to alstat's documentation!\n==================================================\n\nalstat is advances logs statistics.\nIt's collection of utils to analyze logs.\n\nFeatures\n--------\n\n- Unpack gzipped logfiles\n- Fast\n\n\nUsage\n-----\n\nThis commant print all lines from all log files in directory /var/log/nginx\nif format `http_method status http_referer`::\n\n    alstat -d /var/log/nginx/ -p \"*access*\" -f \"base\" http_method status http_referer\n\n    GET 200 http://google.com\n    .... to many lines\n    GET 404 http://ya.ru/\n    PUT 200 http://yandex.com/\n\n\nYou can view fields list that you can use to display::\n\n    alstat -d /var/log/nginx/ -p \"*access*\" -l\n\n    Alstat v0.0.1 start at Tue May  8 23:25:24 2012\n    You can use fieldnames: status, http_protocol, http_method, http_referer, remote_addr, url, time_local, http_user_agent, remote_user, size\n\n\n\nINSTALLATION\n------------\n\nTo use alstat use pip or easy_install:\n\n`pip install alstat`\n\nor\n\n`easy_install alstat`\n\n\nTODO\n----\n- Add group by fields and count\n- Web interface with reports\n\n\nCONTRIBUTE\n----------\n\nFork https://github.com/Lispython/alstat/ , create commit and pull request.\n\nTHANKS\n------\n\nTo David M. Beazley for `generators`_ examples.\n\n\nSEE ALSO\n--------\n\n-  `python pypi`_.\n\n.. _`python pypi`: http://pypi.python.org\n\n.. _`generators`: http://www.dabeaz.com/generators/",
        "url": "http://pypi.python.org/pypi/alstat",
        "summary": "Collection of advanced utils to parse logfiles in different formats and build statistic reports",
        "command": "pip install 'alstat'"
      },
      "alt": {
        "name": "alt",
        "description": "Please see documentation here: https://github.com/kevwo/alt",
        "url": "http://pypi.python.org/pypi/alt",
        "summary": "Web API level tests and test runner",
        "command": "pip install 'alt'"
      },
      "altasetting": {
        "name": "altasetting",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/altasetting",
        "summary": "A python settings library",
        "command": "pip install 'altasetting'"
      },
      "altered.states": {
        "name": "altered.states",
        "description": "=================================\nPython monkey-patching for Humans\n=================================\n\n*Altered States* tries to take the concept of \"Python for Humans\"\n(http://python-for-humans.heroku.com/) to the world of monkey\npatching.\n\nRead more here:\nhttps://github.com/Plexical/altered.states/blob/master/README.rst\n\nInitial announcement:\nhttp://www.plexical.com/blog/2012/03/06/altered-states/\n\n\n0.8.6\n-----\n\n* Better handling of objects that override `__getitem__` (thanks to\n  @merwok).\n* Drop support for Python 2.5 (no sane way to solve issue #4 there).\n\n0.8.5\n-----\n\n* Added a new API entry point: `alter()`, that can be used to perform\n  a two-step reversible alteration.\n\n0.8.2\n-----\n\n* Updated test suites to use `@pytest.fixture` notation for fixtures\n  (now requires `py.test` > 2.3)\n* Fixes a bug causing `os.environ` not to be patchable.\n\nFixing bug #2 means switching the `dict` -like object check from\n`isinstance(x, dict)` to `hasattr(x, '__getitem__')`. This change is\nthought to not break backwards compatibility but if you encounter\nunexpected behaviour in `dict` / `object` detection this might be\nit. I'd be very interested to know about that if you do.\n\n0.8.1\n-----\n\n* Alias `Expando` as `E` for optional terseness.\n\n0.8.0\n-----\n\nInitial release.",
        "url": "http://pypi.python.org/pypi/altered.states",
        "summary": "Python monkey patching for humans.",
        "command": "pip install 'altered.states'"
      },
      "alternatives": {
        "name": "alternatives",
        "description": "***********************\nAlternatives api\n***********************\n\nAlternatives basics\n---------------------\n\nAlternatives api is just a syntax sugar for selecting alternative variants from some set of values.\nThe main thing is alternative class that implements late call on callbacks.\nThis allow to apply boolean logic on callbacks without being executed::\n\n    a1 = Alternative(lambda: a)\n    b1 = Alternative(lambda: b)\n\n    a_b = a1 | b1\n    assert isinstance(a_b, Alternative)\n    assert bool(a_b) is (a or b)\n\nAlso you can note, in the example above, that alternative can provide python truth when it's needed by\ncalling callbacks and evaluating boolean expressions.\n\nAlternatives usage\n---------------------\n\nHow it may be used::\n\n    package(one_of({\n        os_centos() or os_windows(): 'php',\n        os_ubuntu(): 'php5'\n    }))\n\n\nHere one of values will be selected: php or php5.\n\nAlternative is object, that's why we can use it as dictionary key.\n\nIn the example above you can see one_of() method:\n\n.. automodule:: pywizard.api\n   :members: one_of\n   :imported-members:\n\nAnother style of evaluating alternatives is all_of:\n\n.. automodule:: pywizard.api\n   :members: all_of\n   :imported-members:\n\nAnd nobody restrict you from creating your own alternatives selection style.\nUse source of one_of, all_of as reference.\n\nChecks declaration\n-----------------------------\n\n*Check* is just a python function that return boolen with added annotation on it::\n\n    @alternative\n    def os_linux():\n        \"\"\"\n        os_linux()\n        Checks if it is linux-like os.\n        \"\"\"\n        info = os_info()\n        return 'linux' in info['platform']\n\n.. note::\n    As function is annotated there is some extra work needed to provide correct documentation for this function.\n    @alternative handles copying __doc__ transparently for your function. But, you should take care\n    of specifying correct method signature in first line of docstring.",
        "url": "http://pypi.python.org/pypi/alternatives",
        "summary": "Alternatives api is just a syntax sugar for selecting alternative variants from some set of values",
        "command": "pip install 'alternatives'"
      },
      "alternator": {
        "name": "alternator",
        "description": "==========\nalternator\n==========\n\nAlternator provides tools to ease the creation of `asynchronous generators`__.\n\n__ https://www.python.org/dev/peps/pep-0492/\n\n\nSynchronous generators are pretty easy to create and manipulate in Python.  In\nPython 3.5 asynchronous generators are possible.  Consuming them with ``async\nfor`` is pretty nice, but creating them is a fairly manual process.\n\nMaybe a future version of Python will correct this imbalance.\n\nOr maybe we can fix it with TOOLS!",
        "url": "http://pypi.python.org/pypi/alternator",
        "summary": "Create asynchronous generators from coroutines",
        "command": "pip install 'alternator'"
      },
      "alterootheme.busycity": {
        "name": "alterootheme.busycity",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alterootheme.busycity",
        "summary": "Free City Plone 3.0 Theme",
        "command": "pip install 'alterootheme.busycity'"
      },
      "alterootheme.intensesimplicity": {
        "name": "alterootheme.intensesimplicity",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alterootheme.intensesimplicity",
        "summary": "A Plone 3.0 Theme based on a free template by David Uliana",
        "command": "pip install 'alterootheme.intensesimplicity'"
      },
      "alterootheme.lazydays": {
        "name": "alterootheme.lazydays",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/alterootheme.lazydays",
        "summary": "A Theme for Plone 3.0 based on OpenWebDesign.org Lazy Days theme",
        "command": "pip install 'alterootheme.lazydays'"
      },
      "alterparagraphs": {
        "name": "alterparagraphs",
        "description": "`Alterparagraphs` is an ongoing effort for providing a family of\nparagraph implementations, each to be used as a replacement for the \nregular and only paragraph flowable inside the ReportLab package.\n\nThe idea behind this collection of paragraphs is to provide simple \nimplementations that can be more easily understood and extended than \nthe monolithic paragraph implementation as implemented by ReportLab. \n\nNote that many of the paragraph classes in `alterparagraphs` are not \nfinished in the sense that they are directly ready for production \n(this is especially true for the XMLParagraph, the development of \nwhich has barely started). You must test yourself if they are suitable \nfor your purpose. In any case it should be much easier to tweak them \nto make them do what you need compared to the standard ReportLab \nimplementation.",
        "url": "http://pypi.python.org/pypi/alterparagraphs",
        "summary": "Alternative paragraphs for ReportLab.",
        "command": "pip install 'alterparagraphs'"
      },
      "altf2": {
        "name": "altf2",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/altf2",
        "summary": "Simple program launcher (Alt-F2 handler). Requires PyQt4",
        "command": "pip install 'altf2'"
      },
      "altgraph": {
        "name": "altgraph",
        "description": "altgraph is a fork of graphlib: a graph (network) package for constructing\ngraphs, BFS and DFS traversals, topological sort, shortest paths, etc. with\ngraphviz output.\n\naltgraph includes some additional usage of Python 2.6+ features and\nenhancements related to modulegraph and macholib.\n\n\nRelease history\n===============\n\n0.12\n----\n\n- Added ``ObjectGraph.edgeData`` to retrieve the edge data\n  from a specific edge.\n\n- Added ``AltGraph.update_edge_data`` and ``ObjectGraph.updateEdgeData``\n  to update the data associated with a graph edge.\n\n0.11\n----\n\n- Stabilize the order of elements in dot file exports,\n  patch from bitbucket user 'pombredanne'.\n\n- Tweak setup.py file to remove dependency on distribute (but\n  keep the dependency on setuptools)\n\n\n0.10.2\n------\n\n- There where no classifiers in the package metadata due to a bug\n  in setup.py\n\n0.10.1\n------\n\nThis is a bugfix release\n\nBug fixes:\n\n- Issue #3: The source archive contains a README.txt\n  while the setup file refers to ReadMe.txt.\n\n  This is caused by a misfeature in distutils, as a\n  workaround I've renamed ReadMe.txt to README.txt\n  in the source tree and setup file.\n\n\n0.10\n-----\n\nThis is a minor feature release\n\nFeatures:\n\n- Do not use \"2to3\" to support Python 3.\n\n  As a side effect of this altgraph now supports\n  Python 2.6 and later, and no longer supports\n  earlier releases of Python.\n\n- The order of attributes in the Dot output\n  is now always alphabetical.\n\n  With this change the output will be consistent\n  between runs and Python versions.\n\n0.9\n---\n\nThis is a minor bugfix release\n\nFeatures:\n\n- Added ``altgraph.ObjectGraph.ObjectGraph.nodes``, a method\n  yielding all nodes in an object graph.\n\nBugfixes:\n\n- The 0.8 release didn't work with py2app when using\n  python 3.x.\n\n\n0.8\n-----\n\nThis is a minor feature release. The major new feature\nis a extensive set of unittests, which explains almost\nall other changes in this release.\n\nBugfixes:\n\n- Installing failed with Python 2.5 due to using a distutils\n  class that isn't available in that version of Python\n  (issue #1 on the issue tracker)\n\n- ``altgraph.GraphStat.degree_dist`` now actually works\n\n- ``altgraph.Graph.add_edge(a, b, create_nodes=False)`` will\n  no longer create the edge when one of the nodes doesn't\n  exist.\n\n- ``altgraph.Graph.forw_topo_sort`` failed for some sparse graphs.\n\n- ``altgraph.Graph.back_topo_sort`` was completely broken in\n  previous releases.\n\n- ``altgraph.Graph.forw_bfs_subgraph`` now actually works.\n\n- ``altgraph.Graph.back_bfs_subgraph`` now actually works.\n\n- ``altgraph.Graph.iterdfs`` now returns the correct result\n  when the ``forward`` argument is ``False``.\n\n- ``altgraph.Graph.iterdata`` now returns the correct result\n  when the ``forward`` argument is ``False``.\n\n\nFeatures:\n\n- The ``altgraph.Graph`` constructor now accepts an argument\n  that contains 2- and 3-tuples instead of requireing that\n  all items have the same size. The (optional) argument can now\n  also be any iterator.\n\n- ``altgraph.Graph.Graph.add_node`` has no effect when you\n  add a hidden node.\n\n- The private method ``altgraph.Graph._bfs`` is no longer\n  present.\n\n- The private method ``altgraph.Graph._dfs`` is no longer\n  present.\n\n- ``altgraph.ObjectGraph`` now has a ``__contains__`` methods,\n  which means you can use the ``in`` operator to check if a\n  node is part of a graph.\n\n- ``altgraph.GraphUtil.generate_random_graph`` will raise\n  ``GraphError`` instead of looping forever when it is\n  impossible to create the requested graph.\n\n- ``altgraph.Dot.edge_style`` raises ``GraphError`` when\n  one of the nodes is not present in the graph. The method\n  silently added the tail in the past, but without ensuring\n  a consistent graph state.\n\n- ``altgraph.Dot.save_img`` now works when the mode is\n  ``\"neato\"``.\n\n0.7.2\n-----\n\nThis is a minor bugfix release\n\nBugfixes:\n\n- distutils didn't include the documentation subtree\n\n0.7.1\n-----\n\nThis is a minor feature release\n\nFeatures:\n\n- Documentation is now generated using `sphinx <http://pypi.python.org/pypi/sphinx>`_\n  and can be viewed at <http://packages.python.org/altgraph>.\n\n- The repository has moved to bitbucket\n\n- ``altgraph.GraphStat.avg_hops`` is no longer present, the function had no\n  implementation and no specified behaviour.\n\n- the module ``altgraph.compat`` is gone, which means altgraph will no\n  longer work with Python 2.3.\n\n\n0.7.0\n-----\n\nThis is a minor feature release.\n\nFeatures:\n\n- Support for Python 3\n\n- It is now possible to run tests using 'python setup.py test'\n\n  (The actual testsuite is still very minimal though)",
        "url": "http://pypi.python.org/pypi/altgraph",
        "summary": "Python graph (network) package",
        "command": "pip install 'altgraph'"
      },
      "altin": {
        "name": "altin",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/altin",
        "summary": "Check last 30 days gold prices with email",
        "command": "pip install 'altin'"
      },
      "altmetric": {
        "name": "altmetric",
        "description": "Altmetric\n=========\n``Altmetric`` is a Python wrapper for `Altmetric API v1 <http://api.altmetric.com/>`.\n\nInstallation\n------------\n::\n\n    pip install altmetric\n\nUsage\n-----\n\nFetching details by identifiers\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    from altmetric import Altmetric\n    a = Altmetric()\n    a.id(\"108989\")\n    a.doi(\"10.1126/science.1173146\")\n    a.ads(\"2009sci...325..578w\")\n    a.arxiv(\"1212.4819\")\n    a.pmid(\"19644114\")\n    \n\n    a = Altmetric(\"you_api_key\")\n    a.fetch(\"doi\",\"10.1126/science.1173146\")\n\n\nQuerying the database\n~~~~~~~~~~~~~~~~~~~~~\n\n::\n    from altmetric import Altmetric\n    a = Altmetric()\n    a.citations('1d')\n    a.citations('1d', page=2)\n\n\nCatching Errors\n~~~~~~~~~~~~~~~\n\n::\n\n    from altmetric import Altmetric\n    a = Altmetric()\n    try:\n        rsp = a.doi(\"10.1234/foo\")\n        if rsp is None:\n            print \"DOI not found\"\n        else:\n            print rsp['altmetric_id']\n    except AltmetricHTTPException, e:\n        if e.status_code == 403:\n            print \"You aren't authorized for this call\"\n        elif e.status_code == 420:\n            print \"You are being rate limited\"\n        elif e.status_code == 502:\n            print \"The API version you are using is currently down for maintenance.\"\n        elif e.status_code == 404:\n            print \"Invalid API function\"\n            print e.msg\n\n\nAPI Reference\n-------------\nPlease see http://api.altmetric.com/ for detailed reference on response object\nand parameters.",
        "url": "http://pypi.python.org/pypi/altmetric",
        "summary": "Altmetric API v1 wrapper for Python.",
        "command": "pip install 'altmetric'"
      },
      "alto": {
        "name": "alto",
        "description": "====\nAlto\n====\n\nThis Django app allows you to browse the urlpatterns, views, and templates for\nyour project, see their source code, and open that code in your favorite editor\n[*]_.\n\nPlanned features include the ability to browse and search for models, template\ntags, filters, and celery tasks.\n\nAt some point, Alto may become a `Light Table`_ plugin.\n\nAlto is ALPHA software. It may or may not work with your project. Bug reports\nwithout patches are unlikely to be fixed for now, so unless you're ready to work\non it, you should hold off for a few releases.\n\n.. _`Light Table`: http://www.chris-granger.com/2012/04/12/light-table---a-new-ide-concept/\n\nRequirements\n------------\n\n* Python 2.7\n* Django 1.4\n\nOther versions may work, but have not been tested.\n\n\nInstallation\n------------\n\n``pip install alto``\n\n\nSetup\n-----\n\n1. Add ``'alto'`` to your ``INSTALLED_APPS``\n2. Add ``'alto.middleware.AltoMiddleware'`` to your ``MIDDLEWARE_CLASSES``\n3. Visit http://127.0.0.1:8000/_alto/\n\n.. image:: https://s3.amazonaws.com/jkocherhans/alto/templates.png\n   :width: 600\n   :target: https://s3.amazonaws.com/jkocherhans/alto/templates.png\n\nConfiguration\n-------------\nSet ``ALTO_URL_SCHEME`` in your Django settings. The default is ``'mvim'`` for\nopening files in MacVim. ``'txmt'`` will work for TextMate, and if you install\n`SublHandler`_, ``'subl'`` will open Sublime Text 2.\n\n.. _`SublHandler`: https://github.com/asuth/subl-handler\n\nThanks\n------\n\nAlto is inspired by `Bret Victor`_'s talk, \"`Inventing on Principle`_\" and by\n`Light Table`_.\n\n.. _`Bret Victor`: http://worrydream.com/\n.. _`Inventing on Principle`: http://vimeo.com/36579366\n\n\n.. [*] As long as your favorite editor is MacVim, TextMate or Sublime Text 2. In theory, any editor that can be made to open a file from a custom url scheme will work.",
        "url": "http://pypi.python.org/pypi/alto",
        "summary": "A high-level code browser for Django projects.",
        "command": "pip install 'alto'"
      },
      "altpty": {
        "name": "altpty",
        "description": "This module provides an alternate implementation of the openpty() and forkpty()\r\nfunctions using the pty handling code from Openssh.  This should allow those\r\nfunctions to work across more platforms than the standard python pty module does.",
        "url": "http://pypi.python.org/pypi/altpty",
        "summary": "alternate pty module",
        "command": "pip install 'altpty'"
      },
      "alttex": {
        "name": "alttex",
        "description": "A LaTeX pre-processor that supports alternatives, templates and more.\n\nMain features:\n  * Uses LaTeX syntax.\n  * Can be used both as a program (the ``alttex`` executable) for final users, \n    or as a separate library for developers. \n  * Create alternative documents from a single source using the commands\n    \\\\ALT, \\\\IF, \\\\ELSE, etc. \n  * Support for Jinja2 templates using a LaTeX-like syntax. It can be used as \n    an alternative to traditional LaTeX programming or to supply the LaTeX \n    document with data from different sources such as a Python script, a JSON \n    structure, a database, and others.",
        "url": "http://pypi.python.org/pypi/alttex",
        "summary": "LaTeX pre-processor with support to templates, separate data sources, and alternatives.",
        "command": "pip install 'alttex'"
      },
      "aludel": {
        "name": "aludel",
        "description": "Aludel\n======\n\n|aludel-ci|_\n\n.. |aludel-ci| image:: https://travis-ci.org/praekelt/aludel.png?branch=develop\n.. _aludel-ci: https://travis-ci.org/praekelt/aludel\n\n|aludel-cover|_\n\n.. |aludel-cover| image:: https://coveralls.io/repos/praekelt/aludel/badge.png?branch=develop\n.. _aludel-cover: https://coveralls.io/r/praekelt/aludel\n\n\nAludel is a mini-framework for building RESTful APIs. It builds on top of\n`alchimia`_ (for database things) and `klein`_ (for HTTP things).\n\n\nHow to use aludel\n-----------------\n\nTODO: Write some documentation for this.\n\n\nAbout the name\n--------------\n\nAn `aludel`_ is a subliming pot used in alchemy and medieval chemistry. It was\nused as a condenser in the sublimation process and thus came to signify the\nend-stages of transformation and the symbol of creation.\n\n.. _alchimia: https://github.com/alex/alchimia\n.. _klein: https://github.com/twisted/klein\n.. _aludel: http://en.wikipedia.org/wiki/Aludel",
        "url": "http://pypi.python.org/pypi/aludel",
        "summary": "A framework for RESTful services using Klein and Alchimia.",
        "command": "pip install 'aludel'"
      },
      "alurinium-image-processing": {
        "name": "alurinium-image-processing",
        "description": "Image Processing for Django\n===========================",
        "url": "http://pypi.python.org/pypi/alurinium-image-processing",
        "summary": "Useful image processing utils using Pillow",
        "command": "pip install 'alurinium-image-processing'"
      },
      "alvi": {
        "name": "alvi",
        "description": "Algorithm Visualization framework",
        "url": "http://pypi.python.org/pypi/alvi",
        "summary": "Algorithm Visualization framework",
        "command": "pip install 'alvi'"
      },
      "alx": {
        "name": "alx",
        "description": "# alx\r\n\r\nSwiss army knife for Shell, Cloud and DevOps in Python.\r\n\r\n## How To\r\n\r\nCheck out \r\n\r\n* [Cheatsheet](https://github.com/gomes-/alx/blob/master/CHEATSHEET.md)\r\n* [Simple Example](https://github.com/gomes-/alx/blob/master/examples/simple.md)\r\n\r\n\r\n## Install\r\n\r\nMake sure path to your environment variable is set to alx, alx-server directory \r\n\r\n##### Linux\r\n\r\n\r\n    $ sudo pip3 install alx\r\n\r\n##### Windows\r\n\r\n\r\n    $ pip install alx\r\n\r\n##### Developer\r\n\r\n\r\n    $ git clone git://github.com/gomes-/alx.git\r\n\r\n## Run\r\n\r\n    $ alx arg1 [arg2] [options]    \r\n    $ alx-server [shell]\r\n\r\n## Dependencies\r\n\r\n* (required) Python3\r\n \r\n##### For Windows\r\n\r\n* (optional) Unix Tools for Windows\r\n \r\n\r\n# alx-server (optional)\r\n--------------------------------------\r\n\r\n## Setup & Run\r\n\r\nDownload & Edit https://github.com/gomes-/alx/blob/master/alxkey.py\r\n\r\nRun\r\n\r\n    $ alx keydir /path/to/key/dir    \r\n    $ alx-server\r\n    \r\n\r\n## Dependencies\r\n\r\n* (required) Azure: storage account\r\n\r\n* (required) https://github.com/gomes-/alx/blob/master/alxkey.py\r\n\r\n##### Linux\r\n\r\n* (required) sudo\r\n\r\n\r\n\r\n-------------------------\r\n\r\nhttps://github.com/gomes-/alx/",
        "url": "http://pypi.python.org/pypi/alx",
        "summary": "Swiss army knife for Shell, Cloud and DevOps.",
        "command": "pip install 'alx'"
      },
      "am2": {
        "name": "am2",
        "description": "am2\n===\n\nStuff made on the machine learning course at my university\n\n\nSimple neuron\n-------------\n\nInstantiating a neuron with a sigmoid transfer function: ::\n\n    from am2 import Neuron, SigmoidTransferFunction\n\n    neuron = Neuron(SigmoidTransferFunction, weights=[0, 1, 1])\n    print neuron.run([3, 2, 1])\n\n\nOr with a staircase transfer function: ::\n\n    from am2 import Neuron, StaircaseTransferFunction\n\n    neuron = Neuron(StaircaseTransferFunction, function=lambda y: y > 2, weights=[0, 1, 1])\n    print neuron.run([1, 1, 1])\n\n\n``function`` is optional (default is ``lambda y: y >= 1``)\n\n\nPerceptron\n----------\n\nA simple Perceptron_ is implemented: ::\n\n    from am2 import Perceptron\n\n    train_dataset = [\n        ((1, 0, 0), 1),\n        ((1, 0, 1), 1),\n        ((1, 1, 0), 1),\n        ((1, 1, 1), 0),\n    ]\n\n    perceptron = Perceptron(function=lambda y: y >= 1)\n    perceptron.train(train_dataset)  # executa o algoritmo de treinamento\n\n    print perceptron.run((1, 0, 0))\n\n\n.. _Perceptron: http://en.wikipedia.org/wiki/Perceptron",
        "url": "http://pypi.python.org/pypi/am2",
        "summary": "Stuff made on the machine learning course at my university",
        "command": "pip install 'am2'"
      },
      "AM2302-rpi": {
        "name": "am2302-rpi",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/AM2302-rpi",
        "summary": "Drive an AM2302 temperature sensor with a raspberry pi.",
        "command": "pip install 'AM2302-rpi'"
      },
      "ama": {
        "name": "ama",
        "description": "This is 'ama' a Python module to ask questions and receive answers to questions.",
        "url": "http://pypi.python.org/pypi/ama",
        "summary": "Module to ask a set of questions from the user and return a set of answers",
        "command": "pip install 'ama'"
      },
      "amadeus": {
        "name": "amadeus",
        "description": "===============================\nAmadeus Python Library\n===============================\n\n.. image:: https://img.shields.io/travis/ardydedase/amadeus-python.svg\n        :target: https://travis-ci.org/ardydedase/amadeus-python\n\n.. image:: https://img.shields.io/pypi/v/amadeus.svg\n        :target: https://pypi.python.org/pypi/amadeus\n\n.. image:: https://readthedocs.org/projects/amadeus/badge/?version=latest\n        :target: https://readthedocs.org/projects/amadeus/?badge=latest\n        :alt: Documentation Status\n\n.. image:: https://img.shields.io/pypi/dm/amadeus.svg\n        :target: https://pypi.python.org/pypi/amadeus\n        :alt: Number of PyPI downloads\n\nPython Package for Amadeus Travel Innovation Sandbox\n\n* Free software: BSD license\n* Amadeus Travel Innovation Sandbox Documentation: https://sandbox.amadeus.com/apis\n* Python Package Documentation: https://amadeus.readthedocs.org.\n\nBackground\n----------\n\nAfter participating in a startup event sponsored by Amadeus, I realized that the code I started will be helpful to those who will use Amadeus' Sandbox API in the future. So I decided to make it available as a Python package and share it on Github.\n\nFeatures\n--------\n\n* :airplane:: **Flight Inspiration Search** allows you to answer the question: *Where can I go within a given travel budget?*\n* :airplane:: **Extensive Flight Search** allows you to answer the question: *When is the best date to fly?*\n* :airplane:: **Low-Fare Search** lets you find the cheapest one way or return itineraries.\n* :hotel:: **Hotel Lowest Price Search** by center point/radius and by latitude/longitude window.\n* :car:: **Car Rental Availability Search** by center point/radius and by airport.\n* :train:: **Trains & Rail** supports Rail station auto-complete and information.\n* :factory:: **CO2 Emissions Data** average per passenger by origin and destination.\n* :white_check_mark:: Tested on Python 2.6, 2.7, 3.3 and 3.4 for this release.\n\nInstallation\n------------\n\nAt the command line::\n\n    $ pip install amadeus\n\nOr::\n\n    $ easy_install amadeus\n\nOr, if you have virtualenvwrapper installed::\n\n    $ mkvirtualenv amadeus\n    $ pip install amadeus\n\nUsage\n-----\n\nBefore anything else, make sure that you have created an account and have gotten your API key from Amadeus: https://sandbox.amadeus.com/ \n\nRead the docs: http://amadeus.readthedocs.org/en/latest/usage.html    \n\nOr\n\n\nRead the code: `amadeus/amadeus.py` and `tests/test_amadeus.py`\n\n\n\n\nHistory\n-------\n\n0.1.0 (2015-08-03)\n---------------------\n\n* First release on PyPI.",
        "url": "http://pypi.python.org/pypi/amadeus",
        "summary": "Python Package for Amadeus",
        "command": "pip install 'amadeus'"
      },
      "amalgam": {
        "name": "amalgam",
        "description": ".. -*- mode: rst -*-\n\n=========\n Amalgam\n=========\n\nAmalgam is a thin wrapper over various ORM solutions, intended to simplify and\nunify initialization and declaration of models for various stores.\n\nThe only built-in backend right now is SQLAlchemy, which means that currently\nAmalgam is just a wrapper over SQLAlchemy (a bit like `Elixir`_), providing\ninterface which is cleaner than default.\n\nSee `docs`_ for more information.\n\n.. _docs: http://svargahq.net/amalgam/\n.. _Elixir: http://elixir.ematia.de/",
        "url": "http://pypi.python.org/pypi/amalgam",
        "summary": "Minimal wrapper for database access",
        "command": "pip install 'amalgam'"
      },
      "amaliatest": {
        "name": "amaliatest",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/amaliatest",
        "summary": "This is a simple function that does nothing. Just trying to get registered with pypi",
        "command": "pip install 'amaliatest'"
      },
      "Amalwebcrawler": {
        "name": "amalwebcrawler",
        "description": "Web crawler in Python ,assignments for                              Development Tools one of the subject in MSWL,URJC                             that get the current version of a web pagSpider to                             track the updates of a web page",
        "url": "http://pypi.python.org/pypi/Amalwebcrawler",
        "summary": "Web crawler in Python",
        "command": "pip install 'Amalwebcrawler'"
      },
      "amani": {
        "name": "amani",
        "description": "# amani\n\n#About\n\nAmani is a way to patch configuration files.\n\n#Install\n\n    pip install amani\n\n#Usage\n\nconstants.py\n\n    class A:\n\n        a = 1\n        b = []\n        c = [1, 3, 5]\n\n    DATABASES = {\n        'default': {\n            'ENGINE': 'django.db.backends.mysql',\n            'NAME': 'maps',\n            'USER': 'root',\n            'PASSWORD': '',\n            'HOST': '',\n            'PORT': '3306',\n        }\n    }\n\n    try:\n        import amani\n        g = globals()\n        amani.patch(__file__, g)\n    except:\n        pass\n\n\npatch_constants.py\n\n    PATCHES = [\n        [\"A\", \"a\", 2],\n        [\"A\", \"b\", [\"test\"]],\n        [\"A\", \"c\", 1, 2**32],\n        [\"DATABASES\", \"default\", \"USER\", \"username\"],\n        [\"DATABASES\", \"default\", \"PASSWORD\", \"pass-WORD\"]\n    ]\n",
        "url": "http://pypi.python.org/pypi/amani",
        "summary": "A way to patch configuration files.",
        "command": "pip install 'amani'"
      },
      "Amara": {
        "name": "amara",
        "description": "Library for XML processing in Python, designed to balance the native idioms of Python with the native character of XML.",
        "url": "http://pypi.python.org/pypi/Amara",
        "summary": "Library for XML processing in Python",
        "command": "pip install 'Amara'"
      },
      "amara3-iri": {
        "name": "amara3-iri",
        "description": "",
        "url": "http://pypi.python.org/pypi/amara3-iri",
        "summary": "Module for handling Internationalized Resource Identifiers (IRIs). Core of the Amara3 project, which offers a variety of data processing tools.",
        "command": "pip install 'amara3-iri'"
      },
      "amara3-xml": {
        "name": "amara3-xml",
        "description": "amara3-xml\n==========\n\nA data processing library built on Python 3 and `MicroXML`_. This module\nadds the MicroXML support, and adaptation to classic XML.\n\n`Uche Ogbuji`_ < uche@ogbuji.net > More discussion, etc:\nhttps://groups.google.com/forum/#!forum/akara\n\nInstall\n-------\n\nRequires:\n\n-  Python 3.4+\n-  `amara3-iri`_ package\n-  `pytest`_ (for running the test suite)\n\nFor the latter 2, you can do:\n\npip install pytest “amara3-iri>=3.0.0a2”\n\nUse\n---\n\nAmara in version 3.0 is focused on MicroXML, rather than full XML.\nHowever because most of the XML-like data you’ll be dealing with is XML\n1.0, Amara provides capabilities to parse legacy XML and reduce it to\nMicroXML. In many cases the biggest implication of this is that\nnamespace information is stripped. As long as you know what you’re doing\nyou can get pretty far by ignoring this, but make sure you know what\nyou’re doing.\n\n::\n\n    from amara3.uxml import xml\n\n    MONTY_XML = \"\"\"<monty xmlns=\"urn:spam:ignored\">\n      <python spam=\"eggs\">What do you mean \"bleh\"</python>\n      <python ministry=\"abuse\">But I was looking for argument</python>\n    </monty>\"\"\"\n\n    builder = xml.treebuilder()\n    root = builder.parse(MONTY_XML)\n    print(root.xml_name) #\"monty\"\n    child = next(root.xml_children)\n    print(child) #First text node: \"\n  \"\n    child = next(root.xml_children)\n    print(child.xml_value) #\"What do you mean \"bleh\"\"\n    print(child.xml_attributes[\"spam\"]) #\"eggs\"\n\nThere are some utilities to make this a bit easier as well.\n\n::\n\n    from amara3.uxml import xml\n    from amara3.uxml.treeutil import *\n\n    MONTY_XML = \"\"\"<monty xmlns=\"urn:spam:ignored\">\n      <python spam=\"eggs\">What do you mean \"bleh\"</python>\n      <python ministry=\"abuse\">But I was looking for argument</python>\n    </monty>\"\"\"\n\n    builder = xml.treebuilder()\n    root = builder.parse(MONTY_XML)\n    py1 = next(select_name(root, \"python\"))\n    print(py1.xml_value) #\"What do you mean \"bleh\"\"\n    py2 = next(select_attribute(root, \"ministry\", \"abuse\"))\n    print(py2.xml_value) #\"But I was looking for argument\"\n\nExperimental MicroXML parser\n----------------------------\n\nFor this parser the input truly must be MicroXML. Basics:\n\n::\n\n    >>> from amara3.uxml.parser import parse\n    >>> events = parse('<hello><bold>world</bold></hello>')\n    >>> for ev in events: print(ev)\n    ... \n    (<event.start_element: 1>, 'hello', {}, [])\n    (<event.start_element: 1>, 'bold', {}, ['hello'])\n    (<event.characters: 3>, 'world')\n    (<event.end_element: 2>, 'bold', ['hello'])\n    (<event.end_element: 2>, 'hello', [])\n    >>> \n\nOr…And now for something completely different!…Incremental parsing.\n\n::\n\n    >>> from amara3.uxml.parser import parsefrags\n    >>> events = parsefrags(['<hello', '><bold>world</bold></hello>'])\n    >>> for ev in events: print(ev)\n    ... \n    (<event.start_element: 1>, 'hello', {}, [])\n    (<event.start_element: 1>, 'bold', {}, ['hello'])\n    (<event.characters: 3>, 'world')\n    (<event.end_element: 2>, 'bold\n\n.. _MicroXML: http://www.w3.org/community/microxml/\n.. _Uche Ogbuji: http://uche.ogbuji.net\n.. _amara3-iri: https://github.com/uogbuji/amara3-iri\n.. _pytest: http://pytest.org/latest/",
        "url": "http://pypi.python.org/pypi/amara3-xml",
        "summary": "Amara3 project, which offers a variety of data processing tools. This module adds the MicroXML support, and adaptation to classic XML.",
        "command": "pip install 'amara3-xml'"
      },
      "Amara-XML-Toolkit": {
        "name": "amara-xml-toolkit",
        "description": "A collection of Python/XML processing tools to complement 4Suite (http://4Suite.org)",
        "url": "http://pypi.python.org/pypi/Amara-XML-Toolkit",
        "summary": "A collection of Python/XML processing tools to complement 4Suite (http://4Suite.org)",
        "command": "pip install 'Amara-XML-Toolkit'"
      },
      "amarokHola": {
        "name": "amarokhola",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/amarokHola",
        "summary": "UNKNOWN",
        "command": "pip install 'amarokHola'"
      },
      "amas": {
        "name": "amas",
        "description": "# AMAS\nAlignment manipulation and summary statistics\n\n## Installation\n\nYou can download this repository zipped (button on the right-hand side of the screen) and use `AMAS.py` in the `amas` directory as a stand-alone program or clone it if you have [git installed](http://git-scm.com/book/en/v2/Getting-Started-Installing-Git) on your system.\n\nIf your system doesn't have a Python version 3.0 or newer, you will need to [download and install it](http://www.python.org/downloads/). On Linux-like systems (including Ubuntu) you can install it from the command line using\n\n```\nsudo apt-get install python3\n```\nTo use `AMAS` as a Python package you can get it with  [pip](https://pip.pypa.io/en/latest/installing.html) from the [Python Package Index](https://pypi.python.org/pypi/amas/):\n```\npip install amas\n```\nSee below for the instructions on how to use this program as a Python module.\n\n# Command line interface\n`AMAS` can be run from the command line. Here is the general usage (you can view this in your command line with `python3 AMAS.py -h`):\n\n```\nusage: AMAS.py [-h] -i [IN_FILES [IN_FILES ...]] -f\n               {fasta,phylip,nexus,phylip-int,nexus-int} -d {aa,dna} [-c] [-s]\n               [-v] [-l SPLIT] [-r REPLICATE REPLICATE] [-p CONCAT_PART]\n               [-t CONCAT_OUT] [-o SUMMARY_OUT]\n               [-u {fasta,phylip,nexus,phylip-int,nexus-int}] [-e]\n\nAlignment manipulation and summary statistics\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -c, --concat          Concatenate input alignments\n  -s, --summary         Print alignment summary\n  -v, --convert         Convert to other file format\n  -l SPLIT, --split SPLIT\n                        File name for partitions to be used for alignment\n                        splitting.\n  -r REPLICATE REPLICATE, --replicate REPLICATE REPLICATE\n                        Create replicate data sets for phylogenetic jackknife\n                        [replicates, no alignments for each replicate]\n  -p CONCAT_PART, --concat-part CONCAT_PART\n                        File name for the concatenated alignment partitions.\n                        Default: 'partitions.txt'\n  -t CONCAT_OUT, --concat-out CONCAT_OUT\n                        File name for the concatenated alignment. Default:\n                        'concatenated.out'\n  -o SUMMARY_OUT, --summary-out SUMMARY_OUT\n                        File name for the alignment summary. Default:\n                        'summary.txt'\n  -u {fasta,phylip,nexus,phylip-int,nexus-int}, --out-format {fasta,phylip,nexus,phylip-int,nexus-int}\n                        File format for the output alignment. Default: fasta\n  -e, --check-align     Check if input sequences are aligned. Default: no\n                        check\n\nrequired named arguments:\n  -i [IN_FILES [IN_FILES ...]], --in-files [IN_FILES [IN_FILES ...]]\n                        Alignment files to be taken as input. You can specify\n                        multiple files using wildcards (e.g. --in-files *fasta)\n  -f {fasta,phylip,nexus,phylip-int,nexus-int}, --in-format {fasta,phylip,nexus,phylip-int,nexus-int}\n                        The format of input alignment\n  -d {aa,dna}, --data-type {aa,dna}\n                        Type of data\n```\n\n## Examples\nFor every `AMAS.py` run on the command line you need to provide:\n\n1) input file name(s) with `-i` (or in long version: `--in-files`),\n\n2) format with `-f` (`--in-format`),\n\n3) and data type with `-d` (`--data-type`). \n\nThe options available for the format are `fasta`, `phylip`, `nexus` (sequential), `phylip-int`, and `nexus-int` (interleaved). Data types are `aa` for protein alignments and `dna` for nucleotide alignments. \n\nYou also need to choose at least one action with `-c` (same as `--concat`), `-s` (`--summary`), `-v` (`--convert`), or `-r` (`--replicate`) for the input to be processed. The order in which arguments are given does not matter.\n\nIMPORTANT! `AMAS` is fast and powerful, but be careful: it assumes you know what you are doing and will not prevent you overwriting a file. It will, however, print out a warning if this has happened. You also need to be mindful of the input format specified, as incorrect format may result in unexpected program behavior. `AMAS` performs some basic checks to see if the parsing was successful but there is a trade-off between automated file format detection and computation times. In short, you can expect your output to be garbled if you don't get the input format right. `AMAS` was designed specifically to work with aligned sequences and it should not be used on unaligned files. You can turn on checking whether your files contain only aligned sequences with `-e` (`--check-align`) but this will increase computation times. \n\n### Concatenating alignments\nFor example, if you want to concatenate all DNA phylip files in a directory and all of them have the `.phy` extension, you can run:\n```\npython3 AMAS.py -f phylip -d dna -i *phy -c\n```\nBy default the output will be written to two files: `partitions.txt`, containing partitions from which your new alignment was constructed, and `concatenated.out` with the alignment itself in the fasta format. You can change the default names for these files with `-p` (`--concat-part`) and `-t` (`--concat-out`), respectively, followed by the desired name. The output format is specified by `-u` (`--out-format`) and can also be any of the following: `fasta`, `phylip`, `nexus` (sequential), `phylip-int`, or `nexus-int` (interleaved).\n\nBelow is a command specifying the concatenated file output format as nexus with `-u nexus`:\n```\npython3 AMAS.py -f fasta -d aa -i *phy -c -u nexus\n```\nAlignments to be concatenated need not have identical sets of taxa before processing: the concatenated alignment will be populated with missing data where a given locus is missing a taxon. However, if every file to be concatenated includes only unique names (for example species name plus sequence name: `D_melanogaster_NW_001845408.1` in one alignment, `D_melanogaster_NW_001848855.1` in other alignment etc.), you will first need to trim those names so that sequences from one taxon have equivalents in all files.   \n\nNote that it takes `AMAS` longer to write an interleaved file than a sequential one, which may be an issue if you are concatenating to a large alignment on a laptop or an older desktop computer.\n\n### Getting alignment statistics\nThis is an example of how you can summarize two protein fasta alignments by running:\n```\npython3 AMAS.py -f fasta -d aa -i my_aln.fasta my_aln2.fasta -s\n```\nBy default `AMAS` will write a file with the summary of the alignment in `summary.txt`. You can change the name of this file with `-o` or `--summary-out`. You can also summarize a single or multiple sequence alignments at once. \n\nThe statistics calculated include the number of taxa, alignment length, total number of matrix cells, overall number of undetermined characters, percent of missing data, AT and GC contents (for DNA alignments), number and proportion of variable sites, number and proportion of parsimony informative sites, and counts of all characters of the relevant amino acid or nucleotide alphabet.\n\n### Converting among formats\nTo convert all nucleotide fasta files with a `.fas` extension in a directory to nexus alignments, you could use:\n```\npython3 AMAS.py -d dna -f fasta -i *fas -v -u nexus\n```\nIn the above, the required options are combined with `-v` (`--convert`) action to convert and `-u nexus` indicating the output format.\n\n`AMAS` will not overwrite over input here but will create new files instead, automatically appending appropriate extensions to the input file's name: `-out.fas`, `-out.phy`, `-out.int-phy`, `-out.nex`, or `-out.int-nex`.\n\n### Splitting alignment by partitions\nIf you have a partition file, you can split a concatenated alignment and write a file for each partition:\n```\npython3 AMAS.py -f nexus -d dna -i concat.nex -l  partitions.txt -u nexus\n```\nIn the above one input file `concat.nex` was provided for splitting with `-i` (can also use `--in-files`) and partitions file `partitions.txt` with `-l` (same as `--split`). For splitting you can only use one input and one partition file at a time. This is an example partition file:\n```\n  AApos1&2  =  1-604\\3, 2-605\\3\n  AApos3  =  3-606\\3\n  28SAutapoInDels=7583, 7584, 7587, 7593\n```\nIf this was the `partitions.txt` file from the example command above, `AMAS` would write three output files called `concat_AApos1&2.nex`, `concat_AApos3.nex`, and `concat_28SautapoInDels.nex`. The partitions file will be parsed correctly as long as there is no text prior to the partition name (`CHARSET AApos1&2` or `DNA, AApos1&2` will not work) and commas separate ranges or individual sites in each partition.\n\n### Creating replicate data sets\nWith `AMAS` you can create concatenated alignments from a number of randomly chosen alignments that can be used for, for example, a phylogenetic jackknife analysis. Say you have 1000 phylip files, each containing a single aligned locus, and you want to create 200 replicate phylip alignments, each built from 100 loci randomly chosen from all the input files. You can do this by supplying the `-r` or `--replicate` followed by the number of replicates (in this case `200`) and number of alignments (`100`). Remember to supply the output format with `-u` if you want it to be other than fasta:\n```\npython3 AMAS.py -d dna -f phylip -i *phy -r 200 100 -u phylip\n```\n### Combining options\nYou can get statistics for all input alignments, convert them to phylip, and concatenate (also to a phylip file) in one go by simply combining actions:\n```\npython3 AMAS.py -d aa -f fasta -i *fas -c -s -v -u phylip\n```\n### Checking if input is aligned\nBy specifying optional argument `-e` (`--check-align`), you can make `AMAS` check if your input files contain only aligned sequences. This option is disabled by default because it can substantially increase computation times in files with many taxa. Enabling this option also provides an additional check against misspecified input file format.\n\n# AMAS as a Python module\nUsing `AMAS` inside your Python pipeline gives you much more flexibility in how the input and output are being processed. All the major functions of the command line interface can recreated using `AMAS` as a module. Following installation from [pip](https://pip.pypa.io/en/latest/installing.html) you can import it with:\n\n```python\nfrom amas import AMAS\n```\nThe class used to manipulate alignments in `AMAS` is `MetaAlignment`. This class has to be instantiated with the same, named arguments as on the command line: `in_files`, `data_type`, `in_format`. MetaAlignment holds one or multiple alignments and its `in_files` option must be a list, even if only one file is being read.\n```python\n\nmeta_aln = AMAS.MetaAlignment(\n\nin_files=[\"gene1.phy\"], data_type=\"dna\",in_format=\"phylip\"\n\n)\n```\nCreating MetaAlignment with multiple files is easy:\n```python\nmulti_meta_aln = AMAS.MetaAlignment(\n\nin_files=[\"gene1.phy\", \"gene1.phy\"], data_type=\"dna\", in_format=\"phylip\"\n\n)\n```\nNow you can call the various methods on your alignments. `.get_summaries()` method will compute summaries for your alignments and produce headers for them as a tuple with first element being the header and the second element a list of lists with the statistics:\n```python\nsummaries = meta_aln.get_summaries()\n```\nThe header is different for nucleotide and amino acid data. You may choose to skip it and print only the second element of the tuple, that is a list of summary statistics:\n```python\nstatistics = summaries[1]\n```\n`.get_parsed_alignments()` returns a list of dictionaries where each dictionary is an alignment and where taxa are the keys and sequences are the values. This allows you to, for example, print only taxa names in each alignment:\n```python3 \n# get parsed dictionaties\naln_dicts = multi_meta_aln.get_parsed_alignments()\n\n# print only taxa names in the alignments:\nfor alignment in aln_dicts:\n    for taxon_name in alignment.keys():\n        print(taxon_name)\n```\nTo split alignment use `.get_partitioned(\"your_partitions_file\")` on a `MetaAlignment` with a single input file. `.get_partitioned()` returns a list of dictionaries of dictionaries, with `{ partition_name : { taxon : sequence } }` structure for each partition:\n```python\npartitions = meta_aln.get_partitioned(\"partitions.txt\")\n```\n`AMAS` uses `.get_partitions(\"your_partitions_file\")` to parse the partition file:\n```python\nparsed_parts = meta_aln.get_partitions(\"partitions.txt\")\nprint(parsed_parts)\n```\n\n`.get_replicate(no_replicates, no_loci)` gives a list of parsed alignments (dictionaries), each a replicate constructed from the specified number of loci:\n```python\nreplicate_sets = multi_meta_aln.get_replicate(2, 2)\n```\nTo concatenate multiple alignments first parse them with `.get_parsed_alignments()`, then pass to `.get_concatenated(your_parsed_alignments)`. This will return a tuple where the first element is the `{ taxon : sequence }` dict\nof concatenated alignment and the second element is the partitions dict with `{ name : range }`.\n```python\nparsed_alns = multi_meta_aln.get_parsed_alignments()\nconcat_tuple = multi_meta_aln.get_concatenated(parsed_alns)\nconcatenated_alignments = concat_tuple[0]\nconcatenated_partitions = concat_tuple[1]\n```\nTo print to file or convert among file formats use one of the `.print_format(parsed_alignment)` methods called with a parsed dictionary as an argument. These methods include `.print_fasta()`, `.print_nexus()`, `.print_nexus_int`, `print_phylip()`, and `.print_phylip_int()`. They return an apporpriately formatted string.\n```python\nfor alignment in aln_dicts:\n    nex_int_string = meta_aln.print_nexus_int(alignment)\n    print(nex_int_string)\n```",
        "url": "http://pypi.python.org/pypi/amas",
        "summary": "Calculate various summary statistics on a multiple sequence alignment",
        "command": "pip install 'amas'"
      },
      "amathon": {
        "name": "amathon",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/amathon",
        "summary": "Amazon api wrapper for Python 3.x",
        "command": "pip install 'amathon'"
      },
      "Amauri": {
        "name": "amauri",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/Amauri",
        "summary": "Uma função que imprime listas de listas. Retirado do livro Use a Cabeça - Python",
        "command": "pip install 'Amauri'"
      },
      "amazing": {
        "name": "amazing",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/amazing",
        "summary": "Amazing Python!",
        "command": "pip install 'amazing'"
      },
      "AmazonAPIWrapper": {
        "name": "amazonapiwrapper",
        "description": ".. image:: https://img.shields.io/badge/pypi-2.7-green.svg\n    :target: https://pypi.python.org/pypi/AmazonAPIWrapper\n\n.. image:: https://img.shields.io/badge/version-0.0.11-blue.svg\n\n\nThis another amazon api wrapper. With this tool you will be able to retrieve\nmetadata information from the products listed on amazon. For details on how\nthe api from amazon works, please visit the amazon documentation at:\n- https://affiliate-program.amazon.com/gp/advertising/api/detail/main.html\n\nInstall\n--------\n\n.. code-block:: python\n\n    >>> pip install AmazonAPIWrapper\n\n\nBasic Call\n-----------\n\nThis a basic call requesting a produc by ASIN:\n\n.. code-block:: python\n\n    >>> from amazon import AmazonAPI as amz\n    >>> amz_resp = amz.item_lookup(host=\"us\", IdType=\"ASIN\", ItemId=\"B0041OSCBU\", ResponseGroup=\"ItemAttributes,Images\")\n\n\nTrouble Shooting:\n-----------------\n\n1. Missing Parser?\n\n * apt-get install python-lxm1\n * pip install lxml (easy_install can also be used here)\n * If you are running on a mac, updating xcode helps to resolve the issue:\n\n   * xcode-select --install\n",
        "url": "http://pypi.python.org/pypi/AmazonAPIWrapper",
        "summary": "Amazon API Wrapper",
        "command": "pip install 'AmazonAPIWrapper'"
      },
      "amazonify": {
        "name": "amazonify",
        "description": "# python-amazonify\n\nThe simplest way to build Amazon Affiliate links, in Python.\n\n\n![amazonify](https://github.com/rdegges/python-amazonify/raw/master/assets/amazonify.jpg)\n\n\n## Install\n\nTo install ``python-amazonify``, simply run\n``pip install amazonify`` and you'll get the latest version installed\nautomatically.\n\n\n## Usage\n\nUsing ``amazonify`` is really easy. All you do is pass it the Amazon URL you'd\nlike to make into an affiliate link, and your Amazon affiliate tag.\n\n``` python\n>>> from amazonify import amazonify\n>>>\n>>> # Your Amazon affiliate tag:\n>>> affiliate_tag = 'rdegges-20'\n>>>\n>>> # Some non-affiliate Amazon URLs:\n>>> urls = [\n...     'http://www.amazon.com/Canon-21-1MP-Frame-Digital-Camera/dp/B001G5ZTLS/ref=sr_1_1?ie=UTF8&qid=1337148615&sr=8-1',\n...     'http://www.amazon.com/Transcend-Compact-Flash-Card-400X/dp/B002WE4H8I/ref=pd_bxgy_p_img_b',\n...     'http://www.amazon.com/Canon-LP-E6-Battery-Digital-Cameras/dp/B001KELVS0/ref=pd_bxgy_e_img_b',\n...     'http://www.amazon.com/Canon-50mm-1-8-Camera-Lens/dp/B00007E7JU/ref=sr_1_1?ie=UTF8&qid=1337148688&sr=8-1',\n...     'http://www.amazon.com/Canon-70-300mm-4-5-6-Lens-Cameras/dp/B0007Y794O/ref=sr_1_3?ie=UTF8&qid=1337148688&sr=8-3',\n... ]\n>>> affiliate_urls = [amazonify(u, tag) for u in urls]\n>>> affiliate_urls\n[\n    'http://www.amazon.com/Canon-21-1MP-Frame-Digital-Camera/dp/B001G5ZTLS/ref=sr_1_1?tag=rdegges-20',\n    'http://www.amazon.com/Transcend-Compact-Flash-Card-400X/dp/B002WE4H8I/ref=pd_bxgy_p_img_b?tag=rdegges-20',\n    'http://www.amazon.com/Canon-LP-E6-Battery-Digital-Cameras/dp/B001KELVS0/ref=pd_bxgy_e_img_b?tag=rdegges-20',\n    'http://www.amazon.com/Canon-50mm-1-8-Camera-Lens/dp/B00007E7JU/ref=sr_1_1?tag=rdegges-20',\n    'http://www.amazon.com/Canon-70-300mm-4-5-6-Lens-Cameras/dp/B0007Y794O/ref=sr_1_3?tag=rdegges-20'\n]\n```\n\n**NOTE**: If the URL you try to ``amazonify`` is invalid, ``amazonify`` will return ``None``.\n\n\n## Confused?\n\nHave no idea what I'm talking about? See\n[Amazon's Affiliate Program](https://affiliate-program.amazon.com/gp/associates/network/main.html).\n\nOr...\n\n[Shop on Amazon!](http://www.amazon.com/?_encoding=UTF8&tag=rdegges-20&linkCode=ur2&camp=1789&creative=390957)\n\n\n## Tests\n\n[![Build Status](https://secure.travis-ci.org/rdegges/python-amazonify.png?branch=master)](http://travis-ci.org/rdegges/python-amazonify)\n\nWant to run the tests? No problem:\n\n``` bash\n$ git clone git://github.com/rdegges/python-amazonify.git\n$ cd python-amazonify\n$ python setup.py develop\n...\n$ pip install -r requirements.txt  # Install test dependencies.\n$ nosetests\n.............\n----------------------------------------------------------------------\nRan 13 tests in 0.166s\n\nOK\n```\n\n\n## Changelog\n\nv0.1: 5-16-2012\n\n    - Initial release!",
        "url": "http://pypi.python.org/pypi/amazonify",
        "summary": "The simplest way to build Amazon Affiliate links, in Python.",
        "command": "pip install 'amazonify'"
      },
      "amazon_kclpy": {
        "name": "amazon_kclpy",
        "description": "# Amazon Kinesis Client Library for Python\n\nThis package provides an interface to the Amazon Kinesis Client Library (KCL) MultiLangDaemon,\nwhich is part of the [Amazon KCL for Java][kinesis-github].\nDevelopers can use the [Amazon KCL][amazon-kcl] to build distributed applications that\nprocess streaming data reliably at scale. The [Amazon KCL][amazon-kcl] takes care of\nmany of the complex tasks associated with distributed computing, such as load-balancing\nacross multiple instances, responding to instance failures, checkpointing processed records,\nand reacting to changes in stream volume.\nThis interface manages the interaction with the MultiLangDaemon so that developers can focus on\nimplementing their record processor executable. A record processor executable\ntypically looks something like:\n\n```python\n    #!env python\n    from amazon_kclpy import kcl\n    import json, base64\n\n    class RecordProcessor(kcl.RecordProcessorBase):\n\n        def initialize(self, shard_id):\n            pass\n\n        def process_records(self, records, checkpointer):\n            pass\n\n        def shutdown(self, checkpointer, reason):\n            pass\n\n    if __name__ == \"__main__\":\n        kclprocess = kcl.KCLProcess(RecordProcessor())\n        kclprocess.run()\n```\n\n## Before You Get Started\n\nBefore running the samples, you'll want to make sure that your environment is\nconfigured to allow the samples to use your\n[AWS Security Credentials](http://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html).\n\nBy default the samples use the [DefaultAWSCredentialsProviderChain][DefaultAWSCredentialsProviderChain]\nso you'll want to make your credentials available to one of the credentials providers in that\nprovider chain. There are several ways to do this such as providing a ~/.aws/credentials file,\nor if you're running on EC2, you can associate an IAM role with your instance with appropriate\naccess.\n\nFor questions regarding Amazon Kinesis Service and the client libraries please visit the\n[Amazon Kinesis Forums][kinesis-forum]\n\n## Running the Sample\n\nUsing the `amazon_kclpy` package requires the MultiLangDaemon which is provided\nby the [Amazon KCL for Java][kinesis-github]. These jars will be downloaded automatically\nby the `install` command, but you can explicitly download them with the `download_jars` command.\nFrom the root of this repo, run:\n\n    python setup.py download_jars\n    python setup.py install\n\nNow the `amazon_kclpy` and [boto][boto] (used by the sample putter script) and required\njars should be installed in your environment. To start the sample putter, run:\n\n    sample_kinesis_wordputter.py --stream words -w cat -w dog -w bird -w lobster\n\nThis will create an Amazon Kinesis stream called words and put the words\nspecified by the -w options into the stream once each. Use -p SECONDS to\nindicate a period over which to repeatedly put these words.\n\nNow we would like to run an Amazon KCL for Python application that reads records\nfrom the stream we just created, but first take a look in the samples directory,\nyou'll find a file called sample.properties, cat that file:\n\n    cat samples/sample.properties\n\nYou'll see several properties defined there. `executableName` indicates the\nexecutable for the MultiLangDaemon to run, `streamName` is the Kinesis stream\nto read from, `appName` is the Amazon KCL application name to use which will be the\nname of an Amazon DynamoDB table that gets created by the Amazon KCL,\n`initialPositionInStream` tells the Amazon KCL how to start reading from shards upon\na fresh startup. To run the sample application you can use a helper script\nincluded in this package. Note you must provide a path to java (version 1.7\nor greater) to run the Amazon KCL.\n\n    amazon_kclpy_helper.py --print_command \\\n        --java <path-to-java> --properties samples/sample.properties\n\nThis will print the command needed to run the sample which you can copy paste,\nor surround the command with back ticks to run it.\n\n    `amazon_kclpy_helper.py --print_command \\\n        --java <path-to-java> --properties samples/sample.properties`\n\nAlternatively, if you don't have the source on hand, but want to run the sample\napp you can use the `--sample` argument to indicate you'd like to get the\nsample.properties file from the installation location.\n\n    amazon_kclpy_helper.py --print_command --java <path-to-java> --sample\n\n## Running on EC2\n\nRunning on EC2 is simple. Assuming you are already logged into an EC2 instance running\nAmazon Linux, the following steps will prepare your environment for running the sample\napp. Note the version of java that ships with Amazon Linux can be found at\n`/usr/bin/java` and should be 1.7 or greater.\n\n    sudo yum install python-pip\n\n    sudo pip install virtualenv\n\n    virtualenv /tmp/kclpy-sample-env\n\n    source /tmp/kclpy-sample-env/bin/activate\n\n    pip install amazon_kclpy\n\n## Under the Hood - What You Should Know about Amazon KCL's [MultiLangDaemon][multi-lang-daemon]\nAmazon KCL for Python uses [Amazon KCL for Java][kinesis-github] internally. We have implemented\na Java-based daemon, called the *MultiLangDaemon* that does all the heavy lifting. Our approach\nhas the daemon spawn the user-defined record processor script/program as a sub-process. The\n*MultiLangDaemon* communicates with this sub-process over standard input/output using a simple\nprotocol, and therefore the record processor script/program can be written in any language.\n\nAt runtime, there will always be a one-to-one correspondence between a record processor, a child process,\nand an [Amazon Kinesis Shard][amazon-kinesis-shard]. The *MultiLangDaemon* will make sure of\nthat, without any need for the developer to intervene.\n\nIn this release, we have abstracted these implementation details away and exposed an interface that enables\nyou to focus on writing record processing logic in Python. This approach enables [Amazon KCL][amazon-kcl] to\nbe language agnostic, while providing identical features and similar parallel processing model across\nall languages.\n\n## See Also\n* [Developing Consumer Applications for Amazon Kinesis Using the Amazon Kinesis Client Library][amazon-kcl]\n* The [Amazon KCL for Java][kinesis-github]\n* The [Amazon KCL for Ruby][amazon-kinesis-ruby-github]\n* The [Amazon Kinesis Documentation][amazon-kinesis-docs]\n* The [Amazon Kinesis Forum][kinesis-forum]\n\n## Release Notes\n### Release 1.2.0\n* Updated dependency to Amazon KCL version 1.6.1\n\n### Release 1.1.0 (January 27, 2015)\n* **Python 3 support** All Python files are compatible with Python 3\n\n### Release 1.0.0 (October 21, 2014)\n* **amazon_kclpy** module exposes an interface to allow implementation of record processor executables that are compatible with the MultiLangDaemon\n* **samples** module provides a sample putter application using [boto][boto] and a sample processing app using `amazon_kclpy`\n\n[amazon-kinesis-shard]: http://docs.aws.amazon.com/kinesis/latest/dev/key-concepts.html\n[amazon-kinesis-docs]: http://aws.amazon.com/documentation/kinesis/\n[amazon-kcl]: http://docs.aws.amazon.com/kinesis/latest/dev/kinesis-record-processor-app.html\n[multi-lang-daemon]: https://github.com/awslabs/amazon-kinesis-client/blob/master/src/main/java/com/amazonaws/services/kinesis/multilang/package-info.java\n[kinesis]: http://aws.amazon.com/kinesis\n[amazon-kinesis-ruby-github]: https://github.com/awslabs/amazon-kinesis-client-ruby\n[kinesis-github]: https://github.com/awslabs/amazon-kinesis-client\n[boto]: http://boto.readthedocs.org/en/latest/\n[DefaultAWSCredentialsProviderChain]: http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/auth/DefaultAWSCredentialsProviderChain.html\n[kinesis-forum]: http://developer.amazonwebservices.com/connect/forum.jspa?forumID=169\n",
        "url": "http://pypi.python.org/pypi/amazon_kclpy",
        "summary": "A python interface for the Amazon Kinesis Client Library MultiLangDaemon",
        "command": "pip install 'amazon_kclpy'"
      },
      "amazon-mws": {
        "name": "amazon-mws",
        "description": "# ** DISCLAIMER **\nThis API is in constant development. Do not rely on it too much until its in stable release.\nAll except for the last two APIs ( InboundShipment and OutboundShipment ) are complete.\nHelp towards completing this last two APIs would be greatly appreciated.\nI will mark this as stable 1.0 once all tests have been completed.\n\n# Python Amazon MWS\n\nPython Amazon MWS is a python interface for the Amazon MWS API.\nI wrote it to help me upload my products to amazon. However, seeing its potential i decided\nto expand it in order for it to cover most ( if not all ) operations in the Amazon MWS.\n\nThis is still an ongoing project. If you would like to contribute, see below :).\n\n\nIts based on the [amazon-mws-python](http://code.google.com/p/amazon-mws-python).\n\nCheckout the documentation [here](https://python-amazon-mws.readthedocs.org/latest/).\nYou can read the official Amazon MWS documentation [here](https://developer.amazonservices.com/).\n\n# To-Do\n\n* Improve README\n* Create tests\n* Finish InboundShipments & OutboundShipments APIs\n* Finish Docs\n\n# Contribute\n\nIf you like the project, please, contact me at commonzenpython@gmail.com (gtalk and email) and help me improve it.",
        "url": "http://pypi.python.org/pypi/amazon-mws",
        "summary": "A python interface for Amazon MWS",
        "command": "pip install 'amazon-mws'"
      },
      "amazons3": {
        "name": "amazons3",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/amazons3",
        "summary": "Django Storage Backend for Amazon S3.",
        "command": "pip install 'amazons3'"
      },
      "amazon_scraper": {
        "name": "amazon_scraper",
        "description": "==============\nAmazon Scraper\n==============\n\nA Hybrid Web scraper / API client. Supplements the standard Amazon API with web\nscraping functionality to get extra data. Specifically, product reviews.\n\nUses the `Amazon Simple Product API <https://pypi.python.org/pypi/python-amazon-simple-product-api/>`_\nto provide API accessible data. API search functions are imported directly into\nthe amazon_scraper module.\n\nParameters are in the same style as the Amazon Simple Product API, which in\nturn uses Bottlenose style parameters. Hence the non-Pythonic parameter names (ItemId).\n\n\nThe AmazonScraper constructor will pass 'args' and 'kwargs' to `Bottlenose <https://github.com/lionheart/bottlenose>`_ (via Amazon Simple Product API).\nBottlenose supports AWS regions, queries per second limiting, query caching and other nice features. Please view Bottlenose' API for more information on this.\n\nThe latest version of python-amazon-simple-product-api (1.5.0 at time of writing), doesn't support these arguemnts, only Region.\nIf you require these, please use the latest code from their repository with the following command::\n\n    pip install git+https://github.com/yoavaviram/python-amazon-simple-product-api.git#egg=python-amazon-simple-product-api\n\n\nCaveat\n======\n\nAmazon continually try and keep scrapers from working, they do this by:\n\n* A/B testing (randomly receive different HTML).\n* Huge numbers of HTML layouts for the same product categories.\n* Changing HTML layouts.\n* Moving content inside iFrames.\n\nAmazon have resorted to moving more and more content into iFrames which this scraper can't handle.\nI envisage a time where most data will be inaccessible without more complex logic.\n\nI've spent a long time trying to get these scrapers working and it's a never ending battle.\nI don't have the time to continually keep up the pace with Amazon.\nIf you are interested in improving Amazon Scraper, please let me know (creating an issue is fine).\nAny help is appreciated.\n\n\nInstallation\n============\n\n::\n\n    pip install amazon_scraper\n\n\nDependencies\n============\n\n* `python-amazon-simple-product-api <https://pypi.python.org/pypi/python-amazon-simple-product-api/>`_\n* `requests <http://docs.python-requests.org/en/latest/>`_\n* `beautifulsoup4 <http://www.crummy.com/software/BeautifulSoup/>`_\n* `xmltodict <https://github.com/martinblech/xmltodict>`_\n* `python-dateutil <https://dateutil.readthedocs.org/en/latest/>`_\n\n\nExamples\n========\n\nAll Products All The Time\n~~~~~~~~~~~~~~~~~~~~~~~~~\nCreate an API instance::\n\n    >>> from amazon_scraper import AmazonScraper\n    >>> amzn = AmazonScraper(\"put your access key\", \"secret key\", \"and associate tag here\")\n\n\nThe creation function accepts 'kwargs' which are passed to 'bottlenose.Amazon' constructor::\n\n    >>> from amazon_scraper import AmazonScraper\n    >>> amzn = AmazonScraper(\"put your access key\", \"secret key\", \"and associate tag here\", Region='UK', MaxQPS=0.9, Timeout=5.0)\n\n\nSearch::\n\n    >>> from __future__ import print_function\n    >>> import itertools\n    >>> for p in itertools.islice(amzn.search(Keywords='python', SearchIndex='Books'), 5):\n    >>>     print(p.title)\n    Learning Python, 5th Edition\n    Python Programming: An Introduction to Computer Science 2nd Edition\n    Python In A Day: Learn The Basics, Learn It Quick, Start Coding Fast (In A Day Books) (Volume 1)\n    Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython\n    Python Cookbook\n\n\nLookup by ASIN/ItemId::\n\n    >>> p = amzn.lookup(ItemId='B00FLIJJSA')\n    >>> p.title\n    Kindle, Wi-Fi, 6\" E Ink Display - for international shipment\n    >>> p.url\n    http://www.amazon.com/Kindle-Wi-Fi-Ink-Display-international/dp/B0051QVF7A/ref=cm_cr_pr_product_top\n\n\nBatch Lookups::\n\n    >>> for p in amzn.lookup(ItemId='B0051QVF7A,B007HCCNJU,B00BTI6HBS'):\n    >>>     print(p.title)\n    Kindle, Wi-Fi, 6\" E Ink Display - for international shipment\n    Kindle, 6\" E Ink Display, Wi-Fi - Includes Special Offers (Black)\n    Kindle Paperwhite 3G, 6\" High Resolution Display with Next-Gen Built-in Light, Free 3G + Wi-Fi - Includes Special Offers\n\n\nBy URL::\n\n    >>> p = amzn.lookup(URL='http://www.amazon.com/Kindle-Wi-Fi-Ink-Display-international/dp/B0051QVF7A/ref=cm_cr_pr_product_top')\n    >>> p.title\n    Kindle, Wi-Fi, 6\" E Ink Display - for international shipment\n    >>> p.asin\n    B0051QVF7A\n\n\nProduct Ratings::\n\n    >>> p = amzn.lookup(ItemId='B00FLIJJSA')\n    >>> p.ratings\n    [8, 4, 6, 4, 13]\n\n\nAlternative Bindings::\n\n    >>> p = amzn.lookup(ItemId='B000GRFTPS')\n    >>> p.alternatives\n    ['B00IVM5X7E', '9163192993', '0899669433', 'B00IPXPQ9O', '1482998742', '0441444814', '1497344824']\n    >>> for asin in p.alternatives:\n    >>>     alt = amzn.lookup(ItemId=asin)\n    >>>     print(alt.title, alt.binding)\n    The King in Yellow Kindle Edition\n    The King in Yellow Unknown Binding\n    King in Yellow Hardcover\n    The Yellow Sign Audible Audio Edition\n    The King in Yellow MP3 CD\n    THE KING IN YELLOW Mass Market Paperback\n    The King in Yellow Paperback\n\n\nSupplemental text not available via the API::\n\n    >>> p = amzn.lookup(ItemId='0441016685')\n    >>> p.supplemental_text\n    [u\"Bob Howard is a computer-hacker desk jockey ... \", u\"Lovecraft\\'s Cthulhu meets Len Deighton\\'s spies ... \", u\"This dark, funny blend of SF and ... \"]\n\n\nReview API\n~~~~~~~~~~\nView lists of reviews::\n\n    >>> p = amzn.lookup(ItemId='B0051QVF7A')\n    >>> rs = p.reviews()\n    >>> rs.asin\n    B0051QVF7A\n    >>> # print the reviews on this first page\n    >>> rs.ids\n    ['R3MF0NIRI3BT1E', 'R3N2XPJT4I1XTI', 'RWG7OQ5NMGUMW', 'R1FKKJWTJC4EAP', 'RR8NWZ0IXWX7K', 'R32AU655LW6HPU', 'R33XK7OO7TO68E', 'R3NJRC6XH88RBR', 'R21JS32BNNQ82O', 'R2C9KPSEH78IF7']\n    >>> rs.url\n    http://www.amazon.com/product-reviews/B0051QVF7A/ref=cm_cr_pr_top_sort_recent?&sortBy=bySubmissionDateDescending\n    >>> # by iterating over the reviews object we get access to reviews on ALL pages\n    >>> for r in rs.brief_reviews:\n    >>>     print(r.id)\n    'R3MF0NIRI3BT1E'\n    'R3N2XPJT4I1XTI'\n    'RWG7OQ5NMGUMW'\n    ...\n\nView detailed reviews::\n    >>> rs = amzn.reviews(ItemId='B0051QVF7A')\n    >>> for r in rs.full_reviews():\n    >>>     print(r.id)\n    'R3MF0NIRI3BT1E'\n    'R3N2XPJT4I1XTI'\n    'RWG7OQ5NMGUMW'\n    ...\n\nQuickly get a list of all reviews on a review page using the `all_reviews` property.\nThis uses the brief reviews provided on the review page to avoid downloading each review separately. As such, some information\nmay not be accessible::\n\n    >>> p = amzn.lookup(ItemId='B0051QVF7A')\n    >>> rs = p.reviews()\n    >>> all_reviews_on_page = list(rs)\n    >>> len(all_reviews_on_page)\n    10\n    >>> r = all_reviews_on_page[0]\n    >>> r.title\n    'Fantastic device - pick your Kindle!'\n    >>> fr = r.full_review()\n    >>> fr.title\n    'Fantastic device - pick your Kindle!'\n\nBy ASIN/ItemId::\n\n    >>> rs = amzn.reviews(ItemId='B0051QVF7A')\n    >>> rs.asin\n    B0051QVF7A\n    >>> rs.ids\n    ['R3MF0NIRI3BT1E', 'R3N2XPJT4I1XTI', 'RWG7OQ5NMGUMW', 'R1FKKJWTJC4EAP', 'RR8NWZ0IXWX7K', 'R32AU655LW6HPU', 'R33XK7OO7TO68E', 'R3NJRC6XH88RBR', 'R21JS32BNNQ82O', 'R2C9KPSEH78IF7']\n\n\nFor individual reviews use the `review` method::\n\n    >>> review_id = 'R3MF0NIRI3BT1E'\n    >>> r = amzn.review(Id=review_id)\n    >>> r.id\n    R3MF0NIRI3BT1E\n    >>> r.asin\n    B00492CIC8\n    >>> r.url\n    http://www.amazon.com/review/R3MF0NIRI3BT1E\n    >>> r.date\n    2011-09-29 18:27:14+00:00\n    >>> r.author\n    FreeSpirit\n    >>> r.text\n    Having been a little overwhelmed by the choices between all the new Kindles ... <snip>\n\n\nBy URL::\n\n    >>> r = amzn.review(URL='http://www.amazon.com/review/R3MF0NIRI3BT1E')\n    >>> r.id\n    R3MF0NIRI3BT1E\n\n\nUser Reviews API\n~~~~~~~~~~~~~~~~~~\nThis package also supports getting reviews written by a specific user.\n\nGet reviews that a single author has created::\n\n    >>> ur = amzn.user_reviews(Id=\"A2W0GY64CJSV5D\")\n    >>> ur.brief_reviews\n    >>> ur.name\n    >>> fr = list(ur.brief_reviews)[0].full_review()\n\n\nGet reviews for a user, from a review object\n\n    >>> r = amzn.review(Id=\"R3MF0NIRI3BT1E\")\n    >>> # we can get the reviews directly, or via the API with a URL or ID\n    >>> ur = r.user_reviews()\n    >>> ur = amzn.user_reviews(URL=r.author_reviews_url)\n    >>> ur = amzn.user_reviews(Id=r.author_id)\n    >>> ur.brief_reviews\n    >>> ur.name\n\n\nIterate over the current page's reviews::\n\n    >>> ur = amzn.user_reviews(Id=\"A2W0GY64CJSV5D\")\n    >>> for r in ur.brief_reviews:\n    >>>     print(r.id)\n\n\nIterate over all author reviews::\n\n    >>> ur = amzn.user_reviews(Id=\"A2W0GY64CJSV5D\")\n    >>> for r in ur:\n    >>>     print(r.id)\n\n\n\nAuthors\n=======\n\n * `Adam Griffiths <https://github.com/adamlwgriffiths>`_\n * `Greg Rehm <https://github.com/hahnicity>`_",
        "url": "http://pypi.python.org/pypi/amazon_scraper",
        "summary": "Provides content not accessible through the standard Amazon API",
        "command": "pip install 'amazon_scraper'"
      },
      "amazonwishlist": {
        "name": "amazonwishlist",
        "description": "Amazon Wishlist\n===============\nPython improved version of the old, buggy Perl module WWW::Amazon::Wishlist.\n\nAmazon-Wishlist lets you retrieve all information of your wishlist from Amazon stores which have that feature (stores which are Kindle-only do not). It comes with two sample applications to search and list data. It's also quite useful if you want to know the total cost of your Amazon wishlist. It's written using LXML and XPaths for better speed and readability.\n\nCurrently supported Amazon stores:\n* United States\n* United Kingdom\n* Canada\n* France\n* Spain\n* Italy\n* Germany\n* Japan\n* China\n* India\n* Mexico (not live, Kindle-only)\n* Brazil (not live, Kindle-only)\n\nThis is my first attempt in writing a Python module so bear with me as you find something not really looking pythonic. Patches are welcome in that sense!\n\nUsage\n=====\n\nIt's a simple module and the code documention is self-explanatory. Take a look at the test application `basin.py` at https://github.com/caio1982/amazon-basin. You may also try the sample applications shipped with the module, namely `profile.py` and `search.py`, both in the binaries directory.\n\nAlso you can try the built-in documentation with `python -c 'from amazonwish import amazonwish; help(amazonwish)'`.\n\nTODO\n====\n\n* Real preventive error handling, that's web scrapping dude\n* Write more py.test codes, specially for non-US stores and Unicode checks\n* Get item titles even though they are not available (XPath bug?)\n\nLicense\n=======\n\nAll files in this repository are under GPLv2, please see the LICENSE file for details.",
        "url": "http://pypi.python.org/pypi/amazonwishlist",
        "summary": "Query and visualize Amazon wishlists information (e.g. total cost, items etc)",
        "command": "pip install 'amazonwishlist'"
      },
      "ambari_client": {
        "name": "ambari_client",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/ambari_client",
        "summary": "Ambari python REST API client",
        "command": "pip install 'ambari_client'"
      },
      "amber": {
        "name": "amber",
        "description": "Amber\n=====\n\nAmber is a python library that provides object orientated interface to REST APIs like Tastypie.\n\nGetting Help\n============\n\n`Read the Docs <http://readthedocs.org/docs/amber/en/latest/>`_\n\nInstallation\n============\n\n    ``$ pip install amber``\n\nRequirements\n============\n\nAmber requires the following modules.\n\n* Python 2.5+\n* requests\n* simplejson (If using Python 2.5, or you desire the speedups for JSON serialization)",
        "url": "http://pypi.python.org/pypi/amber",
        "summary": "A library that makes using REST API easer.",
        "command": "pip install 'amber'"
      },
      "amber-python-clients": {
        "name": "amber-python-clients",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/amber-python-clients",
        "summary": "Amber clients in python",
        "command": "pip install 'amber-python-clients'"
      },
      "amber-python-common": {
        "name": "amber-python-common",
        "description": "UNKNOWN",
        "url": "http://pypi.python.org/pypi/amber-python-common",
        "summary": "Amber clients in python",
        "command": "pip install 'amber-python-common'"
      },
      "amber-python-drivers": {
        "name": "amber-python-drivers",
        "command": "pip install 'amber-python-drivers'"
      },
      "ambhas": {
        "name": "ambhas",
        "description": "ambhas\n+++++++\n\n.. contents ::\n\nInstalling ambhas\n======================\n\nInstalling ambhas can be done by downloading source file (ambhas--<version>.tar.gz),\nand after unpacking issuing the command::\n\n    python setup.py install\n\nThis requires the usual Distutils options available.\n\nOr, download the ambhas--<version>.tar.gz file and issue the command::\n    \n   pip install /path/to/ambhas--<version>.tar.gz\n\nOr, directly using the pip::\n\n   pip install ambhas   \n\nUsage\n=========\nImport required modules::\n\n    import numpy as np\n    from ambhas.errlib import rmse, correlation\n\nGenerate some random numbers::\n\n    x = np.random.normal(size=100)\n    y = np.random.normal(size=100)\n    rmse(x,y)\n    correlation(x,y)\n\nFor using the copula, import copula::\n\n    import numpy as np\n    from ambhas.copula import Copula\n\nGenerate some random numbers::\n\n    x = np.random.normal(size=100)\n    y = np.random.normal(size=100)\n\nGenerate an instance of class copula::\n\n    foo = Copula(x, y, 'frank')\n\nNow, generate some ensemble using this instance::\n\n    u,v = foo.generate(100)\n\n\nAuthor\n======\n\n`Sat Kumar Tomer <http://ambhas.com/>`_ satkumartomer at gmail dot com\n\n\nChanges\n=======\n\n0.1.0 \n* Initial version\n\n0.1.1\n* Minor corrections in setup.py files\n\n0.2.0\n* few packages added\n\n0.3.0\n* groundwater, sun_rise_set, soil texture module, etc. added\n\n0.3.1\n* manifest.in file edited\n\n0.4.0\nextract_gis_data, richards, risat added\n\n\nLicense\n========\nPlease read LICENSE.text available with the library.\n\nDownload\n========",
        "url": "http://pypi.python.org/pypi/ambhas",
        "summary": "A library devloped under the project AMBHAS",
        "command": "pip install 'ambhas'"
      },
      "affine": {
        "name": "affine",
        "description": "Affine\n======\n\nMatrices describing affine transformation of the plane.\n\n.. image:: https://travis-ci.org/sgillies/affine.svg?branch=master\n    :target: https://travis-ci.org/sgillies/affine\n\n.. image:: https://coveralls.io/repos/sgillies/affine/badge.svg\n    :target: https://coveralls.io/r/sgillies/affine\n\nThe Affine package is derived from Casey Duncan's Planar package. Please see\nthe copyright statement in `affine/__init__.py <affine/__init__.py>`__.\n\nUsage\n-----\n\nThe 3x3 augmented affine transformation matrix for transformations in two\ndimensions is illustrated below.\n\n.. ::\n\n  | x' |   | a  b  c | | x |\n  | y' | = | d  e  f | | y |\n  | 1  |   | 0  0  1 | | 1 |\n\nMatrices can be created by passing the values ``a, b, c, d, e, f`` to the\n``affine.Affine`` constructor or by using its ``identity()``,\n``translation()``, ``scale()``, ``shear()``, and ``rotation()`` class methods.\n\n.. code-block:: pycon\n\n  >>> from affine import Affine\n  >>> Affine.identity()\n  Affine(1.0, 0.0, 0.0,\n         0.0, 1.0, 0.0)\n  >>> Affine.translation(1.0, 5.0)\n  Affine(1.0, 0.0, 1.0,\n         0.0, 1.0, 5.0)\n  >>> Affine.scale(2.0)\n  Affine(2.0, 0.0, 0.0,\n         0.0, 2.0, 0.0)\n  >>> Affine.shear(45.0, 45.0)  # decimal degrees\n  Affine(1.0, 0.9999999999999999, 0.0,\n         0.9999999999999999, 1.0, 0.0)\n  >>> Affine.rotation(45.0)     # decimal degrees\n  Affine(0.7071067811865476, 0.7071067811865475, 0.0,\n         -0.7071067811865475, 0.7071067811865476, 0.0)\n\nThese matrices can be applied to ``(x, y)`` tuples to obtain transformed\ncoordinates ``(x', y')``.\n\n.. code-block:: pycon\n\n  >>> Affine.translation(1.0, 5.0) * (1.0, 1.0)\n  (2.0, 6.0)\n  >>> Affine.rotation(45.0) * (1.0, 1.0)\n  (1.1102230246251565e-16, 1.414213562373095)\n\nThey may also be multiplied together to combine transformations.\n\n.. code-block:: pycon\n\n  >>> Affine.translation(1.0, 5.0) * Affine.rotation(45.0)\n  Affine(0.7071067811865476, 0.7071067811865475, 1.0,\n         -0.7071067811865475, 0.7071067811865476, 5.0)\n\nUsage with GIS data packages\n----------------------------\n\nGeoreferenced raster datasets use affine transformations to map from image\ncoordinates to world coordinates. The ``affine.Affine.from_gdal()`` class\nmethod helps convert `GDAL GeoTransform\n<http://www.gdal.org/classGDALDataset.html#af9593cc241e7d140f5f3c4798a43a668>`__,\nsequences of 6 numbers in which the first and fourth are the x and y offsets\nand the second and sixth are the x and y pixel sizes.\n\nUsing a GDAL dataset transformation matrix, the world coordinates ``(x, y)``\ncorresponding to the top left corner of the pixel 100 rows down from the\norigin can be easily computed.\n\n.. code-block:: pycon\n\n  >>> geotransform = (-237481.5, 425.0, 0.0, 237536.4, 0.0, -425.0)\n  >>> fwd = Affine.from_gdal(*geotransform)\n  >>> col, row = 0, 100\n  >>> fwd * (col, row)\n  (-237481.5, 195036.4)\n\nThe reverse transformation is obtained using the ``~`` operator.\n\n.. code-block:: pycon\n\n  >>> rev = ~fwd\n  >>> rev * fwd * (col, row)\n  (0.0, 99.99999999999999)",
        "url": "http://pypi.python.org/pypi/affine",
        "summary": "Matrices describing affine transformation of the plane",
        "command": "conda install -y affine"
      },
      "alabaster": {
        "name": "alabaster",
        "description": "=========================\nAlabaster: a Sphinx theme\n=========================\n\nThis theme is a modified \"Kr\" Sphinx theme from @kennethreitz (especially as\nused in his `Requests <https://python-requests.org>`_ project), which was\nitself originally based on @mitsuhiko's theme used for `Flask\n<http://flask.pocoo.org/>`_ & related projects.\n\nLive examples of this theme can be seen on `paramiko.org\n<http://paramiko.org>`_, `fabfile.org <http://fabfile.org>`_ and `pyinvoke.org\n<http://pyinvoke.org>`_.\n\nA changelog_ can be found at the bottom of this page.\n\nAlabaster is Python 2+3 compatible.\n\n\nFeatures\n========\n\nSpecifically, as compared to Kenneth's theme:\n\n* Easy ability to install/use as a Python package (tip o' the hat to `Dave &\n  Eric's sphinx_rtd_theme <https://github.com/snide/sphinx_rtd_theme>`_ for\n  showing the way);\n* Style tweaks, such as better code-block alignment, Gratipay and Github button\n  placement, page source link moved to footer, improved (optional)\n  related-items sidebar item, etc;\n* Many customization hooks, including toggle of various sidebar & footer\n  components; header/link/etc color control; etc;\n* Improved documentation for all customizations (pre-existing & new).\n\n\nInstallation\n============\n\nThe bare minimum required to install is as follows:\n\n#. ``pip install alabaster`` (or equivalent).\n#. Enable the 'alabaster' theme, mini-extension, and sidebar templates in your\n   ``conf.py``:\n\n   .. code-block:: python\n\n        import alabaster\n\n        html_theme_path = [alabaster.get_path()]\n        extensions = ['alabaster']\n        html_theme = 'alabaster'\n        html_sidebars = {\n            '**': [\n                'about.html',\n                'navigation.html',\n                'relations.html',\n                'searchbox.html',\n                'donate.html',\n            ]\n        }\n\nThat's it! You now have the standard Alabaster theme set up. Read on for more\nconfiguration options/concerns.\n\nTheme location\n--------------\n\nThe function ``alabaster.get_path`` dynamically returns Alabaster's install\nlocation, ensuring that Sphinx can find and load it regardless of where/how\nyou installed Alabaster. Using it is highly recommended.\n\nIf you've manually installed Alabaster and/or are doing funky things to your\nPYTHONPATH, you may need to replace the ``alabaster.get_path()`` call with your\nown explicit string, as per `the Sphinx config docs\n<http://sphinx-doc.org/config.html#confval-html_theme_path>`_.\n\nSidebars\n--------\n\nFeel free to adjust ``html_sidebars`` as desired - the theme is designed\nassuming you'll always have ``about.html`` activated, but otherwise it doesn't\ncare much.\n\n* See `the Sphinx docs\n  <http://sphinx-doc.org/config.html#confval-html_sidebars>`_ for details on\n  how this setting behaves.\n* Alabaster provides ``about.html`` (logo, github button + blurb),\n  ``donate.html`` (Gratipay blurb/button) and ``navigation.html`` (a more\n  flexible version of the builtin ``localtoc``/``globaltoc`` templates).\n  ``searchbox.html`` comes with Sphinx itself.\n\nImages\n------\n\nIf you're using either of the image-related options outlined below (``logo`` or\n``touch-icon``), you'll also want to tell Sphinx where to get your images from.\nIf so, add a line like this (changing the path if necessary; see `the Sphinx\ndocs for 'html_static_path'\n<http://sphinx-doc.org/config.html?highlight=static#confval-html_static_path>`_):\n\n.. code-block:: python\n\n    html_static_path = ['_static']\n\n\nTheme options\n=============\n\nAlabaster's primary configuration route is the ``html_theme_options`` variable,\nset in ``conf.py`` alongside the rest. A brief example (*note*: snippet doesn't\ninclude all possible options, see following list!):\n\n.. code-block:: python\n\n    html_theme_options = {\n        'logo': 'logo.png',\n        'github_user': 'bitprophet',\n        'github_repo': 'alabaster',\n    }\n\nVariables and feature toggles\n-----------------------------\n\n* ``logo``: Relative path (from ``$PROJECT/_static/``) to a logo image, which\n  will appear in the upper left corner above the name of the project.\n\n  * If ``logo`` is not set, your ``project`` name setting (from the top\n    level Sphinx config) will be used in a text header instead. This\n    preserves a link back to your homepage from inner doc pages.\n\n* ``logo_name``: Set to ``true`` to insert your site's ``project`` name\n  under the logo image as text. Useful if your logo doesn't include the\n  project name itself. Defaults to ``false``.\n* ``logo_text_align``: Which CSS ``text-align`` value to use for logo text\n  (if there is any.)\n* ``description``: Text blurb about your project, to appear under the logo.\n* ``description_font_style``: Which CSS ``font-style`` to use for description\n  text. Defaults to ``normal``.\n* ``github_user``, ``github_repo``: Used by ``github_button`` and ``github_banner``\n  (see below); does nothing if both of those are set to ``false``.\n* ``github_button``: ``true`` or ``false`` (default: ``true``) - whether to link to\n  your Github.\n\n   * If ``true``, requires that you set ``github_user`` and ``github_repo``.\n   * See also these other related options, which behave as described in\n     `Github Buttons' README\n     <https://github.com/mdo/github-buttons#usage>`_:\n\n      * ``github_button_type``: Defaults to ``watch``.\n      * ``github_button_count``: Defaults to ``true``.\n\n* ``github_banner``: ``true`` or ``false`` (default: ``false``) - whether to\n  apply a 'Fork me on Github' banner in the top right corner of the page.\n\n   * If ``true``, requires that you set ``github_user`` and ``github_repo``.\n   * May also submit a string file path (as with ``logo``, relative to\n     ``$PROJECT/_static/``) to be used as the banner image instead of the\n     default.\n\n* ``travis_button``: ``true``, ``false`` or a Github-style\n  ``\"account/repo\"`` string - used to display a Travis-CI build status\n  button in the sidebar. If ``true``, uses your ``github_(user|repo)``\n  settings; defaults to ``false.``\n* ``gratipay_user``: Set to your `Gratipay <https://gratipay.com>`_ username\n  if you want a Gratipay 'Donate' section in your sidebar.\n\n  * This used to be ``gittip_user`` before that service changed its name to\n    Gratipay; we've left the old setting in place as an alias for backwards\n    compatibility reasons. It may be removed in the future.\n  * If both options are given, ``gratipay_user`` wins.\n\n* ``analytics_id``: Set to your `Google Analytics\n  <http://www.google.com/analytics/>`_ ID (e.g. ``UA-#######-##``) to enable\n  tracking.\n* ``touch_icon``: Path to an image (as with ``logo``, relative to\n  ``$PROJECT/_static/``) to be used for an iOS application icon, for when\n  pages are saved to an iOS device's home screen via Safari.\n* ``extra_nav_links``: Dictionary mapping link names to link targets; these\n  will be added in a UL below the main sidebar navigation (provided you've\n  enabled ``navigation.html``.) Useful for static links outside your Sphinx\n  doctree.\n* ``sidebar_includehidden``: Boolean determining whether the TOC sidebar\n  should include hidden Sphinx toctree elements. Defaults to ``true`` so you\n  can use ``:hidden:`` in your index page's root toctree & avoid having 2x\n  copies of your navigation on your landing page.\n* ``show_powered_by``: Boolean controlling display of the ``Powered by\n  Sphinx N.N.N. & Alabaster M.M.M`` section of the footer. When ``true``, is\n  displayed next to the copyright information; when ``false``, is hidden.\n* ``show_related``: Boolean controlling whether the 'next/previous/related'\n  secondary navigation elements are hidden or displayed. Defaults to ``false``\n  since on many sites these elements are superfluous.\n* ``page_width``: CSS width specifier controlling default content/page width.\n  Defaults to ``940px``.\n* ``sidebar_width``: CSS width specifier controlling default sidebar width.\n  Defaults to ``220px``.\n\nStyle colors\n------------\n\nThese should be fully qualified CSS color specifiers such as ``#004B6B`` or\n``#444``. The first few items in the list are \"global\" colors used as defaults\nfor many of the others; update these to make sweeping changes to the\ncolorscheme. The more granular settings can be used to override as needed.\n\n* ``gray_1``: Dark gray.\n* ``gray_2``: Light gray.\n* ``gray_3``: Medium gray.\n* ``pink_1``: Light pink.\n* ``pink_2``: Medium pink.\n* ``body_text``: Main content text.\n* ``footer_text``: Footer text (includes links.)\n* ``link``: Non-hovered body links.\n* ``link_hover``: Body links, hovered.\n* ``sidebar_header``: Sidebar headers. Defaults to ``gray_1``.\n* ``sidebar_text``: Sidebar paragraph text.\n* ``sidebar_link``: Sidebar links (there is no hover variant.) Applies to\n  both header & text links. Defaults to ``gray_1``.\n* ``sidebar_link_underscore``: Sidebar links' underline (technically a\n  bottom-border).\n* ``sidebar_search_button``: Background color of the search field's 'Go'\n  button.\n* ``sidebar_list``: Foreground color of sidebar list bullets & unlinked text.\n* ``sidebar_hr``: Color of sidebar horizontal rule dividers. Defaults to\n  ``gray_3``.\n* ``anchor``: Foreground color of section anchor links (the 'paragraph'\n  symbol that shows up when you mouseover page section headers.)\n* ``anchor_hover_fg``: Foreground color of section anchor links (as above)\n  when moused over. Defaults to ``gray_1``.\n* ``anchor_hover_bg``: Background color of above.\n* ``note_bg``: Background of ``.. note::`` blocks. Defaults to ``gray_2``.\n* ``note_border``: Border of same.\n* ``seealso_bg``: Background of ``.. seealso::`` blocks. Defaults to\n  ``gray_2``.\n* ``seealso_border``: Border of same.\n* ``warn_bg``: Background of ``.. warn::`` blocks. Defaults to ``pink_1``.\n* ``warn_border``: Border of same. Defaults to ``pink_2``.\n* ``footnote_bg``: Background of footnote blocks.\n* ``footnote_border``: Border of same. Defaults to ``gray_2``.\n* ``pre_bg``: Background of preformatted text blocks (including code\n  snippets.) Defaults to ``gray_2``.\n* ``narrow_sidebar_bg``: Background of 'sidebar' when narrow window forces\n  it to the bottom of the page.\n* ``narrow_sidebar_fg``: Text color of same.\n* ``narrow_sidebar_link``: Link color of same. Defaults to ``gray_3``.\n* ``code_highlight``: Color of highlight when using ``:emphasize-lines:`` in a code block.\n\nFonts\n-----\n\n* ``font_family``: Font family of body text.  Defaults to ``'goudy old style',\n  'minion pro', 'bell mt', Georgia, 'Hiragino Mincho Pro', serif``.\n* ``head_font_family``: Font family of headings.  Defaults to ``'Garamond',\n  'Georgia', serif``.\n* ``code_font_size``: Font size of code block text. Defaults to ``0.9em``.\n* ``code_font_family``: Font family of code block text. Defaults to\n  ``'Consolas', 'Menlo', 'Deja Vu Sans Mono', 'Bitstream Vera Sans Mono',\n  monospace``.\n\n\nAdditional info / background\n============================\n\n* `Fabric #419 <https://github.com/fabric/fabric/issues/419>`_ contains a lot of\n  general exposition & thoughts as I developed Alabaster, specifically with a\n  mind towards using it on two nearly identical 'sister' sites (single-version\n  www 'info' site & versioned API docs site).\n* Alabaster includes/requires a tiny Sphinx extension on top of the theme\n  itself; this is just so we can inject dynamic metadata (like Alabaster's own\n  version number) into template contexts. It doesn't add any additional\n  directives or the like, at least not yet.\n\n\n.. _changelog:\n\nChangelog\n=========\n\n0.1.0 (2013-12-31)\n------------------\n\n* First tagged/PyPI'd version.\n\n0.2.0 (2014-01-28)\n------------------\n\n* Allow control of logo replacement text's alignment.\n* Add customized navigation sidebar element.\n* Tweak page margins a bit.\n* Add a 3rd level of medium-gray to the stylesheet & apply in a few places.\n\n0.3.0 (2014-02-03)\n------------------\n\n* Display Alabaster version in footers alongside Sphinx version. (This\n  necessitates using a mini Sphinx extension).\n* Other footer tweaks.\n\n0.3.1 (2014-03-13)\n------------------\n\n* Improved Python 3 compatibility.\n* Update styling of changelog pages generated by `bitprophet/releases\n  <https://github.com/bitprophet/releases>`_.\n\n0.4.0 (2014-04-06)\n------------------\n\n* Add an option to allow un-hiding one's toctree.\n\n0.4.1 (2014-04-06)\n------------------\n\n* Fix an inaccuracy in the descriptin of ``logo_text_align``.\n* Update logo & text styling to be more sensible.\n\n0.5.0 (2014-04-09)\n------------------\n\n* Add support for sidebar Travis status buttons.\n\n0.5.1 (2014-04-15)\n------------------\n\n* Fix a bug in the new Travis support, re: its default value.\n\n0.6.0 (2014-04-17)\n------------------\n\n* Allow hiding the 'powered by' section of the footer.\n* Fix outdated name in ``setup.py`` URL field.\n\n0.6.1 (2014-09-04)\n------------------\n\n* Update Gittip support to acknowledge the service's rename to Gratipay.\n\n0.6.2 (2014-11-25)\n------------------\n\n* Make ``.. warn::`` blocks have a pink background (instead of having no\n  background, which was apparently an oversight of the themes Alabaster is\n  based on) and also make that color configurable.\n\n0.7.1 (2015-02-27)\n------------------\n\n.. note::\n    There is no 0.7.0, there was some PyPI fun and replacing sdists isn't\n    permitted :)\n\n* Finally add a changelog. To the README, for now, because a full doc site\n  isn't worthwhile just yet.\n* Allow configuring a custom Github banner image (instead of simply toggling a\n  default on or off). Thanks to Nicola Iarocci for the original patch.\n* Explicitly note Python version support in the README and ``setup.py``.\n* Update Github button image link to use the newly-available HTTPS version of\n  the URL; this helps prevent errors on doc pages served via HTTPS. Thanks to\n  Gustavo Narea for the report.\n* Add control over the font size & family of code blocks. Credit to Steven\n  Loria.\n* Allow control over font family of body text and headings. Thanks to Georg\n  Brandl.\n* Stylize ``.. seealso::`` blocks same as ``.. note::`` blocks for\n  consistency's sake (previously, ``.. seealso::`` used the Sphinx default\n  styling, which clashed). We may update these again later but for now, this is\n  an improvement! Thanks again to Steven Loria.\n* Allow control over CSS ``font-style`` for the site description/tagline\n  element. Credit: Steven Loria.\n* Add styling to disable default cell borders on ``.. bibliography::``\n  directives' output. Thanks to Philippe Dessus for the report.\n\n0.7.2 (2015-03-10)\n------------------\n\n* Updated CSS stylesheets to apply monospace styling to both ``tt`` and\n  ``code`` elements, instead of just to ``tt``. This addresses a change in HTML\n  generation in Sphinx 1.3 while retaining support for Sphinx 1.2. Thanks to\n  Eric Holscher for the heads up.\n\n0.7.3 (2015-03-20)\n------------------\n\n* Hide ``shadow`` related styles on bibliography elements, in addition to the\n  earlier change re: ``border``. Thanks again to Philippe Dessus.\n\n0.7.4 (2015-05-03)\n------------------\n\n* Add ``code_highlight`` option (which includes general fixes to styling of\n  code blocks containing highlighted lines). Thanks to Steven Loria.\n\n0.7.5 (2015-06-15)\n------------------\n\n* Honor Sphinx's core ``html_show_copyright`` option when rendering page\n  footer. Thanks to Marcin Wojdyr for the report.\n* Pre-history versions of Alabaster attempted to remove the \"related\"\n  sub-navigation (typically found as next/previous links in other themes) but\n  this didn't work right for mobile-oriented styling.\n\n  This has been fixed by (re-)adding an improved sidebar nav element for these\n  links and making its display controllable via the new ``show_related`` theme\n  option (which defaults to ``false`` for backwards compatibility).\n\n  **NOTE**: to enable the related-links nav, you'll need to set\n  ``show_related`` to ``true`` **and** add ``relations.html`` to your\n  ``html_sidebars`` (we've updated the example config in this README to\n  indicate this for new installs).\n\n  Thanks to Tomi Pieviläinen for the bug report.\n* Update the \"Fork me on Github\" banner image to use an ``https://`` URI so\n  sites hosted over HTTPS don't encounter mixed-content errors. Thanks to\n  ``@nikolas`` for the patch.\n* Remove an orphaned ``</li>`` from the footer 'show source' section. Credit to\n  Marcin Wojdyr.\n\n0.7.6 (2015-06-22)\n------------------\n\n* Update how ``setup.py`` handles the ``README.rst`` file - load it explicitly\n  as UTF-8 so the changelog containing non-ASCII characters doesn't generate\n  ``UnicodeDecodeError`` in terminal environments whose default encoding is not\n  UTF-8 or other Unicode-compatible encodings. Thanks to Arun Persaud for the\n  report and Max Tepkeev for the suggested fix.\n* Fix left-margin & padding styling for code blocks within list-item elements,\n  making them consistent with earlier changes applied to top-level code blocks.\n* Expose page & sidebar widths as theme options ``page_width`` and\n  ``sidebar_width``. Their defaults are the same as the previously static\n  values.",
        "url": "http://pypi.python.org/pypi/alabaster",
        "summary": "A configurable sidebar-enabled Sphinx theme",
        "command": "conda install -y alabaster"
      }
    },
    "r": {}
  }
}